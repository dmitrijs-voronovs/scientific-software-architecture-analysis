id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:293,Availability,avail,available,293,"# Cromwell Change Log. ## 88 Release Notes. ### New feature: Prevent Job start during Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:756,Availability,failure,failure,756,"# Cromwell Change Log. ## 88 Release Notes. ### New feature: Prevent Job start during Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1235,Availability,recover,recover,1235,"austion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1513,Availability,error,error,1513,"s://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1546,Availability,error,error,1546,"s://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1631,Availability,error,error,1631," Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is availa",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2504,Availability,error,errors,2504,"riate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance o",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2640,Availability,avail,available,2640,"er potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2751,Availability,error,errors,2751," Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` ad",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2773,Availability,error,error,2773," Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` ad",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2792,Availability,avail,available,2792," Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` ad",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4869,Availability,avail,availability,4869,"tion Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progres",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:8676,Availability,down,downloads,8676,"ance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinsti",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9130,Availability,error,error,9130," |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9629,Availability,error,error,9629,"or call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker m",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10186,Availability,error,error,10186," ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""re",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10367,Availability,down,downloads,10367,"ll/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""retry with more memory"" behavior. Cromwell will now retry a task with more memory after it fails with return code 137, provided all; the other requirements for retrying with more memory are met. ### DRS Improvements. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10717,Availability,error,error,10717,"cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""retry with more memory"" behavior. Cromwell will now retry a task with more memory after it fails with return code 137, provided all; the other requirements for retrying with more memory are met. ### DRS Improvements. #### Support for invoking `CromwellDRSLocalizer` with manifest file. `CromwellDRSLocalizer` can now handle multiple file localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the prog",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12093,Availability,failure,failures,12093,"KFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""retry with more memory"" behavior. Cromwell will now retry a task with more memory after it fails with return code 137, provided all; the other requirements for retrying with more memory are met. ### DRS Improvements. #### Support for invoking `CromwellDRSLocalizer` with manifest file. `CromwellDRSLocalizer` can now handle multiple file localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the program exiting if any fail.; ```; java -jar /path/to/localizer.jar [options] -m /local/path/to/manifest/file.txt; ```. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for G",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12908,Availability,error,errors,12908,"lization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling use",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12999,Availability,error,error,12999,"lization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling use",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:14629,Availability,error,error,14629," to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25175,Availability,down,down,25175,"hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting funct",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25322,Availability,down,download,25322,"/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),;",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:26906,Availability,error,errors,26906,"point. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27730,Availability,error,error-keys,27730,"the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON dat",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27810,Availability,error,error-keys,27810," a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:28224,Availability,error,error,28224,"ning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Refer",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:28290,Availability,error,errors,28290,"configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29806,Availability,recover,recover,29806,"nwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog fac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29861,Availability,checkpoint,checkpoint,29861,"nwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog fac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34906,Availability,error,error,34906,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35095,Availability,error,error,35095,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35161,Availability,error,error,35161,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36325,Availability,avail,available,36325,"exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increa",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38110,Availability,downtime,downtime,38110," Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:41089,Availability,avail,available,41089,ffers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for more details. #### Adding support for Google Cloud Life Sciences v2beta; Cromwell now supports running workflows using Google Cloud Life Sciences v2beta API in addition to Google Cloud Genomics v2alpha1.; More information about migration to the new API from v2alpha1; [here](https://cromwell.readthedocs.io/en/stable/backends/Google#migration-from-google-cloud-genomics-v2alpha1-to-google-cloud-life-sciences-v2beta).; * **Note** Google Cloud Life Sciences is the new name for newer versions of Google Cloud Genomics.; * **Note** Support for Google Cloud Genomics v2alpha1 will be removed in a future version of Cromwell. Advance notice will be provided. ### New Docs. #### Installation methods. Links to the conda package and docker container are now available in; [the install documentation](https://cromwell.readthedocs.io/en/stable/Getting/). ### Bug Fixes. + Fix a bug where zip files with directories could not be imported.; For example a zip with `a.wdl` and `b.wdl` could be imported but one with `sub_workflows/a.wdl`; and `imports/b.wdl` could not.; + Fix a bug which sometimes allowed execution scripts copied by a failed cache-copy to be run instead; of the attempt-1 script for a live job execution. ## 48 Release Notes. ### Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#518,MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43708,Availability,error,error,43708,"figuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43820,Availability,error,error,43820,"re](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43850,Availability,error,error,43850,"re](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43985,Availability,error,error,43985,"/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45238,Availability,avail,available,45238,"tible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45642,Availability,failure,failures,45642,"puts improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45735,Availability,failure,failure,45735,"ndencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45944,Availability,failure,failure,45944,"s using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the tim",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46272,Availability,failure,failures,46272,"g`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migratio",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47239,Availability,downtime,downtime,47239,"s PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48269,Availability,avail,available,48269,"please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [he",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50543,Availability,error,errors,50543,"flow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52095,Availability,failure,failure,52095," to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52157,Availability,heartbeat,heartbeats,52157,"avase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52219,Availability,down,down,52219,"avase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52406,Availability,heartbeat,heartbeats,52406,"omwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52521,Availability,heartbeat,heartbeats,52521,"ree digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission ti",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52538,Availability,failure,failure-shutdown-duration,52538,"1-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. Thi",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53662,Availability,avail,available,53662,"runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54053,Availability,heartbeat,heartbeats,54053,"low job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54068,Availability,error,error,54068,".; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54126,Availability,heartbeat,heartbeats,54126,"gure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54137,Availability,heartbeat,heartbeat-interval,54137,"ckend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54196,Availability,heartbeat,heartbeats,54196,"f jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) Noop",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:55955,Availability,ping,ping-me-bucket,55955,"ard; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-name = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:56199,Availability,ping,ping-me-bucket,56199,"oopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-name = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was refe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:56892,Availability,error,error,56892,"me = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Sp",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57163,Availability,error,error,57163," }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58984,Availability,avail,available,58984,"rlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59198,Availability,error,errors,59198,"Factory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent sp",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60768,Availability,failure,failure-prefix-blacklisting,60768,"sion 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. T",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62151,Availability,alive,alive,62151,"shes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first wr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62741,Availability,error,error,62741,"token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata request",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63091,Availability,down,downloaded,63091,"; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release No",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63270,Availability,echo,echo,63270," endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63734,Availability,redundant,redundant,63734,"purious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63794,Availability,redundant,redundant,63794,"ll/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:66471,Availability,error,error,66471,"_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequences. ### Private Docker Support on Pipelines API v2. Support for private Docker Hub images is now included in the Google Pipelines API v2 backend. PAPI v2 private Docker support is; equivalent to that in PAPI v1 but the configuration differs, please see; [Docker configuration](http://cromwell.readthedocs.io/en/develop/filesystems/Google#Docker) for more de",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69141,Availability,avail,available,69141,"well now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; More information can be found at [REST API](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Query workflows by Submission time. Cromwell now supports querying workflows by submission time. This will help find workflows that are submitted but not started yet (i.e. workflows which are; in On Hold state). More information can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Submission time in Workflow Query Response. Submission time of a workflow is now included in WorkflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73433,Availability,avail,available,73433," contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made rela",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74106,Availability,avail,available,74106,"mal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81923,Availability,error,error,81923,"w authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82468,Availability,avail,available,82468,"hat right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurren",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82607,Availability,avail,available,82607,"ease see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](ht",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91552,Availability,avail,available,91552,"o specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are depre",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93369,Availability,failure,failure,93369,"s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93383,Availability,failure,failure,93383," Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the J",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93480,Availability,failure,failure,93480,"le service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota ava",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93530,Availability,failure,failures,93530," {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93815,Availability,failure,failure,93815,"es. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5;",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94461,Availability,avail,available,94461,"ld. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"":",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94600,Availability,avail,availble,94600,"e: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many va",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:108488,Availability,echo,echo,108488,"ackend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:579,Deployability,release,releases,579,"# Cromwell Change Log. ## 88 Release Notes. ### New feature: Prevent Job start during Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1051,Deployability,configurat,configuration,1051,"ring Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:3302,Deployability,install,installations,3302,"ket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4913,Deployability,configurat,configurations,4913,"tion Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progres",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:5443,Deployability,install,install,5443,"well's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using; WDL version `development-1.1`. As of Cromwell 87, `development-1.1` includes:; * Engine functions:; * Added `suffix` ([#7363](https://github.com/broadinstitute/cromwell/pull/7363)); * Added `unzip` ([#7363](https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwel",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:6751,Deployability,upgrade,upgrade,6751,"ed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using; WDL version `development-1.1`. As of Cromwell 87, `development-1.1` includes:; * Engine functions:; * Added `suffix` ([#7363](https://github.com/broadinstitute/cromwell/pull/7363)); * Added `unzip` ([#7363](https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; ref",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:6830,Deployability,upgrade,upgrade,6830,"mwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using; WDL version `development-1.1`. As of Cromwell 87, `development-1.1` includes:; * Engine functions:; * Added `suffix` ([#7363](https://github.com/broadinstitute/cromwell/pull/7363)); * Added `unzip` ([#7363](https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7098,Deployability,release,release,7098,"d `suffix` ([#7363](https://github.com/broadinstitute/cromwell/pull/7363)); * Added `unzip` ([#7363](https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast |",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7397,Deployability,release,release,7397,"ithub.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/pe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12433,Deployability,configurat,configuration,12433," localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the program exiting if any fail.; ```; java -jar /path/to/localizer.jar [options] -m /local/path/to/manifest/file.txt; ```. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12634,Deployability,release,release,12634,"n; sequence, with the program exiting if any fail.; ```; java -jar /path/to/localizer.jar [options] -m /local/path/to/manifest/file.txt; ```. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit mem",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12798,Deployability,release,release,12798,"``. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12856,Deployability,release,releases,12856," container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIA",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:14455,Deployability,configurat,configuration,14455,"ewer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented an",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:15410,Deployability,release,release,15410,"onfiguration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also be moved, implemented, and documented within Cromwell. As a result of this, we can safely remove; and deprecate the wes2cromwell project from the repo. Previous endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. Newly implemented endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |-----------------|; | GET | /api/ga4gh/wes/v1/runs | List workflows |; | POST | /api/ga4gh/wes/v1/runs | Submit workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id} | Workflow details |. ## 79 Release Notes. ### Last release with CWL support. Cromwell 79 is the last release with CWL. Support will be re",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:16370,Deployability,release,release,16370,"well repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also be moved, implemented, and documented within Cromwell. As a result of this, we can safely remove; and deprecate the wes2cromwell project from the repo. Previous endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. Newly implemented endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |-----------------|; | GET | /api/ga4gh/wes/v1/runs | List workflows |; | POST | /api/ga4gh/wes/v1/runs | Submit workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id} | Workflow details |. ## 79 Release Notes. ### Last release with CWL support. Cromwell 79 is the last release with CWL. Support will be removed in Cromwell 80 and above. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supporting-more-workflow-languages/) for details. | Product | Language | Support |; |-------------------------------------------|----------|-----------------------|; | Cromwell standalone | WDL | :white_check_mark: |; | Cromwell standalone | CWL | :x: |; | [Terra SaaS platform](https://terra.bio/) | WDL | :white_check_mark: |; | [Terra SaaS platform](https://terra.bio/) | CWL | Future support planned |. ### Last release with Alibaba Cloud. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) will be removed in version 80. ### WES endpoints preview. As a means to stay on top of endpoints within our repo, 3 new Workflow Executi",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:16420,Deployability,release,release,16420,"e, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also be moved, implemented, and documented within Cromwell. As a result of this, we can safely remove; and deprecate the wes2cromwell project from the repo. Previous endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. Newly implemented endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |-----------------|; | GET | /api/ga4gh/wes/v1/runs | List workflows |; | POST | /api/ga4gh/wes/v1/runs | Submit workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id} | Workflow details |. ## 79 Release Notes. ### Last release with CWL support. Cromwell 79 is the last release with CWL. Support will be removed in Cromwell 80 and above. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supporting-more-workflow-languages/) for details. | Product | Language | Support |; |-------------------------------------------|----------|-----------------------|; | Cromwell standalone | WDL | :white_check_mark: |; | Cromwell standalone | CWL | :x: |; | [Terra SaaS platform](https://terra.bio/) | WDL | :white_check_mark: |; | [Terra SaaS platform](https://terra.bio/) | CWL | Future support planned |. ### Last release with Alibaba Cloud. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) will be removed in version 80. ### WES endpoints preview. As a means to stay on top of endpoints within our repo, 3 new Workflow Execution Service (WES) endpoints are now doc",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:17141,Deployability,release,release,17141,"--- |-----------------|; | GET | /api/ga4gh/wes/v1/runs | List workflows |; | POST | /api/ga4gh/wes/v1/runs | Submit workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id} | Workflow details |. ## 79 Release Notes. ### Last release with CWL support. Cromwell 79 is the last release with CWL. Support will be removed in Cromwell 80 and above. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supporting-more-workflow-languages/) for details. | Product | Language | Support |; |-------------------------------------------|----------|-----------------------|; | Cromwell standalone | WDL | :white_check_mark: |; | Cromwell standalone | CWL | :x: |; | [Terra SaaS platform](https://terra.bio/) | WDL | :white_check_mark: |; | [Terra SaaS platform](https://terra.bio/) | CWL | Future support planned |. ### Last release with Alibaba Cloud. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) will be removed in version 80. ### WES endpoints preview. As a means to stay on top of endpoints within our repo, 3 new Workflow Execution Service (WES) endpoints are now documented in the Cromwell Swagger (others to follow as part of later work):. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. ### Scala 2.13. Cromwell is now built with Scala version 2.13. This change should not be noticeable to users but may be of interest to developers of Cromwell backend implementations. ### Bug Fixes. * Fixed a call caching bug in which an invalid cache entry could cause a valid cache entry to be ignored. ## 75 Release Notes. ### New `AwaitingCloudQuota` backend status. For C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:21311,Deployability,configurat,configuration,21311,"s than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22242,Deployability,configurat,configuration,22242,"efault unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22375,Deployability,update,updates,22375,"h CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism`",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22410,Deployability,configurat,configuration,22410,"itigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22628,Deployability,update,updates,22628,"1110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22708,Deployability,deploy,deployments,22708,"1110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22825,Deployability,configurat,configuration,22825,"al Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renam",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22965,Deployability,update,updated,22965,"ubnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (G",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23127,Deployability,configurat,configuration,23127,"the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23449,Deployability,configurat,configuration,23449,"in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23508,Deployability,configurat,configuration,23508,"ence.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome suppo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23849,Deployability,configurat,configuration,23849,"ced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24087,Deployability,configurat,configuration,24087," * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the AP",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24210,Deployability,configurat,configuration,24210,"eness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes suppor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25506,Deployability,release,release,25506,"ed. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-meta",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25578,Deployability,update,update,25578,"CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25814,Deployability,update,update,25814," support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be acce",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:26515,Deployability,configurat,configuration,26515,"drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ##",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27125,Deployability,configurat,configuration,27125,"arboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that cause",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27282,Deployability,configurat,configuration,27282,"tadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27681,Deployability,configurat,configuration,27681,"enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27841,Deployability,configurat,configuration,27841," a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:31647,Deployability,update,update,31647,"m the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:32765,Deployability,update,update,32765,"stems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha v3 Support. Cromwell now supports resolving DRS URIs through Martha v3 (in addition to Martha v2). To switch to the new version of Martha, update the `martha.url` found in the [filesystems config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to; point to `/martha_v3`. More information on Martha v3 request and response schema can be found [here](https://github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pip",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:33865,Deployability,pipeline,pipelines-api-workflow-options,33865,"le/filesystems/Filesystems/#overview) to; point to `/martha_v3`. More information on Martha v3 request and response schema can be found [here](https://github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by sett",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34169,Deployability,upgrade,upgrade,34169,"ints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `Th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34482,Deployability,release,release,34482," limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34497,Deployability,update,updated,34497," limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35448,Deployability,configurat,configuration,35448,"ries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35506,Deployability,update,updated,35506,"ries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37282,Deployability,configurat,configuration,37282," the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_ST",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37383,Deployability,update,updated,37383," the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_ST",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37985,Deployability,deploy,deployments,37985," Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39986,Deployability,pipeline,pipelines-api-workflow-options,39986,"ls]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for more details. #### Adding support for Google Cloud Life Sciences v2beta; Cromwell now supports running workflows using Google Cloud Life Sciences v2beta API in addition to Google Cloud Genomics v2alpha1.; More information about migration to the new API from v2alpha1; [here](https://cromwell.readthedocs.io/en/stable/backends/Google#migration-from-google-cloud-genomics-v2alpha1-to-google-cloud-life-sciences-v2beta).; * **Note** Google Cloud Life Sciences is the new name for newer versions of Google Cloud Genomics.; * **Note** Support for Google Cloud Genomics v2alpha1 will be removed in a future version of Cromwell. Advance notice will be provided. ##",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:41108,Deployability,install,install,41108,ffers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for more details. #### Adding support for Google Cloud Life Sciences v2beta; Cromwell now supports running workflows using Google Cloud Life Sciences v2beta API in addition to Google Cloud Genomics v2alpha1.; More information about migration to the new API from v2alpha1; [here](https://cromwell.readthedocs.io/en/stable/backends/Google#migration-from-google-cloud-genomics-v2alpha1-to-google-cloud-life-sciences-v2beta).; * **Note** Google Cloud Life Sciences is the new name for newer versions of Google Cloud Genomics.; * **Note** Support for Google Cloud Genomics v2alpha1 will be removed in a future version of Cromwell. Advance notice will be provided. ### New Docs. #### Installation methods. Links to the conda package and docker container are now available in; [the install documentation](https://cromwell.readthedocs.io/en/stable/Getting/). ### Bug Fixes. + Fix a bug where zip files with directories could not be imported.; For example a zip with `a.wdl` and `b.wdl` could be imported but one with `sub_workflows/a.wdl`; and `imports/b.wdl` could not.; + Fix a bug which sometimes allowed execution scripts copied by a failed cache-copy to be run instead; of the attempt-1 script for a live job execution. ## 48 Release Notes. ### Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#518,MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:42714,Deployability,configurat,configuration,42714," WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43390,Deployability,update,updated,43390,"ed in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell n",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46600,Deployability,configurat,configuration,46600,"untime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Googl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47116,Deployability,deploy,deployments,47116,"s PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47890,Deployability,configurat,configuration,47890,"ll not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the m",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48010,Deployability,update,updated,48010,"ronment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`call",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48073,Deployability,configurat,configuration,48073,"TRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets retur",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:49209,Deployability,install,installed,49209,"w experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private N",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50341,Deployability,configurat,configuration,50341,".io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:51785,Deployability,update,updated,51785," possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Beca",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52484,Deployability,configurat,configuration,52484,", are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52760,Deployability,configurat,configuration,52760,"ready formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52961,Deployability,configurat,configuration,52961,"ime zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1)",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54310,Deployability,configurat,configuration,54310,"2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54532,Deployability,configurat,configuration,54532,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57362,Deployability,configurat,configuration,57362," used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57458,Deployability,configurat,configuration,57458,"o their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. F",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58388,Deployability,configurat,configuration,58388," `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58835,Deployability,deploy,deployments,58835,"lementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59377,Deployability,configurat,configuration,59377,"iguration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database depl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60118,Deployability,deploy,deployments,60118,"eturning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previous",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60389,Deployability,deploy,deployment,60389,"s of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60492,Deployability,configurat,configuration,60492,"e information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61297,Deployability,configurat,configuration,61297,"ds to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functional",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61492,Deployability,configurat,configuration,61492,"iguration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy developm",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61732,Deployability,configurat,configuration,61732,"lCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62002,Deployability,configurat,configuration,62002,"shes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first wr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62578,Deployability,release,release,62578,"us why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](h",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63336,Deployability,configurat,configuration,63336,"l to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63422,Deployability,configurat,configuration,63422,"idation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63987,Deployability,configurat,configuration,63987,"and lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on fu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64560,Deployability,configurat,configuration,64560," are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64613,Deployability,hotfix,hotfix,64613,"equest Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64856,Deployability,release,release,64856,"ant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCa",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65838,Deployability,configurat,configuration,65838,"fier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Acc",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65912,Deployability,configurat,configuration,65912,"sers may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requeste",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:66047,Deployability,release,releaseHold,66047,"d `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequence",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:67330,Deployability,configurat,configuration,67330,"n the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequences. ### Private Docker Support on Pipelines API v2. Support for private Docker Hub images is now included in the Google Pipelines API v2 backend. PAPI v2 private Docker support is; equivalent to that in PAPI v1 but the configuration differs, please see; [Docker configuration](http://cromwell.readthedocs.io/en/develop/filesystems/Google#Docker) for more details. ### Updated MySQL client with 8.0 support. Updated the MySQL connector client from `5.1.42` to `5.1.46` which adds support for connecting to MySQL 8.0. See the; documentation on [Changes in MySQL Connector/J](https://dev.mysql.com/doc/relnotes/connector-j/5.1/en/news-5-1.html) for; more information. ## 33 Release Notes. ### Query endpoint. #### Exclude workflows based on Labels. This gives the ability to **filter out** workflows based on labels. Two new parameters called `excludeLabelAnd` and `excludeLabelOr` can be used for this purpose.; More details on how to use them can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Include/Exclude subworkflows. Cromwell now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; Mor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:67373,Deployability,configurat,configuration,67373,"n the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequences. ### Private Docker Support on Pipelines API v2. Support for private Docker Hub images is now included in the Google Pipelines API v2 backend. PAPI v2 private Docker support is; equivalent to that in PAPI v1 but the configuration differs, please see; [Docker configuration](http://cromwell.readthedocs.io/en/develop/filesystems/Google#Docker) for more details. ### Updated MySQL client with 8.0 support. Updated the MySQL connector client from `5.1.42` to `5.1.46` which adds support for connecting to MySQL 8.0. See the; documentation on [Changes in MySQL Connector/J](https://dev.mysql.com/doc/relnotes/connector-j/5.1/en/news-5-1.html) for; more information. ## 33 Release Notes. ### Query endpoint. #### Exclude workflows based on Labels. This gives the ability to **filter out** workflows based on labels. Two new parameters called `excludeLabelAnd` and `excludeLabelOr` can be used for this purpose.; More details on how to use them can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Include/Exclude subworkflows. Cromwell now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; Mor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70144,Deployability,update,update,70144,"[documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as the",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70156,Deployability,configurat,configuration,70156,"[documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as the",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70346,Deployability,pipeline,pipelines,70346,"ing the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70439,Deployability,pipeline,pipelines,70439,"port for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onward",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70530,Deployability,pipeline,pipelines,70530,").; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70597,Deployability,update,update,70597,"e near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:72956,Deployability,release,releaseHold,72956,"ig; All language factories can now be configured on a per-language-version basis. All languages and versions will support the following options:; * `enabled`: Defaults to `true`. Set to `false` to disallow workflows of this language and version.; * `strict-validation`: Defaults to `true` for WDL draft 3 and `false` for WDL draft 2 and CWL. Specifies whether workflows fail if the inputs JSON (or YAML) file contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73599,Deployability,configurat,configuration,73599,"503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73742,Deployability,configurat,configuration,73742,"low but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74232,Deployability,configurat,configuration,74232,"e {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previou",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74949,Deployability,update,update-labels-for-a-workflow,74949,"al backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previously updated using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:75226,Deployability,update,updated,75226,"guration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previously updated using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:75330,Deployability,update,update-labels-for-a-workflow,75330,"bitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previously updated using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter wil",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:75734,Deployability,update,update,75734," value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previously updated using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:76189,Deployability,update,updated,76189,"els for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:76618,Deployability,pipeline,pipelines-api-workflow-options,76618," prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwel",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77008,Deployability,configurat,configuration,77008,"://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77361,Deployability,configurat,configuration,77361,"w options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating do",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77741,Deployability,update,update,77741,"rce code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78208,Deployability,configurat,configuration,78208,"art rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://cromwell.readthedocs.io/en/develop/). There are new [Tutorials](http://cromwell.readthedocs.io/en/develop/tutorials/FiveMinuteIntro/) and much of the document",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81205,Deployability,configurat,configuration,81205,"ntal; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The res",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82768,Deployability,update,updated,82768,"he next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON valu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87169,Deployability,update,update,87169,"s fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87236,Deployability,patch,patch-apiworkflowsversionidlabels,87236," of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, b",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87336,Deployability,update,updated,87336,"ed to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87523,Deployability,configurat,configuration,87523,"dmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this ver",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:89935,Deployability,update,update,89935,"As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:90032,Deployability,upgrade,upgrade,90032,"executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. P",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91419,Deployability,configurat,configuration,91419," tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for goo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91945,Deployability,install,installed,91945,"ally appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93893,Deployability,upgrade,upgrade,93893,"re information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their con",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94004,Deployability,upgrade,upgrade,94004,"ault settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved he",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94236,Deployability,configurat,configuration,94236,"ng on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or no",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94430,Deployability,update,updated,94430,"ld. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"":",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95960,Deployability,configurat,configuration,95960," All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) =",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96584,Deployability,pipeline,pipeline,96584," which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99427,Deployability,configurat,configuration,99427,"he job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes eac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:101395,Deployability,configurat,configuration,101395,"ut arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now require a multipart/form-data encoded body.; * Support for sub workflows (see [Annex A](#annex-a---workflow-outputs)); * Enable WDL imports when running in Single Workflow Runner Mode as well as Server Mode; * Support for WDL imports through an additional imports.zip parameter; * Support for sub workflows; * Corrected file globbing in JES to correctly report all generated files. Additionally, file globbing in JES now uses bash-style glob syntax instead of python style glob syntax; * Support declarations as graph nodes; * Added the ability to override the default service account that the compute VM is started with via the configuration option `JES.config.genomics.compute-service-account` or through the workflow options parameter `google_compute_service_account`. More details can be found in the README.md; * Fix bugs related to the behavior of Cromwell in Single Workflow Runner Mode. Cromwell will now exit once a workflow completes in Single Workflow Runner Mode. Additionally, when restarting Cromwell in Single Workflow Runner Mode, Cromwell will no longer restart incomplete workflows from a previous session. ### Annex A - Workflow outputs. The WDL specification has changed regarding [workflow outputs](https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md#outputs) to accommodate sub workflows.; This change is backward compatible in terms of runnable WDLs (WDL files using the deprecated workflow outputs syntax will still run the same).; The only visible change lies in the metadata (",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106611,Deployability,update,updates,106611,"ipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107041,Deployability,configurat,configuration,107041,"s_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add suppo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:108045,Deployability,update,updated,108045,"or backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains a",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:108681,Deployability,update,updated,108681,"flow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 500",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109266,Deployability,configurat,configuration,109266,"oject must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; para",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109399,Deployability,configurat,configuration,109399,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7308,Energy Efficiency,power,powerful,7308,"e/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10438,Energy Efficiency,reduce,reduces,10438,"ntel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""retry with more memory"" behavior. Cromwell will now retry a task with more memory after it fails with return code 137, provided all; the other requirements for retrying with more memory are met. ### DRS Improvements. #### Support for invoking `CromwellDRSLocalizer` with manifest file. `CromwellDRSLocalizer` can no",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47561,Energy Efficiency,monitor,monitoring,47561,"tual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It als",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50508,Energy Efficiency,reduce,reduce,50508,"flow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54633,Energy Efficiency,monitor,monitor,54633,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54797,Energy Efficiency,monitor,monitors,54797," are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54831,Energy Efficiency,monitor,monitor,54831,"e applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58599,Energy Efficiency,monitor,monitor,58599,"e logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backen",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58666,Energy Efficiency,monitor,monitor,58666,"ixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65368,Energy Efficiency,efficient,efficient,65368,"ine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI ve",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77100,Energy Efficiency,monitor,monitor,77100,"vel-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77540,Energy Efficiency,monitor,monitored,77540,"readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78033,Energy Efficiency,monitor,monitoring,78033,"s been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82285,Energy Efficiency,reduce,reduce,82285,"nd should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed inform",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1552,Integrability,message,message,1552,"s://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1637,Integrability,message,message,1637," Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is availa",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:3237,Integrability,depend,depends,3237,"ket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9713,Integrability,depend,dependencies,9713,"g forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encoun",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10192,Integrability,message,message,10192," ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""re",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:13699,Integrability,depend,dependencies,13699,"emain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the reque",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:14672,Integrability,message,message,14672,"x security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also be moved, implemented, and documented within Cromwell. As a result of this, we can safely remove; and deprecate the wes2cromw",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34912,Integrability,message,message,34912,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43826,Integrability,message,message,43826,"re](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:43961,Integrability,message,message,43961,"/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44736,Integrability,depend,dependencies,44736,"PI v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45743,Integrability,message,messages,45743,"ndencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54587,Integrability,interface,interface,54587,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59146,Integrability,depend,dependencies,59146,"``; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For mu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69820,Integrability,message,messages,69820,"kflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:75683,Integrability,depend,depending,75683,"evelop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previously updated using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow). The database table storing custom labels will delete duplicate rows for any workflow label key. For efficiency purposes; the values are not regenerated automatically from the potentially large metadata table. In rare cases where one tried to revert to a prior custom label value you may continue to see different results; depending on the REST API used. After the database update; [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most-recent-unique value while; [""Get workflow and call-level metadata for a specified workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-o",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82184,Integrability,depend,depending,82184," is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82677,Integrability,rout,routeUnwrapped,82677," to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93241,Integrability,depend,depending,93241,"the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Con",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93403,Integrability,message,message,93403," Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the J",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93544,Integrability,message,message,93544," {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93580,Integrability,message,message,93580," {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93620,Integrability,message,message,93620," {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:93664,Integrability,message,message,93664," {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit than read_string. See reference.conf for default settings. ## 26. ### Breaking Changes. * Failure metadata for calls and workflows was being displayed inconsistently, with different formats depending on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:829,Modifiability,config,configured,829,"# Cromwell Change Log. ## 88 Release Notes. ### New feature: Prevent Job start during Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1051,Modifiability,config,configuration,1051,"ring Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2051,Modifiability,config,config,2051,"figuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. ####",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:3680,Modifiability,enhance,enhancement,3680,"ill now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub`",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4636,Modifiability,config,config,4636,"obs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240));",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4671,Modifiability,config,config,4671," This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4913,Modifiability,config,configurations,4913,"tion Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progres",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4993,Modifiability,config,config,4993,"ersions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using;",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:5029,Modifiability,config,config,5029,"a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using; WDL version `development-1.1`.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:5690,Modifiability,config,config,5690,"hMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progress. Users that would like to try out the current partial support can do so by using; WDL version `development-1.1`. As of Cromwell 87, `development-1.1` includes:; * Engine functions:; * Added `suffix` ([#7363](https://github.com/broadinstitute/cromwell/pull/7363)); * Added `unzip` ([#7363](https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10009,Modifiability,config,configured,10009,"ed output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12231,Modifiability,config,configure,12231,"l; the other requirements for retrying with more memory are met. ### DRS Improvements. #### Support for invoking `CromwellDRSLocalizer` with manifest file. `CromwellDRSLocalizer` can now handle multiple file localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the program exiting if any fail.; ```; java -jar /path/to/localizer.jar [options] -m /local/path/to/manifest/file.txt; ```. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://crom",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12433,Modifiability,config,configuration,12433," localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the program exiting if any fail.; ```; java -jar /path/to/localizer.jar [options] -m /local/path/to/manifest/file.txt; ```. The previous method of passing in a single DRS file and container destination using positional arguments is still; supported. #### Improvement to DRS localization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:13372,Modifiability,config,configured,13372,"(Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:14455,Modifiability,config,configuration,14455,"ewer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented an",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:20408,Modifiability,config,configured,20408,"e backend |; | `backendStatus` |`Running`|`Running`| Job state reported by backend |. ### New 'requestedWorkflowId' API Option. Allows users to choose their own workflow IDs at workflow submission time. If supplied for single workflows, this value must be a JSON string containing a valid, and not already used, UUID. For batch submissions, this value must be a JSON array of valid UUIDs. If not supplied, the behavior is as today: Cromwell will generate a random workflow ID for every workflow submitted. ### Bug Fixes. * Fixed a bug on Google Pipelines API backends where missing optional output files (`File?`) were not correctly detected by Cromwell and caused invalid call cache entries to be written. ## 73 Release Notes. ### Workflow Restart Performance Improvements. Cromwell now allows for improved performance restarting large workflows through the use of a separate rate limiter for restart checks than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affect",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:21311,Modifiability,config,configuration,21311,"s than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:21519,Modifiability,config,config,21519,"com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22242,Modifiability,config,configuration,22242,"efault unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22410,Modifiability,config,configuration,22410,"itigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22621,Modifiability,config,config,22621,"1110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22825,Modifiability,config,configuration,22825,"al Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renam",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23127,Modifiability,config,configuration,23127,"the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23449,Modifiability,config,configuration,23449,"in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23508,Modifiability,config,configuration,23508,"ence.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome suppo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23849,Modifiability,config,configuration,23849,"ced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24087,Modifiability,config,configuration,24087," * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the AP",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24210,Modifiability,config,configuration,24210,"eness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes suppor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:26515,Modifiability,config,configuration,26515,"drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ##",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27125,Modifiability,config,configuration,27125,"arboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that cause",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27282,Modifiability,config,configuration,27282,"tadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27681,Modifiability,config,configuration,27681,"enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27710,Modifiability,config,config,27710,"in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The fun",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27841,Modifiability,config,configuration,27841," a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27870,Modifiability,config,config,27870,"ws to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:31019,Modifiability,config,config,31019,"lop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:31146,Modifiability,config,config,31146,"he function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Marth",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:31698,Modifiability,config,config,31698,"roved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha v3 Support. Cromwell now supports resolving DRS URIs through Martha v",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:32815,Modifiability,config,config,32815,"e; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha v3 Support. Cromwell now supports resolving DRS URIs through Martha v3 (in addition to Martha v2). To switch to the new version of Martha, update the `martha.url` found in the [filesystems config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to; point to `/martha_v3`. More information on Martha v3 request and response schema can be found [here](https://github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34786,Modifiability,config,configures,34786,"(https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the inp",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35448,Modifiability,config,configuration,35448,"ries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37282,Modifiability,config,configuration,37282," the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_ST",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37587,Modifiability,refactor,refactoring,37587,"ng docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37658,Modifiability,refactor,refactored,37658,"d5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The di",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37815,Modifiability,refactor,refactor,37815,"and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:42211,Modifiability,config,config,42211,"h `a.wdl` and `b.wdl` could be imported but one with `sub_workflows/a.wdl`; and `imports/b.wdl` could not.; + Fix a bug which sometimes allowed execution scripts copied by a failed cache-copy to be run instead; of the attempt-1 script for a live job execution. ## 48 Release Notes. ### Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Releas",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:42382,Modifiability,config,config,42382,"h `a.wdl` and `b.wdl` could be imported but one with `sub_workflows/a.wdl`; and `imports/b.wdl` could not.; + Fix a bug which sometimes allowed execution scripts copied by a failed cache-copy to be run instead; of the attempt-1 script for a live job execution. ## 48 Release Notes. ### Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Releas",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:42714,Modifiability,config,configuration,42714," WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44198,Modifiability,enhance,enhances,44198,"s and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46600,Modifiability,config,configuration,46600,"untime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Googl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46719,Modifiability,refactor,refactoring,46719,"ed number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAP",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46790,Modifiability,refactor,refactored,46790,"well call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ##",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46947,Modifiability,refactor,refactor,46947,"nformation on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Original",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47604,Modifiability,config,configure,47604,"tion. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47890,Modifiability,config,configuration,47890,"ll not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the m",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47938,Modifiability,config,config,47938,"ion for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** m",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:47975,Modifiability,config,config,47975,"ogle Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48047,Modifiability,config,config,48047,"oximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48073,Modifiability,config,configuration,48073,"TRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets retur",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48543,Modifiability,config,configurable,48543," [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid wor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48650,Modifiability,config,configuring,48650,"n/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provide",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:49342,Modifiability,config,configuring,49342,"found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:49839,Modifiability,config,configured,49839,"ludeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:49971,Modifiability,config,configured,49971,"udeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AW",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50078,Modifiability,config,config,50078,"QL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings u",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50341,Modifiability,config,configuration,50341,".io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52264,Modifiability,config,configuring,52264,"rmats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that so",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52431,Modifiability,config,configured,52431,", are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52484,Modifiability,config,configuration,52484,", are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52760,Modifiability,config,configuration,52760,"ready formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC time zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:52961,Modifiability,config,configuration,52961,"ime zones,; and may or may not include microseconds or even nanoseconds, for example `2017-01-19T12:34:56.123456789-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1)",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53065,Modifiability,config,configurable,53065,"-04:00`. ### Config Changes. #### Heartbeat failure shutdown. When a Cromwell instance is unable to write heartbeats for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53122,Modifiability,config,configure,53122,"s for some period of time it will automatically shut down. For more; information see the docs on [configuring Workflow Hearbeats](https://cromwell.readthedocs.io/en/stable/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not le",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53323,Modifiability,config,config,53323,"ble/Configuring/). NOTE: In the remote chance that the `system.workflow-heartbeats.ttl` has been configured to be less than `5 minutes`; then the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54310,Modifiability,config,configuration,54310,"2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54532,Modifiability,config,configuration,54532,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54555,Modifiability,refactor,refactored,54555,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54691,Modifiability,inherit,inherited,54691,"ions. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ``",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:55565,Modifiability,config,config,55565,"no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-name = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:55818,Modifiability,config,config,55818,"isted in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-name = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:56036,Modifiability,config,config,56036,"ard; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; }; }; }; ```; ###### From `WorkbenchHealthMonitorServiceActor`:; Replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.workbench.WorkbenchHealthMonitorServiceActor"". config {; papi-backend-name = PAPIv1; papi-v2-backend-name = PAPIv2. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-database: true; check-gcs: true; check-papi-backends: [PAPIv1, PAPIv2]. google-auth-name = service-account; gcs-bucket-to-check = ""cromwell-ping-me-bucket""; }; }; }; ```; ### Workflow options changes. A new workflow option is added. If the `final_workflow_outputs_dir` is set; `use_relative_output_paths` can be used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57362,Modifiability,config,configuration,57362," used. When set to `true` this will copy; all the outputs relative to their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57458,Modifiability,config,configuration,57458,"o their execution directory.; my_final_workflow_outputs_dir/~~MyWorkflow/af76876d8-6e8768fa/call-MyTask/execution/~~output_of_interest.; More information can be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. F",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58238,Modifiability,variab,variables,58238," a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:58388,Modifiability,config,configuration,58388," `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59377,Modifiability,config,configuration,59377,"iguration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default health monitor. Previous versions of Cromwell defaulted to using a health monitor service that checked Docker Hub and engine database status.; Neither check was useful if the `status` endpoint was never consulted as is likely the case in most deployments. Cromwell 38; now defaults to a `NoopHealthMonitorServiceActor` which does nothing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database depl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60492,Modifiability,config,configuration,60492,"e information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61297,Modifiability,config,configuration,61297,"ds to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functional",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61492,Modifiability,config,configuration,61492,"iguration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy developm",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61732,Modifiability,config,configuration,61732,"lCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62002,Modifiability,config,configuration,62002,"shes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first wr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63336,Modifiability,config,configuration,63336,"l to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63422,Modifiability,config,configuration,63422,"idation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63987,Modifiability,config,configuration,63987,"and lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on fu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64560,Modifiability,config,configuration,64560," are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64730,Modifiability,config,config,64730,"equest Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65838,Modifiability,config,configuration,65838,"fier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Acc",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65912,Modifiability,config,configuration,65912,"sers may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requeste",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:67330,Modifiability,config,configuration,67330,"n the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequences. ### Private Docker Support on Pipelines API v2. Support for private Docker Hub images is now included in the Google Pipelines API v2 backend. PAPI v2 private Docker support is; equivalent to that in PAPI v1 but the configuration differs, please see; [Docker configuration](http://cromwell.readthedocs.io/en/develop/filesystems/Google#Docker) for more details. ### Updated MySQL client with 8.0 support. Updated the MySQL connector client from `5.1.42` to `5.1.46` which adds support for connecting to MySQL 8.0. See the; documentation on [Changes in MySQL Connector/J](https://dev.mysql.com/doc/relnotes/connector-j/5.1/en/news-5-1.html) for; more information. ## 33 Release Notes. ### Query endpoint. #### Exclude workflows based on Labels. This gives the ability to **filter out** workflows based on labels. Two new parameters called `excludeLabelAnd` and `excludeLabelOr` can be used for this purpose.; More details on how to use them can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Include/Exclude subworkflows. Cromwell now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; Mor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:67373,Modifiability,config,configuration,67373,"n the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows returned first. ### Requester Pays on GCS. Access of Google Cloud Storage buckets with Requester Pays enabled is now supported.; Please read the [relevant documentation](http://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage#requester-pays) for information on how to enable it and the consequences. ### Private Docker Support on Pipelines API v2. Support for private Docker Hub images is now included in the Google Pipelines API v2 backend. PAPI v2 private Docker support is; equivalent to that in PAPI v1 but the configuration differs, please see; [Docker configuration](http://cromwell.readthedocs.io/en/develop/filesystems/Google#Docker) for more details. ### Updated MySQL client with 8.0 support. Updated the MySQL connector client from `5.1.42` to `5.1.46` which adds support for connecting to MySQL 8.0. See the; documentation on [Changes in MySQL Connector/J](https://dev.mysql.com/doc/relnotes/connector-j/5.1/en/news-5-1.html) for; more information. ## 33 Release Notes. ### Query endpoint. #### Exclude workflows based on Labels. This gives the ability to **filter out** workflows based on labels. Two new parameters called `excludeLabelAnd` and `excludeLabelOr` can be used for this purpose.; More details on how to use them can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Include/Exclude subworkflows. Cromwell now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; Mor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70156,Modifiability,config,configuration,70156,"[documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as the",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:72066,Modifiability,config,configured,72066,"el-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing the classes into your own scala project, make sure you are using Scala 2.12. ### Input Validation; Cromwell can now validate that your inputs files do not supply inputs with no impact on the workflow. Strict validation will be disabled by default in WDL draft 2 and CWL but enabled in WDL draft 3. See the 'Language Factory Config' below for details. ### Language Factory Config; All language factories can now be configured on a per-language-version basis. All languages and versions will support the following options:; * `enabled`: Defaults to `true`. Set to `false` to disallow workflows of this language and version.; * `strict-validation`: Defaults to `true` for WDL draft 3 and `false` for WDL draft 2 and CWL. Specifies whether workflows fail if the inputs JSON (or YAML) file contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, a",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73599,Modifiability,config,configuration,73599,"503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73742,Modifiability,config,configuration,73742,"low but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:73813,Modifiability,config,config-key-for-backend,73813,"ion. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74017,Modifiability,config,config,74017," allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary pro",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74138,Modifiability,variab,variable,74138,"mal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:74232,Modifiability,config,configuration,74232,"e {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GPU supported are `nvidia-tesla-k80` and `nvidia-tesla-p100`. **Important**: Before adding a GPU, make sure it is available in the zone the job is running in: https://cloud.google.com/compute/docs/gpus/. ### Job Shell. Cromwell now allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. ### Bug Fixes. The imports zip no longer unpacks a single (arbitrary) internal directory if it finds one (or more). Instead, import statements should now be made relative to the base of the import zip root. #### Reverting Custom Labels. Reverting to a prior custom label value now works. [""Retrieves the current labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#retrieves-the-current-labels-for-a-workflow); will return the most recently summarized custom label value. The above endpoint may still return the prior value for a short period of time after using; [""Updated labels for a workflow""](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#update-labels-for-a-workflow); until the background metadata summary process completes. #### Deleting Duplicate Custom Label Rows. If you never used the REST API to revert a custom label back to a prior value you will not be affected. This only applies to workflows previou",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77008,Modifiability,config,configuration,77008,"://cromwell.readthedocs.io/en/develop/api/RESTAPI/#get-workflow-and-call-level-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77361,Modifiability,config,configuration,77361,"w options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating do",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78208,Modifiability,config,configuration,78208,"art rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://cromwell.readthedocs.io/en/develop/). There are new [Tutorials](http://cromwell.readthedocs.io/en/develop/tutorials/FiveMinuteIntro/) and much of the document",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81205,Modifiability,config,configuration,81205,"ntal; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The res",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:83239,Modifiability,config,config,83239,"o have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:83299,Modifiability,config,configure,83299," sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ""null_input_values.maybeString"": null,; ""null_input_values.arrayOfMaybeIn",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:83709,Modifiability,variab,variables,83709,"he response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ""null_input_values.maybeString"": null,; ""null_input_values.arrayOfMaybeInts"": [1, 2, null, 4]; }; ```. workflow.wdl; ```; workflow null_input_values {; String? maybeString; Array[Int?] arrayOfMaybeInts; }; ```. ## 28. ### Bug Fixes. #### WDL write_* functions add a final newline. The following WDL functions now add a newline after the final line of output (the previous behavior of not adding this; newline was inadvertent):; - `write_lines`; - `write_map`; - `write_object`; - `write_objects`; - `write_tsv`. For example:. ```; task writer {",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:84008,Modifiability,variab,variables,84008,"T` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ""null_input_values.maybeString"": null,; ""null_input_values.arrayOfMaybeInts"": [1, 2, null, 4]; }; ```. workflow.wdl; ```; workflow null_input_values {; String? maybeString; Array[Int?] arrayOfMaybeInts; }; ```. ## 28. ### Bug Fixes. #### WDL write_* functions add a final newline. The following WDL functions now add a newline after the final line of output (the previous behavior of not adding this; newline was inadvertent):; - `write_lines`; - `write_map`; - `write_object`; - `write_objects`; - `write_tsv`. For example:. ```; task writer {; Array[String] a = [""foo"", ""bar""]; command {; # used to output: ""foo\nbar""; # now outputs: ""foo\nbar\n""; cat write_lines(a); }; }; ```. #### `ContinueWhilePossible`. A workflow utilizing the WorkflowFailureMode Workflow Option `ContinueWhilePossible` will now successfully reach",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:84123,Modifiability,variab,variables,84123,"efore exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ""null_input_values.maybeString"": null,; ""null_input_values.arrayOfMaybeInts"": [1, 2, null, 4]; }; ```. workflow.wdl; ```; workflow null_input_values {; String? maybeString; Array[Int?] arrayOfMaybeInts; }; ```. ## 28. ### Bug Fixes. #### WDL write_* functions add a final newline. The following WDL functions now add a newline after the final line of output (the previous behavior of not adding this; newline was inadvertent):; - `write_lines`; - `write_map`; - `write_object`; - `write_objects`; - `write_tsv`. For example:. ```; task writer {; Array[String] a = [""foo"", ""bar""]; command {; # used to output: ""foo\nbar""; # now outputs: ""foo\nbar\n""; cat write_lines(a); }; }; ```. #### `ContinueWhilePossible`. A workflow utilizing the WorkflowFailureMode Workflow Option `ContinueWhilePossible` will now successfully reach a terminal state once all runnable jobs have completed.; #### `FailOnStderr`; When `FailOnStderr` is set t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87523,Modifiability,config,configuration,87523,"dmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this ver",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:89243,Modifiability,variab,variables,89243,"s versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.j",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:90286,Modifiability,rewrite,rewriteBatchedStatements,90286,"e you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91419,Modifiability,config,configuration,91419," tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for goo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94236,Modifiability,config,configuration,94236,"ng on the originating Cromwell version. Failures will now always present as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or no",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94345,Modifiability,config,configure,94345,"as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95682,Modifiability,config,config,95682,"imes an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95785,Modifiability,config,config,95785," ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array con",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95896,Modifiability,config,config,95896,"k, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `Strin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95960,Modifiability,config,configuration,95960," All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) =",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96024,Modifiability,config,configurable,96024," All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) =",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96045,Modifiability,config,config,96045," All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) =",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96293,Modifiability,rewrite,rewriteBatchedStatements,96293,":; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker imag",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96351,Modifiability,config,config,96351,":; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker imag",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99427,Modifiability,config,configuration,99427,"he job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes eac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:101395,Modifiability,config,configuration,101395,"ut arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now require a multipart/form-data encoded body.; * Support for sub workflows (see [Annex A](#annex-a---workflow-outputs)); * Enable WDL imports when running in Single Workflow Runner Mode as well as Server Mode; * Support for WDL imports through an additional imports.zip parameter; * Support for sub workflows; * Corrected file globbing in JES to correctly report all generated files. Additionally, file globbing in JES now uses bash-style glob syntax instead of python style glob syntax; * Support declarations as graph nodes; * Added the ability to override the default service account that the compute VM is started with via the configuration option `JES.config.genomics.compute-service-account` or through the workflow options parameter `google_compute_service_account`. More details can be found in the README.md; * Fix bugs related to the behavior of Cromwell in Single Workflow Runner Mode. Cromwell will now exit once a workflow completes in Single Workflow Runner Mode. Additionally, when restarting Cromwell in Single Workflow Runner Mode, Cromwell will no longer restart incomplete workflows from a previous session. ### Annex A - Workflow outputs. The WDL specification has changed regarding [workflow outputs](https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md#outputs) to accommodate sub workflows.; This change is backward compatible in terms of runnable WDLs (WDL files using the deprecated workflow outputs syntax will still run the same).; The only visible change lies in the metadata (",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:101421,Modifiability,config,config,101421," Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now require a multipart/form-data encoded body.; * Support for sub workflows (see [Annex A](#annex-a---workflow-outputs)); * Enable WDL imports when running in Single Workflow Runner Mode as well as Server Mode; * Support for WDL imports through an additional imports.zip parameter; * Support for sub workflows; * Corrected file globbing in JES to correctly report all generated files. Additionally, file globbing in JES now uses bash-style glob syntax instead of python style glob syntax; * Support declarations as graph nodes; * Added the ability to override the default service account that the compute VM is started with via the configuration option `JES.config.genomics.compute-service-account` or through the workflow options parameter `google_compute_service_account`. More details can be found in the README.md; * Fix bugs related to the behavior of Cromwell in Single Workflow Runner Mode. Cromwell will now exit once a workflow completes in Single Workflow Runner Mode. Additionally, when restarting Cromwell in Single Workflow Runner Mode, Cromwell will no longer restart incomplete workflows from a previous session. ### Annex A - Workflow outputs. The WDL specification has changed regarding [workflow outputs](https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md#outputs) to accommodate sub workflows.; This change is backward compatible in terms of runnable WDLs (WDL files using the deprecated workflow outputs syntax will still run the same).; The only visible change lies in the metadata (as well as the console output in single workflow mode, when workflow outputs are printed out at the end of a successful workflow). TL;DR Unle",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104454,Modifiability,config,configurable,104454,"l generate a ""new syntax"" workflow output for each task output, and name them.; Their name will be generated using their FQN, which would give. ```; output {; String w.t.out1 = t.out1; String w.t.out2 = t.out2; }; ```. However as the FQN separator is `.`, the name itself cannot contain any `.`.; For that reason, `.` are replaced with `_` :. *Old syntax expanded to new syntax*; ```; output {; String w_t_out1 = t.out1; String w_t_out2 = t.out2; }; ```. The consequence is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submi",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104605,Modifiability,config,configurable,104605,"l be generated using their FQN, which would give. ```; output {; String w.t.out1 = t.out1; String w.t.out2 = t.out2; }; ```. However as the FQN separator is `.`, the name itself cannot contain any `.`.; For that reason, `.` are replaced with `_` :. *Old syntax expanded to new syntax*; ```; output {; String w_t_out1 = t.out1; String w_t_out2 = t.out2; }; ```. The consequence is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This e",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104697,Modifiability,config,config,104697,"ver as the FQN separator is `.`, the name itself cannot contain any `.`.; For that reason, `.` are replaced with `_` :. *Old syntax expanded to new syntax*; ```; output {; String w_t_out1 = t.out1; String w_t_out2 = t.out2; }; ```. The consequence is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Eac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106443,Modifiability,config,config,106443,"heck-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106529,Modifiability,config,config,106529,"kflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""crom",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107041,Modifiability,config,configuration,107041,"s_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add suppo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107294,Modifiability,config,config,107294,"owInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107338,Modifiability,config,config,107338,". * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Priva",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107369,Modifiability,config,config,107369,"current jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's n",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107471,Modifiability,config,config,107471,"```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107502,Modifiability,config,config,107502,"endName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107570,Modifiability,config,config,107570,"0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ``",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107614,Modifiability,config,config,107614," database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:107645,Modifiability,config,config,107645,"version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:108704,Modifiability,config,configured,108704,"flow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow_log_dir”; “call_logs_dir” -> “final_call_logs_dir”; “outputs_path” -> “final_workflow_outputs_dir”; “defaultRuntimeOptions” -> “default_runtime_attributes”. * Timing diagrams endpoint has been updated to include additional state information about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 500",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109266,Modifiability,config,configuration,109266,"oject must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; para",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109399,Modifiability,config,configuration,109399,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109866,Modifiability,config,config,109866,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2603,Performance,queue,queueing,2603,"er potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:3470,Performance,perform,performance,3470,"ved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's heal",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:3561,Performance,perform,perform,3561,"Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fixes. #### Improved `size()` function performance on arrays. Resolved a hotspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7261,Performance,perform,performant,7261,"(https://github.com/broadinstitute/cromwell/pull/7368)); * Added `quote` and `squote` ([#7375](https://github.com/broadinstitute/cromwell/pull/7375)); * Updated `sub` to expect POSIX-flavor regex ([#7374](https://github.com/broadinstitute/cromwell/pull/7374)); * Struct literals can be included in WDLs ([#7391](https://github.com/broadinstitute/cromwell/pull/7391)) ([#7402](https://github.com/broadinstitute/cromwell/pull/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Through",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7666,Performance,perform,performance,7666,"l/7402)); * Added `returnCodes` runtime attribute ([#7389](https://github.com/broadinstitute/cromwell/pull/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:8282,Performance,perform,performance,8282," sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:8422,Performance,perform,performance,8422," to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); *",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:18020,Performance,cache,cache,18020," WDL | :white_check_mark: |; | [Terra SaaS platform](https://terra.bio/) | CWL | Future support planned |. ### Last release with Alibaba Cloud. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) will be removed in version 80. ### WES endpoints preview. As a means to stay on top of endpoints within our repo, 3 new Workflow Execution Service (WES) endpoints are now documented in the Cromwell Swagger (others to follow as part of later work):. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. ### Scala 2.13. Cromwell is now built with Scala version 2.13. This change should not be noticeable to users but may be of interest to developers of Cromwell backend implementations. ### Bug Fixes. * Fixed a call caching bug in which an invalid cache entry could cause a valid cache entry to be ignored. ## 75 Release Notes. ### New `AwaitingCloudQuota` backend status. For Cloud Life Sciences v2beta only. When a user's GCP project reaches a quota limit, Cromwell continues to submit jobs and Life Sciences acknowledges them as created even if the physical VM cannot yet start. Cromwell now detects this condition in the backend and reports `AwaitingCloudQuota`. The status is informational and does not require any action. Users wishing to maximize throughput can use `AwaitingCloudQuota` as an indication they should check quota in Cloud Console and request a quota increase from GCP. `AwaitingCloudQuota` will appear between the `Initializing` and `Running` backend statuses, and will be skipped if not applicable. Now:. | Status in metadata |Quota normal| Quota delay | Status meaning |; |--------------------|----|----------------------|---------------------------------------------------|; | `executionStatus` |`Running`| `Running` | Job state",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:18052,Performance,cache,cache,18052," WDL | :white_check_mark: |; | [Terra SaaS platform](https://terra.bio/) | CWL | Future support planned |. ### Last release with Alibaba Cloud. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) will be removed in version 80. ### WES endpoints preview. As a means to stay on top of endpoints within our repo, 3 new Workflow Execution Service (WES) endpoints are now documented in the Cromwell Swagger (others to follow as part of later work):. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. ### Scala 2.13. Cromwell is now built with Scala version 2.13. This change should not be noticeable to users but may be of interest to developers of Cromwell backend implementations. ### Bug Fixes. * Fixed a call caching bug in which an invalid cache entry could cause a valid cache entry to be ignored. ## 75 Release Notes. ### New `AwaitingCloudQuota` backend status. For Cloud Life Sciences v2beta only. When a user's GCP project reaches a quota limit, Cromwell continues to submit jobs and Life Sciences acknowledges them as created even if the physical VM cannot yet start. Cromwell now detects this condition in the backend and reports `AwaitingCloudQuota`. The status is informational and does not require any action. Users wishing to maximize throughput can use `AwaitingCloudQuota` as an indication they should check quota in Cloud Console and request a quota increase from GCP. `AwaitingCloudQuota` will appear between the `Initializing` and `Running` backend statuses, and will be skipped if not applicable. Now:. | Status in metadata |Quota normal| Quota delay | Status meaning |; |--------------------|----|----------------------|---------------------------------------------------|; | `executionStatus` |`Running`| `Running` | Job state",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:18526,Performance,throughput,throughput,18526,"|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. ### Scala 2.13. Cromwell is now built with Scala version 2.13. This change should not be noticeable to users but may be of interest to developers of Cromwell backend implementations. ### Bug Fixes. * Fixed a call caching bug in which an invalid cache entry could cause a valid cache entry to be ignored. ## 75 Release Notes. ### New `AwaitingCloudQuota` backend status. For Cloud Life Sciences v2beta only. When a user's GCP project reaches a quota limit, Cromwell continues to submit jobs and Life Sciences acknowledges them as created even if the physical VM cannot yet start. Cromwell now detects this condition in the backend and reports `AwaitingCloudQuota`. The status is informational and does not require any action. Users wishing to maximize throughput can use `AwaitingCloudQuota` as an indication they should check quota in Cloud Console and request a quota increase from GCP. `AwaitingCloudQuota` will appear between the `Initializing` and `Running` backend statuses, and will be skipped if not applicable. Now:. | Status in metadata |Quota normal| Quota delay | Status meaning |; |--------------------|----|----------------------|---------------------------------------------------|; | `executionStatus` |`Running`| `Running` | Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`| `AwaitingCloudQuota` | Job state reported by backend |. Previously:. | Status in metadata |Quota normal|Quota delay| Status meaning |; |--------------------|----|----|-----------------------------------------------------------|; | `executionStatus` |`Running`|`Running`| Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`|`Running`| Job state reported by backend |. ### New 'requestedWorkflowId' API Option. Allows users to choose their own workflow I",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:20088,Performance,cache,cache,20088,"te Cromwell is requesting from the backend |; | `backendStatus` |`Running`| `AwaitingCloudQuota` | Job state reported by backend |. Previously:. | Status in metadata |Quota normal|Quota delay| Status meaning |; |--------------------|----|----|-----------------------------------------------------------|; | `executionStatus` |`Running`|`Running`| Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`|`Running`| Job state reported by backend |. ### New 'requestedWorkflowId' API Option. Allows users to choose their own workflow IDs at workflow submission time. If supplied for single workflows, this value must be a JSON string containing a valid, and not already used, UUID. For batch submissions, this value must be a JSON array of valid UUIDs. If not supplied, the behavior is as today: Cromwell will generate a random workflow ID for every workflow submitted. ### Bug Fixes. * Fixed a bug on Google Pipelines API backends where missing optional output files (`File?`) were not correctly detected by Cromwell and caused invalid call cache entries to be written. ## 73 Release Notes. ### Workflow Restart Performance Improvements. Cromwell now allows for improved performance restarting large workflows through the use of a separate rate limiter for restart checks than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:20218,Performance,perform,performance,20218,"-------------------------------------------------|; | `executionStatus` |`Running`|`Running`| Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`|`Running`| Job state reported by backend |. ### New 'requestedWorkflowId' API Option. Allows users to choose their own workflow IDs at workflow submission time. If supplied for single workflows, this value must be a JSON string containing a valid, and not already used, UUID. For batch submissions, this value must be a JSON array of valid UUIDs. If not supplied, the behavior is as today: Cromwell will generate a random workflow ID for every workflow submitted. ### Bug Fixes. * Fixed a bug on Google Pipelines API backends where missing optional output files (`File?`) were not correctly detected by Cromwell and caused invalid call cache entries to be written. ## 73 Release Notes. ### Workflow Restart Performance Improvements. Cromwell now allows for improved performance restarting large workflows through the use of a separate rate limiter for restart checks than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22603,Performance,throttle,throttle,22603,"1110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23275,Performance,load,load-control,23275,"e info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23318,Performance,load,load-control,23318,"/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24200,Performance,throttle,throttle,24200,"eness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes suppor",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29474,Performance,cache,cache,29474,"new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/S",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29574,Performance,cache,caches,29574,"ll.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29715,Performance,cache,cache-support,29715,"ives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved D",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:30030,Performance,optimiz,optimizations,30030," Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:32317,Performance,optimiz,optimizations,32317,"# `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha v3 Support. Cromwell now supports resolving DRS URIs through Martha v3 (in addition to Martha v2). To switch to the new version of Martha, update the `martha.url` found in the [filesystems config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to; point to `/martha_v3`. More information on Martha v3 request and response schema can be found [here](https://github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:32560,Performance,optimiz,optimizations,32560,"nt `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here](https://github.com/broadinstitute/martha#martha-v3). ### DOS/DRS `localization_optional` Support. When running on a backend that supports `localization_optional: true` any DOS or DRS `File` values in the generated; command line will be substituted with the `gsUri` returned from Martha's `martha_v3` endpoint. More information on; `localization_optional` can be found [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ### DOS/DRS metadata retrieval retried by default. Attempts to retrieve DOS/DRS metadata from Martha will be retried by default. More information can be found; [here](https://cromwell.readthedocs.io/en/stable/optimizations/FileLocalization/). ## 53 Release Notes. ### Martha v3 Support. Cromwell now supports resolving DRS URIs through Martha v3 (in addition to Martha v2). To switch to the new version of Martha, update the `martha.url` found in the [filesystems config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to; point to `/martha_v3`. More information on Martha v3 request and response schema can be found [here](https://github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:33989,Performance,cache,cache,33989,"github.com/broadinstitute/martha#martha-v3). ### Support for custom entrypoints on Docker images. Cromwell can now support docker images which have custom entrypoints in the PAPIv2 alpha and beta backends. ### Alpha support for WDL optional outputs on PAPI v2. * Alpha support for WDL optional output files on the PAPI v2 backend has been added, please see the; [documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#alpha-support-for-wdl-optional-outputs-on-papi-v2); for known limitations. ### Monitoring Image Script. * Cromwell now supports an optional `monitoring_image_script` workflow option in addition to the existing; `monitoring_script` and `monitoring_image` options. For more information see the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34727,Performance,cache,caches,34727,"ee the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:34878,Performance,cache,cache-ttl,34878,"rkflow-options). ## 52 Release Notes. ### Documentation. Information on how to properly use the Singularity cache with Cromwell is now; provided in the [Cromwell Singularity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35478,Performance,cache,cache,35478,"ries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36064,Performance,cache,cache,36064,"from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ##",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36181,Performance,cache,cache,36181," this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36265,Performance,cache,caches,36265," this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36518,Performance,cache,cache,36518,"://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38398,Performance,cache,cache,38398,"ed documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38439,Performance,cache,cache,38439,"tadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38479,Performance,cache,cacheCopy,38479,"tadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38622,Performance,cache,cache,38622,"ring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38737,Performance,cache,cache,38737,"r this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objec",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38791,Performance,cache,cache,38791,"r this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objec",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38829,Performance,cache,cache,38829,"r this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objec",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38883,Performance,cache,cache,38883,"r this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objec",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38926,Performance,cache,cache,38926,"ployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-p",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:38980,Performance,cache,cache,38980,"ployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-p",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39111,Performance,cache,cacheCopy,39111,"ease plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metada",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39189,Performance,cache,cache,39189,"s in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39239,Performance,cache,cache,39239,"s in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39294,Performance,cache,cache,39294,"_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39524,Performance,cache,cached,39524," directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for more details. #### Adding support for Google Cloud Life Sciences v2beta; Cromwell now supports running workflows using Google Cloud Life Sciences v2beta",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:39594,Performance,optimiz,optimizations,39594,"or attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - stdout [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - output.file [from the cache copy attempt, or for execution attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. but is now:. ```; [...]/callRoot/; - cacheCopy/; - script; - stdout; - output.file; - script [for attempt 1 if the cache copy fails]; - stdout [for attempt 1 if the cache copy fails]; - output.file [for attempt 1 if the cache copy fails]; - attempt-2/ [if attempt 1 fails]; - script; - stdout; - output.file; ```. ### New Functionality. #### Disable call-caching for tasks. It is now possible to indicate in a workflow that a task should not be call-cached. See details; [here](https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks). #### Delete Intermediate Outputs on PapiV2. * **Experimental:** When a new workflow option `delete_intermediate_output_files` is submitted with the workflow,; intermediate `File` objects will be deleted when the workflow completes. See the [Google Pipelines API Workflow Options; documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Google#google-pipelines-api-workflow-options); for more information. #### Metadata Archival Support. Cromwell 49 now offers the option to archive metadata to GCS and remove the equivalent metadata from relational; database storage. Please see; [the documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for more details. #### Adding support for Google Cloud Life Sciences v2beta; Cromwell now supports running workflows using Google Cloud Life Sciences v2beta API in addition to Google Cloud Genomics v2alpha1.; More information about migration to the new API from v2alpha",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:41470,Performance,cache,cache-copy,41470,"e Sciences v2beta API in addition to Google Cloud Genomics v2alpha1.; More information about migration to the new API from v2alpha1; [here](https://cromwell.readthedocs.io/en/stable/backends/Google#migration-from-google-cloud-genomics-v2alpha1-to-google-cloud-life-sciences-v2beta).; * **Note** Google Cloud Life Sciences is the new name for newer versions of Google Cloud Genomics.; * **Note** Support for Google Cloud Genomics v2alpha1 will be removed in a future version of Cromwell. Advance notice will be provided. ### New Docs. #### Installation methods. Links to the conda package and docker container are now available in; [the install documentation](https://cromwell.readthedocs.io/en/stable/Getting/). ### Bug Fixes. + Fix a bug where zip files with directories could not be imported.; For example a zip with `a.wdl` and `b.wdl` could be imported but one with `sub_workflows/a.wdl`; and `imports/b.wdl` could not.; + Fix a bug which sometimes allowed execution scripts copied by a failed cache-copy to be run instead; of the attempt-1 script for a live job execution. ## 48 Release Notes. ### Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:42615,Performance,perform,performance,42615,"## Womtool Graph for WDL 1.0. The `womtool graph` command now supports WDL 1.0 workflows.; * **Note:** Generated graphs - including in WDL draft 2 - may look slightly different than they did in version 47. ### Documentation. + Documented the use of a HSQLDB file-based database so users can try call-caching without needing a database server.; Please checkout [the database documentation](https://cromwell.readthedocs.io/en/stable/Configuring#database). ## 47 Release Notes. ### Retry with more memory on Papiv2 [(#5180)](https://github.com/broadinstitute/cromwell/pull/5180). Cromwell now allows user defined retries. With `memory-retry` config you can specify an array of strings which when encountered in the `stderr`; file by Cromwell, allows the task to be retried with multiplier factor mentioned in the config. More information [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### GCS Parallel Composite Upload Support. Cromwell 47 now supports GCS parallel composite uploads which can greatly improve delocalization performance.; This feature is turned off by default, it can be turned on by either a backend-level configuration setting or; on a per-workflow basis with workflow options. More details [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Papi V2 Localization Using GCR [(#5200)](https://github.com/broadinstitute/cromwell/pull/5200). The Docker image for the Google Cloud SDK was previously only [published on Docker; Hub](https://hub.docker.com/r/google/cloud-sdk). Now that the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPU",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44339,Performance,perform,performance,44339,"he default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call cach",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45636,Performance,cache,cache,45636,"puts improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45729,Performance,cache,cache,45729,"ndencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45938,Performance,cache,cache,45938,"s using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the tim",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48185,Performance,cache,cached-copy,48185,"the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Lar",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:48231,Performance,cache,cached-copy,48231,"please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Originally, the path to the config was `services.Instrumentation.config.statsd`; which now has been updated to `services.Instrumentation.config`. More info on its configuration can be found; [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### cached-copy. A new experimental feature, the `cached-copy` localization strategy is available for the shared filesystem.; More information can be found in the [documentation on localization](https://cromwell.readthedocs.io/en/stable/backends/HPC). #### Yaml node limits. Yaml parsing now checks for cycles, and limits the maximum number of parsed nodes to a configurable value. It also; limits the nesting depth of sequences and mappings. See [the documentation on configuring; YAML](https://cromwell.readthedocs.io/en/stable/Configuring/#yaml) for more information. ### API Changes. #### Workflow Metadata. * It is now possible to use `includeKey` and `excludeKey` at the same time. If so, the metadata key must match the `includeKey` **and not** match the `excludeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [he",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59916,Performance,cache,cache,59916,"thing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name fo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60517,Performance,cache,cache,60517,"lly adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Lo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60623,Performance,cache,cache,60623,"ze of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60743,Performance,cache,cache-copy-authorization-failure-prefix-blacklisting,60743,"sion 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. T",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61054,Performance,cache,cache,61054,"nd the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61216,Performance,cache,cache,61216,"rlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61592,Performance,queue,queued,61592,"ll cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64484,Performance,cache,cache,64484,"elop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64663,Performance,cache,cache,64663,"equest Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:64674,Performance,cache,cache,64674,"equest Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65343,Performance,cache,cache,65343," `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Cl",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65378,Performance,cache,cache,65378,"ine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI ve",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65576,Performance,cache,cache-hit-path-prefixes,65576,"n for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubw",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65688,Performance,cache,cache,65688,"ed on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:68998,Performance,optimiz,optimization,68998,"hem can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Include/Exclude subworkflows. Cromwell now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; More information can be found at [REST API](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Query workflows by Submission time. Cromwell now supports querying workflows by submission time. This will help find workflows that are submitted but not started yet (i.e. workflows which are; in On Hold state). More information can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Submission time in Workflow Query Response. Submission time of a workflow is now included in WorkflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backe",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69187,Performance,optimiz,optimization,69187,"well now supports excluding subworkflows from workflow query results using the `includeSubworkflows` parameter. By default they are included in the results.; More information can be found at [REST API](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Query workflows by Submission time. Cromwell now supports querying workflows by submission time. This will help find workflows that are submitted but not started yet (i.e. workflows which are; in On Hold state). More information can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Submission time in Workflow Query Response. Submission time of a workflow is now included in WorkflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69243,Performance,optimiz,optimizations,69243,"ludeSubworkflows` parameter. By default they are included in the results.; More information can be found at [REST API](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Query workflows by Submission time. Cromwell now supports querying workflows by submission time. This will help find workflows that are submitted but not started yet (i.e. workflows which are; in On Hold state). More information can be found [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/). #### Submission time in Workflow Query Response. Submission time of a workflow is now included in WorkflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:-----------------",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77035,Performance,load,load,77035,"vel-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77123,Performance,load,load,77123,"vel-metadata-for-a-specified-workflow); will return the up-to-date value. For example, if one previously updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77146,Performance,load,load,77146,"usly updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77474,Performance,load,load-control,77474,"will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. Se",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77522,Performance,load,load,77522,"readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77616,Performance,load,load,77616,"es-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fi",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77845,Performance,load,load,77845,"cala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77996,Performance,queue,queue,77996,"s been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78048,Performance,throughput,throughput,78048,"s been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78073,Performance,queue,queued,78073,"s been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81703,Performance,tune,tuned,81703,"cation mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal con",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:83483,Performance,concurren,concurrent,83483,"ilable under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurrent jobs for any backend. Previously this was only possible in some backend implementations. Please see the [README](https://github.com/broadinstitute/cromwell#backend-job-limits) for details. ### WDL. * **Optional WDL variables**; Empty optional WDL values are now rendered as the `null` JSON value instead of the JSON string `""null""` in the metadata and output endpoints. You do not need to migrate previous workflows. Workflows run on Cromwell 28 and prior will still render empty values as `""null""`. * **Empty WDL variables**; Cromwell now accepts `null` JSON values in the input file and coerces them as an empty WDL value. WDL variables must be declared optional in order to be supplied with a `null` JSON value. input.json; ```json; {; ""null_input_values.maybeString"": null,; ""null_input_values.arrayOfMaybeInts"": [1, 2, null, 4]; }; ```. workflow.wdl; ```; workflow null_input_values {; String? maybeString; Array[Int?] arrayOfMaybeInts; }; ```. ## 28. ### Bug Fixes. #### ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:87657,Performance,cache,cache,87657,"fferential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:88058,Performance,cache,cached,88058,"oved in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:88610,Performance,cache,cached,88610,"o specify the desired behavior of Cromwell regarding call outputs when a call finds a hit in the cache.; The default value is `copy` which will copy all output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HAS",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:88765,Performance,cache,cached,88765,"ll output files to the new call directory.; A second value is allowed, `reference`, that will instead point to the original output files, without copying them. ```hocon; filesystems {; gcs {; auth = ""application-default"". caching {; duplication-strategy = ""reference""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the prop",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:89095,Performance,cache,cached,89095," the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `dr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:94278,Performance,throttle,throttle,94278,"as an array of JSON objects each representing a failure. Each failure will have a message and a causedBy field. The causedBy field will be an array of similar failure objects. An example is given below:. ```; failures: [{; message: ""failure1"",; causedBy: [{; message: ""cause1"",; causedBy: []; }, {; message: ""cause2"",; causedBy: []; }]; }, {; message: ""failure2"",; causedBy: []; }]; ```. ### Additional Upgrade Time. * Upgrading to Cromwell 26 will take additional time due to the migration of failure metadata. Cromwell will automatically run a database query during the upgrade which appears to be roughly linear to the number of rows in the METADATA_ENTRY table. You can estimate upgrade time using the following equation: `time to migrate (in seconds) ~= (rows in METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95065,Performance,cache,cache,95065," METADATA_ENTRY) / 65000` Note that due to differences in hardware and database speed, this is only a rough estimate. ### Config Changes. * Added a configuration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, def",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96193,Performance,scalab,scalability,96193,"imple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:97879,Performance,cache,cache,97879,"array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99506,Performance,tune,tune,99506,"he job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes eac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99684,Performance,cache,cache-results,99684,"ble to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99752,Performance,cache,cached,99752,"gine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99806,Performance,cache,cache,99806,"gine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104391,Performance,scalab,scalability,104391," give the ability to name workflow outputs. For consistency reasons, Cromwell will generate a ""new syntax"" workflow output for each task output, and name them.; Their name will be generated using their FQN, which would give. ```; output {; String w.t.out1 = t.out1; String w.t.out2 = t.out2; }; ```. However as the FQN separator is `.`, the name itself cannot contain any `.`.; For that reason, `.` are replaced with `_` :. *Old syntax expanded to new syntax*; ```; output {; String w_t_out1 = t.out1; String w_t_out2 = t.out2; }; ```. The consequence is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106361,Performance,concurren,concurrent,106361,"heck-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106539,Performance,concurren,concurrent-job-limit,106539,"kflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""crom",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:106874,Performance,perform,performance,106874,"NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. ## 0.21. * Warning: Significant database updates when you switch from version 0.19 to 0.21 of Cromwell.; There may be a long wait period for the migration to finish for large databases.; Please refer to MIGRATION.md for more details. * There are significant architectural changes related to increases in performance and scaling. * The biggest user-facing changes from 0.19 to 0.21 are related to the application.conf file, which has been restructured significantly.; The configuration for backends now is all contained within a `backend` stanza, which specifies 1 stanza per name per backend and a default backend, as follows:. ```; backend {; default=Local; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; ... backend specific config ...; }; }; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ... backend specific config ...; }r; }; }; }; ```; * A new `/stats` endpoint has been added to get workflow and job count for a Cromwell running in server mode. * Renamed Workflow Options:; “workflow_log_dir” -> “final_workflow",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:1235,Safety,recover,recover,1235,"austion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets co",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9124,Safety,abort,abort,9124," |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:15676,Safety,safe,safely,15676,"pecified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Cromwell 81 we will populate the `tags` field of tasks created by the TES backend; with the labels applied to the workflow at creation time. No guarantee is made about labels; added while the workflow is running. ### Alibaba BCS backend and OSS filesystem removed. The BCS backend and OSS filesystem (both of which support Alibaba Cloud) have been removed. ## 80 Release Notes. ### Direct WES support in Cromwell. Cromwell 80 no longer supports the wes2cromwell project within the Cromwell repository. In the previous release, 3 Wes2Cromwell endpoints in the Cromwell project were implemented and documented in the Swagger API. Three new endpoints,; located within the wes2cromwell project, will also be moved, implemented, and documented within Cromwell. As a result of this, we can safely remove; and deprecate the wes2cromwell project from the repo. Previous endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. Newly implemented endpoints:. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |-----------------|; | GET | /api/ga4gh/wes/v1/runs | List workflows |; | POST | /api/ga4gh/wes/v1/runs | Submit workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id} | Workflow details |. ## 79 Release Notes. ### Last release with CWL support. Cromwell 79 is the last release with CWL. Support will be removed in Cromwell 80 and above. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https:/",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:18367,Safety,detect,detects,18367,"endpoints are now documented in the Cromwell Swagger (others to follow as part of later work):. | HTTP verb | Endpoint path | Description |; | --------- | ------------- |---------------|; | GET | /api/ga4gh/wes/v1/service-info | Server info |; | POST | /api/ga4gh/wes/v1/runs/{run_id}/cancel | Abort workflow |; | GET | /api/ga4gh/wes/v1/runs/{run_id}/status | Workflow status |. ### Scala 2.13. Cromwell is now built with Scala version 2.13. This change should not be noticeable to users but may be of interest to developers of Cromwell backend implementations. ### Bug Fixes. * Fixed a call caching bug in which an invalid cache entry could cause a valid cache entry to be ignored. ## 75 Release Notes. ### New `AwaitingCloudQuota` backend status. For Cloud Life Sciences v2beta only. When a user's GCP project reaches a quota limit, Cromwell continues to submit jobs and Life Sciences acknowledges them as created even if the physical VM cannot yet start. Cromwell now detects this condition in the backend and reports `AwaitingCloudQuota`. The status is informational and does not require any action. Users wishing to maximize throughput can use `AwaitingCloudQuota` as an indication they should check quota in Cloud Console and request a quota increase from GCP. `AwaitingCloudQuota` will appear between the `Initializing` and `Running` backend statuses, and will be skipped if not applicable. Now:. | Status in metadata |Quota normal| Quota delay | Status meaning |; |--------------------|----|----------------------|---------------------------------------------------|; | `executionStatus` |`Running`| `Running` | Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`| `AwaitingCloudQuota` | Job state reported by backend |. Previously:. | Status in metadata |Quota normal|Quota delay| Status meaning |; |--------------------|----|----|-----------------------------------------------------------|; | `executionStatus` |`Running`|`Running`| Job state Cromwell is requ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:20043,Safety,detect,detected,20043,"te Cromwell is requesting from the backend |; | `backendStatus` |`Running`| `AwaitingCloudQuota` | Job state reported by backend |. Previously:. | Status in metadata |Quota normal|Quota delay| Status meaning |; |--------------------|----|----|-----------------------------------------------------------|; | `executionStatus` |`Running`|`Running`| Job state Cromwell is requesting from the backend |; | `backendStatus` |`Running`|`Running`| Job state reported by backend |. ### New 'requestedWorkflowId' API Option. Allows users to choose their own workflow IDs at workflow submission time. If supplied for single workflows, this value must be a JSON string containing a valid, and not already used, UUID. For batch submissions, this value must be a JSON array of valid UUIDs. If not supplied, the behavior is as today: Cromwell will generate a random workflow ID for every workflow submitted. ### Bug Fixes. * Fixed a bug on Google Pipelines API backends where missing optional output files (`File?`) were not correctly detected by Cromwell and caused invalid call cache entries to be written. ## 73 Release Notes. ### Workflow Restart Performance Improvements. Cromwell now allows for improved performance restarting large workflows through the use of a separate rate limiter for restart checks than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:29806,Safety,recover,recover,29806,"nwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta. Cromwell now offers support for the use of Docker image caches on the PAPI v2 lifesciences beta backend. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#docker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog fac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35047,Safety,abort,abort,35047,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:35119,Safety,abort,aborted,35119,"ity documentation](; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#singularity). ### Google library upgrade [(#5565)](https://github.com/broadinstitute/cromwell/pull/5565). All previous versions of Cromwell shipped with Google Cloud Storage (GCS) libraries that are now deprecated and will [stop working in August 2020](https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html). This release adopts updated libraries to ensure uninterrupted operation. The only user action required is upgrading Cromwell. ### Bug fixes. * Fixed a bug that required Cromwell to be restarted in order to pick up DNS changes.; * By default, the JVM caches DNS records with a TTL of infinity.; * Cromwell now configures its JVM with a 3-minute TTL. This value can be customized by setting `system.dns-cache-ttl`.; * Clarified an error message that Cromwell emits when the compute backend terminates a job of its own volition (as opposed to termination in response to an abort request from Cromwell); * Previously, the error read `The job was aborted from outside Cromwell`; * The new error reads `The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.`. ## 51 Release Notes. ### Changes and Warnings. The configuration format for call cache blacklisting has been updated, please see the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching) for details. ### Bug fixes. * Fixed a bug where the `size(...)` function did not work correctly on files; from a shared filesystem if `size(...)` was called in the input section on a; relative path.; + Fixed a bug where the `use_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS bucket",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44088,Safety,detect,detects,44088,"the image is [publicly hosted in; GCR](http://gcr.io/google.com/cloudsdktool/cloud-sdk), Papi V2 jobs will localize inputs and delocalize outputs using; the GCR image. ## 46 Release Notes. ### Nvidia GPU Driver Update. The default driver for Nvidia GPU's on Google Cloud has been updated from `390` to `418.87.00`. A user may override this option at anytime by providing the `nvidiaDriverVersion` runtime attribute. See the [Runtime Attribute description for GPUs](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#runtime-attribute-descriptions) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:49919,Safety,timeout,timeout,49919,"udeKey` to be included.; * It is now possible to use ""`calls`"" as one of your `excludeKey`s, to request that only workflow metadata gets returned. ### PostgreSQL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AW",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:50106,Safety,timeout,timeouts,50106,"QL support. Cromwell now supports PostgreSQL (version 9.6 or higher, with the Large Object; extension installed) as a database backend.; See [here](https://cromwell.readthedocs.io/en/stable/Configuring/#database) for; instructions for configuring the database connection. ## 42 Release Notes. ### Womtool endpoint. The `/describe` endpoint now differentiates between an invalid workflow and a valid workflow with invalid inputs. Specifically, the new `validWorkflow` key indicates whether the workflow file is valid by itself. If inputs are provided, they are not considered when calculating this field; if inputs are not provided, the value is identical to `valid`. ### Configuration Changes. * Virtual private networks can now be configured. See the section below for details. #### Batch Request Timeouts. The timeout on Cromwell's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings u",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60083,Safety,abort,abort,60083,"uld cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes genera",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60195,Safety,abort,abort,60195,"eturning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previous",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60315,Safety,abort,abort,60315,"s of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60486,Safety,abort,abort-configuration,60486,"e information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### C",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61697,Safety,safe,safety,61697,".readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62119,Safety,timeout,timeout-seconds,62119,"shes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first wr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62196,Safety,timeout,timeout,62196,"shes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first wr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62880,Safety,abort,aborted,62880,"ngine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metad",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63380,Safety,timeout,timeout-seconds,63380,"idation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.r",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63520,Safety,timeout,timeout,63520,"hould not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draf",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63734,Safety,redund,redundant,63734,"purious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63794,Safety,redund,redundant,63794,"ll/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81850,Safety,timeout,timeouts,81850,"w authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81946,Safety,timeout,timeouts,81946,"w authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82041,Safety,timeout,timeout,82041," refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96009,Safety,timeout,timeout,96009," All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) =",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:96076,Safety,timeout,timeout,96076,"esult`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of internal metadata events. Note that one must add `rewriteBatchedStatements=true` to their JDBC URL in their config in order to take advantage of this. ### General Changes. * Cromwell's WDL parser now recognizes empty array literals correctly, e.g. `Array[String] emptyArray = []`.; * Cromwell now applies default labels automatically to JES pipeline runs.; * Added support for new WDL functions:; * `length: (Array[X]) => Integer` - report the length of the specified array; * `prefix: (String, Array[X]) => Array[String]` - generate an array consisting of each element of the input array prefixed; by a specified `String`. The input array can have elements of any primitive type, the return array will always have; type `Array[String]`.; * `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all oth",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:100494,Safety,abort,abort-jobs-on-terminate,100494,"h polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - align items in the two arrays by index and return them as WDL pairs; * `cross: (Array[X], Array[Y]) => Array[Pair[X, Y]]` - create every possible pair from the two input arrays and return them all as WDL pairs; * `transpose: (Array[Array[X]]) => Array[Array[X]]` compute the matrix transpose for a 2D array. Assumes each inner array has the same length.; * By default, `system.abort-jobs-on-terminate` is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <wdl> <inputs>`.; * Enable WDL imports when running in Single Workflow Runner Mode.; * Both batch and non-batch REST workflow submissions now require a multipart/form-data encoded body.; * Support for sub workflows (see [Annex A](#annex-a---workflow-outputs)); * Enable WDL imports when running in Single Workflow Runner Mode as well as Server Mode; * Support for WDL imports through an additional imports.zip parameter; * Support for sub workflows; * Corrected file globbing in JES to correctly report all generated files. Additionally, file globbing in JES now uses bash-style glob syntax instead of python style glob syntax; * Support declarations as graph nodes; * Added the ability to override the default service account that the compute VM is started with via the configuration option `JES.config.genomics.compute-service-account` or through the workflow options parameter `google_compute_service_",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4505,Security,authenticat,authenticated,4505,"otspot in Cromwell to make the `size()` engine function perform much faster on file arrays. Common examples of file arrays could include globs or scatter-gather results. This enhancement applies only to WDL 1.0 and later, because that's when `size()` added [support for arrays](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#acceptable-compound-input-types). #### Fixed Optional and String Concatenation Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:7736,Security,checksum,checksum,7736,"l/7389)). ### `upgrade` command removed from Womtool. Womtool previously supported a `womtool upgrade` command for upgrading draft-2 WDLs to 1.0. With WDL 1.1 soon to ; become the latest supported version, this functionality is retiring. ([#7382](https://github.com/broadinstitute/cromwell/pull/7382)). ### Replacement of `gsutil` with `gcloud storage`. In this release ([#7359](https://github.com/broadinstitute/cromwell/pull/7359)), all **localization** functionality on the GCP backend migrates to use the more modern and performant `gcloud storage`. With sufficiently powerful worker VMs, Cromwell can now localize at up to 1200 MB/s [0][1][2]. In a future release, **delocalization** will also migrate to `gcloud storage`. As part of that upcoming change, we are considering turning on [parallel composite uploads](https://cromwell.readthedocs.io/en/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:8584,Security,hash,hashes,8584,"n/stable/backends/Google/#parallel-composite-uploads) by default to maximize performance. Delocalized composite objects will no longer have an md5 checksum in their metadata; refer to the matrix below [3]. If you have compatibility concerns for your workflow, please [submit an issue](https://github.com/broadinstitute/cromwell/issues). | Delocalization Strategy | Performance | crc32c | md5 |; |-------------------------|---------------|--------|-----|; | Classic | Baseline/slow | ✅ | ✅ |; | Parallel Composite | Fast | ✅ | ❌ |. [0] Tested with Intel Ice Lake CPU platform, 16 vCPU, 32 GB RAM, 2500 GB SSD. [1] [Throughput scales with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9733,Security,secur,security,9733,"g forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encoun",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:13719,Security,secur,security,13719,"emain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the reque",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:13866,Security,access,access,13866,"* Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google Cloud Storage I/O error.; * Response code `400` bad request, message `User project specified in the request is invalid`; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 81 Release Notes. ### Workflow labels in TES tasks. Beginning in Crom",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:20883,Security,secur,security,20883,"workflow submitted. ### Bug Fixes. * Fixed a bug on Google Pipelines API backends where missing optional output files (`File?`) were not correctly detected by Cromwell and caused invalid call cache entries to be written. ## 73 Release Notes. ### Workflow Restart Performance Improvements. Cromwell now allows for improved performance restarting large workflows through the use of a separate rate limiter for restart checks than the rate limiter used for starting new jobs.; The restart check rate limiter is pre-configured in Cromwell's bundled [reference.conf](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); see the `job-restart-check-rate-control` stanza in that file for explanations of the various parameters if adjustments are desired. ## 71 Release Notes. ### Bug Fixes. * Fixed an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Pr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:21721,Security,secur,security,21721," an issue handling data in Google Cloud Storage buckets with requester pays enabled that could sometimes cause I/O to fail. ## 70 Release Notes. ### CWL security fix [#6510](https://github.com/broadinstitute/cromwell/pull/6510). Fixed an issue that could allow submission of an untrusted CWL file to initiate remote code execution. The vector was improper deserialization of the YAML source file. CWL execution is enabled by default unless a `CWL` [stanza](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L460-L482) is present in the configuration that specifies `enabled: false`. Cromwell instances with CWL disabled were not affected. Consequently, users who wish to mitigate the vulnerability without upgrading Cromwell may do so via this config change. - Thank you to [Bruno P. Kinoshita](https://github.com/kinow) who first found the issue in a different CWL project ([CVE-2021-41110](https://github.com/common-workflow-language/cwlviewer/security/advisories/GHSA-7g7j-f5g3-fqp7)) and [Michael R. Crusoe](https://github.com/mr-c) who suggested we investigate ours. ## 68 Release Notes. ### Virtual Private Cloud. Previous Cromwell versions allowed PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The def",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:22941,Security,hash,hash-batch-size,22941,"ubnetwork inside a private network by adding the; information to Google Cloud project labels. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the network and; subnetwork name directly inside the `virtual-private-cloud` backend configuration. More info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (G",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23832,Security,hash,hash-lookup,23832," parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23891,Security,hash,hash-lookup,23891,"iously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://c",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24042,Security,hash,hash-lookup,24042,"0`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:24186,Security,hash,hash-lookup,24186,"o.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this versio",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25011,Security,authenticat,authentication,25011,"sitories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:25066,Security,authenticat,authentication,25066,"onds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell's bundled; [`reference.conf`](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf); for more details. ## 65 Release Notes. * An additional set of metrics relating to metadata age were added. ### AMD Rome support on PAPI v2; On the PAPI v2 backends ""AMD Rome"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 64 Release Notes. ### Intel Cascade Lake support on PAPI v2. On the PAPI v2 backends ""Intel Cascade Lake"" is now supported as a CPU platform. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#cpuplatform). ## 63 Release Notes. ### Removed refresh token authentication mode. Google Pipelines API v1 supported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 Ho",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:26748,Security,access,accessible,26748,"adata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:27004,Security,access,accessing,27004,"romwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. Internal CI-related changes only. ## 57 Release Notes. ### Breaking configuration change to reference disk support on PAPI v2. Beginning with Cromwell 57, reference disk manifests are now specified completely within Cromwell configuration; rather than through a level of indirection to a manifest file stored in GCS. More details can be found; [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). ## 56 Release Notes. ### Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be foun",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:28472,Security,access,access,28472," Retry with More Memory as workflow option. The experimental memory retry feature gains per-workflow customization and includes breaking changes:; * The per-backend configuration key `<backend>.config.memory-retry.error-keys` has been removed and replaced; with global key `system.memory-retry-error-keys`; * The per-backend configuration key `<backend>.config.memory-retry.multiplier` has been replaced with **workflow option**; `memory_retry_multiplier`. More details can be found [here](https://cromwell.readthedocs.io/en/develop/wf_options/Overview.md#retry-with-more-memory-multiplier). ### Bug Fixes. * Fixed a bug that caused Cromwell to mark workflows as failed after a single `500`, `503`, or `504` error from Google Cloud Storage.; * Cromwell will now retry these errors as designed.; * The default retry count is `5` and may be customized with `system.io.number-of-attempts`. ## 55 Release Notes. ### Apple Silicon support statement. Users with access to the new Mac hardware should review [important information provided here](https://cromwell.readthedocs.io/en/stable/Releases). ### Bug Fixes. * Fixed a bug that prevented `read_json()` from working with arrays and primitives. The function now works as expected for all valid JSON data inputs.; More information on JSON Type to WDL Type conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). * Now retries HTTP 408 responses as well as HTTP 429 responses during DOS/DRS resolution requests. * Fixed a bug that prevented the call caching diff endpoint from working with scatters in workflows with archived metadata. ### New Features. #### Reference disk support on PAPI v2. Cromwell now offers support for the use of reference disks on the PAPI v2 backend as an alternative to localizing; reference inputs. More details [here](https://cromwell.readthedocs.io/en/develop/backends/Google#reference-disk-support). #### Docker image cache support on PAPI v2 lifesciences beta",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:36831,Security,hash,hashing,36831,"_relative_output_paths` option would not preserve intermediate folders. ### New functionality. #### Call caching blacklisting improvements. Cromwell previously supported blacklisting GCS buckets containing cache hits which could not be copied for permissions; reasons. Cromwell now adds support for blacklisting individual cache hits which could not be copied for any reason,; as well as grouping blacklist caches according to a workflow option key. More information available in the [; call caching documentation]( https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). #### new xxh64 and fingerprint strategies for call caching. Existing call cache strategies `path` and `path+modtime` don't work when using docker on shared filesystems; (SFS backend, i.e. not in cloud storage). The `file` (md5sum) strategy works, but uses a lot of resources.; Two faster strategies have been added for this use case: `xxh64` and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud S",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44934,Security,validat,validate,44934,"o complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/Cal",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53467,Security,validat,validated,53467,"the new configuration value `system.workflow-heartbeats.write-failure-shutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:53535,Security,validat,validation,53535,"hutdown-duration` must also be explicitly; set less than the `ttl`. #### nVidia Driver Attribute Change. The runtime attribute `nvidia-driver-version` was previously allowed only as a default runtime attribute in configuration.; Because WDL does not allow attribute names to contain `-` characters, this has been changed to `nvidiaDriverVersion`.; This field is now accepted within WDL files as well as within the configuration file. #### Logging long running jobs. All backends can now emit slow job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration h",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54030,Security,validat,validation,54030,"low job warnings after a configurable time running.; NB This example shows how to configure this setting for the PAPIv2 backend:; ```conf; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck.; backend {; providers {; PAPIv2 {; config {; slow-job-warning-time: 24 hours; }; }; }; }; ```. ### Runtime Attributes. #### GPU Attributes. * The `gpuType` attribute is no longer validated against a whitelist at workflow submission time. Instead, validation now happens at runtime. This allows any valid accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59935,Security,hash,hashing,59935,"thing. The previous health service implementation is still; available as `StandardHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name fo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:59966,Security,hash,hashes,59966,"rdHealthMonitorServiceActor`. ### Bug fixes; - Fixed an issue that could cause Cromwell to consume disk space unnecessarily when using zipped dependencies. #### HTTP responses. - When returning errors as json the `Content-Type` header is set to `application/json`. ## 37 Release Notes. ### Docker. - Adds support for retrieving docker digests of asia.gcr.io images; - Adds configuration settings for docker digest lookups. See the `docker` section of the `reference.conf` for more information; - Attempt to automatically adjust the boot disk size on the Google Cloud Backend (version 2) if the size of the image is greater than the default disk size or the required disk size in the runtime attributes.; Only works for registries that support the version 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:60754,Security,authoriz,authorization-failure-prefix-blacklisting,60754,"sion 2 of the manifest schema (https://docs.docker.com/registry/spec/manifest-v2-2/); At this date (12/09/18) this includes GCR and Dockerhub. ### Added new call cache path+modtime hashing strategy. Call caching hashes with this new strategy are based on the path and the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. T",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61060,Security,hash,hashes,61060,"nd the last modified time of the file. ### Instance independent abort. For multi-instance Cromwell deployments sharing a single database, earlier versions of Cromwell required abort; requests to be sent specifically to the instance that was running the targeted workflow. Cromwell 37 now; allows abort commands to be sent to any Cromwell instance in the shared-database deployment. Configuration details; [here](https://cromwell.readthedocs.io/en/develop/Configuring/abort-configuration). ### Call cache blacklisting. The Google Pipelines API (PAPI) version 1 and 2 backends now offer the option of call cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:62394,Security,validat,validation,62394," caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63565,Security,encrypt,encrypted,63565," ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.com/broadinstitute/cromwell/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65631,Security,hash,hash,65631,"n of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65699,Security,hash,hashes,65699,"ed on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:65813,Security,hash,hash-caching,65813,"upport for the `version draft-3` identifier in this release. In the rare case where end users may have been using `version draft-3`, `version 1.0` is a drop-in replacement with no effect on functionality. ### HTTP Workflow Inputs for Shared File System and Google Pipelines API Version 2 Backends. `http` and `https` workflow inputs are now supported for shared filesystem and Google Pipelines API (PAPI) version 2; backends. Configuration details are described [here](http://cromwell.readthedocs.io/en/develop/filesystems/HTTP). ### Call cache hint support. More efficient cache hit copying in multi-user environments is now supported through the `call_cache_hit_path_prefixes` workflow option.; Details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-hit-path-prefixes). ### Root workflow level file hash caching support. Cromwell now offers the ability to cache file hashes on a root workflow level basis, details [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#file-hash-caching). ### Extra configuration options. The value `dockerRoot` can now be set in a backend configuration.; This will set the execution folder in the container (default: `/cromwell-executions`). ### Bug Fixes. #### API; - The `releaseHold` endpoint will now return `404 Not Found` for an unrecognized workflow ID and `400 Bad Request` for a malformed or invalid workflow ID. #### Languages. - Fixed a bug that allowed values to be ""auto-boxed"" into a single-element `Array` of that type, which is not allowed in the WDL spec (Closes [#3478](https://github.com/broadinstitute/cromwell/issues/3478)). #### PAPI version 1. - Restored standard output and error streaming for jobs. ## 34 Release Notes. ### Query API. * Fixes a bug which stopped `includeSubworkflow=false` from paging correctly and subworkflows from being discounted correctly from `totalResultsCount`.; * Query results will now be returned in reverse chronological order, with the most-recently submitted workflows return",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69703,Security,authenticat,authentication,69703,"o/en/develop/api/RESTAPI/). #### Submission time in Workflow Query Response. Submission time of a workflow is now included in WorkflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:71768,Security,validat,validate,71768,"o a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing the classes into your own scala project, make sure you are using Scala 2.12. ### Input Validation; Cromwell can now validate that your inputs files do not supply inputs with no impact on the workflow. Strict validation will be disabled by default in WDL draft 2 and CWL but enabled in WDL draft 3. See the 'Language Factory Config' below for details. ### Language Factory Config; All language factories can now be configured on a per-language-version basis. All languages and versions will support the following options:; * `enabled`: Defaults to `true`. Set to `false` to disallow workflows of this language and version.; * `strict-validation`: Defaults to `true` for WDL draft 3 and `false` for WDL draft 2 and CWL. Specifies whether workflows fail if the inputs JSON (or YAML) file contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked u",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:71860,Security,validat,validation,71860," WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing the classes into your own scala project, make sure you are using Scala 2.12. ### Input Validation; Cromwell can now validate that your inputs files do not supply inputs with no impact on the workflow. Strict validation will be disabled by default in WDL draft 2 and CWL but enabled in WDL draft 3. See the 'Language Factory Config' below for details. ### Language Factory Config; All language factories can now be configured on a per-language-version basis. All languages and versions will support the following options:; * `enabled`: Defaults to `true`. Set to `false` to disallow workflows of this language and version.; * `strict-validation`: Defaults to `true` for WDL draft 3 and `false` for WDL draft 2 and CWL. Specifies whether workflows fail if the inputs JSON (or YAML) file contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:72285,Security,validat,validation,72285,"abels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing the classes into your own scala project, make sure you are using Scala 2.12. ### Input Validation; Cromwell can now validate that your inputs files do not supply inputs with no impact on the workflow. Strict validation will be disabled by default in WDL draft 2 and CWL but enabled in WDL draft 3. See the 'Language Factory Config' below for details. ### Language Factory Config; All language factories can now be configured on a per-language-version basis. All languages and versions will support the following options:; * `enabled`: Defaults to `true`. Set to `false` to disallow workflows of this language and version.; * `strict-validation`: Defaults to `true` for WDL draft 3 and `false` for WDL draft 2 and CWL. Specifies whether workflows fail if the inputs JSON (or YAML) file contains values which the workflow did not ask for (and will therefore have no effect). Additional strict checks may be added in the future. ### API. * More accurately returns 503 instead of 500 when Cromwell can not respond in a timely manner; * Cromwell now allows a user to submit a workflow but in a state where it will not automatically be picked up for execution. This new state is called 'On Hold'. To do this you need to set the parameter workflowOnHold to true while submitting the workflow.; * API end point 'releaseHold' will allow the user to send a signal to Cromwell to allow a workflow to be startable, at which point it will be picked up by normal execution schemes. ### GPU. The PAPI backend now supports specifying GPU through WDL runtime attributes:. ```wdl; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; zones: [""us-central1-c""]; }; ```. The two types of GP",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78243,Security,hash,hash-lookup,78243,"from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://cromwell.readthedocs.io/en/develop/). There are new [Tutorials](http://cromwell.readthedocs.io/en/develop/tutorials/FiveMinuteIntro/) and much of the documentation has been re-written. Th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:78282,Security,hash,hash,78282,"he system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks it has left. * Added a configuration option under `docker.hash-lookup.enabled` to disable docker hash lookup.; Disabling it will also disable call caching for jobs with floating docker tags. * **API**; + Updated the `/query` response to include the total number of query results returned. See [here](http://cromwell.readthedocs.io/en/develop/api/RESTAPI/#workflowqueryresponse) for more information. ## 30.1 Release Notes. * A set of bug fixes following the migration of Cromwell to WOM (the Workflow Object Model) in version 30. ## 30 Release Notes. ### Breaking changes. * The `customLabels` form field for workflow submission has been renamed to `labels`. ### Other changes. * **New Cromwell documentation**; Our documentation has moved from our [README](https://github.com/broadinstitute/cromwell/blob/29_hotfix/README.md) to a new website: [Cromwell Documentation](http://cromwell.readthedocs.io/en/develop/). There are new [Tutorials](http://cromwell.readthedocs.io/en/develop/tutorials/FiveMinuteIntro/) and much of the documentation has been re-written. The source files are in the ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:80715,Security,authenticat,authentication,80715,"in a separate SQL database than the database containing the internal engine; data. When switching connection information for an existing database containing historical data, the tables; should be manually replicated from one database instance to another using the tools appropriate for your specific; database types. Cromwell will not move any existing data automatically. This feature should be considered experimental; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:80927,Security,authenticat,authentication,80927,"orical data, the tables; should be manually replicated from one database instance to another using the tools appropriate for your specific; database types. Cromwell will not move any existing data automatically. This feature should be considered experimental; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now re",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81022,Security,authenticat,authentication,81022,"our specific; database types. Cromwell will not move any existing data automatically. This feature should be considered experimental; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Serv",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:81174,Security,encrypt,encrypted-fields,81174,"ntal; and likely to change in the future. See the [Database Documentation](https://cromwell.readthedocs.io/en/develop/Configuring/#database) or the `database` section in; [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf) for more; information. * **StatsD**; Added initial support for StatsD instrumentation. See the [Instrumentation Documentation](https://cromwell.readthedocs.io/en/develop/Instrumentation) for details on how to use it. * **User Service Account auth mode for Google**; Added a new authentication mode for [Google Cloud Platform](https://cromwell.readthedocs.io/en/develop/backends/Google) which will allow a user to supply the JSON key file in their workflow options to allow for per-workflow authentication via service account. This is analogous to the previously existing refresh token authentication scheme. As with the refresh token scheme it is encouraged that the **user_service_account_json** workflow option field is added to the **encrypted-fields** list in the configuration. * **Bugfixes**; Abort of Dockerized tasks on the Local backend should now work as expected. Cromwell uses `docker kill` to kill the Docker container. ## 29 Release Notes. ### Breaking Changes. * **Command line**; In preparation for supporting CWL scripts (yes, you read that right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The res",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:82562,Security,authenticat,authentication,82562,"hat right!), we have extensively revised the Command Line in Cromwell 29. For more details about the usage changes please see the [README](https://github.com/broadinstitute/cromwell#command-line-usage). And stay tuned to the [WDL/Cromwell blog](https://software.broadinstitute.org/wdl/blog) over the next couple of months for more news about CWL. * **Request timeouts**; Cromwell now returns more specific `503 Service Unavailable` error codes on request timeouts, rather than the more generic `500 Internal Server Error`. The response for a request timeout will now be plain text, rather than a JSON format. * **Metadata endpoint**; The response from the metadata endpoint can be quite large depending on your workflow. You can now opt-in to have Cromwell gzip your metadata file, in order to reduce file size, by sending the `Accept-Encoding: gzip` header. The default behavior now does not gzip encode responses. * **Engine endpoints**; Previously the engine endpoints were available under `/api/engine` but now the endpoints are under `/engine` so they don't require authentication. Workflow endpoints are still available under `/api/workflows`. We also deprecated the setting `api.routeUnwrapped` as a part of this internal consistency effort. * **Call caching diff**; We updated the response format of the [callcaching/diff](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) endpoint. ### Other changes. * **Cromwell server**; When running in server mode, Cromwell now attempts to gracefully shutdown after receiving a `SIGINT` (`Ctrl-C`) or `SIGTERM` (`kill`) signal. This means that Cromwell waits for all pending database writes before exiting, as long as you include `application.conf` at the top of your config file. You can find detailed information about how to configure this feature in the [Cromwell Wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#graceful-server-shutdown). * **Concurrent jobs**; You can now limit the number of concurren",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:86006,Security,hash,hash,86006,"le` will now successfully reach a terminal state once all runnable jobs have completed.; #### `FailOnStderr`; When `FailOnStderr` is set to false, Cromwell no longer checks for the existence of a stderr file for that task. ### WDL Functions. #### New functions: floor, ceil and round:. Enables the `floor`, `ceil` and `round` functions in WDL to convert floating point numbers to integers. For example we can now use the size of an input file to influence the amount of memory the task is given. In the example below a 500MB input file will result in a request for a VM with 2GB of memory:. ```; task foo {; File in_file; command { ... }; runtime {; docker: ""...""; memory: ceil(size(in_file)) * 4; }; }; ```. ### Call Caching. * Hash values calculated by Cromwell for a call when call caching is enabled are now published to the metadata.; It is published even if the call failed. However if the call is attempted multiple times (because it has been preempted for example),; since hash values are strictly identical for all attempts, they will only be published in the last attempt section of the metadata for this call.; If the hashes fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromw",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:86154,Security,hash,hashes,86154,"e of a stderr file for that task. ### WDL Functions. #### New functions: floor, ceil and round:. Enables the `floor`, `ceil` and `round` functions in WDL to convert floating point numbers to integers. For example we can now use the size of an input file to influence the amount of memory the task is given. In the example below a 500MB input file will result in a request for a VM with 2GB of memory:. ```; task foo {; File in_file; command { ... }; runtime {; docker: ""...""; memory: ceil(size(in_file)) * 4; }; }; ```. ### Call Caching. * Hash values calculated by Cromwell for a call when call caching is enabled are now published to the metadata.; It is published even if the call failed. However if the call is attempted multiple times (because it has been preempted for example),; since hash values are strictly identical for all attempts, they will only be published in the last attempt section of the metadata for this call.; If the hashes fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:86214,Security,hash,hashFailures,86214,"e of a stderr file for that task. ### WDL Functions. #### New functions: floor, ceil and round:. Enables the `floor`, `ceil` and `round` functions in WDL to convert floating point numbers to integers. For example we can now use the size of an input file to influence the amount of memory the task is given. In the example below a 500MB input file will result in a request for a VM with 2GB of memory:. ```; task foo {; File in_file; command { ... }; runtime {; docker: ""...""; memory: ceil(size(in_file)) * 4; }; }; ```. ### Call Caching. * Hash values calculated by Cromwell for a call when call caching is enabled are now published to the metadata.; It is published even if the call failed. However if the call is attempted multiple times (because it has been preempted for example),; since hash values are strictly identical for all attempts, they will only be published in the last attempt section of the metadata for this call.; If the hashes fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:86412,Security,hash,hashes,86412,"umbers to integers. For example we can now use the size of an input file to influence the amount of memory the task is given. In the example below a 500MB input file will result in a request for a VM with 2GB of memory:. ```; task foo {; File in_file; command { ... }; runtime {; docker: ""...""; memory: ceil(size(in_file)) * 4; }; }; ```. ### Call Caching. * Hash values calculated by Cromwell for a call when call caching is enabled are now published to the metadata.; It is published even if the call failed. However if the call is attempted multiple times (because it has been preempted for example),; since hash values are strictly identical for all attempts, they will only be published in the last attempt section of the metadata for this call.; If the hashes fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) f",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:86596,Security,hash,hash,86596,"ith 2GB of memory:. ```; task foo {; File in_file; command { ... }; runtime {; docker: ""...""; memory: ceil(size(in_file)) * 4; }; }; ```. ### Call Caching. * Hash values calculated by Cromwell for a call when call caching is enabled are now published to the metadata.; It is published even if the call failed. However if the call is attempted multiple times (because it has been preempted for example),; since hash values are strictly identical for all attempts, they will only be published in the last attempt section of the metadata for this call.; If the hashes fail to be calculated, the reason is indicated in a `hashFailures` field in the `callCaching` section of the call metadata.; *Important*: Hashes are not retroactively published to the metadata. Which means only workflows run on Cromwell 28+ will have hashes in their metadata. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversionidmetadata) for an example metadata response. * New endpoint returning the hash differential for 2 calls. `GET /api/workflows/:version/callcaching/diff`. See the [README](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff) for more details. ### Workflow Submission. * The workflow submission parameters `wdlSource` and `wdlDependencies` have been deprecated in favor of `workflowSource` and; `workflowDependencies` respectively. The older names are still supported in Cromwell 28 with deprecation warnings but will; be removed in a future version of Cromwell. ### Labels; * A new `/labels` endpoint has been added to update labels for an existing workflow. See the [README](README.md#patch-apiworkflowsversionidlabels) for more information.; * Label formatting requirements have been updated, please check the [README](README.md#label-format) for more detailed documentation. ### JES Backend. The JES backend now supports a `filesystems.gcs.caching.duplication-strategy` configuration entry.; It can be set to specify the desired behavior of Cr",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:90333,Security,password,password,90333,"e you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:90575,Security,hash,hashes,90575,"RY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""l",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:90727,Security,hash,hash,90727,"alue:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a database stanza to; [switch](http://slick.lightbend.com/doc/3.2.0/upgrade.html#profiles-vs-drivers) from using `driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91098,Security,hash,hash,91098,"driver` to `profile`. ```hocon; database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](h",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91202,Security,hash,hash,91202,"QLProfile$"" #new; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ### Call Caching. Cromwell now supports call caching with floating Docker tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91495,Security,hash,hash,91495," tags (e.g. `docker: ""ubuntu:latest""`). Note it is still considered; a best practice to specify Docker images as hashes where possible, especially for production usages. Within a single workflow Cromwell will attempt to resolve all floating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for goo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91717,Security,hash,hash,91717,"loating tags to the same Docker hash, even if Cromwell is restarted; during the execution of a workflow. In call metadata the `docker` runtime attribute is now the same as the; value that actually appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; schem",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:91788,Security,hash,hash,91788,"ally appeared in the WDL:. ```; ""runtimeAttributes"": {; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false"",; ""continueOnReturnCode"": ""0""; }; ```. Previous versions of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:92036,Security,hash,hash,92036,"s of Cromwell rewrote the `docker` value to the hash of the Docker image. There is a new call-level metadata value `dockerImageUsed` which captures the hash of the Docker image actually used to; run the call:. ```; ""dockerImageUsed"": ""library/ubuntu@sha256:382452f82a8bbd34443b2c727650af46aced0f94a44463c62a9848133ecb1aa8""; ```. ### Docker. * The Docker section of the configuration has been slightly reworked; An option to specify how a Docker hash should be looked up has been added. Two methods are available.; ""local"" will try to look for the image on the machine where cromwell is running. If it can't be found, Cromwell will try to `pull` the image and use the hash from the retrieved image.; ""remote"" will try to look up the image hash directly on the remote repository where the image is located (Docker Hub and GCR are supported); Note that the ""local"" option will require docker to be installed on the machine running cromwell, in order for it to call the docker CLI.; * Adds hash lookup support for public [quay.io](https://quay.io/) images. ### WDL Feature Support; * Added support for the new WDL `basename` function. Allows WDL authors to get just the file name from a File (i.e. removing the directory path); * Allows coercion of `Map` objects into `Array`s of `Pair`s. This also allows WDL authors to directly scatter over WDL `Map`s. ### Miscellaneous; * Adds support for JSON file format for google service account credentials. As of Cromwell 27, PEM credentials for PAPI are deprecated and support might be removed in a future version. ```; google {. application-name = ""cromwell"". auths = [; {; name = ""service-account""; scheme = ""service_account""; json-file = ""/path/to/file.json""; }; ]; }; ```. ### General Changes. * The `/query` endpoint now supports querying by `label`. See the [README](README.md#get-apiworkflowsversionquery) for more information.; * The `read_X` standard library functions limit accepted filesizes. These differ by type, e.g. read_bool has a smaller limit",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98026,Security,hash,hash,98026,"* `defined: (Any) => Boolean` - Will return false if the provided value is an optional that is not defined. Returns true in all other cases.; * Cromwell's Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98139,Security,hash,hash,98139," Config (Shared Filesystem) backend now supports invocation of commands which run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`i",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98184,Security,hash,hash,98184,"ich run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as lo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98242,Security,hash,hash,98242,"ich run in a Docker image as a non-root user.; The non-root user could either be the default user for a given Docker image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as lo",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98364,Security,hash,hash,98364," image (e.g. specified in a Dockerfile via a `USER` directive),; or the Config backend could pass an optional `""-u username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98428,Security,hash,hash,98428," username""` as part of the `submit-docker` command.; * In some cases the SFS backend, used for Local, SGE, etc., coerced `WdlFile` to `WdlString` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98563,Security,hash,hashes,98563,"String` by using `.toUri`. This; resulted in strings prepended with `file:///path/to/file`. Now absolute file paths will not contain the uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quota",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:98721,Security,hash,hashes,98721," uri scheme.; * Launch jobs on servers that support the GA4GH Task Execution Schema using the TES backend.; * **Call caching: Cromwell will no longer try to use the cache for WDL tasks that contain a floating docker tag.**; Call caching will still behave the same for tasks having a docker image with a specific hash.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104894,Security,hash,hash,104894,"nded to new syntax*; ```; output {; String w_t_out1 = t.out1; String w_t_out2 = t.out2; }; ```. The consequence is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:104950,Security,hash,hash,104950,"nce is that the workflow outputs section of the metadata for `old_syntax` would previously look like. ```; outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:105123,Security,hash,hashed,105123," outputs {; ""w.t.out1"": ""hello"",; ""w.t.out2"": ""hello""; }; ```. but it will now look like. ```; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input wit",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:105132,Security,hash,hashing-strategy,105132,"`; outputs {; ""w_t_out1"": ""hello"",; ""w_t_out2"": ""hello""; }; ```. The same applies for the console output of a workflow run in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; sp",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:105300,Security,hash,hash,105300,"in single workflow mode. ## 0.22. * Improved retries for Call Caching and general bug fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInpu",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:105381,Security,hash,hashing,105381," fixes.; * Users will experience better scalability of status polling for Google JES.; * Now there are configurable caching strategies for a SharedFileSystem backend (i.e. Local, SFS) in the backend's stanza:; See below for detailed descriptions of each configurable key. ```; backend {; ...; providers {; SFS_BackendName {; actor-factory = ...; config {; ...; filesystems {; local {; localization: [; ...; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""file"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; ```; * Multiple Input JSON files can now be submitted in server mode through the existing submission endpoint: /api/workflows/:version.; This endpoint accepts a POST request with a multipart/form-data encoded body. You can now include multiple keys for workflow inputs. Each key below can contain an optional JSON file of the workflow inputs. A skeleton file can be generated from wdltool using the ""inputs"" subcommand.; NOTE: In case of key conflicts between multiple JSON files, higher values of x in workflowInputs_x override lower values. For example, an input; specified in workflowInputs_3 will override an input with the same name that was given in workflowInputs or workflowInputs_2. Similarly, an input; specified in workflowInputs_5 will override an input with the same name in any other input file. workflowInputs; workflowInputs_2; workflowInputs_3; workflowInputs_4; workflowInputs_5. * You can now limit the n",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109686,Security,password,password,109686,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109971,Security,hash,hash,109971,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:499,Testability,test,tested,499,"# Cromwell Change Log. ## 88 Release Notes. ### New feature: Prevent Job start during Cloud Quota exhaustion. This optional feature prevents Cromwell from starting new jobs in a group that is currently experiencing ; cloud quota exhaustion. Jobs will be started once the group's quota becomes available. To enable this feature, ; set `quota-exhaustion-job-start-control.enabled` to true. ### Java 17. As of this version, a distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). ### Improved status reporting behavior. When Cromwell restarts during a workflow that is failing, it no longer reports pending tasks as a reason for that failure. ### Optional docker soft links. Cromwell now allows opting into configured soft links on shared file systems such as HPC environments. More details can; be found [here](https://cromwell.readthedocs.io/en/stable/backends/HPC/#optional-docker-soft-links). ### GCP Batch. - The `genomics` configuration entry was renamed to `batch`, see [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/backends/GCPBatch/) for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for th",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2064,Testability,log,logs-policy,2064,") for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2167,Testability,log,logs,2167,") for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2216,Testability,log,log,2216,") for more information.; - Fixes a bug with not being able to recover jobs on Cromwell restart.; - Fixes machine type selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardin",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2283,Testability,log,log,2283,"selection to match the Google Cloud Life Sciences backend, including default n1 non shared-core machine types and correct handling of `cpuPlatform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:2442,Testability,log,log,2442,"tform` to select n2 or n2d machine types as appropriate.; - Fixes the preemption error handling, now, the correct error message is printed, this also handles the other potential exit codes.; - Fixes error message reporting for failed jobs.; - Fixes the ""retry with more memory"" feature.; - Fixes the reference disk feature.; - Fixes pulling Docker image metadata from private GCR repositories.; - Fixed `google_project` and `google_compute_service_account` workflow options not taking effect when using GCP Batch backend; - Added a way to use a custom LogsPolicy for the job execution, setting `backend.providers.batch.config.batch.logs-policy` to ""CLOUD_LOGGING"" (default) keeps the current behavior, or, set it to ""PATH"" to save the logs into the the mounted disk, at the end, this log file gets copied to the google cloud storage bucket with ""task.log"" as the name.; - When ""CLOUD_LOGGING"" is used, many more Cromwell / WDL labels for workflow, root workflow, call, shard etc. are now assigned to GCP Batch log entries. ### Improved handling of Life Sciences API quota errors. Users reported cases where Life Sciences jobs failed due to insufficient quota, instead of queueing and waiting until; quota is available (which is the expected behavior). Cromwell will now retry under these conditions, which present with errors; such as ""PAPI error code 9"", ""no available zones"", and/or ""quota too low"". ### Database. #### New table 'GROUP_METRICS_ENTRY'. A new table called `GROUP_METRICS_ENTRY` has been added. The purpose of this table is to track when a group or billing project last ran into Cloud Quota exhaustion. #### Index removal. The `IX_WORKFLOW_STORE_ENTRY_WS` index is removed from `WORKFLOW_STORE_ENTRY`. The index had low cardinality and workflow pickup is faster without it. Migration time depends on workflow store size, but should be very fast for most installations. Terminal workflows are removed from the workflow store, so only running workflows contribute to the cost. ### Bug fi",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:4960,Testability,test,test,4960,"tion Bug. As outlined in the [WDL Spec](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#prepending-a-string-to-an-optional-parameter), concatenating a string with an empty optional now correctly evaluates to the empty string. ### Removals. #### `RESTAPI.md` docs discontinued. Due to deprecation of the underlying library, Markdown docs will no longer be generated from the Cromwell API Swagger. The recommended alternative is starting a server and viewing the Swagger directly. #### Removed Docker Hub health check. Cromwell's healthcheck requests to Docker Hub were not authenticated, and thus became subject to rate limiting. To eliminate these false alarms, this functionality has been removed. The config key `services.HealthMonitor.config.check-dockerhub` is therefore obsolete. There is no change to any other usage of Docker Hub. #### Removed GCS health check. Cromwell's health check of GCS has been removed. GCS does not have availability issues of note, and in typical configurations the check does not meaningfully test Cromwell's permissions. The config keys `services.HealthMonitor.config.check-gcs` and `.gcs-bucket-to-check` are therefore obsolete. #### Removed Genomics Backend code; Code relating to the Google Genomics API (aka `v1Alpha`) has been removed since Google has entirely disabled that service.; Cloud Life Sciences (aka `v2Beta`, deprecated) and Google Batch (aka `batch`, recommended) remain the two viable GCP backends. ## 87 Release Notes. ### GCP Batch. * Added Nvidia driver install (default 418) ([#7235](https://github.com/broadinstitute/cromwell/pull/7235})); * Fixed Docker mounting volumes with extra colon ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed issue with multiple zones defined in config ([#7240](https://github.com/broadinstitute/cromwell/pull/7240)); * Fixed Batch label regex ([#7355](https://github.com/broadinstitute/cromwell/pull/7355)). ### Progress toward WDL 1.1 Support. WDL 1.1 support is in progres",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:9221,Testability,log,logging,9221,"with vCPU count](https://cloud.google.com/compute/docs/disks/performance#n2_vms) with a plateau at 16 vCPUs. [2] [Throughput scales with disk size and type](https://cloud.google.com/compute/docs/disks/performance#throughput_limits_for_zonal) with at a plateau at 2.5 TB SSD. Worked example: 1200 MB/s ÷ 0.48 MB/s per GB = 2500 GB. [3] Cromwell itself uses crc32c hashes for call caching and is not affected. ### Other Improvements; * In certain cases DRS downloads have been found to hang forever. Cromwell will now time these out. ([#7416](https://github.com/broadinstitute/cromwell/pull/7416)); * Increased default Akka `client.parsing.max-response-reason-length` to 1024 ([#7406](https://github.com/broadinstitute/cromwell/pull/7406)); * Workflow Completion Callback bodies now include fully-qualified output names ([#7234](https://github.com/broadinstitute/cromwell/pull/7234)); * Improved workflow abort error handling ([#7245](https://github.com/broadinstitute/cromwell/pull/7245)); * Improved logging for troubleshooting ([#7246](https://github.com/broadinstitute/cromwell/pull/7246)) ([#7253](https://github.com/broadinstitute/cromwell/pull/7253)) ([#7388](https://github.com/broadinstitute/cromwell/pull/7388)); * Support for Intel Ice Lake chips in Life Sciences backend ([#7252](https://github.com/broadinstitute/cromwell/pull/7252)); * Fix workflows getting stuck in Aborting when WDL has a type error ([#7385](https://github.com/broadinstitute/cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallbac",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:10614,Testability,log,logging,10614,"cromwell/pull/7385)); * Updates to dependencies to fix security vulnerabilities. ## 86 Release Notes. ### GCP Batch; Cromwell now supports the GCP Batch backend for running workflows. See `Backend` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Workflow Completion Callback; Cromwell can be configured to send a POST request to a specified URL when a workflow completes. The request body includes the workflow ID, terminal state,; and (if applicable) final outputs or error message. See `WorkflowCallback` in [ReadTheDocs](https://cromwell.readthedocs.io/en/stable/) for more information. ### Other Improvements; * Cromwell will now parallelize the downloads of DRS files that resolve to signed URLs. This significantly reduces the time localization takes in certain situations.; * WDL size engine function now works for HTTP files; * Improved Cromwell's handling of docker manifests. Additional logging information is emitted, and Cromwell will fall back to using OCI manifests if it encounters an error with a Docker Image Manifest V2. . ## 85 Release Notes. ### Migration of PKs to BIGINT. The PK of below tables will be migrated from INT to BIGINT. Also, since `ROOT_WORKFLOW_ID` in `SUB_WORKFLOW_STORE_ENTRY` is a FK to `WORKFLOW_STORE_ENTRY_ID` in `WORKFLOW_STORE_ENTRY`; it is also being migrated from INT to BIGINT.; * DOCKER_HASH_STORE_ENTRY; * WORKFLOW_STORE_ENTRY; * SUB_WORKFLOW_STORE_ENTRY. ### Improvement to ""retry with more memory"" behavior. Cromwell will now retry a task with more memory after it fails with return code 137, provided all; the other requirements for retrying with more memory are met. ### DRS Improvements. #### Support for invoking `CromwellDRSLocalizer` with manifest file. `CromwellDRSLocalizer` can now handle multiple file localizations in a single invocation. Users can provide a; manifest file containing multiple (DRS id, local container path) pairs in CSV format, and they will be localized in; sequence, with the prog",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:12958,Testability,log,logs,12958,"lization in GCP papiv2beta backend. All DRS inputs to a task are now localized in a single PAPI action, which should improve speed and resolve; failures observed when attempting to localize a large number of DRS files. ### Allow list for HTTP WDL resolution. Administrators can now configure Cromwell with an allow list that limits the domains from which WDLs can be resolved and imported.; Default behavior is unchanged (Cromwell attempts to resolve WDL files from any URI). Example configuration:; ```; languages {; WDL {; http-allow-list {; enabled: true; allowed-http-hosts: [; ""my.wdl.repo.org"",; ""raw.githubusercontent.com""; ]; }; }; }; ```. ### CWL implementation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling use",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:13609,Testability,log,logging,13609,"mentation removed. This release removes the `cwl` top-level artifact. Some nonfunctional references may remain, and will be addressed over time. For more information, see the [Cromwell 79 release notes](https://github.com/broadinstitute/cromwell/releases/tag/79). ### TES Improvments. * Tes system errors are are now reported in Cromwell execution logs when the TES backend returns a task error. * Cromwell now attempts to translate `disks` attributes [written for GCP](https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/#disks) into valid `disk` attributes for TES. For information on supported conversions, refer to the [TES documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/). ### Bug Fixes. * Reference disks are only mounted if configured in the workflow options. * Recent docker images of Ubuntu use a new manifest format, ensure that these newer image versions can be pulled from Docker Registry without issue. * When converting ValueStore objects to strings for logging, we truncate long values to limit memory usage. ### Security Patching. Updates to dependencies to fix security vulnerabilities. ## 84 Release Notes. ### CromIAM enabled user checks. For Cromwell instances utilizing the optional CromIAM identity and access management component, the following endpoints now verify that the calling user is enabled before forwarding the request.; * `/api/workflows/v1/backends`; * `/api/womtool/v1/describe`. This change makes the above endpoints consistent with the existing behavior of all the other endpoints in the `/api/` path of CromIAM. ## 83 Release Notes. * Changes the type of several primary key columns in call caching tables from int to bigint. The database migration may be lengthy if your database contains a large amount of call caching data. ## 82 Release Notes. * Restored missing example configuration file; * Upgraded to latest version of the Google Cloud Storage NIO library (0.124.8); * Cromwell will now finitely retry the following Google",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:23256,Testability,log,log-threshold,23256,"e info; [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ## 67 Release Notes. ### Configuration updates for improved scaling. Some configuration changes were introduced in Cromwell 67 to support improved scaling. See Cromwell's `reference.conf` for details on new parameters. * I/O throttling moved from `io` to its own `io.throttle` stanza; config updates may be required if these values are currently being overridden in local deployments. * The default `system.job-rate-control` has been changed from 50 per second to 20 per 10 seconds. * New configuration parameters have been introduced for values which were previously hardcoded constants:; * `system.file-hash-batch-size`, value updated from `100` to `50`.; * `io.gcs.max-batch-size`, value stays the same at `100`.; * `io.gcs.max-batch-duration`, value stays the same at `5 seconds`. * New configuration parameters which should not require updating:; * `io.command-backpressure-staleness`; * `io.backpressure-extension-log-threshold`; * `load-control.io-normal-window-minimum`; * `load-control.io-normal-window-maximum`. * `io.nio.parallelism` was previously misspelled in `reference.conf` but not in Cromwell's configuration reading code. Only correct spellings of this configuration key had or will have effect. ## 66 Release Notes. ### Google Artifact Registry Support; Cromwell now supports call caching when using Docker images hosted on; [Google Artifact Registry](https://cloud.google.com/artifact-registry). ### Google Image Repository Hashing Updates; The previously documented `docker.hash-lookup.gcr` configuration has been renamed to `docker.hash-lookup.google` and; now applies to both Google Container Registry (GCR) and Google Artifact Registry (GAR) repositories.; Support for the `docker.hash-lookup.gcr-api-queries-per-100-seconds` configuration key has been formally discontinued; and a bug preventing correct handling of `docker.hash-lookup...throttle` configuration has been fixed.; Please see Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:26029,Testability,test,tested,26029,"upported authentication with refresh tokens, while v2 of the API does not. Now that v1 has been discontinued and shut down, this version of Cromwell removes support for refresh tokens. ## 62 Release Notes. ### Downloading Access URLs. Added experimental support to download data during Google [Cloud Life Sciences](https://cloud.google.com/life-sciences); jobs using [DRS; AccessURLs](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.1.0/docs/#_accessurl). ## 61 Release Notes. ### No labels update for Archived workflows. If **- and ONLY if -** you have metadata archiving turned on, then for a workflow whose metadata has been archived by Cromwell; according to the lifecycle policy, Cromwell will no longer add new labels or update existing labels for this workflow; coming through PATCH `/labels` endpoint. ## 60 Release Notes. ### Java 11. As of this version, a distribution of Java 11 is required to run Cromwell. Cromwell is developed, tested, and; containerized using [AdoptOpenJDK 11 HotSpot](https://adoptopenjdk.net/). ### Hybrid metadata storage (""carboniting"") removed. Carboniting functionality has been removed from Cromwell.; There will be no effect for customers who store metadata permanently in the relational database (most common),; and there will also be no effect for customers who use the in-memory database. Breaking change only for customers who explicitly enabled `carbonite-metadata-service` in their configuration to split; metadata storage between a relational database and Google Cloud Storage. If you had previously enabled carboniting and; deletion, any workflows marked as `ArchivedAndPurged` in your database will no longer be accessible via the Cromwell metadata API. ## 59 Release Notes. ### Bug Fixes. * Fixed a pair of bugs that could cause workflows to fail unexpectedly with the errors ""413 Request Entity Too Large""; and ""java.net.SocketTimeoutException: Read timed out"" when accessing Google Cloud Storage. ## 58 Release Notes. ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:30714,Testability,log,logging,30714,"cker-image-cache-support). #### Preemptible Recovery via Checkpointing. * Cromwell can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:30729,Testability,log,logging,30729,"ll can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:30921,Testability,log,log,30921,"d; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to point to `/martha_v3`. More; information on Martha's `martha_v3` request and response schema can be found; [here]",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:44610,Testability,test,testing,44610,"s) for detailed information. ### Enhanced ""error code 10"" handling in PAPIv2. On Google Pipelines API v2, a worker VM that is preempted may emit a generic error message like; ```; PAPI error code 10. The assigned worker has failed to complete the operation; ```; instead of a preemption-specific message like; ```; PAPI error code 14. Task was preempted for the 2nd time.; ```; Cromwell 44 introduced special handling that detects both preemption indicators and re-runs the job consistent with the `preemptible` setting. Cromwell 46 enhances this handling in response to user reports of possible continued issues. ## 45 Release Notes. ### Improved input and output transfer performance on PAPI v2. Cromwell now requires only a single PAPI ""action"" each for the entire localization or delocalization process, rather than two per file or directory.; This greatly increases execution speed for jobs with large numbers of input or output files.; In testing, total execution time for a call with 800 inputs improved from more than 70 minutes to less than 20 minutes. ### List dependencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45782,Testability,log,log,45782,"ndencies flag in Womtool Command Line [(#5098)](https://github.com/broadinstitute/cromwell/pull/5098). Womtool now outputs the list of files referenced in import statements using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell'",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:45952,Testability,log,logging,45952,"s using `-l` flag for `validate` command.; More info [here](https://cromwell.readthedocs.io/en/stable/WOMtool/). ### BCS backend new Features support. #### New docker registry; Alibaba Cloud Container Registry is now supported for the `docker` runtime attribute, and the previous `dockerTag`; runtime attribute continues to be available for Alibaba Cloud OSS Registry.; #### Call caching; Cromwell now supports Call caching when using the BCS backend.; #### Workflow output glob; Globs can be used to define outputs for BCS backend.; #### NAS mount; Alibaba Cloud NAS is now supported for the `mounts` runtime attribute. ### Call Caching Failure Messages [(#5095)](https://github.com/broadinstitute/cromwell/pull/5095). Call cache failures are no longer sent to the workflow metadata. Instead a limited number of call cache failure messages; will be sent to the workflow log. See [the Cromwell call caching; documentation](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) for more information on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the tim",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:57579,Testability,log,logs,57579,"n be found in [the workflow options documentation](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/#output-copying). ### Bug fixes. #### WDL 1.0 strings can contain escaped quotes. For example, the statement `String s = ""\""""` is now supported, whereas previously it produced a syntax error. #### Empty call blocks in WDL 1.0. Cromwell's WDL 1.0 implementation now allows empty call blocks, e.g. `call task_with_no_inputs {}`. This brings 1.0 in line with draft-2, which has always supported this syntax. #### Packed CWL bugfix. Fixed a bug that caused an error like `Custom type was referred to but not found` to be issued when using an imported type as a `SchemaDefRequirement` in packed CWL. ## 39 Release Notes. ### Cromwell ID changes. When set, the configuration value of `system.cromwell_id` will now have a random suffix appended, unless the; configuration key `system.cromwell_id_random_suffix` is set to `false`. The generated id also appears more places in the logs, including when picking up workflows from the database and during; shutdown. ### Bug fixes. #### Format fix for `write_map()`. Fixed an issue that caused the `write_map()` function in Cromwell's WDL 1.0 implementation to produce output in the wrong format. Specifically, the output's rows and columns were swapped. WDL draft-2 was not affected. Incorrect `write_map()` output in Cromwell 38 and earlier:; ```; key1 key2 key3; value1 value2 value3; ```; Corrected `write_map()` output in Cromwell 39 and later:; ```; key1 value1; key2 value2; key3 value3; ```. ## 38 Release Notes. ### HPC paths with Docker. The `ConfigBackendLifecycleActorFactory` path variables `script`, `out` and `err` are now consistent when running with; and without docker. Similarly, when killing a docker task the `kill-docker` configuration key is now used instead of; `kill`. For more information see the [online documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE/). ### No-op Health Monitor is now the default hea",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61627,Testability,log,logging,61627,"ll cache blacklisting on a per-bucket basis.; More info [here](http://cromwell.readthedocs.io/en/develop/CallCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ###",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61710,Testability,log,log-interval-seconds,61710,"lCaching/#call-cache-copy-authorization-failure-prefix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:61785,Testability,log,logging,61785,"efix-blacklisting). ### WDL. - All memory units in WDL are now treated as base-2.; For instance `1 KB == 1 KiB == 1024 Bytes`. ### Backend name for call caching purposes. Previous versions of Cromwell incorporated the name of the backend on which a call was run into the call cache hashes generated for that call.; Unfortunately this made it impossible to change the name of a backend without losing all previously run calls as potential cache hits.; Cromwell 37 introduces the `name-for-call-caching-purposes` backend configuration option as a means of decoupling the backend name from the; value used for the backend name for call caching purposes. ### CWL. Support `InputResourceRequirement` hint. ### Changing configuration options. #### Logging Token Distribution. In cases where its not obvious why jobs are queued in Cromwell, you can enable logging for the Job Execution Token Dispenser, using; the `system.hog-safety.token-log-interval-seconds` configuration value. The default, `0`, means that no logging will occur. #### HTTP Filesystem. - The HTTP filesystem is now enabled for engine use by default. To continue without an HTTP filesystem, you can add the; following content into the appropriate stanza of your configuration file:; ```; engine {; filesystems {; http {; enabled: false; }; }; }; ```; - When the value `exit-code-timeout-seconds` is set, `check-alive` command is now only called once every timeout interval instead of each poll. ### Beta preview of new Womtool `/describe` endpoint. This new endpoint brings the functionality of Womtool to the world of web services. Submit workflows for validation and receive a JSON description in response. The endpoint is still undergoing heavy development and should not be used in production. The final version will ship in a future release of Cromwell; watch this space. ### Bug fixes. - Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error (closes [#4318](https://github.",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63808,Testability,log,logging,63808,"ll/issues/4318)). #### Abort On Hold Workflows. On Hold workflows may now be aborted. #### Command fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops s",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:63852,Testability,log,logging,63852,"nd fixes for AWS and TES. The AWS and TES backends can now handle calls that generate longer command lines. Like the other; backends, commands scripts are first written to a file, the file is downloaded to the execution; host, and then the localized script is run. Also fixed are AWS `command {}` blocks that use `|` at the start of a line. For example:. ```; command {; echo hello world \; | cat; }; ```. ## 36 Release Notes. ### Extra configuration options. The value `exit-code-timeout-seconds` can now set in a backend configuration.; Details [here](https://cromwell.readthedocs.io/en/develop/backends/HPC/#exit-code-timeout). ### [AWS S3 file transfers are now encrypted](https://github.com/broadinstitute/cromwell/pull/4264). ### Bug fixes. #### Metadata Request Coalescing. Coalesce metadata requests to eliminate expensive and redundant queries and metadata construction. #### Eliminate redundant SFS logging and metadata. Eliminate superfluous logging and metadata publishing in the shared filesystem backend on poll intervals where there was not a state change. #### AWS region configuration respected throughout. Previously US-EAST-1 was hardcoded in places. ## 35 Release Notes. ### Submit workflow using URL. Cromwell now allows for a user to submit the URL pointing to workflow file to run a workflow.; More details on how to use it in:; - `Server` mode can be found [here](https://cromwell.readthedocs.io/en/develop/api/RESTAPI/).; - `Run` mode can be found [here](https://cromwell.readthedocs.io/en/develop/CommandLine/#run). ### Languages. - Added an opt-in namespace cache for the WDL Draft 2 language factory. Please see the Cromwell example configuration for details. NOTE: if upgrading from a hotfix version of Cromwell; that relied upon this cache, the cache is now opt-in and must be turned on explicitly in config.; - To maintain conformance with the OpenWDL spec, Cromwell drops support for the `version draft-3` identifier in this release. In the rare case where end users ma",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:69887,Testability,log,log,69887,"kflowQueryResult, which is part of the response for workflow query. ### File Localization (NIO) Hint. Cromwell now allows tasks in WDL 1.0 can now specify an optimization in their `parameter_meta` that some `File` inputs do not need to be localized for the task to run successfully.; Full details are available in the [documentation page for this optimization](http://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization). ### Bug Fixes. Workflows which are in 'On Hold' state can now be fetched using the query endpoint. ## 32 Release Notes. ### Backends. #### Pipelines API V2; Initial support for Google [Pipelines API version 2](https://cloud.google.com/genomics/reference/rest/).; Expect feature parity except for private dockerhub images which are not supported at the moment, but will be in the near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:70671,Testability,log,logs,70671,"e near future.; Additionally, the ""refresh token"" authentication mode is **NOT** supported on PAPI V2. In addition, the following changes are to be expected:; * Error messages for failed jobs might differ from V1; * The Pipelines API log file content might differ from V1. **Important (If you're running Cromwell with a Google backend, read this)**:; The `actor-factory` value for the google backend (`cromwell.backend.impl.jes.JesBackendLifecycleActorFactory`) is being deprecated.; Please update your configuration accordingly. | PAPI Version | actor-factory |; |---------------|:----------------------------------------------------------------------------:|; | V1 | cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory |; | V2alpha1 | cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory |; | V2beta | cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory |. If you don't update the `actor-factory` value, you'll get a deprecation warning in the logs, and Cromwell will default back to **PAPI V1**. ### Task Retries; Cromwell now supports retrying failed tasks up to a specified count by declaring a value for the [maxRetries](RuntimeAttributes.md#maxRetries) key through the WDL runtime attributes. ### Labels; * Cromwell has removed most of the formatting restrictions from custom labels. Please check the [README](README.md#label-format) for more detailed documentation.; * Custom labels won't be submitted to Google backend as they are now decoupled from Google's default labels.; * Cromwell now publishes the labels as soon as the workflow is submitted (whether started or on hold). If the labels are invalid, the workflow will not be submitted and request will fail. ### Scala 2.11 Removed; From version 32 onwards we will no longer be publishing build artifacts compatible with Scala 2.11. * If you don't import the classes into your own scala project then this should have no impact on you.; * If you **are** importing t",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:88945,Testability,benchmark,benchmark,88945,"ence""; }; }; }; ```. A placeholder file will be placed in the execution folder of the cached call to explain the absence of output files and point to the location of the original ones. ### Metadata Write Batching. Metadata write batching works the same as in previous versions of Cromwell, but the default batch size has been changed from 1 to 200. It's possible that 200 is too high in some environments, but 200 is more likely to be an appropriate value; than the previous default. ## 27. ### Migration. * Call Caching has been improved in this version of Cromwell, specifically the time needed to determine whether or not a job can be cached; has drastically decreased. To achieve that the database schema has been modified and a migration is required in order to preserve the pre-existing cached jobs.; This migration is relatively fast compared to previous migrations. To get an idea of the time needed, look at the size of your `CALL_CACHING_HASH_ENTRY` table.; As a benchmark, it takes 1 minute for a table with 6 million rows.; The migration will only be executed on MySQL. Other databases will lose their previous cached jobs.; In order to run properly on MySQL, **the following flag needs to be adjusted**: https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_group_concat_max_len; The following query will give you a minimum to set the group_concat_max_len value to:. ```sql; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(CONCAT(cche.HASH_KEY, cche.HASH_VALUE))) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. Here is the SQL command to run to set the group_concat_max_len flag to the proper value:. ```sql; SET GLOBAL group_concat_max_len = value; ```. Where `value` is replaced with the value you want to set it to. Note that the migration will fail if the flag is not set properly. ### Breaking Changes. * The update to Slick 3.2 requires a databa",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:99039,Testability,log,log,99039,"/cromwell#call-caching-docker-tags for more details.; * Added docker hash lookup. Cromwell will try to lookup the hash for a docker image with a floating tag, and use that hash when executing the job.; This will be reflected in the metadata where the docker runtime attribute will contains the hash that was used.; If Cromwell is unable to lookup the docker hash, the job will be run with the original user defined floating tag.; Cromwell is currently able to lookup public and private docker hashes for images on Docker Hub and Google Container Engine for job running on the JES backend.; For other backends, cromwell is able to lookup public docker hashes for Docker Hub and Google Container Engine.; See https://github.com/broadinstitute/cromwell#call-caching-docker-tags for more details. ### Database schema changes; * Added CUSTOM_LABELS as a field of WORKFLOW_STORE_ENTRY, to store workflow store entries. ## 24. * When emitting workflow outputs to the Cromwell log only the first 1000 characters per output will be printed; * Added support for conditional (`if`) statements.; * Globs for Shared File System (SFS) backends, such as local or SGE, now use bash globbing instead of Java globbing, consistent with the JES backend. ## 23. * The `meta` and `parameter_meta` blocks are now valid within `workflow` blocks, not just `task`; * The JES backend configuration now has an option `genomics-api-queries-per-100-seconds` to help tune the rate of batch polling against the JES servers. Users with quotas larger than default should make sure to set this value.; * Added an option `call-caching.invalidate-bad-cache-results` (default: `true`). If true, Cromwell will invalidate cached results which have failed to copy as part of a cache hit.; * Timing diagrams and metadata now receive more fine grained workflow states between submission and Running.; * Support for the Pair WDL type (e.g. `Pair[Int, File] floo = (3, ""gs://blar/blaz/qlux.txt"")`); * Added support for new WDL functions:; * `zip:",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109197,Testability,log,logs,109197,"about jobs. * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/mani",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:30783,Usability,clear,clear,30783,"ll can now help tasks recover from preemption by allowing them to specify a 'checkpoint' file which will be restored; to the worker VM on the next attempt if the task is interrupted. More details [here](https://cromwell.readthedocs.io/en/develop/optimizations/CheckpointFiles). ## 54 Release Notes. ### Bug Fixes. * Fixed a bug that prevented `write_json()` from working with arrays and primitives. The function now works as expected for `Boolean`, `String`, `Integer`, `Float`,; `Pair[_, _]`, `Object`, `Map[_, _]` and `Array[_]` (including array of objects) type inputs. More information on WDL Type to JSON Type; conversion can be found [here](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#mixed-read_jsonstringfile). ### Spark backend support removal. Spark backend was not widely used and it was decided to remove it from the codebase in order to narrow the scope of Cromwell code. ### Improved DRS Localizer logging. Error logging while localizing a DRS URI should now be more clear especially when there is a Requester Pays bucket involved. ### Per-backend hog factors; Cromwell now allows overriding system-level log factors on back-end level. First, Cromwell will try to use hog-factor; defined in the backend config, and if it is not defined, it will default to using system-wide hog factor.; ```conf; backend {; providers {; PAPIv2 {; config {; hog-factor: 2; }; }; }; }; ```; For more information about hog factors please see [this page](https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/). ### `martha_v2` Support Removed. Cromwell now only supports resolving DOS or DRS URIs through [Martha](https://github.com/broadinstitute/martha)'s most; recent metadata endpoint `martha_v3`, dropping support for Martha's previous metadata endpoint `martha_v2`. To switch to; the new version of Martha's metadata endpoint, update the `martha.url` found in the [filesystems; config](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/#overview) to",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:37759,Usability,usab,usable,37759,"and; `fingerprint`. `xxh64` is a lightweight hashing algorithm, `fingerprint` is a strategy designed to be very; lightweight. Read more about it in the [call caching documentation](; https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching). ## 50 Release Notes. ### Changes and Warnings. #### Metadata Archival Config Change. **Note:** Unless you have already opted-in to GCS-archival of metadata during its development, this change will not affect you.; Cromwell's metadata archival configuration has changed in a backwards incompatible way to increase consistency,; please see; [the updated documentation](https://cromwell.readthedocs.io/en/stable/Configuring#hybrid-metadata-storage-classic-carbonite) for details. ## 49 Release Notes. ### Changes and Warnings. #### Job store database refactoring. The primary keys of Cromwell's job store tables have been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 40,000 `JOB_STORE_SIMPLETON_ENTRY`; rows per second. In deployments with millions or billions of `JOB_STORE_SIMPLETON_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; SELECT table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'cromwell' AND table_name = 'JOB_STORE_SIMPLETON_ENTRY';; ```. #### Execution Directory Layout (cache copies). When an attempt to copy a cache result is made, you'll now see a `cacheCopy` directory in the call root directory.; This prevents them clashing with the files staged to the same directory for attempt 1 if the cache copy fails (see also: Bug Fixes). The directory layout used to be:. ```; [...]/callRoot/; - script [from the cache copy attempt, or for execution attempt 1 if",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:46891,Usability,usab,usable,46891,"nformation on call; cache failure logging. ## 44 Release Notes. ### Improved PAPI v2 Preemptible VM Support. In some cases PAPI v2 will report the preemption of a VM in a way that differs from PAPI v1. This novel means of reporting; preemption was not recognized by Cromwell's PAPI v2 backend and would result in preemptions being miscategorized as call failures.; Cromwell's PAPI v2 backend will now handle this type of preemption. ## 43 Release Notes. ### Virtual Private Cloud with Subnetworks. Cromwell now allows PAPIV2 jobs to run on a specific subnetwork inside a private network by adding the subnetwork key; `subnetwork-label-key` inside `virtual-private-cloud` in backend configuration. More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### Call caching database refactoring. Cromwell's `CALL_CACHING_HASH_ENTRY` primary key has been refactored to use a `BIGINT` datatype in place of the previous; `INT` datatype. Cromwell will not be usable during the time the Liquibase migration for this refactor is running.; In the Google Cloud SQL with SSD environment this migration runs at a rate of approximately 100,000 `CALL_CACHING_HASH_ENTRY`; rows per second. In deployments with millions or billions of `CALL_CACHING_HASH_ENTRY` rows the migration may require; a significant amount of downtime so please plan accordingly. The following SQL could be used to estimate the number of; rows in this table:. ```; select max(CALL_CACHING_HASH_ENTRY_ID) from CALL_CACHING_HASH_ENTRY; ```. ### Stackdriver Instrumentation. Cromwell now supports sending metrics to [Google's Stackdriver API](https://cloud.google.com/monitoring/api/v3/).; Learn more on how to configure [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). ### BigQuery in PAPI. Cromwell now allows a user to specify BigQuery jobs when using the PAPIv2 backend. ### Configuration Changes. #### StatsD Instrumentation. There is a small change in StatsD's configuration path. Original",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:51002,Usability,simpl,simply,51002,"well's requests to PAPIv2 can now be configured. See the sample PAPIv2.conf for more documentation:. ```conf; backend {; providers {; PAPIv2 {; config {; batch-requests {; timeouts {; read = 10 seconds; connect = 10 seconds; }; }; }; }; }; }; ```. ### Virtual Private Networks. Cromwell now allows PAPIV2 jobs to run on a private network by adding the network name inside `virtual-private-cloud` in backend configuration.; More info [here](https://cromwell.readthedocs.io/en/stable/backends/Google/). ### AWS Backend. Now includes background job status polling to hopefully reduce the incidence of 'HTTP 429' errors for large workflows. ## 41 Release Notes. ### Workflow Options. * It is now possible to supply custom `google-labels` in [workflow options](https://cromwell.readthedocs.io/en/stable/wf_options/Google/). ### AWS backend. It is now possible to use WDL disk attributes with the following formats on AWS.; ```; disks: ""local-disk 20 SSD""; ```; ```; disks: ""/some/mnt 20 SSD""; ```; Because Cromwell's AWS backend auto-sizes disks, the size specification is simply discarded. ### Time Formatting. In previous versions of Cromwell, times were converted to strings using; [the default Java formatter](https://docs.oracle.com/javase/8/docs/api/java/time/OffsetDateTime.html#toString--) which; generates a variety of ISO-8601 formats. String conversions also retained whatever server time zone generated that; specific time instance. Going forward, times stored in Cromwell metadata, and later returned via the HTTP endpoint, are now converted to UTC; then formatted with exactly three digits of milliseconds. For example:; - `2017-01-19T12:34:56-04:00` will now be formatted as; - `2017-01-19T16:34:56.000Z`. This change only affects newly formatted dates. Older dates already formatted and stored by previous versions of; Cromwell will not be updated however they will still return a; [valid ISO-8601 format](https://en.wikipedia.org/wiki/ISO_8601). The older format may be in various non-UTC ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:54579,Usability,simpl,simpler,54579,"id accelerator to be used.; * The `nvidiaDriverVersion` attribute is now available in WDL `runtime` sections. The default continues to be `390.46` which applies if and only if GPUs are being used.; * A default `gpuType` (""nvidia-tesla-k80"") will now be applied if `gpuCount` is specified but `gpuType` is not.; * Similarly, a default `gpuCount` (1) will be applied if `gpuType` is specified but `cpuCount` is not. ### Bug fixes. #### Better validation of workflow heartbeats. An error will be thrown on startup when the `system.workflow-heartbeats.heartbeat-interval` is not less than the; `system.workflow-heartbeats.ttl`. ## 40 Release Notes. ### Config Changes. #### Cromwell ID in instrumentation path. When set, the configuration value of `system.cromwell_id` will be prepended to StatsD metrics. More info [here](https://cromwell.readthedocs.io/en/stable/developers/Instrumentation/). #### HealthMonitor Configuration. The HealthMonitor configuration has been refactored to provide a simpler interface:; * You no longer need to specify a monitor class in your `cromwell.conf` as this will now be inherited from the `reference.conf` value.; * You can now opt-in and opt-out of any combination of status monitors.; * The PAPI backends to monitor can now be listed in a single field. ##### Upgrading. You are no longer tied to the previous preset combinations of health checks. However if you just want to carry forward; the exact same set of health checks, you can use one of the following standard recipes:. ###### From default, or `NoopHealthMonitorActor`:; If you're currently using the (default) NoopHealthMonitorActor, no action is required. ###### From `StandardHealthMonitorServiceActor`:; If you're currently using the `StandardHealthMonitorServiceActor`, replace this stanza:; ```; services {; HealthMonitor {; class = ""cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor""; }; }; ```; With this one:; ```; services {; HealthMonitor {; config {; check-engine-d",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:77177,Usability,simpl,simple,77177,"usly updated a value from `""value-1""` > `""value-2""` >; `""value-3""` > `""value-2""` then the former REST API will return `value-3` while the latter will return `value-2`. #### Workflow options `google_project` output in metadata. Workflow metadata for jobs run on a Google Pipelines API backend will report the `google_project` specified via a; [workflow options json](http://cromwell.readthedocs.io/en/develop/wf_options/Google/#google-pipelines-api-workflow-options). ## 31 Release Notes. * **Cromwell server**; The Cromwell server source code is now located under `server/src`. `sbt assembly` will build the runnable Cromwell JAR in; `server/target/scala-2.12/` with a name like `cromwell-<VERSION>.jar`. * **Robustness**; + The rate at which jobs are being started can now be controlled using the `system.job-rate-control` configuration stanza.; + A load controller service has been added to allow Cromwell to self-monitor and adjust its load accordingly.; The load controller is currently a simple on/off switch controlling the job start rate. It gathers metrics from different parts of the system; to inform its decision to stop the creation of jobs.; You can find relevant configuration in the `services.LoadController` section of the `cromwell.examples.conf` file,; as well as in the `load-control` section in `reference.conf`.; The load level of the monitored sub-systems are instrumented and can be found under the `cromwell.load` statsD path.; + The statsD metrics have been re-shuffled a bit. If you had a dashboard you might find that you need to update it.; Changes include:; + Removed artificially inserted ""count"" and ""timing"" the path; + Added a `load` section; + Metrics were prefixed twice with `cromwell` (`cromwell.cromwell.my_metric`), now they're only prefixed once; + Added `processed` and `queue` metrics under various metrics monitoring the throughput and amount of queued work respectively; + Added a memory metric representing an estimation of the free memory Cromwell thinks ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:95214,Usability,simpl,simple,95214,"uration option under `system.io` to throttle the number of I/O queries that Cromwell makes, as well as configure retry parameters.; This is mostly useful for the JES backend and should be updated to match the GCS quota available for the project. ```; system.io {; # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds. # Number of times an I/O operation should be attempted before giving up and failing it.; number-of-attempts = 5; }; ```. ## 25. ### External Contributors; * A special thank you to @adamstruck, @antonkulaga and @delocalizer for their contributions to Cromwell.; ### Breaking Changes. * Metadata keys for call caching are changed. All call caching keys are now in a `callCaching` stanza. `Call cache read result` has moved here and is now `result`. The `allowResultReuse` and `effectiveCallCachingMode` have moved here. The `hit` boolean is a simple indication of whether or not it was a hit, with no additional information. An example using the new format is:; ```; ""callCaching"": {; ""hit"": false,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""result"": ""Cache Miss"",; ""allowResultReuse"": true; }; ```. ### Config Changes. * Added a field `insert-batch-size` to the `database` stanza which defines how many values from a batch insert will be processed at a time. This value defaults to 2000.; * Moved the config value `services.MetadataService.metadata-summary-refresh-interval` to `services.MetadataService.config.metadata-summary-refresh-interval`; * Added ability to override the default zone(s) used by JES via the config structure by setting `genomics.default-zones` in the JES configuration; * The cromwell server TCP binding timeout is now configurable via the config key `webservice.binding-timeout`, defaulted; to the previous value `5s` (five seconds) via the reference.conf.; * For MySQL users, a massive scalability improvement via batched DB writing of ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md:109853,Usability,undo,undocumented,109853,"d in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```. * The Local and the SGE backend have been merged into a generic; Shared File System (SFS) backend. This updated backend can be configured; to work with various other command line dispatchers such as LSF. See the; [README](README.md#sun-gridengine-backend) for more info. * On the JES and SFS backends, task `command` blocks are now always; passed absolute paths for input `File`s. * On the SFS backends, the call directory now contains two sub-directories:; * `inputs` contains all the input files that have been localized for this task (see next below for more details); * `execution` contains all other files (script, logs, rc, potential outputs etc...). * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc.; * Override the default database configuration by setting the keys; `database.driver`, `database.db.driver`, `database.db.url`, etc. For example:; ```; # use a mysql database; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. ## 0.20. * The default per-upload bytes size for GCS is now the minimum 256K; instead of 64M. There is also an undocumented config key; `google.upload-buffer-bytes` that allows adjusting this internal value. * Updated Docker Hub hash retriever to parse json with [custom media; types](https://github.com/docker/distribution/blob/05b0ab0/docs/spec/manifest-v2-1.md). * Added a `/batch` submit endpoint that accepts a single wdl with; multiple input files. * The `/query` endpoint now supports querying by `id`, and submitting; parameters as a HTTP POST.; ",MatchSource.DOCS,CHANGELOG.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CHANGELOG.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:1822,Deployability,update,updates,1822,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:313,Energy Efficiency,reduce,reduce,313,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:1520,Energy Efficiency,schedul,schedule,1520,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:960,Modifiability,enhance,enhances,960,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:575,Usability,feedback,feedback,575,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:818,Usability,feedback,feedback,818,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:1286,Usability,simpl,simply,1286,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md:1382,Usability,feedback,feedback,1382,"### Contributing to Cromwell. Thank you for contributing to Cromwell. The project is sponsored by Broad Institute and has participants all over the world, who have collectively added tremendous value over the years. This page describes how we handle external contributions to maximize the impact of your work and reduce delays in getting your PRs accepted. #### Run your idea by us first; If you're thinking of writing a non-trivial amount of code to solve a problem, we encourage you to reach out via an [issue](https://github.com/broadinstitute/cromwell/issues/new) to get feedback. It is likely we will have suggestions about how to proceed. It's also possible, though hopefully rare, that there is a hidden impediment that would prevent your solution from working. If we spot it at the idea stage, we can give you feedback much earlier than if we have to reject your pull request!. #### Maintenance considerations; The Cromwell team at Broad maintains and enhances the application to serve the needs of both Broad Institute and external users. Sometimes, we may identify a feature idea or pull request that works and is a good idea, but we may be unable to commit to maintaining it indefinitely. This may be because it does not align with the strategic direction of the project, or simply due to time constraints on the maintainers. Once again, it always helps to solicit early feedback. #### Reviewing pull requests; Because pull requests require a substantial amount of time to review carefully, we prioritize and schedule them into our sprints alongside all of our other work. At present, the team operates on three-week sprints so if you happen to submit a PR early on in the sprint it may be a while before a team member has a chance to look at it. We realize this may be frustrating and strive to provide timely updates about PR status.; ",MatchSource.DOCS,CONTRIBUTING.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/CONTRIBUTING.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:1202,Availability,avail,available,1202,"tem for bioinformatics. Licensing is [BSD 3-Clause](LICENSE.txt). The [Cromwell documentation has a dedicated site](https://cromwell.readthedocs.io/en/stable). First time to Cromwell? Get started with [Tutorials](https://cromwell.readthedocs.io/en/stable/tutorials/FiveMinuteIntro/). ### Community. Thinking about contributing to Cromwell? Get started by reading our [Contributor Guide](CONTRIBUTING.md). Cromwell has a growing ecosystem of community-backed projects to make your experience even better! Check out our [Ecosystem](https://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other b",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:1693,Availability,down,download,1693,"munity-backed projects to make your experience even better! Check out our [Ecosystem](https://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other backends is primarily community-based. Cromwell [supports](https://cromwell.readthedocs.io/en/stable/LanguageSupport/) the WDL workflow language. Cromwell version 80 and above no longer support CWL. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supportin",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:1638,Deployability,install,install,1638,"munity-backed projects to make your experience even better! Check out our [Ecosystem](https://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other backends is primarily community-based. Cromwell [supports](https://cromwell.readthedocs.io/en/stable/LanguageSupport/) the WDL workflow language. Cromwell version 80 and above no longer support CWL. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supportin",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:1746,Deployability,release,releases,1746,"://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other backends is primarily community-based. Cromwell [supports](https://cromwell.readthedocs.io/en/stable/LanguageSupport/) the WDL workflow language. Cromwell version 80 and above no longer support CWL. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supporting-more-workflow-languages/) for details. ### Security reports. If you believe you have foun",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:2752,Security,secur,security,2752,"- More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other backends is primarily community-based. Cromwell [supports](https://cromwell.readthedocs.io/en/stable/LanguageSupport/) the WDL workflow language. Cromwell version 80 and above no longer support CWL. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog post [""Terra’s roadmap to supporting more workflow languages""](https://terra.bio/terras-roadmap-to-supporting-more-workflow-languages/) for details. ### Security reports. If you believe you have found a security issue please contact `infosec@broadinstitute.org`. ### Issue tracking. Need to file an issue? Head over to [Github Issues](https://github.com/broadinstitute/cromwell/issues). If you previously filed an issue in JIRA, the link is [here](https://broadworkbench.atlassian.net/jira/software/c/projects/CROM/issues). New signups are no longer accepted. ![Jamie, the Cromwell pig](docs/jamie_the_cromwell_pig.png); ",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:805,Usability,learn,learn,805,"[![codecov](https://codecov.io/gh/broadinstitute/cromwell/branch/develop/graph/badge.svg)](https://codecov.io/gh/broadinstitute/cromwell). ## Welcome to Cromwell. Cromwell is an open-source Workflow Management System for bioinformatics. Licensing is [BSD 3-Clause](LICENSE.txt). The [Cromwell documentation has a dedicated site](https://cromwell.readthedocs.io/en/stable). First time to Cromwell? Get started with [Tutorials](https://cromwell.readthedocs.io/en/stable/tutorials/FiveMinuteIntro/). ### Community. Thinking about contributing to Cromwell? Get started by reading our [Contributor Guide](CONTRIBUTING.md). Cromwell has a growing ecosystem of community-backed projects to make your experience even better! Check out our [Ecosystem](https://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive dev",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/README.md:1590,Usability,guid,guide,1590,"? Get started by reading our [Contributor Guide](CONTRIBUTING.md). Cromwell has a growing ecosystem of community-backed projects to make your experience even better! Check out our [Ecosystem](https://cromwell.readthedocs.io/en/stable/Ecosystem/) page to learn more. Talk to us:; - [Join the Cromwell Slack workspace](https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g) to discuss the Cromwell workflow engine.; - [Join the OpenWDL Slack workspace](https://join.slack.com/t/openwdl/shared_invite/zt-ctmj4mhf-cFBNxIiZYs6SY9HgM9UAVw) to discuss the evolution of the WDL language itself.; - More information about WDL is available in [that project's repository](https://github.com/openwdl/wdl). . ### Capabilities and roadmap. Many users today run their WDL workflows in [Terra](https://app.terra.bio/), a managed cloud bioinformatics platform with built-in WDL support provided by Cromwell. See [here](https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows) for a quick-start guide. Users with specialized needs who wish to install and maintain their own Cromwell instances can [download](https://github.com/broadinstitute/cromwell/releases) a JAR or Docker image. The development team accepts reproducible bug reports from self-managed instances, but cannot feasibly provide direct support. [Cromwell's backends](https://cromwell.readthedocs.io/en/stable/backends/Backends/) receive development resources proportional to user demand. The team is actively developing for Google Cloud and Microsoft Azure (see [Cromwell on Azure](https://github.com/microsoft/CromwellOnAzure)). Maintenance of other backends is primarily community-based. Cromwell [supports](https://cromwell.readthedocs.io/en/stable/LanguageSupport/) the WDL workflow language. Cromwell version 80 and above no longer support CWL. CWL will be re-introduced at a later date in the [Terra platform](https://terra.bio/), using a solution other than Cromwell. See the blog po",MatchSource.DOCS,README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/README.md
https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md:578,Deployability,configurat,configuration,578,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ",MatchSource.DOCS,.github/issue_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md:578,Modifiability,config,configuration,578,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ",MatchSource.DOCS,.github/issue_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md:47,Usability,feedback,feedback,47,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ",MatchSource.DOCS,.github/issue_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/issue_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md:152,Deployability,update,updated,152,### Description. <!-- What is the purpose of this change? What should reviewers know? -->. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.DOCS,.github/pull_request_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md:354,Deployability,release,release,354,### Description. <!-- What is the purpose of this change? What should reviewers know? -->. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.DOCS,.github/pull_request_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md:445,Deployability,release,release,445,### Description. <!-- What is the purpose of this change? What should reviewers know? -->. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.DOCS,.github/pull_request_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md:195,Testability,assert,assert,195,### Description. <!-- What is the purpose of this change? What should reviewers know? -->. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.DOCS,.github/pull_request_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md
https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md:403,Testability,assert,assert,403,### Description. <!-- What is the purpose of this change? What should reviewers know? -->. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.DOCS,.github/pull_request_template.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/.github/pull_request_template.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:196,Modifiability,extend,extending,196,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:236,Testability,test,test,236,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:276,Testability,test,test,276,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:348,Testability,test,test,348,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:365,Testability,test,test,365,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:539,Testability,test,test,539,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:703,Testability,test,test,703,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:740,Testability,assert,asserting,740,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md:801,Testability,test,test,801,"For information on Cromwell's Integration Testing Suite, see the [Cromwell documentation on Centaur](https://cromwell.readthedocs.io/en/develop/developers/Centaur/). ### `centaur/src/it`. Classes extending `org.scalatest` that ingest `.test` files and turn them into runnable test suites. ### `centaur/src/main`. #### `/resources`. Collection of `.test` cases. In `test.inc.sh` we map Github Action jobs to case directories with `create_centaur_variables()`. Not all cases are run!. As of July 2024, Centaur searches **recursively** for `.test` files, so they can be placed in subdirectories along with their resources. #### `/scala`. Functionality to start, stop, and restart the Cromwell server under test. Also contains abstractions for asserting on metadata and workflow outputs. ### `centaur/src/test`. Tests for Centaur itself.; ",MatchSource.DOCS,centaur/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/centaur/README.md
https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md:212,Deployability,configurat,configuration,212,"# Cromwell Example Backends. This is a folder of example backend providers for Cromwell. You can read about; the providers here, and then copy paste one or more of the providers you want; to use to your Cromwell configuration file, represented here as the; [cromwell.examples.conf](cromwell.examples.conf) file in the base of the ; repository. ## What are the backend providers?. ### Cloud Providers. - [AWS](AWS.conf): Amazon Web Services ([documentation](https://cromwell.readthedocs.io/en/stable/tutorials/AwsBatch101/)); - [TES](TES.conf) is a backend that submits jobs to a server with protocol defined by GA4GH ([documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/)); - [PAPIv2](PAPIv2.conf): Google Pipelines API backend (version 2!) ([documentation](https://cromwell.readthedocs.io/en/stable/backends/Google/)). ### Containers. - [Docker](Docker.conf): an example backend that only runs workflows with docker in *every* command; - [Singularity](singularity.conf): run Singularity containers locally ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#local-environments)); - [Singularity+Slurm](singularity.slurm.conf): An example using Singularity with SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#job-schedulers)); - [TESK](TESK.conf) is the same, but intended for Kubernetes. See the [TES docs](https://cromwell.readthedocs.io/en/stable/backends/TES/) at the bottom.; - [udocker](udocker.conf): to interact with udocker locally [documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker); - [udocker+Slurm](udocker.slurm.conf): to interact with udocker on SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker)). ### Workflow Managers. - [HtCondor](HtCondor.conf): a workload manager at UW-Madison ([documentation](https://cromwell.readthedocs.io/en/stable/backends/HTcondor/)); - [LSF](LSF.conf): the Platform Load Sharing Fa",MatchSource.DOCS,cromwell.example.backends/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md
https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md:1303,Energy Efficiency,schedul,schedulers,1303,"es.conf) file in the base of the ; repository. ## What are the backend providers?. ### Cloud Providers. - [AWS](AWS.conf): Amazon Web Services ([documentation](https://cromwell.readthedocs.io/en/stable/tutorials/AwsBatch101/)); - [TES](TES.conf) is a backend that submits jobs to a server with protocol defined by GA4GH ([documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/)); - [PAPIv2](PAPIv2.conf): Google Pipelines API backend (version 2!) ([documentation](https://cromwell.readthedocs.io/en/stable/backends/Google/)). ### Containers. - [Docker](Docker.conf): an example backend that only runs workflows with docker in *every* command; - [Singularity](singularity.conf): run Singularity containers locally ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#local-environments)); - [Singularity+Slurm](singularity.slurm.conf): An example using Singularity with SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#job-schedulers)); - [TESK](TESK.conf) is the same, but intended for Kubernetes. See the [TES docs](https://cromwell.readthedocs.io/en/stable/backends/TES/) at the bottom.; - [udocker](udocker.conf): to interact with udocker locally [documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker); - [udocker+Slurm](udocker.slurm.conf): to interact with udocker on SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker)). ### Workflow Managers. - [HtCondor](HtCondor.conf): a workload manager at UW-Madison ([documentation](https://cromwell.readthedocs.io/en/stable/backends/HTcondor/)); - [LSF](LSF.conf): the Platform Load Sharing Facility backend ([documentation](https://cromwell.readthedocs.io/en/stable/backends/LSF/)); - [SGE](SGE.conf): a backend for Sungrid Engine ([documentation](https://cromwell.readthedocs.io/en/stable/backends/SGE)); - [slurm](slurm.conf): SLURM workload manager ([documentation](https://cromwell.re",MatchSource.DOCS,cromwell.example.backends/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md
https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md:591,Integrability,protocol,protocol,591,"# Cromwell Example Backends. This is a folder of example backend providers for Cromwell. You can read about; the providers here, and then copy paste one or more of the providers you want; to use to your Cromwell configuration file, represented here as the; [cromwell.examples.conf](cromwell.examples.conf) file in the base of the ; repository. ## What are the backend providers?. ### Cloud Providers. - [AWS](AWS.conf): Amazon Web Services ([documentation](https://cromwell.readthedocs.io/en/stable/tutorials/AwsBatch101/)); - [TES](TES.conf) is a backend that submits jobs to a server with protocol defined by GA4GH ([documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/)); - [PAPIv2](PAPIv2.conf): Google Pipelines API backend (version 2!) ([documentation](https://cromwell.readthedocs.io/en/stable/backends/Google/)). ### Containers. - [Docker](Docker.conf): an example backend that only runs workflows with docker in *every* command; - [Singularity](singularity.conf): run Singularity containers locally ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#local-environments)); - [Singularity+Slurm](singularity.slurm.conf): An example using Singularity with SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#job-schedulers)); - [TESK](TESK.conf) is the same, but intended for Kubernetes. See the [TES docs](https://cromwell.readthedocs.io/en/stable/backends/TES/) at the bottom.; - [udocker](udocker.conf): to interact with udocker locally [documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker); - [udocker+Slurm](udocker.slurm.conf): to interact with udocker on SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker)). ### Workflow Managers. - [HtCondor](HtCondor.conf): a workload manager at UW-Madison ([documentation](https://cromwell.readthedocs.io/en/stable/backends/HTcondor/)); - [LSF](LSF.conf): the Platform Load Sharing Fa",MatchSource.DOCS,cromwell.example.backends/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md
https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md:212,Modifiability,config,configuration,212,"# Cromwell Example Backends. This is a folder of example backend providers for Cromwell. You can read about; the providers here, and then copy paste one or more of the providers you want; to use to your Cromwell configuration file, represented here as the; [cromwell.examples.conf](cromwell.examples.conf) file in the base of the ; repository. ## What are the backend providers?. ### Cloud Providers. - [AWS](AWS.conf): Amazon Web Services ([documentation](https://cromwell.readthedocs.io/en/stable/tutorials/AwsBatch101/)); - [TES](TES.conf) is a backend that submits jobs to a server with protocol defined by GA4GH ([documentation](https://cromwell.readthedocs.io/en/stable/backends/TES/)); - [PAPIv2](PAPIv2.conf): Google Pipelines API backend (version 2!) ([documentation](https://cromwell.readthedocs.io/en/stable/backends/Google/)). ### Containers. - [Docker](Docker.conf): an example backend that only runs workflows with docker in *every* command; - [Singularity](singularity.conf): run Singularity containers locally ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#local-environments)); - [Singularity+Slurm](singularity.slurm.conf): An example using Singularity with SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#job-schedulers)); - [TESK](TESK.conf) is the same, but intended for Kubernetes. See the [TES docs](https://cromwell.readthedocs.io/en/stable/backends/TES/) at the bottom.; - [udocker](udocker.conf): to interact with udocker locally [documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker); - [udocker+Slurm](udocker.slurm.conf): to interact with udocker on SLURM ([documentation](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#udocker)). ### Workflow Managers. - [HtCondor](HtCondor.conf): a workload manager at UW-Madison ([documentation](https://cromwell.readthedocs.io/en/stable/backends/HTcondor/)); - [LSF](LSF.conf): the Platform Load Sharing Fa",MatchSource.DOCS,cromwell.example.backends/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md
https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md:3972,Usability,clear,clearly,3972,"stom. - [LocalExample](LocalExample.conf): What you should use if you want to define a new backend provider ([documentation](https://cromwell.readthedocs.io/en/stable/backends/Local/)). ## How do I add a backend provider?. The section in the file called ""backends"" has a key, ""providers"" that looks like; this:. ```. backend {. # Override the default backend.; #default = ""LocalExample"". # The list of providers. Copy paste the contents of a backend provider in this section; providers {; ....; }. }; ```. The examples here also have this section. You would want to copy paste the content; of the file, specifically the section for the provider under backend -> providers,; into the backend -> providers section in the [cromwell.examples.conf](cromwell.examples.conf).; Here is what it would look like to add the [slurm](slurm.conf) backend; provider example. . ```; backend {. # Override the default backend.; #default = ""LocalExample"". # The list of providers. Copy paste the contents of a backend provider in this section; providers {; slurm {; ...; }; }. # Second backend provider would be copy pasted here!. }; }; ```. This isn't json, so you don't need to add commas between the providers - just; copy paste them one after the other in the backend -> providers section.; Let's say we wanted slurm to be our default! We would do this:. ```; backend {. # Override the default backend.; default = slurm. # The list of providers. Copy paste the contents of a backend provider in this section; providers {; slurm {; ...; }; }; }; }; ```. Don't forget to customize the sections for your purposes! If anything is; not explained clearly, please [open an issue](https://github.com/broadinstitute/cromwell/issues). ## What if a provider is missing?. If a provider is missing and you don't want to use the [LocalExample](LocalExample.conf); to write a custom provider, please [let us know](https://github.com/broadinstitute/cromwell/issues); and we can start discussion about how to define your backend.; ",MatchSource.DOCS,cromwell.example.backends/README.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/cromwell.example.backends/README.md
https://github.com/broadinstitute/cromwell/tree/87/docs/CommandLine.md:172,Integrability,message,message,172,"; For built-in documentation of Cromwell command line usage, run the Cromwell JAR file with no arguments:. `$ java -jar cromwell-<versionNumber>.jar`. You will get a usage message like the following:. ```bash; cromwell 29; Usage: java -jar /path/to/cromwell.jar [server|run] [options] <args>... --help Cromwell - Workflow Execution Engine; --version ; Command: server; Starts a web server on port 8000. See the web server documentation for more details about the API endpoints.; Command: run [options] workflow-source; Run the workflow and print out the outputs in JSON format.; workflow-source Workflow source file or workflow url .; --workflow-root <value> Workflow root; -i, --inputs <value> Workflow inputs file.; -o, --options <value> Workflow options file.; -t, --type <value> Workflow type.; -v, --type-version <value>; Workflow type version.; -l, --labels <value> Workflow labels file.; -p, --imports <value> A zip file to search for workflow imports.; -m, --metadata-output <value>; An optional JSON file path to output metadata.; ```. Cromwell's Server and Run modes can be invoked with the `server` and `run` arguments respectively. More information on these Cromwell modes can be found in [Modes](Modes). The Cromwell jar file can be built as described in [Building](Building). . ## `server`. `server` mode accepts no arguments and runs Cromwell as a web server that accepts REST requests. The default mode for most applications of Cromwell, suitable for production use. Cromwell self-documents its API with Swagger, viewable at `http://localhost:8000` or equivalent depending on your setup. . ## `run`. `run` mode executes a single workflow in Cromwell and then exits. It is designed for local prototyping or demos and has limited features compared to `server`. * **`workflow-source`** ; The single required argument. It can be either a local path or a remote URL pointing to the workflow source file.; ; * **`--inputs`** ; An optional file of workflow inputs. Although optional, it is a ",MatchSource.DOCS,docs/CommandLine.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/CommandLine.md
https://github.com/broadinstitute/cromwell/tree/87/docs/CommandLine.md:1579,Integrability,depend,depending,1579,"int out the outputs in JSON format.; workflow-source Workflow source file or workflow url .; --workflow-root <value> Workflow root; -i, --inputs <value> Workflow inputs file.; -o, --options <value> Workflow options file.; -t, --type <value> Workflow type.; -v, --type-version <value>; Workflow type version.; -l, --labels <value> Workflow labels file.; -p, --imports <value> A zip file to search for workflow imports.; -m, --metadata-output <value>; An optional JSON file path to output metadata.; ```. Cromwell's Server and Run modes can be invoked with the `server` and `run` arguments respectively. More information on these Cromwell modes can be found in [Modes](Modes). The Cromwell jar file can be built as described in [Building](Building). . ## `server`. `server` mode accepts no arguments and runs Cromwell as a web server that accepts REST requests. The default mode for most applications of Cromwell, suitable for production use. Cromwell self-documents its API with Swagger, viewable at `http://localhost:8000` or equivalent depending on your setup. . ## `run`. `run` mode executes a single workflow in Cromwell and then exits. It is designed for local prototyping or demos and has limited features compared to `server`. * **`workflow-source`** ; The single required argument. It can be either a local path or a remote URL pointing to the workflow source file.; ; * **`--inputs`** ; An optional file of workflow inputs. Although optional, it is a best practice to use an inputs file to satisfy workflow; requirements rather than hardcoding inputs directly into a workflow source file. * **`--options`** ; An optional file of workflow options. Some options are global (supported by all backends), while others are backend-specific. See the [Workflow Options](wf_options/Overview) for more details. * **`--type`** ; An optional parameter to specify the language for the workflow source. As of Cromwell 29 any value specified for this parameter is currently ignored and internally the value `",MatchSource.DOCS,docs/CommandLine.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/CommandLine.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3426,Availability,failure,failures,3426,"s, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3445,Availability,error,errors,3445,"s, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3467,Availability,error,errors,3467,"ebservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-con",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3561,Availability,error,errors,3561,"port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1`",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:6884,Availability,avail,available,6884,"rovides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cl",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8740,Availability,down,down,8740,"docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hoc",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:14856,Availability,error,errors,14856,"max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple giga",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17553,Availability,failure,failure,17553," By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order l",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:23158,Availability,avail,available,23158,"ting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24398,Availability,heartbeat,heartbeat,24398,"ckend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This pe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24497,Availability,heartbeat,heartbeat,24497,"amples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown durat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24651,Availability,avail,available,24651,"ell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24691,Availability,heartbeat,heartbeat,24691,"<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24761,Availability,heartbeat,heartbeats,24761,"ortion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the he",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24944,Availability,heartbeat,heartbeats,24944,"ll restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch siz",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25003,Availability,heartbeat,heartbeats,25003,"would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heart",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25017,Availability,heartbeat,heartbeat-interval,25017,"would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heart",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25276,Availability,heartbeat,heartbeats,25276," or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshol",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25378,Availability,heartbeat,heartbeats,25378,"t"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold v",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25398,Availability,failure,failure-shutdown-duration,25398,"t"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold v",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25574,Availability,heartbeat,heartbeats,25574," been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can cra",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25700,Availability,heartbeat,heartbeats,25700," value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing durin",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25774,Availability,heartbeat,heartbeat,25774," value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing durin",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25880,Availability,heartbeat,heartbeats,25880,"eartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 10000",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26020,Availability,heartbeat,heartbeats,26020,"ts {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum dept",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26070,Availability,heartbeat,heartbeats-to-write,26070,"val option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26218,Availability,heartbeat,heartbeat,26218,"**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https:/",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26339,Availability,heartbeat,heartbeats,26339,"ocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; ma",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26450,Availability,heartbeat,heartbeat,26450," minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26534,Availability,error,error,26534," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:64,Deployability,configurat,configuration,64,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:477,Deployability,configurat,configuration,477,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:508,Deployability,configurat,configuration,508,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:664,Deployability,configurat,configuration,664,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:919,Deployability,configurat,configuration,919,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1090,Deployability,configurat,configurations,1090,"iles or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromw",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1238,Deployability,configurat,configuration,1238,"ind a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1454,Deployability,configurat,configuration,1454," You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port =",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1485,Deployability,configurat,configuration,1485," You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port =",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1919,Deployability,configurat,configuration,1919,"file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1966,Deployability,configurat,configuration,1966,"file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2110,Deployability,configurat,configuration,2110,"ocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2153,Deployability,configurat,configuration,2153,"(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the nu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2452,Deployability,configurat,configuration,2452,"ce.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network f",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2544,Deployability,configurat,configuration,2544,"xt two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retry",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2643,Deployability,configurat,configuration,2643,"); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the num",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2746,Deployability,configurat,configuration,2746,"ted values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following confi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2872,Deployability,configurat,configuration,2872,".interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent W",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3256,Deployability,configurat,configuration,3256,"well server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ``",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3730,Deployability,configurat,configuration,3730,"](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration*",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4676,Deployability,configurat,configuration,4676," that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an exter",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4746,Deployability,configurat,configuration,4746," option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By defau",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:6141,Deployability,configurat,configuration,6141,"or a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-m",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7333,Deployability,configurat,configuration,7333," ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8043,Deployability,configurat,configuration,8043," change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Not",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10651,Deployability,configurat,configuration,10651,"umber of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for y",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10710,Deployability,configurat,configuration,10710,"te Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Ob",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10791,Deployability,configurat,configurations,10791,"es metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromw",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10941,Deployability,configurat,configurations,10941,", etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; dat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11014,Deployability,install,installed,11014,", etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; dat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11698,Deployability,install,install,11698,"well's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedC",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11919,Deployability,configurat,configuration,11919,"se configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13585,Deployability,configurat,configuration,13585,"l's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16416,Deployability,configurat,configuration,16416," is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell w",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17080,Deployability,configurat,configuration,17080,"ed. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possibl",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22579,Deployability,configurat,configuration,22579,"d `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Wo",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22651,Deployability,configurat,configuration,22651,"y. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22794,Deployability,configurat,configuration,22794,"g directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portio",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:23284,Deployability,configurat,configuration,23284,"oring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24119,Deployability,configurat,configuration,24119,"; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. Th",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24486,Deployability,update,update,24486,"amples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown durat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24713,Deployability,configurat,configuration,24713,"<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26291,Deployability,configurat,configuration,26291,"tbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). Thi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26841,Deployability,configurat,configuration,26841," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:27315,Deployability,configurat,configuration,27315," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3207,Energy Efficiency,allocate,allocated,3207,"y affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22095,Energy Efficiency,reduce,reduce,22095,"poch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.L",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22268,Energy Efficiency,monitor,monitoring,22268,"ely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for th",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22383,Energy Efficiency,monitor,monitor,22383,"he ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cr",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22454,Energy Efficiency,monitor,monitoring,22454,"king as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-fol",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1694,Integrability,interface,interface,1694,"our configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration set",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1837,Integrability,interface,interface,1837,"ile=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2505,Integrability,interface,interface,2505,"ion as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5084,Integrability,message,messaged,5084," Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empt",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8287,Integrability,protocol,protocols,8287,"ocal backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11095,Integrability,message,message,11095,"tadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/crom",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21,Modifiability,config,configure,21,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:64,Modifiability,config,configuration,64,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:477,Modifiability,config,configuration,477,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:508,Modifiability,config,configuration,508,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:571,Modifiability,config,config,571,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:621,Modifiability,config,config-object-notation,621,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:664,Modifiability,config,configuration,664,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:919,Modifiability,config,configuration,919,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1090,Modifiability,config,configurations,1090,"iles or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromw",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1238,Modifiability,config,configuration,1238,"ind a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1454,Modifiability,config,configuration,1454," You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port =",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1485,Modifiability,config,configuration,1485," You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port =",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1919,Modifiability,config,configuration,1919,"file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:1966,Modifiability,config,configuration,1966,"file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2110,Modifiability,config,configuration,2110,"ocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2153,Modifiability,config,configuration,2153,"(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the nu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2452,Modifiability,config,configuration,2452,"ce.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network f",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2544,Modifiability,config,configuration,2544,"xt two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retry",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2643,Modifiability,config,configuration,2643,"); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the num",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2746,Modifiability,config,configuration,2746,"ted values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following confi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2872,Modifiability,config,configuration,2872,".interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent W",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3256,Modifiability,config,configuration,3256,"well server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ``",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3730,Modifiability,config,configuration,3730,"](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration*",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3863,Modifiability,config,configurable,3863,"file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; syste",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4140,Modifiability,config,configured,4140,"econd. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next s",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4676,Modifiability,config,configuration,4676," that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an exter",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4746,Modifiability,config,configuration,4746," option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By defau",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5980,Modifiability,config,configure,5980," will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell u",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:6141,Modifiability,config,configuration,6141,"or a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-m",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:6329,Modifiability,rewrite,rewriteBatchedStatements,6329,"e should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used ca",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7333,Modifiability,config,configuration,7333," ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7396,Modifiability,config,config,7396," ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7528,Modifiability,config,config,7528,"he `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL.",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7644,Modifiability,config,config,7644,"ver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-comp",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8043,Modifiability,config,configuration,8043," change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Not",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8078,Modifiability,variab,variables,8078," change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Not",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10159,Modifiability,config,config,10159," add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized o",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10175,Modifiability,config,configure,10175," add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized o",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10651,Modifiability,config,configuration,10651,"umber of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for y",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10710,Modifiability,config,configuration,10710,"te Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Ob",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10791,Modifiability,config,configurations,10791,"es metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromw",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:10941,Modifiability,config,configurations,10941,", etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; dat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11357,Modifiability,rewrite,rewriteBatchedStatements,11357,"ch larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgre",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11919,Modifiability,config,configuration,11919,"se configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:12871,Modifiability,config,config,12871,"esql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:12981,Modifiability,config,config,12981,"profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13044,Modifiability,config,configured,13044,".Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13585,Modifiability,config,configuration,13585,"l's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16193,Modifiability,config,configured,16193,"lly after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (def",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16416,Modifiability,config,configuration,16416," is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell w",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17080,Modifiability,config,configuration,17080,"ed. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possibl",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17916,Modifiability,config,config,17916,"ell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17943,Modifiability,config,config,17943,"cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time,",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18712,Modifiability,extend,extended,18712,"l-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprin",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21748,Modifiability,config,configurable,21748,"ault.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22579,Modifiability,config,configuration,22579,"d `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Wo",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22651,Modifiability,config,configuration,22651,"y. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22794,Modifiability,config,configuration,22794,"g directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portio",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22865,Modifiability,config,config-key-for-backend,22865,"change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:23069,Modifiability,config,config,23069," workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:23190,Modifiability,variab,variable,23190,"ting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:23284,Modifiability,config,configuration,23284,"oring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24119,Modifiability,config,configuration,24119,"; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends/cromwell.examples.conf; [cromwell-examples-folder]: https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends. ### Workflow Heartbeats. **Cromwell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. Th",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24713,Modifiability,config,configuration,24713,"<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25652,Modifiability,config,configurable,25652," value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing durin",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26106,Modifiability,config,configurable,26106,"val option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26272,Modifiability,config,configured,26272,"tbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). Thi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26291,Modifiability,config,configuration,26291,"tbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). Thi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26822,Modifiability,config,configured,26822," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26841,Modifiability,config,configuration,26841," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:27296,Modifiability,config,configured,27296," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:27315,Modifiability,config,configuration,27315," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:611,Performance,optimiz,optimized-config-object-notation,611,"## Overview. You can configure Cromwell settings either through configuration files or the Java command line. Check out the tutorial on [How to Configure Cromwell](tutorials/ConfigurationFiles) for more information. ### Configuration examples. You can find a description of options and example stanzas in the [Cromwell Example Configuration][cromwell-examples-conf],; along with backend provider examples in the [Example Providers Folder][cromwell-examples-folder]. ### Custom configuration files. You write configuration files in; [HOCON](https://github.com/typesafehub/config/blob/master/HOCON.md#hocon-human-optimized-config-object-notation). To run using your configuration file, you should copy relevant stanzas from `cromwell.examples.conf` into a new; file, modify it as appropriate, then pass it to Cromwell via:. ```; $ java -Dconfig.file=/path/to/yourOverrides.conf cromwell.jar ...; ``` . To create your own configuration file, start by creating a new text file, for example `my.conf`. At the start of your file, include the file `application.conf` at the top before your custom configurations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify valu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2203,Performance,perform,performance,2203,"(classpath(""application"")); ```. From there, copy or add other configuration values and/or stanzas with your customizations. ```hocon; # include the application.conf at the top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the nu",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:3161,Performance,throttle,throttle,3161,"y affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4009,Performance,concurren,concurrent-workflows,4009,"mits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell w",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4477,Performance,concurren,concurrent-workflows,4477,"etried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; `",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4985,Performance,cache,cache,4985,"n; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5048,Performance,cache,cache,5048," Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empt",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5197,Performance,cache,cache,5197,"ge the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follow",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5275,Performance,cache,cache,5275,"oll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5292,Performance,cache,cache,5292,"oll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5298,Performance,concurren,concurrency,5298,"oll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5312,Performance,concurren,concurrency,5312,"ell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; u",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5354,Performance,cache,cache,5354,"ell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; u",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5408,Performance,cache,cache,5408,"ell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; u",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5468,Performance,cache,cache,5468,"ws to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the f",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:9491,Performance,queue,queues,9491,"ySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; };",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:9569,Performance,perform,performance,9569,"ySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; };",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:11575,Performance,perform,performs,11575,"tionTimeout = 3000; }; }; }; ```. If no override is found for `metadata`, Cromwell falls back to using the settings under the root `database` configuration. **Database Time Zones**. Cromwell's default configuration assumes that its MySQL database is set to UTC. The following MySQL configurations typically default to UTC and work with Cromwell out of the box:; - Google CloudSQL; - An official MySQL image running in Docker. These configurations may use the system, or local, time zone instead:; - MySQL installed natively on a workstation or server. If Cromwell fails to start with a message like; ```; The server time zone value 'XXX' is unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role th",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13831,Performance,cache,cached,13831,"at owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:14460,Performance,cache,cached,14460,"**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `n",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17148,Performance,cache,cache-results,17148,"For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more informa",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17352,Performance,cache,cache-results,17352,"he configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""c",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17420,Performance,cache,cache,17420,"he configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""c",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17487,Performance,cache,cache-hit,17487,"he configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""c",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17734,Performance,cache,cache,17734,"rkflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18103,Performance,cache,cached-copy,18103,"onfiguration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy wil",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18305,Performance,cache,cached,18305,"ropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18420,Performance,cache,cached-copy,18420,"l will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file pat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20146,Performance,cache,cache,20146," copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file.",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20421,Performance,optimiz,optimized,20421,"f the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:25600,Performance,queue,queued,25600," been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can cra",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26061,Performance,queue,queue,26061,"val option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26228,Performance,load,load,26228,"**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https:/",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2818,Safety,timeout,timeout,2818,".interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent W",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2923,Safety,timeout,timeout,2923,"tion files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network failures to server errors. Some of those errors are not fatal and can be retried. Cromwell will retry I/O operations on such retryable errors, for a limited number of times before giving up and failing. This number (more precisely the number of attempts that will be made) can be set using the following configuration option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4717,Safety,abort,abort,4717," option:. ```; system.io {; number-of-attempts = 5; }; ```. ### Workflows. **Max Concurrent Workflows**. Cromwell has a configurable cap on the number of workflows running at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By defau",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4891,Safety,abort,abort,4891,"nning at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up M",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:4942,Safety,abort,aborts,4942,"nning at a time. You can adjust the limit from the default `5000` by setting:. ```hocon; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up M",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5006,Safety,abort,aborts,5006,"n; system.max-concurrent-workflows = 5000; ```. **New Workflow Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5096,Safety,abort,abort,5096," Poll Rate**. Cromwell will look for new workflows to start on a regular interval, configured as a number of seconds. You can change the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empt",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:5261,Safety,abort,abort,5261,"ge the polling rate from the default `20` seconds by editing the value:. ```hocon; system.new-workflow-poll-rate = 20; ```. **Max Workflow Launch Count**. On every poll, Cromwell will take at limited number of new submissions, provided there are new workflows to launch and the `system.max-concurrent-workflows` number has not been reached. While the default is to launch up to `1` workflow, you can override this by setting:. ```hocon; system.max-workflow-launch-count = 1; ```. ***Abort configuration***. Cromwell will scan for abort requests using default configuration values equivalent to those below. In most circumstances; there shouldn't be a need to override these defaults. ```hocon; system {; abort {; # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follow",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:15056,Safety,redund,redundancy,15056,"ion of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabl",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:15378,Safety,timeout,timeout,15378,"wn unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this fe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16119,Safety,abort,abort,16119,"b.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {;",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16162,Safety,abort,aborting,16162,"lly after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (def",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16228,Safety,abort,abort,16228,"lly after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (def",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16459,Safety,abort,abort-jobs-on-terminate,16459,"1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot b",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16515,Safety,abort,abort-jobs-on-terminate,16515," environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwa",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16767,Safety,abort,abort,16767," Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Loc",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16806,Safety,abort,abort,16806," Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Loc",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16869,Safety,detect,detect,16869," * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional option",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:26545,Safety,detect,detecting,26545," }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued by Cromwell and written in batches. When the configurable batch size is; reached, all of the heartbeats within the batch will be written at the same time, even if the heartbeat interval has not; elapsed. This batch threshold may be adjusted via:. ```hocon; system.workflow-heartbeats {; write-batch-size = 100; }; ```. The default batch size is 100. **Heartbeat Threshold**. Cromwell writes one batch of workflow heartbeats at a time. While the internal queue of heartbeats-to-write passes above; a configurable threshold then [instrumentation](developers/Instrumentation.md) may send a metric signal that the; heartbeat load is above normal. This threshold may be configured via the configuration value:. ```hocon; system.workflow-heartbeats {; write-threshold = 100; }; ```. The default threshold value is 100, just like the default for the heartbeat batch size. ### YAML. **Maximum number of nodes**. Cromwell will throw an error when detecting cyclic loops in Yaml inputs. However one can craft small acyclic YAML; documents that consume significant amounts of memory or cpu. To limit the amount of processing during parsing, there is; a limit on the number of nodes parsed per YAML document. This limit may be configured via the configuration value:. ```hocon; yaml {; max-nodes = 1000000; }; ```. The default limit is 1,000,000 nodes. **Maximum nesting depth**. There is a limit on the maximum depth of nested YAML. If you decide to increase this value, you will likely need to also; increase the Java Virtual Machine's thread stack size as well using; [either `-Xss` or `-XX:ThreadStackSize`](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html). This limit may be configured via the configuration value:. ```hocon; yaml {; max-depth = 100; }; ```. The default limit is a maximum nesting depth of 1,000.; ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2327,Security,access,access,2327,"e top; include required(classpath(""application"")). # Add customizations; webservice.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. *",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:6376,Security,password,password,6376,"e should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }; }; ```. ### Database. **Using a MySQL Database**. Cromwell tracks the execution of workflows and stores outputs of task invocations in a SQL database. Cromwell supports either an external MySQL database, or a temporary in-memory database. By default, Cromwell uses an in-memory database which will only live for the duration of the JVM. This provides a quick way to run workflows locally without having to set up MySQL, though it also makes workflow executions somewhat transient. To configure Cromwell to instead point to a MySQL database, first create the empty database. In the example below, the database name is `cromwell`. Then, edit your configuration file `database` stanza, as follows:. ```hocon; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }; ```. To see the full list of possible parameters and values for the `db` stanza see [the slick documentation](http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used ca",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:12153,Security,password,password,12153," unrecognized or represents more than one time zone.; ```; you can resolve the problem by adding the option `&serverTimezone=UTC` to your database connection URL:; ```hocon; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""s",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:12380,Security,access,access,12380,"rl = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true&serverTimezone=UTC""; ```. Using this option does not alter your database's underlying timezone; rather, it causes Cromwell to ""speak UTC"" when communicating with the DB, and the DB server performs the conversion for you. . **Using Cromwell with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; pa",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13323,Security,password,password,13323,", you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:15678,Security,password,passwords,15678,"ry for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script_format=3`. Compress script. (uses gzip internally). ; The script can still be opened normally after decompressing with gzip.; * `connectionTimeout = 120000` opening the large database files again when running cromwell will ; take some time. The default timeout of 3000 ms (3s) is not enough. So it is set to 120000ms (120s).; * `numThreads = 1`. This will limit the CPU usage of Cromwell, which can be useful in HPC environments. Comparison to MySQL (or PostgreSQL) server:; Advantages:. * No need to set up a server; * No worries about database users, passwords and permissions. This will be handled by filesystem permissions. Disadvantages:. * Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17469,Security,access,accessed,17469,"he configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""c",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:17619,Security,authenticat,authentication,17619," By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order l",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18837,Security,hash,hash,18837,"the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18896,Security,hash,hash,18896,"tions in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When localizing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same nam",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:18999,Security,hash,hash,18999,"zing a file, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If fals",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:19233,Security,hash,hash,19233,"ization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; # When copying a cached result, what type of file duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the e",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:19406,Security,hash,hashed,19406,"ile duplication should occur. ; # possible values: ""hard-link"", ""soft-link"", ""copy"", ""cached-copy"".; # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:19452,Security,hash,hash,19452," check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem; # Attempted in the order listed below:; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:19567,Security,hash,hashing-strategy,19567,"link"", ""copy""; ]. # Possible values: md5, xxh64, fingerprint, path, path+modtime; # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching; # ""md5"" will compute an md5 hash of the file content.; # ""xxh64"" will compute an xxh64 hash of the file content. Much faster than md5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely ligh",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:19975,Security,hash,hash,19975,"5; # ""fingerprint"" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20056,Security,hash,hashing,20056,"xh64 to create a file fingerprint.; # This strategy will only be effective if the duplication-strategy (above) is set to ""hard-link"", as copying changes the last modified time.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20193,Security,hash,hash,20193,".; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than th",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20440,Security,integrity,integrity,20440,"f the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20450,Security,hash,hashing,20450,"f the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: ""md5""; hashing-strategy: ""md5""; ; # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint. ; # If the file is smaller than this size the entire file will be read.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strat",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20774,Security,hash,hash,20774,"ad.; # Default: 10485760 (10MB). ; fingerprint-size: 10485760. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### W",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:20824,Security,hash,hash,20824,"60. # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; # Default: false; check-sibling-md5: false; }; }; }; }; ```. #### Call cache strategy options for local filesystem. * hash based options. These read the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwe",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21203,Security,hash,hash,21203,"ead the entire file. These strategies work with containers.; * `xxh64` (community-supported*). This uses the 64-bit implementation of the [xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; wor",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21364,Security,hash,hashing,21364,"[xxHash](https://www.xxhash.com); algorithm. This algorithm is optimized for file integrity hashing and provides a more than 10x speed improvement over; md5.; * `md5`. The well-known md5sum algorithm; * Path based options. These are based on filepath. Extremely lightweight, but only work with the `soft-link` file ; caching strategy and can therefore do not work with containers by default.; * `path` creates a md5 hash of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a serv",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:9242,Testability,log,logs,9242,"google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metad",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:9291,Testability,log,logs,9291,"google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metad",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:9341,Testability,log,logs,9341,"set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature should be considered _experimental_ and likely to change in the future. Cromwell stores metadata about each job and workflow intended. This metadata is intended for end users, and includes paths to job results, start and end times, etc. The metadata grows at a significantly faster rate than the rest of the internal engine data. To use a separate database for metadata, under the `database` config section, configure a sub-path for `metadata` with custom settings. ```hocon; database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; m",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:12664,Testability,log,login,12664,"ll with Postgresql**. To use Postgresql as the database, you will need to install and enable the; Large Object extension. If the extension is present, setting up the database; requires just these commands:. ```; $ createdb cromwell; $ psql -d cromwell -c ""create extension lo;""; ```. Postgresql configuration in Cromwell is very similar to MySQL. An example:. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; d",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:13055,Testability,log,login,13055,".Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. If you want multiple database users to be able to read Cromwell's data from a Postgresql database, you'll need to create a; role that all relevant users have access to, and adjust Cromwell to use this role. This is because each Large Object is owned; by, and only readable by, the role that wrote it. First, pass these options when executing Cromwell. They will ensure that Cromwell's database tables are ; owned by the role, not the initial login user.; * `-DengineSharedCromwellDbRole=your_role` to control the role that owns the engine tables; * `-DsharedCromwellDbRole=your_role` to control the role that owns the metadata tables. Next, use the config key `pgLargeObjectWriteRole` to set the role that should own all large objects, as shown below. ; This config will have no effect if you aren't using Postgresql. The configured login user can be any user that is; granted the shared role. ```hocon; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21778,Testability,log,log,21778,"sh of the path.; * `path+modtime` creates a md5 hash of the path and its modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wi",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21848,Testability,log,logs,21848,"ts modification time.; * Fingerprinting. This strategy works with containers.; * `fingerprint` (community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-bac",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21941,Testability,log,log-dir,21941,"community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:21970,Testability,log,logs,21970,"community-supported*) tries to create a fingerprint for each file by taking its last modified time (milliseconds since; epoch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, ",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22059,Testability,log,logs,22059,"poch in hexadecimal) + size (bytes in hexadecimal) + the xxh64 sum of the first 10 MB** of the file. ; It is much more lightweight than the hash based options while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.L",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22226,Testability,log,log-temporary,22226,"s while still unique enough that collisions are unlikely. This ; strategy works well for workflows that generate multi-gigabyte files and where hashing these files on the ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `refer",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:22431,Testability,log,logs,22431,"he ; cromwell instance provides CPU or I/O problems. ; NOTE: This strategy requires hard-linking as a dupliation strategy, as copying changes the last modified time. (*) The `fingerprint` and `xxh64` strategies are features that are community supported by Cromwell's HPC community. There; is no official support from the core Cromwell team. (**) This value is configurable.; ; ### Workflow log directory. To change the directory where Cromwell writes workflow logs, change the directory location via the setting:. ```hocon; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; }; ```. **Preserving Workflow Logs**. By default Cromwell erases the per workflow logs when the workflow completes to reduce disk usage. You can change this behavior by setting the following value to `false`:. ```hocon; workflow-options {; workflow-log-temporary = true; }; ```. **Exception monitoring via Sentry**. Cromwell supports [Sentry](https://docs.sentry.io) which is a service that can be used to monitor exceptions reported in an application’s logs. To enable Sentry monitoring in Cromwell, enter your DSN URL using the system property:. ```properties; sentry.dsn=DSN_URL; ```. ### Job shell configuration. Cromwell allows for system-wide or per-backend job shell configuration for running user commands rather than always; using the default `/bin/bash`. To set the job shell on a system-wide basis use the configuration key `system.job-shell` or on a; per-backend basis with `<config-key-for-backend>.job-shell`. For example:. ```; # system-wide setting, all backends get this; -Dsystem.job-shell=/bin/sh; ```. ```; # override for just the Local backend; -Dbackend.providers.Local.config.job-shell=/bin/sh; ```. For the Config backend the value of the job shell will be available in the `${job_shell}` variable. See Cromwell's `reference.conf` for an example; of how this is used for the default configuration of the `Local` backend. [cromwell-examples-conf]: https://www.github.com/broadinstitute/cr",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:2411,Usability,simpl,simply,2411,"ce.port = 58000; ```. Your configuration file can specify configuration as JSON-like stanzas or as dot-separated values. These next two examples are are equivalent. _JSON-like stanza:_. ```hocon; include required(classpath(""application"")); webservice {; port = 8000; interface = 0.0.0.0; }; ```. _Dot-separated values:_. ```hocon; include required(classpath(""application"")); webservice.port = 8000; webservice.interface = 0.0.0.0; ```. ## Configuration via command line. In addition to using configuration files, you can use dot-separated configuration names to specify values directly on the Java command line:. ```; $ java -Dwebservice.port=8080 cromwell.jar ...; ```. ## Advanced configuration. **WARNING:** These advanced configuration values can significantly affect the performance of Cromwell. . ### Server. By default the Cromwell server will bind to `0.0.0.0` on port `8000`. ; You can then access it through a browser at `http://localhost:8000`. ; To change these settings, simply edit the following values in your configuration file:. ```; webservice {; port = 9000; interface = 0.0.0.0; }; ```. The above configuration will use port `9000`. Cromwell uses `akka-http` to serve requests. For more advanced configuration settings, refer to the [akka-http](https://doc.akka.io/docs/akka-http/current/scala/http/configuration.html) documentation. For example, to increase the request timeout to 30 seconds you can add this stanza to your configuration file:. ```; akka.http.server.request-timeout = 30s; ```. ### I/O. **I/O Throttling**. Certain [backends](backends/Backends) impose I/O limits. For example the Pipelines API imposes a quota on the number of queries that can be made per second. You can effectively control and throttle the number of requests and resources allocated to those operations in the `system.io` configuration:. ```; system.io {; number-of-requests = 100000; per = 100 seconds; }; ```. **I/O Resilience**. I/O operations can fail for a number of reason from network f",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:7571,Usability,simpl,simply,7571,"ick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database). **Cromwell server on MySQL Database**. You can use [docker-compose](https://github.com/broadinstitute/cromwell/tree/develop/scripts) to link together a Cromwell docker image (built locally with `sbt docker` or available on [Dockerhub](https://hub.docker.com/r/broadinstitute/cromwell/)) with a MySQL docker image. To change the version of Cromwell used, [change the tag in `compose/cromwell/Dockerfile`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/Dockerfile). **Local**. `docker-compose up` from this directory will start a Cromwell server running on a MySQL instance with local backend. The default configuration file used can be [found at `compose/cromwell/app-config/application.conf`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf).; To override it, simply mount a volume containing your custom `application.conf` to `/app-config` ([see `jes-cromwell/docker-compose.yml` for an example](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:8772,Usability,simpl,simply,8772,"ts/docker-compose-mysql/jes-cromwell/docker-compose.yml)). **Google Cloud**. The [`jes-cromwell` directory](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/jes-cromwell) is an example of how to customize the original compose file with a configuration file and environment variables. It uses the application default credentials of the host machine. To use it make sure your gcloud is up to date and that your [application-default credentials](https://developers.google.com/identity/protocols/application-default-credentials) are set up. Then run `docker-compose -f docker-compose.yml -f jes-cromwell/docker-compose.yml up` to start a Cromwell server with a Google Cloud backend on MySQL. **MySQL**. The data directory in the MySQL container is [mounted to `compose/mysql/data`](https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql/compose/mysql/init), which allows the data to survive a `docker-compose down`. To disable this feature, simply remove the `./compose/mysql/data:/var/lib/mysql` line in the [volume section of `docker-compose.yml`](https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/docker-compose.yml). Note that in such case, the data will still be preserved by a `docker-compose stop` that stops the container but doesn't delete it. **Notes**. To run Cromwell in the background, add `-d` at the end of the command:; `docker-compose up -d`. To then see the logs for a specific service, run `docker-compose logs -f <service>`. ; For example `docker-compose logs -f cromwell`. For more information about docker compose: [Docker compose doc](https://docs.docker.com/compose/). **Insert Batch Size**. Cromwell queues up and then inserts batches of records into the database for increased performance. You can adjust the; number of database rows batch inserted by Cromwell as follows:. ```hocon; database {; insert-batch-size = 2000; }; ```. **Separate Metadata Database**. This feature sh",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:14112,Usability,guid,guide,14112,"n; database {; profile = ""slick.jdbc.PostgresProfile$""; pgLargeObjectWriteRole = ""your_role""; db {; driver = ""org.postgresql.Driver""; url = ""jdbc:postgresql://localhost:5432/cromwell""; user = ""user""; password = ""pass""; port = 5432; connectionTimeout = 5000; }; }; ```. **Using Cromwell with file-based database (No server required)**. SQLite is currently not supported. However, HSQLDB does support running with a persistence file.; To set this up the following configuration can be used:; ```hocon; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. Explanation of the options (see also http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html):. * `jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;` This will make sure; all persistence files will end up in a folder `cromwell-db` inside `cromwell-executions`.; * `shutdown=false`. This makes sure the database will not be shutdown unless Cromwell explicitly does so.; * `hsqlldb.default_table_type=cached`. ; By default hsqldb uses in memory tables, this will ensure data is written to disk and ; decrease memory usage.; * `hsqldb.result_max_memory_rows=10000` . Limits the amount of rows in memory for temp tables. ; * `hsqldb.tx=mvcc` this is a cromwell default for running with hsqldb.; * `hsqldb.large_data=true`. Cromwell creates huge DBs that need to be opened.; * `hsqldb.applog=1`. Log errors relating to the database.; * `hsqldb.lob_compressed=true`. Compress lobs. This saves some space. Do note that lobs are ; compressed individually. The total database will still contain a lot of redundancy because a; lot of lobs will be similar.; * `hsqldb.script",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16785,Usability,learn,learn,16785," Cromwell requires more memory; * The database files will consume a lot of disk space (multiple gigabytes are not uncommon); * Cromwell's interaction with the database is slower. Comparison to the default in-memory database:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Loc",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:16959,Usability,learn,learn,16959,"atabase:; Advantages:. * Much less memory needed.; * Call-caching enabled. Disadvantages:. * Slower. ### Abort. **Control-C (SIGINT) abort handler**. For backends that support aborting jobs, Cromwell can be configured to automatically try to abort all calls when it receives a Control-C, also known as SIGINT. All currently running calls will also set their status to `Aborted`. To explicitly turn this feature on or off, set the configuration option:. ```hocon; system {; abort-jobs-on-terminate=true; }; ```. Or, via `-Dsystem.abort-jobs-on-terminate=true` command line option. By default, this value is false when running `java -jar cromwell.jar server`, and true when running `java -jar cromwell.jar run <workflow source> <inputs>`. Read the [Abort](execution/ExecutionTwists/#abort) section to learn more about how abort works. ### Call caching. Call Caching allows Cromwell to detect when a job has been run in the past so it doesn't have to re-compute results. ; To learn more see [Call Caching](cromwell_features/CallCaching). To enable Call Caching, add the following to your Cromwell configuration:. ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```. When `call-caching.enabled=true` (default: `false`), Cromwell will be able to to reference or copy results from previously run jobs (when appropriate).; When `invalidate-bad-cache-results=true` (default: `true`), Cromwell will invalidate any cache results which contain files that cannot be accessed within a cache-hit. This is usually desired, but might be unwanted if this failure occurs for external reasons, such as a difference in user authentication. Cromwell also accepts [Workflow Options](wf_options/Overview#call-caching-options) to override the cache read/write behavior. . ### Local filesystem options. When running a job on the Config (Shared Filesystem) backend, Cromwell provides some additional options in the backend's ; config section:. ```HOCON; config {; filesystems {; local {; # When loc",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md:24632,Usability,resume,resumed,24632,"ell ID**. Each Cromwell instance is assigned a `cromwell_id`. By default, the Cromwell ID is `cromid-<7_digit_random_hex>`.; A custom identifier may replace the ""cromid"" portion of the string. For example:. ```hocon; system {; cromwell_id = ""main""; }; ```. This would generates a `cromwell_id` of `main-<7_digit_random_hex>`. Each time Cromwell restarts the random part of the; ID will change, however the `main` prefix would remain the same. If the random part of the Cromwell ID should not be generated, set the configuration value:. ```hocon; system {; cromwell_id_random_suffix = false; }; ```. **Heartbeat TTL**. When a Cromwell instance begins running or resuming a workflow it stores the above `cromwell_id` within the database row; for the workflow, along with a timestamp called the ""heartbeat"". As the workflow continues to run the Cromwell instance; will intermittently update the heartbeat for the running workflow. If the Cromwell dies, after some time-to-live (TTL),; the workflow has been abandoned, and will be resumed by another available Cromwell instance. Adjust the heartbeat TTL via the configuration value:. ```hocon; system.workflow-heartbeats {; ttl = 10 minutes; }; ```. The default TTL is 10 minutes. The shortest allowable value for the TTL option is 10 seconds. **Heartbeat Interval**. The interval for writing heartbeats may be adjusted via:. ```hocon; system.workflow-heartbeats {; heartbeat-interval = 2 minutes; }; ```. The default interval is 2 minutes. The shortest interval option is 3.333 seconds. The interval may not be greater than; the TTL. **Heartbeat Failure Shutdown**. Cromwell will automatically shutdown when unable to write heartbeats for a period of time. This period of time may be; adjusted via:. ```hocon; system.workflow-heartbeats {; write-failure-shutdown-duration = 5 minutes; }; ```. The default shutdown duration is 5 minutes. The maximum allowed shutdown duration is the TTL. **Heartbeat Batch Size**. Workflow heartbeats are internally queued",MatchSource.DOCS,docs/Configuring.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Configuring.md
https://github.com/broadinstitute/cromwell/tree/87/docs/GettingHelp.md:497,Usability,guid,guide,497,"**Support Forum**. If you have questions that aren't covered by this documentation you can ask them in the; [Support Forum](http://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team).; Please note that despite the `wdl` currently in its name, this is a forum that supports Cromwell users too. **Website and User Guide**. The [WDL website](https://software.broadinstitute.org/wdl/) is the best place to go for more information on WDL.; In particular new users should check out the [user guide](https://software.broadinstitute.org/wdl/userguide/); which has many tutorials, examples and other bits to get you started.; ",MatchSource.DOCS,docs/GettingHelp.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/GettingHelp.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Imports.md:88,Availability,mainten,maintenance,88,"Sometimes you might want to break up a long WDL file into smaller components for easier maintenance. Sometimes you'll want to do it to reuse components in multiple workflows. Have no fear, imports are here! Imports allow you to reference other WDL files that contain entire workflows or even just raw tasks. To import a WDL, you can use the `import` WDL construct at the top of your workflow:. ```; import ""<resource>"" as <alias>; ```. There are two types of resources that are supported in imports: *http(s)* and *file-path based*. Any public http(s) based URL can be used as the resource for an import, such as a website, github or a GA4GH compliant TES endpoint. For example:. ```wdl; import ""http://mywdlrepository/my.wdl"" as http_import1; import ""https://raw.githubusercontent.com/broadinstitute/cromwell/master/engine/src/main/resources/3step.wdl"" as http_import2; ```; To use a file-based import resource, provide a ZIP bundle of your resources and then use a path relative to that ZIP in your import statement. For example:. ```wdl; import ""my-wdl-in-the-root-directory.wdl"" as file_import1; import ""my/wdl/sub/directory/example.wdl"" as file_import2; ```. Imports from your submitted workflow are evaluated relative to the base of the zip file. In other cases, import paths are relative to the file you are currently importing from, for example:. >If there exists a `my/wdl/sub/directory/imports/importing_an_import.wdl`, `my/wdl/sub/directory/example.wdl` could import it relatively like so:; >```wdl; >import ""imports/importing_an_import.wdl"" as file_import3; >```. Here's a complete example showing both http(s) and file-based imports workflow in WDL:. _workflow.wdl_; ```wdl; import ""https://raw.githubusercontent.com/broadinstitute/cromwell/master/engine/src/main/resources/3step.wdl"" as http_import; import ""imports/imported.wdl"" as provided_import. workflow my_workflow {; ...; }; ```. Note that we said ""`import ""imports/imported.wdl`"" in the workflow so we must have a `imports/import",MatchSource.DOCS,docs/Imports.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Imports.md
https://github.com/broadinstitute/cromwell/tree/87/docs/LanguageSupport.md:965,Performance,optimiz,optimizations,965,"# Language Support. Below are the Domain Specific Languages (DSL) that Cromwell currently supports and will soon support for describing your workflow. ## Current Language Support. ### WDL Draft 2; Cromwell started life as a WDL engine and WDL draft2 was our first language!; For many examples on how to use WDL and some great getting-started resources you can view [the OpenWDL site](https://github.com/openwdl/wdl#getting-started-with-wdl). Cromwell supports the majority of [Draft-2 of the WDL Spec](https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md). > *Known Issues:*; >; > - Be careful when using `Object`. They are superceded by 'struct' in WDL 1.0 and are being removed outright in WDL 2.0.; > - Cromwell does not support nested `scatter`s in draft-2. ### WDL 1.0. Cromwell also supports WDL version 1.0. As well as the changes to the WDL spec between draft-2 and 1.0, Cromwell also supports nested scatters and the [localization_optional](optimizations/FileLocalization.md) optimization in WDL 1.0. . ## Future Language Support. ### WDL 'development'. As the SPEC is being improved and honed, Cromwell continues to support the current `development` version of WDL. That; means that when (or shortly after) new versions are published, Cromwell will be ready to support them.; ",MatchSource.DOCS,docs/LanguageSupport.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/LanguageSupport.md
https://github.com/broadinstitute/cromwell/tree/87/docs/LanguageSupport.md:1000,Performance,optimiz,optimization,1000,"# Language Support. Below are the Domain Specific Languages (DSL) that Cromwell currently supports and will soon support for describing your workflow. ## Current Language Support. ### WDL Draft 2; Cromwell started life as a WDL engine and WDL draft2 was our first language!; For many examples on how to use WDL and some great getting-started resources you can view [the OpenWDL site](https://github.com/openwdl/wdl#getting-started-with-wdl). Cromwell supports the majority of [Draft-2 of the WDL Spec](https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md). > *Known Issues:*; >; > - Be careful when using `Object`. They are superceded by 'struct' in WDL 1.0 and are being removed outright in WDL 2.0.; > - Cromwell does not support nested `scatter`s in draft-2. ### WDL 1.0. Cromwell also supports WDL version 1.0. As well as the changes to the WDL spec between draft-2 and 1.0, Cromwell also supports nested scatters and the [localization_optional](optimizations/FileLocalization.md) optimization in WDL 1.0. . ## Future Language Support. ### WDL 'development'. As the SPEC is being improved and honed, Cromwell continues to support the current `development` version of WDL. That; means that when (or shortly after) new versions are published, Cromwell will be ready to support them.; ",MatchSource.DOCS,docs/LanguageSupport.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/LanguageSupport.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1555,Availability,error,errors,1555,"rty overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `fin",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2631,Availability,error,error,2631," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1245,Integrability,message,messages,1245,".jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure C",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2702,Integrability,depend,depending,2702," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:331,Modifiability,variab,variable,331,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:479,Modifiability,variab,variable,479,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:535,Modifiability,variab,variable,535,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2237,Modifiability,config,configure,2237," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:103,Testability,log,logging,103,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:302,Testability,log,log,302,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:580,Testability,log,log,580,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:671,Testability,log,logs,671,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:742,Testability,log,logs,742,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:840,Testability,log,logs,840,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:871,Testability,log,logs,871,"## Logging Properties. ### Setting Logging Properties. Cromwell accepts two properties for controlling logging. You can set these properties via a Java system property on the command line using `-D`:. ```bash; $ java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. Alternatively, you can also set the log level via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1331,Testability,log,logged,1331,"el via an environment variable:. ```bash; export LOG_LEVEL=DEBUG; java -jar cromwell.jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Norma",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1432,Testability,log,logs,1432,".jar server; ```. *If you set same property via a system property, and an environment variable, the system property overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the rem",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1538,Testability,log,log,1538,"rty overrides the environment variable.*. ### Log Format. Cromwell outputs log in one of two formats, either `pretty` or `standard`. You can change the format of the logs by setting the property to `LOG_MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `fin",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1705,Testability,log,log,1705,"MODE`. * In `standard` mode, your logs will be written without ANSI escape code coloring, with a layout more appropriate for server logs. * In `pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, dependi",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1857,Testability,log,log,1857,"`pretty` mode, your logs are output in a colorful, easier to read format, more appropriate for a single workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1997,Testability,log,log,1997,"gle workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copy",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2052,Testability,log,log-directory,2052," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2078,Testability,log,logs,2078," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2155,Testability,log,log,2155," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2278,Testability,log,logs,2278," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2339,Testability,log,log,2339," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2421,Testability,log,logs,2421," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2677,Testability,log,log,2677," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2754,Testability,log,logs,2754," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:2795,Testability,log,logs,2795," mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copying) `final_call_logs_dir`.; ",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md:1930,Usability,clear,clear,1930,"gle workflow run. The default mode for server is `standard`, while the default when running a single worklow is `pretty`. You can explicitly specify the format by running cromwell with:. ```bash; java -DLOG_MODE=pretty -jar cromwell.jar server; ```. ### Log Level. By default, Cromwell outputs messages at a `LOG_LEVEL` of `INFO`. Sometimes, you may want more or less information logged. For example, while debugging an issue you may want to increase the amount information in the logs temporarily. Alternatively, the standard level may be too verbose, and you may only want Cromwell to log warnings and errors. You can set the level via the property `LOG_LEVEL` to any one of the values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, or `OFF`. The default log level is `INFO`. ```bash; java -DLOG_LEVEL=DEBUG -jar cromwell.jar server; ```. ## Workflow Logs. While a workflow is running, Cromwell generates a log file specifically for the workflow. After the workflow completes, to clear up local disk space, Cromwell deletes the local copy of this log file. See the [Configuration](Configuring#workflow-log-directory) section on logs for more information on preventing cromwell from deleting each workflow log. Before Cromwell deletes the files and before the workflow completes, you can configure Cromwell to copy the workflow; logs to various locations. Normally, you'll want to copy the log to a remote bucket or directory. To specify the remote; directory to copy the logs to, use the separate [Workflow Option](wf_options/Overview#output-copying); `final_workflow_log_dir`. ## Call Logs. As each call in a workflow runs, it generates output to the standard output and standard error. This output is stored per call in call log files. Additionally, depending on the backend, specific per call backand logs may be generated. All of these call logs may be copied at the end of a workflow to a remote directory. Configure this directory by setting the [Workflow Option](wf_options/Overview#output-copy",MatchSource.DOCS,docs/Logging.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Logging.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:191,Availability,avail,available,191,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:323,Deployability,configurat,configuration,323,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:1012,Deployability,configurat,configuration,1012,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:323,Modifiability,config,configuration,323,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:368,Modifiability,config,configure,368,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:918,Modifiability,config,configured,918,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:1012,Modifiability,config,configuration,1012,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:858,Safety,abort,abort,858,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:990,Safety,abort,abort,990,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:141,Security,expose,exposes,141,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md:232,Security,access,accessible,232,"## Server. The default mode for most applications of Cromwell, suitable for production use. Server mode starts Cromwell as a web server that exposes REST endpoints. All features and APIs are available. By default the server will be accessible at `http://localhost:8000`. See the [Server Section](Configuring#server) of the configuration for more information on how to configure it. Follow the [Server Tutorial](tutorials/ServerMode) to get your Cromwell server up and running in a few steps. ## Run. A good way to get started with Cromwell and experiment quickly. Run mode launches a single workflow from the command line and exits `0` or `1` to indicate the result. Appropriate for prototyping or demo use on a user's local machine. Features are limited and the web API is not supported. Sending a `SIGINT` signal (via `CTRL-C` for example) will by default abort all running jobs and then exit.; This behavior can be configured, and is explained in more details in the [Abort](Configuring#abort) section of the configuration.; ",MatchSource.DOCS,docs/Modes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Modes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:43,Availability,avail,available,43,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1807,Availability,avail,available,1807,"you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 tra",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:2153,Availability,avail,available,2153,"ar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment). Please contact the tool maintainers for more information. ; ",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:30,Deployability,release,releases,30,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:121,Deployability,release,releases,121,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:192,Deployability,release,release,192,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:363,Deployability,install,installing,363,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:553,Deployability,install,installed,553,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:601,Deployability,install,install,601,"# Cromwell Releases. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 J",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:935,Deployability,install,installation,935,"s. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1126,Deployability,install,installs,1126,"rongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become avai",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1269,Deployability,install,install,1269,"distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Deskto",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1428,Deployability,release,releases,1428,"ml) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1492,Deployability,configurat,configuration,1492,"ml) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1667,Deployability,release,releases,1667," can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images runnin",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1855,Deployability,update,updated,1855,"might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https:/",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1960,Deployability,install,installation,1960,"ion of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment). Pleas",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1985,Deployability,install,install,1985,"ar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment). Please contact the tool maintainers for more information. ; ",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:2362,Deployability,update,update,2362,"ar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment). Please contact the tool maintainers for more information. ; ",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:973,Integrability,wrap,wrapper,973,"s. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1153,Integrability,depend,dependency,1153,"rongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become avai",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1492,Modifiability,config,configuration,1492,"ml) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:2164,Performance,perform,performance,2164,"ar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Docker Desktop goes native on Apple Silicon, any tool images running on the local backend will need to cross-compile for the x86 and Arm architectures. This is because the Rosetta 2 translation layer [does not support virtualization](https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment). Please contact the tool maintainers for more information. ; ",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1087,Security,validat,validate,1087,"s. Cromwell releases are available at the [GitHub Releases](https://github.com/broadinstitute/cromwell/releases/latest) page. ; You are strongly encouraged to use the latest release of Cromwell whenever possible. Cromwell is distributed as a conda package on [conda-forge](https://conda-forge.org/).; These instructions need to be followed for [installing the miniconda distribution](https://docs.conda.io/en/latest/miniconda.html) and ; [activating the conda-forge channel](https://conda-forge.org/#about). After this Cromwell can be installed in the ; base environment with `conda install -c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md:1587,Testability,test,tested,1587,"-c conda-forge cromwell` or a separate environment for Cromwell can be created with ; `conda create -n cromwell cromwell` (be sure to activate the conda-forge channel first). ; If you are using Cromwell for bioinformatics workflows, you might like to take; a look at [bioconda](http://bioconda.github.io) as well. ; The conda installation of Cromwell comes with a wrapper that locates the jar for you and allows for running Cromwell or Womtool with a ; `cromwell run`, `womtool validate` or other command. Conda also installs the required Java dependency ; in the environment automatically. Mac users with Homebrew can also get Cromwell with the command `brew install cromwell`. This documentation frequently refers to a ""Cromwell jar"" with a name like `cromwell-<version>.jar`. ; This is the main artifact in Cromwell releases that contains all executable Cromwell code and default configuration. . A distribution of Java 17 is required to run Cromwell. Cromwell is developed, tested, and containerized using; [Eclipse Temurin](https://adoptium.net/temurin/releases/?version=17). For users running a Cromwell server [a docker image](https://hub.docker.com/r/broadinstitute/cromwell) has been made available. ### Apple Silicon support statement (updated 2020-11-17). #### Cromwell JAR works out of the box. The Cromwell JAR works on any standard Java installation. A user can install an x86 Java runtime on an Apple Silicon Mac and the Rosetta 2 translation layer runs Cromwell at near-native speed. Once natively-compiled Java runtimes become available, performance will increase with no change in functionality. . #### Docker Desktop support is in progress. The Cromwell Docker image will not run on M1 Macs until Docker Desktop ships the appropriate update. For more details, please see [their official announcement](https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/). By extension, the absence of Docker means that Cromwell's local Docker backend is not yet supported. Even when Dock",MatchSource.DOCS,docs/Releases.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/Releases.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:349,Availability,echo,echo,349,"# Customize tasks. Runtime attributes can be specified in one of two ways:. 1. Within a task you can specify runtime attributes to customize the environment for the call. ; 2. [Default runtime attributes](#default-values) for all tasks can be specified in [Workflow Options](wf_options/Overview.md). _Task Example_. ```; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-b""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. ## Recognized Runtime attributes and Backends. Cromwell recognizes certain runtime attributes and has the ability to format these for some [Backends](/backends/Backends). See the table below for common attributes that apply to _most_ backends. | Runtime Attribute | Local | Google Cloud | TES | AWS Batch | HPC |; |-------------------------------------------------|:-----:|:------------:|-----------|:---------:|:-------------------------:|; | [`cpu`](#cpu) | | ✅ | | ✅ | `cpu` |; | [`memory`](#memory) | | ✅ | | ✅ | `memory_mb` / `memory_gb` |; | [`disks`](#disks) | | ✅ | ⚠️ Note 1 | ⚠️ Note 2 | ℹ️ Note 3 |; | [`disk`](#disk) | | | ✅ | | |; | [`docker`](#docker) | ✅ | ✅ | | ✅ | `docker` ℹ️ Note 3 |; | [`maxRetries`](#maxretries) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`continueOnReturnCode`](#continueonreturncode) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`failOnStderr`](#failonstderr) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |. > **Note 1**; > ; > Partial support. See [TES documentation](/backends/TES) for details. ; ; > **Note 2**; >; > Partial support. See [`disks`](#disks) for details. > **Note 3**; > ; > The HPC [Shared Filesystem backend](/backends/HPC#shared-filesystem) (SFS) is fully configurable and any number of attributes can be exposed. Cromwell recognizes some of these attributes (`cpu`, `memory` and `docker`) and parses them into the attribute listed in the table which can be used within the HPC backend configuration. ### Google Clou",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:7414,Availability,failure,failures,7414," are set to auto-delete after the job completes. *Example 1: Changing the Localization Disk*. ```; runtime {; disks: ""local-disk 100 SSD""; }; ```. *Example 2: Mounting an Additional Two Disks*. ```; runtime {; disks: ""/mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""; }; ```. ### `disk`. Specific to the TES backend, sets the `disk_gb` resource. ```; runtime {; disk: ""25 GB""; }; ```. ### `docker`. When specified, Cromwell will run your task within the specified Docker image. . ```; runtime {; docker: ""ubuntu:latest""; }; ```. - Local: Cromwell will automatically run the docker container.; - SFS: When a docker container exists within a task, the `submit-docker` method is called. See the [Getting started with containers](/tutorials/Containers/) guide for more information.; - GCP: This attribute is mandatory when submitting tasks to Google Cloud.; - AWS Batch: This attribute is mandatory when submitting tasks to AWS Batch. ### `maxRetries`. *Default: _0_*. This retry option is introduced to provide a method for tackling transient job failures. For example, if a task fails due to a timeout from accessing an external service, then this option helps re-run the failed the task without having to re-run the entire workflow. It takes an Int as a value that indicates the maximum number of times Cromwell should retry a failed task. This retry is applied towards jobs that fail while executing the task command. This method only applies to transient job failures and is a feeble attempt to retry a job, that is it cannot be used to increase memory in out-of-memory situations. If using the Google backend, it's important to note that The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:7830,Availability,failure,failures,7830,"ker: ""ubuntu:latest""; }; ```. - Local: Cromwell will automatically run the docker container.; - SFS: When a docker container exists within a task, the `submit-docker` method is called. See the [Getting started with containers](/tutorials/Containers/) guide for more information.; - GCP: This attribute is mandatory when submitting tasks to Google Cloud.; - AWS Batch: This attribute is mandatory when submitting tasks to AWS Batch. ### `maxRetries`. *Default: _0_*. This retry option is introduced to provide a method for tackling transient job failures. For example, if a task fails due to a timeout from accessing an external service, then this option helps re-run the failed the task without having to re-run the entire workflow. It takes an Int as a value that indicates the maximum number of times Cromwell should retry a failed task. This retry is applied towards jobs that fail while executing the task command. This method only applies to transient job failures and is a feeble attempt to retry a job, that is it cannot be used to increase memory in out-of-memory situations. If using the Google backend, it's important to note that The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runti",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:8403,Availability,failure,failure,8403,"od for tackling transient job failures. For example, if a task fails due to a timeout from accessing an external service, then this option helps re-run the failed the task without having to re-run the entire workflow. It takes an Int as a value that indicates the maximum number of times Cromwell should retry a failed task. This retry is applied towards jobs that fail while executing the task command. This method only applies to transient job failures and is a feeble attempt to retry a job, that is it cannot be used to increase memory in out-of-memory situations. If using the Google backend, it's important to note that The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:8568,Availability,failure,failure,8568," failed the task without having to re-run the entire workflow. It takes an Int as a value that indicates the maximum number of times Cromwell should retry a failed task. This retry is applied towards jobs that fail while executing the task command. This method only applies to transient job failures and is a feeble attempt to retry a job, that is it cannot be used to increase memory in out-of-memory situations. If using the Google backend, it's important to note that The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the conf",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:8990,Availability,error,error,8990,"at The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell wi",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9020,Availability,error,error,9020,"at The `maxRetries` count is independent from the [preemptible](#preemptible) count. For example, the task below can be retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell wi",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9134,Availability,failure,failure,9134,"retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell will request a preemptible VM, if the VM is preempted, the task will be retried with a non-preemptible VM.*. ```; runtime {",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9181,Availability,error,error,9181,"retried up to 6 times if it's preempted 3 times AND the command execution fails 3 times. ```; runtime {; preemptible: 3; maxRetries: 3; }; ```. ### `continueOnReturnCode`; *Default: _0_*. When each task finishes it returns a code. Normally, a non-zero return code indicates a failure. However you can override this behavior by specifying the `continueOnReturnCode` attribute. When set to false, any non-zero return code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell will request a preemptible VM, if the VM is preempted, the task will be retried with a non-preemptible VM.*. ```; runtime {",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:11270,Availability,echo,echo,11270," disk size. This is the disk where the docker image itself is booted (**not the working directory of your task on the VM**).; Its primary purpose is to ensure that larger docker images can fit on the boot disk.; ```; runtime {; # Yikes, we have a big OS in this docker image! Allow 50GB to hold it:; bootDiskSizeGb: 50; }; ```. Since no `local-disk` entry is specified, Cromwell will automatically add `local-disk 10 SSD` to this list. ### `noAddress`. This runtime attribute adds support to disable assigning external IP addresses to VMs provisioned by the Google backend. If set to true, the VM will NOT be provided with a public IP address, and only contain an internal IP. If this option is enabled, the associated job can only load docker images from Google Container Registry, and the job executable cannot use external services other than Google APIs. Note well! You must enable ""Private Google Access"" for this feature to work. See ""How To Setup"" below. For example, the task below will succeed:; ```; command {; echo ""hello!""; ; }. runtime {; docker: ""gcr.io/gcp-runtimes/ubuntu_16_0_4:latest""; noAddress: true; }; ```. The task below will fail for two reasons:; 1. The command is accessing an external service, in this case GitHub.; 2. The docker image is available in DockerHub and not the Google Container Registry. ; ```; command {; git clone https://github.com/broadinstitute/cromwell.git; ; }. runtime {; docker: ""docker.io/alpine/git:latest""; noAddress: true; }; ```. #### How to Setup. Configure your Google network to use ""Private Google Access"". This will allow your VMs to access Google Services including Google Container Registry, as well as Dockerhub images. 1. Using `gcloud compute networks subnets list`, identify the subnet and region you will be using with Cromwell. If multiple, run the next step for each region and subnet you wish to use.; 1. `gcloud compute networks subnets update [SUBNET-NAME] --region [REGION] --enable-private-ip-google-access`. That's it! You can ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:11515,Availability,avail,available,11515," to hold it:; bootDiskSizeGb: 50; }; ```. Since no `local-disk` entry is specified, Cromwell will automatically add `local-disk 10 SSD` to this list. ### `noAddress`. This runtime attribute adds support to disable assigning external IP addresses to VMs provisioned by the Google backend. If set to true, the VM will NOT be provided with a public IP address, and only contain an internal IP. If this option is enabled, the associated job can only load docker images from Google Container Registry, and the job executable cannot use external services other than Google APIs. Note well! You must enable ""Private Google Access"" for this feature to work. See ""How To Setup"" below. For example, the task below will succeed:; ```; command {; echo ""hello!""; ; }. runtime {; docker: ""gcr.io/gcp-runtimes/ubuntu_16_0_4:latest""; noAddress: true; }; ```. The task below will fail for two reasons:; 1. The command is accessing an external service, in this case GitHub.; 2. The docker image is available in DockerHub and not the Google Container Registry. ; ```; command {; git clone https://github.com/broadinstitute/cromwell.git; ; }. runtime {; docker: ""docker.io/alpine/git:latest""; noAddress: true; }; ```. #### How to Setup. Configure your Google network to use ""Private Google Access"". This will allow your VMs to access Google Services including Google Container Registry, as well as Dockerhub images. 1. Using `gcloud compute networks subnets list`, identify the subnet and region you will be using with Cromwell. If multiple, run the next step for each region and subnet you wish to use.; 1. `gcloud compute networks subnets update [SUBNET-NAME] --region [REGION] --enable-private-ip-google-access`. That's it! You can now run with `noAddress` runtime attribute and it will work as expected. ### `gpuCount`, `gpuType`, and `nvidiaDriverVersion`. Attach GPUs to the instance when running on the Pipelines API([GPU documentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone f",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:12582,Availability,avail,available,12582,"e Google Container Registry. ; ```; command {; git clone https://github.com/broadinstitute/cromwell.git; ; }. runtime {; docker: ""docker.io/alpine/git:latest""; noAddress: true; }; ```. #### How to Setup. Configure your Google network to use ""Private Google Access"". This will allow your VMs to access Google Services including Google Container Registry, as well as Dockerhub images. 1. Using `gcloud compute networks subnets list`, identify the subnet and region you will be using with Cromwell. If multiple, run the next step for each region and subnet you wish to use.; 1. `gcloud compute networks subnets update [SUBNET-NAME] --region [REGION] --enable-private-ip-google-access`. That's it! You can now run with `noAddress` runtime attribute and it will work as expected. ### `gpuCount`, `gpuType`, and `nvidiaDriverVersion`. Attach GPUs to the instance when running on the Pipelines API([GPU documentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone for which the type of GPU you want to attach is available. The types of compute GPU supported are:. * `nvidia-tesla-k80` ; * `nvidia-tesla-v100`; * `nvidia-tesla-p100`; * `nvidia-tesla-p4`; * `nvidia-tesla-t4`. For the latest list of supported GPU's, please visit [Google's GPU documentation](nvidia-drivers-us-public). The default driver is `418.87.00`, you may specify your own via the `nvidiaDriverVersion` key. Make sure that driver exists in the `nvidia-drivers-us-public` beforehand, per the [Google Pipelines API documentation](https://cloud.google.com/genomics/reference/rest/Shared.Types/Metadata#VirtualMachine). . ```; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; }; ```. ### `cpuPlatform`. This option is specific to the Google Cloud backend, specifically [this](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform) feature when a certain minimum CPU platform is desired. A usage example:. ```; runtime {; cpu: 2; ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:13675,Availability,avail,available,13675,"umentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone for which the type of GPU you want to attach is available. The types of compute GPU supported are:. * `nvidia-tesla-k80` ; * `nvidia-tesla-v100`; * `nvidia-tesla-p100`; * `nvidia-tesla-p4`; * `nvidia-tesla-t4`. For the latest list of supported GPU's, please visit [Google's GPU documentation](nvidia-drivers-us-public). The default driver is `418.87.00`, you may specify your own via the `nvidiaDriverVersion` key. Make sure that driver exists in the `nvidia-drivers-us-public` beforehand, per the [Google Pipelines API documentation](https://cloud.google.com/genomics/reference/rest/Shared.Types/Metadata#VirtualMachine). . ```; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; }; ```. ### `cpuPlatform`. This option is specific to the Google Cloud backend, specifically [this](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform) feature when a certain minimum CPU platform is desired. A usage example:. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Cascade Lake""; }; ```; Note that when this options is specified, make sure the requested CPU platform is [available](https://cloud.google.com/compute/docs/regions-zones/#available) in the `zones` you selected. The following CPU platforms are currently supported by the Google Cloud backend:; - `Intel Ice Lake`; - `Intel Cascade Lake`; - `Intel Skylake` ; - `Intel Broadwell` ; - `Intel Haswell` ; - `Intel Ivy Bridge` ; - `Intel Sandy Bridge`; - `AMD Rome`. ### 'useDockerImageCache'. This option is specific to the Google Cloud backend, moreover it is only supported by Google Life Sciences API starting from version v2 beta.; In order to use this feature Cromwell has to have PAPI v2 backend configured with this feature enabled. ; More information about this feature and it's configuration can be found [in the Google backend section of documentation](backends/Google.md).; ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:13739,Availability,avail,available,13739,"umentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone for which the type of GPU you want to attach is available. The types of compute GPU supported are:. * `nvidia-tesla-k80` ; * `nvidia-tesla-v100`; * `nvidia-tesla-p100`; * `nvidia-tesla-p4`; * `nvidia-tesla-t4`. For the latest list of supported GPU's, please visit [Google's GPU documentation](nvidia-drivers-us-public). The default driver is `418.87.00`, you may specify your own via the `nvidiaDriverVersion` key. Make sure that driver exists in the `nvidia-drivers-us-public` beforehand, per the [Google Pipelines API documentation](https://cloud.google.com/genomics/reference/rest/Shared.Types/Metadata#VirtualMachine). . ```; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; }; ```. ### `cpuPlatform`. This option is specific to the Google Cloud backend, specifically [this](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform) feature when a certain minimum CPU platform is desired. A usage example:. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Cascade Lake""; }; ```; Note that when this options is specified, make sure the requested CPU platform is [available](https://cloud.google.com/compute/docs/regions-zones/#available) in the `zones` you selected. The following CPU platforms are currently supported by the Google Cloud backend:; - `Intel Ice Lake`; - `Intel Cascade Lake`; - `Intel Skylake` ; - `Intel Broadwell` ; - `Intel Haswell` ; - `Intel Ivy Bridge` ; - `Intel Sandy Bridge`; - `AMD Rome`. ### 'useDockerImageCache'. This option is specific to the Google Cloud backend, moreover it is only supported by Google Life Sciences API starting from version v2 beta.; In order to use this feature Cromwell has to have PAPI v2 backend configured with this feature enabled. ; More information about this feature and it's configuration can be found [in the Google backend section of documentation](backends/Google.md).; ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:1971,Deployability,configurat,configuration,1971,"-----------------------------------------|:-----:|:------------:|-----------|:---------:|:-------------------------:|; | [`cpu`](#cpu) | | ✅ | | ✅ | `cpu` |; | [`memory`](#memory) | | ✅ | | ✅ | `memory_mb` / `memory_gb` |; | [`disks`](#disks) | | ✅ | ⚠️ Note 1 | ⚠️ Note 2 | ℹ️ Note 3 |; | [`disk`](#disk) | | | ✅ | | |; | [`docker`](#docker) | ✅ | ✅ | | ✅ | `docker` ℹ️ Note 3 |; | [`maxRetries`](#maxretries) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`continueOnReturnCode`](#continueonreturncode) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`failOnStderr`](#failonstderr) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |. > **Note 1**; > ; > Partial support. See [TES documentation](/backends/TES) for details. ; ; > **Note 2**; >; > Partial support. See [`disks`](#disks) for details. > **Note 3**; > ; > The HPC [Shared Filesystem backend](/backends/HPC#shared-filesystem) (SFS) is fully configurable and any number of attributes can be exposed. Cromwell recognizes some of these attributes (`cpu`, `memory` and `docker`) and parses them into the attribute listed in the table which can be used within the HPC backend configuration. ### Google Cloud Specific Attributes; There are a number of additional runtime attributes that apply to the Google Cloud Platform:. - [zones](#zones); - [preemptible](#preemptible); - [bootDiskSizeGb](#bootdisksizegb); - [noAddress](#noaddress); - [gpuCount, gpuType, and nvidiaDriverVersion](#gpucount-gputype-and-nvidiadriverversion); - [cpuPlatform](#cpuplatform); - [useDockerImageCache](#usedockerimagecache). ## Expression support. Runtime attribute values are interpreted as expressions. This means that it has the ability to express the value of a runtime attribute as a function of one of the task's inputs. ; _For example:_. ```; task runtime_test {; String ubuntu_tag; Int memory_gb. command {; ./my_binary; }. runtime {; docker: ""ubuntu:"" + ubuntu_tag; memory: memory_gb + ""GB""; }; }; ```. HPC backends may define other configurable runtime attributes beyond the five listed, to find out more v",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:4862,Deployability,configurat,configuration,4862,"""; }; ```. Note how for `task second` the WDL value for `docker` is used instead of the default provided in the workflow options. ## Runtime Attribute Descriptions. ### `cpu`. *Default: _1_*. The `cpu` runtime attribute represents the number of cores that a job requires, however each backend may interpret this differently:. - In Google Cloud: this is interpreted as ""the minimum number of cores to use.""; - In HPCs (SFS): this is configurable, but usually a reservation and/or limit of number of cores. Example; ```; runtime {; cpu: 2; }; ```. ### `memory`; *Default: ""2G""*. Memory is the amount of RAM that should be allocated to a task, however each backend may interpret this differently:. - Google Cloud: The minimum amount of RAM to use.; - SFS: Configurable, but usually a reservation and/or limit of memory. The memory size is specified as an amount and units of memory, for example ""4G"":. ```; runtime {; memory: ""4G""; }; ```. Within the SFS backend, you can additionally specify `memory_mb` or `memory_gb` as runtime attributes within the configuration. More information can be found [here](https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks). ### `disks`. This attribute specifies volumes that will be mounted to the VM for your job. These volumes are where you can read and write files that will be used by the commands within your workflow. . They are specified as a comma separated list of disks. Each disk is further separated as a space separated triplet (e.g. `local-disk 10 SSD`) consisting of:. 1. Mount point (absolute path), or `local-disk` to reference the mount point where Google Cloud will localize files and the task's current working directory will be; 2. Disk size in GB (rounded to the next 375 GB for LOCAL); 3. Disk type. One of: ""LOCAL"", ""SSD"", or ""HDD"" ([documentation](https://cloud.google.com/compute/docs/disks/#overview)). All tasks launched on Google Cloud *must* have a `local-disk`. If one is no",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9535,Deployability,configurat,configuration,9535,"code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell will request a preemptible VM, if the VM is preempted, the task will be retried with a non-preemptible VM.*. ```; runtime {; preemptible: 1; }; ```. ### `bootDiskSizeGb`. In addition to working disks, Google Cloud allows specification of a boot disk size. This is the disk where the docker image itself is booted (**not the working directory of your task on the VM**).; Its primary purpose is to ensure that larger docker images can fit on the boot disk.; ```; runtime {; # Yikes, we have a big OS in this docker image! Allow 50GB to hold",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9602,Deployability,configurat,configuration,9602," considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell will request a preemptible VM, if the VM is preempted, the task will be retried with a non-preemptible VM.*. ```; runtime {; preemptible: 1; }; ```. ### `bootDiskSizeGb`. In addition to working disks, Google Cloud allows specification of a boot disk size. This is the disk where the docker image itself is booted (**not the working directory of your task on the VM**).; Its primary purpose is to ensure that larger docker images can fit on the boot disk.; ```; runtime {; # Yikes, we have a big OS in this docker image! Allow 50GB to hold it:; bootDiskSizeGb: 50; }; ```. Since no `local-disk` entry is specified, ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:12156,Deployability,update,update,12156,"to work. See ""How To Setup"" below. For example, the task below will succeed:; ```; command {; echo ""hello!""; ; }. runtime {; docker: ""gcr.io/gcp-runtimes/ubuntu_16_0_4:latest""; noAddress: true; }; ```. The task below will fail for two reasons:; 1. The command is accessing an external service, in this case GitHub.; 2. The docker image is available in DockerHub and not the Google Container Registry. ; ```; command {; git clone https://github.com/broadinstitute/cromwell.git; ; }. runtime {; docker: ""docker.io/alpine/git:latest""; noAddress: true; }; ```. #### How to Setup. Configure your Google network to use ""Private Google Access"". This will allow your VMs to access Google Services including Google Container Registry, as well as Dockerhub images. 1. Using `gcloud compute networks subnets list`, identify the subnet and region you will be using with Cromwell. If multiple, run the next step for each region and subnet you wish to use.; 1. `gcloud compute networks subnets update [SUBNET-NAME] --region [REGION] --enable-private-ip-google-access`. That's it! You can now run with `noAddress` runtime attribute and it will work as expected. ### `gpuCount`, `gpuType`, and `nvidiaDriverVersion`. Attach GPUs to the instance when running on the Pipelines API([GPU documentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone for which the type of GPU you want to attach is available. The types of compute GPU supported are:. * `nvidia-tesla-k80` ; * `nvidia-tesla-v100`; * `nvidia-tesla-p100`; * `nvidia-tesla-p4`; * `nvidia-tesla-t4`. For the latest list of supported GPU's, please visit [Google's GPU documentation](nvidia-drivers-us-public). The default driver is `418.87.00`, you may specify your own via the `nvidiaDriverVersion` key. Make sure that driver exists in the `nvidia-drivers-us-public` beforehand, per the [Google Pipelines API documentation](https://cloud.google.com/genomics/reference/rest/Shared.Types/Metadata#VirtualMachine). . ```; runtime {; g",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:14349,Deployability,configurat,configuration,14349,"umentation](https://cloud.google.com/compute/docs/gpus/)).; Make sure to choose a zone for which the type of GPU you want to attach is available. The types of compute GPU supported are:. * `nvidia-tesla-k80` ; * `nvidia-tesla-v100`; * `nvidia-tesla-p100`; * `nvidia-tesla-p4`; * `nvidia-tesla-t4`. For the latest list of supported GPU's, please visit [Google's GPU documentation](nvidia-drivers-us-public). The default driver is `418.87.00`, you may specify your own via the `nvidiaDriverVersion` key. Make sure that driver exists in the `nvidia-drivers-us-public` beforehand, per the [Google Pipelines API documentation](https://cloud.google.com/genomics/reference/rest/Shared.Types/Metadata#VirtualMachine). . ```; runtime {; gpuType: ""nvidia-tesla-k80""; gpuCount: 2; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; }; ```. ### `cpuPlatform`. This option is specific to the Google Cloud backend, specifically [this](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform) feature when a certain minimum CPU platform is desired. A usage example:. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Cascade Lake""; }; ```; Note that when this options is specified, make sure the requested CPU platform is [available](https://cloud.google.com/compute/docs/regions-zones/#available) in the `zones` you selected. The following CPU platforms are currently supported by the Google Cloud backend:; - `Intel Ice Lake`; - `Intel Cascade Lake`; - `Intel Skylake` ; - `Intel Broadwell` ; - `Intel Haswell` ; - `Intel Ivy Bridge` ; - `Intel Sandy Bridge`; - `AMD Rome`. ### 'useDockerImageCache'. This option is specific to the Google Cloud backend, moreover it is only supported by Google Life Sciences API starting from version v2 beta.; In order to use this feature Cromwell has to have PAPI v2 backend configured with this feature enabled. ; More information about this feature and it's configuration can be found [in the Google backend section of documentation](backends/Google.md).; ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:4432,Energy Efficiency,allocate,allocated,4432,"docker` and `zones` will be used for any task that does not explicitly override them in the WDL file. In return, the effective runtime for `task first` is:. ```; {; ""docker"": ""ubuntu:latest"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. And the effective runtime for `task second` is:. ```; {; ""docker"": ""my_docker_image"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. Note how for `task second` the WDL value for `docker` is used instead of the default provided in the workflow options. ## Runtime Attribute Descriptions. ### `cpu`. *Default: _1_*. The `cpu` runtime attribute represents the number of cores that a job requires, however each backend may interpret this differently:. - In Google Cloud: this is interpreted as ""the minimum number of cores to use.""; - In HPCs (SFS): this is configurable, but usually a reservation and/or limit of number of cores. Example; ```; runtime {; cpu: 2; }; ```. ### `memory`; *Default: ""2G""*. Memory is the amount of RAM that should be allocated to a task, however each backend may interpret this differently:. - Google Cloud: The minimum amount of RAM to use.; - SFS: Configurable, but usually a reservation and/or limit of memory. The memory size is specified as an amount and units of memory, for example ""4G"":. ```; runtime {; memory: ""4G""; }; ```. Within the SFS backend, you can additionally specify `memory_mb` or `memory_gb` as runtime attributes within the configuration. More information can be found [here](https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks). ### `disks`. This attribute specifies volumes that will be mounted to the VM for your job. These volumes are where you can read and write files that will be used by the commands within your workflow. . They are specified as a comma separated list of disks. Each disk is further separated as a space separated triplet (e.g. `local-disk 10 SSD`) consisting of:. 1. Mount point (absolute path), or `local-disk` to refer",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:1741,Modifiability,config,configurable,1741,"(/backends/Backends). See the table below for common attributes that apply to _most_ backends. | Runtime Attribute | Local | Google Cloud | TES | AWS Batch | HPC |; |-------------------------------------------------|:-----:|:------------:|-----------|:---------:|:-------------------------:|; | [`cpu`](#cpu) | | ✅ | | ✅ | `cpu` |; | [`memory`](#memory) | | ✅ | | ✅ | `memory_mb` / `memory_gb` |; | [`disks`](#disks) | | ✅ | ⚠️ Note 1 | ⚠️ Note 2 | ℹ️ Note 3 |; | [`disk`](#disk) | | | ✅ | | |; | [`docker`](#docker) | ✅ | ✅ | | ✅ | `docker` ℹ️ Note 3 |; | [`maxRetries`](#maxretries) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`continueOnReturnCode`](#continueonreturncode) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`failOnStderr`](#failonstderr) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |. > **Note 1**; > ; > Partial support. See [TES documentation](/backends/TES) for details. ; ; > **Note 2**; >; > Partial support. See [`disks`](#disks) for details. > **Note 3**; > ; > The HPC [Shared Filesystem backend](/backends/HPC#shared-filesystem) (SFS) is fully configurable and any number of attributes can be exposed. Cromwell recognizes some of these attributes (`cpu`, `memory` and `docker`) and parses them into the attribute listed in the table which can be used within the HPC backend configuration. ### Google Cloud Specific Attributes; There are a number of additional runtime attributes that apply to the Google Cloud Platform:. - [zones](#zones); - [preemptible](#preemptible); - [bootDiskSizeGb](#bootdisksizegb); - [noAddress](#noaddress); - [gpuCount, gpuType, and nvidiaDriverVersion](#gpucount-gputype-and-nvidiadriverversion); - [cpuPlatform](#cpuplatform); - [useDockerImageCache](#usedockerimagecache). ## Expression support. Runtime attribute values are interpreted as expressions. This means that it has the ability to express the value of a runtime attribute as a function of one of the task's inputs. ; _For example:_. ```; task runtime_test {; String ubuntu_tag; Int memory_gb. command {; ./my_binary; }. runtime {",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:1971,Modifiability,config,configuration,1971,"-----------------------------------------|:-----:|:------------:|-----------|:---------:|:-------------------------:|; | [`cpu`](#cpu) | | ✅ | | ✅ | `cpu` |; | [`memory`](#memory) | | ✅ | | ✅ | `memory_mb` / `memory_gb` |; | [`disks`](#disks) | | ✅ | ⚠️ Note 1 | ⚠️ Note 2 | ℹ️ Note 3 |; | [`disk`](#disk) | | | ✅ | | |; | [`docker`](#docker) | ✅ | ✅ | | ✅ | `docker` ℹ️ Note 3 |; | [`maxRetries`](#maxretries) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`continueOnReturnCode`](#continueonreturncode) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |; | [`failOnStderr`](#failonstderr) | ✅ | ✅ | | ✅ | ℹ️ Note 3 |. > **Note 1**; > ; > Partial support. See [TES documentation](/backends/TES) for details. ; ; > **Note 2**; >; > Partial support. See [`disks`](#disks) for details. > **Note 3**; > ; > The HPC [Shared Filesystem backend](/backends/HPC#shared-filesystem) (SFS) is fully configurable and any number of attributes can be exposed. Cromwell recognizes some of these attributes (`cpu`, `memory` and `docker`) and parses them into the attribute listed in the table which can be used within the HPC backend configuration. ### Google Cloud Specific Attributes; There are a number of additional runtime attributes that apply to the Google Cloud Platform:. - [zones](#zones); - [preemptible](#preemptible); - [bootDiskSizeGb](#bootdisksizegb); - [noAddress](#noaddress); - [gpuCount, gpuType, and nvidiaDriverVersion](#gpucount-gputype-and-nvidiadriverversion); - [cpuPlatform](#cpuplatform); - [useDockerImageCache](#usedockerimagecache). ## Expression support. Runtime attribute values are interpreted as expressions. This means that it has the ability to express the value of a runtime attribute as a function of one of the task's inputs. ; _For example:_. ```; task runtime_test {; String ubuntu_tag; Int memory_gb. command {; ./my_binary; }. runtime {; docker: ""ubuntu:"" + ubuntu_tag; memory: memory_gb + ""GB""; }; }; ```. HPC backends may define other configurable runtime attributes beyond the five listed, to find out more v",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:2818,Modifiability,config,configurable,2818," `docker`) and parses them into the attribute listed in the table which can be used within the HPC backend configuration. ### Google Cloud Specific Attributes; There are a number of additional runtime attributes that apply to the Google Cloud Platform:. - [zones](#zones); - [preemptible](#preemptible); - [bootDiskSizeGb](#bootdisksizegb); - [noAddress](#noaddress); - [gpuCount, gpuType, and nvidiaDriverVersion](#gpucount-gputype-and-nvidiadriverversion); - [cpuPlatform](#cpuplatform); - [useDockerImageCache](#usedockerimagecache). ## Expression support. Runtime attribute values are interpreted as expressions. This means that it has the ability to express the value of a runtime attribute as a function of one of the task's inputs. ; _For example:_. ```; task runtime_test {; String ubuntu_tag; Int memory_gb. command {; ./my_binary; }. runtime {; docker: ""ubuntu:"" + ubuntu_tag; memory: memory_gb + ""GB""; }; }; ```. HPC backends may define other configurable runtime attributes beyond the five listed, to find out more visit the [SunGridEngine](/backends/SGE) tutorial. ## Default Values. Default values for runtime attributes can be specified via [Workflow Options](wf_options/overview). ; For example, consider this WDL file:. ```wdl; task first {; command { ... }; }. task second {; command {...}; runtime {; docker: ""my_docker_image""; }; }. workflow w {; call first; call second; }; ```. And this set of workflow options:. ```json; {; ""default_runtime_attributes"": {; ""docker"": ""ubuntu:latest"",; ""zones"": ""us-central1-c us-central1-b""; }; }; ```. Then, these values for `docker` and `zones` will be used for any task that does not explicitly override them in the WDL file. In return, the effective runtime for `task first` is:. ```; {; ""docker"": ""ubuntu:latest"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. And the effective runtime for `task second` is:. ```; {; ""docker"": ""my_docker_image"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. Note how for `task second` the WDL value ",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:4244,Modifiability,config,configurable,4244,"d this set of workflow options:. ```json; {; ""default_runtime_attributes"": {; ""docker"": ""ubuntu:latest"",; ""zones"": ""us-central1-c us-central1-b""; }; }; ```. Then, these values for `docker` and `zones` will be used for any task that does not explicitly override them in the WDL file. In return, the effective runtime for `task first` is:. ```; {; ""docker"": ""ubuntu:latest"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. And the effective runtime for `task second` is:. ```; {; ""docker"": ""my_docker_image"",; ""zones"": ""us-central1-c us-central1-b""; }; ```. Note how for `task second` the WDL value for `docker` is used instead of the default provided in the workflow options. ## Runtime Attribute Descriptions. ### `cpu`. *Default: _1_*. The `cpu` runtime attribute represents the number of cores that a job requires, however each backend may interpret this differently:. - In Google Cloud: this is interpreted as ""the minimum number of cores to use.""; - In HPCs (SFS): this is configurable, but usually a reservation and/or limit of number of cores. Example; ```; runtime {; cpu: 2; }; ```. ### `memory`; *Default: ""2G""*. Memory is the amount of RAM that should be allocated to a task, however each backend may interpret this differently:. - Google Cloud: The minimum amount of RAM to use.; - SFS: Configurable, but usually a reservation and/or limit of memory. The memory size is specified as an amount and units of memory, for example ""4G"":. ```; runtime {; memory: ""4G""; }; ```. Within the SFS backend, you can additionally specify `memory_mb` or `memory_gb` as runtime attributes within the configuration. More information can be found [here](https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks). ### `disks`. This attribute specifies volumes that will be mounted to the VM for your job. These volumes are where you can read and write files that will be used by the commands within your workflow. . They are specified as a comma sep",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:4862,Modifiability,config,configuration,4862,"""; }; ```. Note how for `task second` the WDL value for `docker` is used instead of the default provided in the workflow options. ## Runtime Attribute Descriptions. ### `cpu`. *Default: _1_*. The `cpu` runtime attribute represents the number of cores that a job requires, however each backend may interpret this differently:. - In Google Cloud: this is interpreted as ""the minimum number of cores to use.""; - In HPCs (SFS): this is configurable, but usually a reservation and/or limit of number of cores. Example; ```; runtime {; cpu: 2; }; ```. ### `memory`; *Default: ""2G""*. Memory is the amount of RAM that should be allocated to a task, however each backend may interpret this differently:. - Google Cloud: The minimum amount of RAM to use.; - SFS: Configurable, but usually a reservation and/or limit of memory. The memory size is specified as an amount and units of memory, for example ""4G"":. ```; runtime {; memory: ""4G""; }; ```. Within the SFS backend, you can additionally specify `memory_mb` or `memory_gb` as runtime attributes within the configuration. More information can be found [here](https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks). ### `disks`. This attribute specifies volumes that will be mounted to the VM for your job. These volumes are where you can read and write files that will be used by the commands within your workflow. . They are specified as a comma separated list of disks. Each disk is further separated as a space separated triplet (e.g. `local-disk 10 SSD`) consisting of:. 1. Mount point (absolute path), or `local-disk` to reference the mount point where Google Cloud will localize files and the task's current working directory will be; 2. Disk size in GB (rounded to the next 375 GB for LOCAL); 3. Disk type. One of: ""LOCAL"", ""SSD"", or ""HDD"" ([documentation](https://cloud.google.com/compute/docs/disks/#overview)). All tasks launched on Google Cloud *must* have a `local-disk`. If one is no",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md:9535,Modifiability,config,configuration,9535,"code will be considered a failure. When set to true, all return codes will be considered successful. ```; runtime {; continueOnReturnCode: true; }; ```. When set to an integer, or an array of integers, only those integers will be considered as successful return codes. ```; runtime {; continueOnReturnCode: 1; }; ```. ```; runtime {; continueOnReturnCode: [0, 1]; }; ```. ### `failOnStderr`. *Default: _false_*. Some programs write to the standard error stream when there is an error, but still return a zero exit code. Set `failOnStderr` to true for these tasks, and it will be considered a failure if anything is written to the standard error stream. ```; runtime {; failOnStderr: true; }; ```. ### `zones`. The ordered list of zone preference (see [Region and Zones](https://cloud.google.com/compute/docs/zones) documentation for specifics). *The zones are specified as a space separated list, with no commas:*. ```; runtime {; zones: ""us-central1-c us-central1-b""; }; ```. Defaults to the configuration setting `genomics.default-zones` in the Google Cloud configuration block, which in turn defaults to using `us-central1-b`. ### `preemptible`. *Default: _0_*. Passed to Google Cloud: ""If applicable, preemptible machines may be used for the run."". Take an Int as a value that indicates the maximum number of times Cromwell should request a preemptible machine for this task before defaulting back to a non-preemptible one. ; *eg. With a value of 1, Cromwell will request a preemptible VM, if the VM is preempted, the task will be retried with a non-preemptible VM.*. ```; runtime {; preemptible: 1; }; ```. ### `bootDiskSizeGb`. In addition to working disks, Google Cloud allows specification of a boot disk size. This is the disk where the docker image itself is booted (**not the working directory of your task on the VM**).; Its primary purpose is to ensure that larger docker images can fit on the boot disk.; ```; runtime {; # Yikes, we have a big OS in this docker image! Allow 50GB to hold",MatchSource.DOCS,docs/RuntimeAttributes.md,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/docs/RuntimeAttributes.md
