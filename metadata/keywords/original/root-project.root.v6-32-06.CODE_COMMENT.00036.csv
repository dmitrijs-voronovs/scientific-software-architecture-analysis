id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Performance,load,load,45,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Performance,load,load,70,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:187,Performance,load,load,187,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:233,Performance,load,load,233,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:274,Performance,load,load,274,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Performance,perform,perform,22,// VPERMQ/VPERMPD can perform the cross-lane shuffle directly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Availability,down,down,133,"// We only support broadcasting from 128-bit vectors to minimize the; // number of patterns we need to deal with in isel. So extract down to; // 128-bits, removing as many bitcasts as possible.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Performance,perform,perform,106,"// Otherwise cast V to a vector with the same element type as VT, but; // possibly narrower than VT. Then perform the broadcast.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Performance,perform,perform,44,// Check for whether we can use INSERTPS to perform the shuffle. We only use; // INSERTPS when the V1 elements are already in the correct locations; // because otherwise we can just always use two SHUFPS instructions which; // are much smaller to encode than a SHUFPS and an INSERTPS. We can also; // perform INSERTPS if a single V1 element is out of place and all V2; // elements are zeroable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:301,Performance,perform,perform,301,// Check for whether we can use INSERTPS to perform the shuffle. We only use; // INSERTPS when the V1 elements are already in the correct locations; // because otherwise we can just always use two SHUFPS instructions which; // are much smaller to encode than a SHUFPS and an INSERTPS. We can also; // perform INSERTPS if a single V1 element is out of place and all V2; // elements are zeroable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:146,Deployability,update,updated,146,"// Attempt to match INSERTPS with one element from VA or VB being; // inserted into VA (or undef). If successful, V1, V2 and InsertPSMask; // are updated.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Availability,mask,mask,21,// Synthesize a zero mask from the zeroable elements (includes undefs).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Availability,mask,mask,88,"// If no V1 inputs are used in place, then the result is created only from; // the zero mask and the V2 insertion - so remove V1 dependency.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Integrability,depend,dependency,129,"// If no V1 inputs are used in place, then the result is created only from; // the zero mask and the V2 insertion - so remove V1 dependency.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,"// Update V1, V2 and InsertPSMask accordingly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:319,Safety,avoid,avoid,319,/// Handle lowering of 2-lane 64-bit floating point shuffles.; ///; /// This is the basis function for the 2-lane 64-bit shuffles as we have full; /// support for floating point shuffles but not integer shuffles. These; /// instructions will incur a domain crossing penalty on some chips though so; /// it is better to avoid lowering through this for integer vectors where; /// possible.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Performance,load,load,67,"// If we have AVX, we can use VPERMILPS which will allow folding a load; // into the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,load,loading,8,// When loading a scalar and then shuffling it into a vector we can often do; // the insertion cheaply.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Availability,mask,masks,44,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Availability,reliab,reliably,84,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Availability,mask,mask,102,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Performance,load,load,46,// We can either use a special instruction to load over the low double or; // to move just the low double.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:166,Availability,mask,mask,166,// Straight shuffle of a single input vector. For everything from SSE2; // onward this has a single fast instruction with no scary immediates.; // We have to map the mask as it is actually a v4i32 shuffle instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,load,loading,8,// When loading a scalar and then shuffling it into a vector we can often do; // the insertion cheaply.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Availability,mask,masks,44,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Availability,reliab,reliably,84,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Availability,mask,mask,102,// Try inverting the insertion since for v2 masks it is easy to do and we; // can't reliably sort the mask one way or the other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Integrability,rout,routine,84,"/// Lower a vector shuffle using the SHUFPS instruction.; ///; /// This is a helper routine dedicated to lowering vector shuffles using SHUFPS.; /// It makes no assumptions about whether this is the *best* lowering, it simply; /// uses it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:219,Usability,simpl,simply,219,"/// Lower a vector shuffle using the SHUFPS instruction.; ///; /// This is a helper routine dedicated to lowering vector shuffles using SHUFPS.; /// It makes no assumptions about whether this is the *best* lowering, it simply; /// uses it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Safety,detect,detect,84,// We also handle the reversed case because this utility may get called; // when we detect a SHUFPS pattern but can't easily commute the shuffle to; // arrange things in the right direction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:201,Availability,mask,mask,201,"// We have a mixture of V1 and V2 in both low and high lanes. Rather than; // trying to place elements directly, just blend them and set up the final; // shuffle to place them.; // The first two blend mask elements are for V1, the second two are for; // V2.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:128,Availability,mask,mask,128,"// Ideally canonicalizeShuffleMaskWithCommute should have caught this, but; // we can get here due to other paths (e.g repeated mask matching) that we; // don't want to do another round of lowerVECTOR_SHUFFLE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,masks,43,// Use even/odd duplicate instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Performance,load,load,67,"// If we have AVX, we can use VPERMILPS which will allow folding a load; // into the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:287,Availability,mask,mask,287,"// There are special ways we can lower some single-element blends. However, we; // have custom ways we can lower more complex single-element blends below that; // we defer to if both this and BLENDPS fail to match, so restrict this to; // when the V2 input is targeting element 0 of the mask -- that is the fast; // case here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Energy Efficiency,efficient,efficiently,47,// Use INSERTPS if we can complete the shuffle efficiently.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,// Try to use broadcast unless the mask only has one non-undef element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:320,Performance,load,load,320,// Straight shuffle of a single input vector. For everything from SSE2; // onward this has a single fast instruction with no scary immediates.; // We coerce the shuffle pattern to be compatible with UNPCK instructions; // but we aren't actually going to use the UNPCK instruction because doing; // so prevents folding a load into this instruction or making a copy.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:737,Availability,Mask,Mask,737,"/// Lowering of single-input v8i16 shuffles is the cornerstone of SSE2; /// shuffle lowering, and the most complex part.; ///; /// The lowering strategy is to try to form pairs of input lanes which are; /// targeted at the same half of the final vector, and then use a dword shuffle; /// to place them onto the right half, and finally unpack the paired lanes into; /// their final position.; ///; /// The exact breakdown of how to form these dword pairs and align them on the; /// correct sides is really tricky. See the comments within the function for; /// more of the details.; ///; /// This code also handles repeated 128-bit lanes of v8i16 shuffles, but each; /// lane must shuffle the *exact* same way. In fact, you must pass a v8 Mask to; /// this routine for it to work correctly. To shuffle a 256-bit or 512-bit i16; /// vector, form the analogous 128-bit 8-element Mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:875,Availability,Mask,Mask,875,"/// Lowering of single-input v8i16 shuffles is the cornerstone of SSE2; /// shuffle lowering, and the most complex part.; ///; /// The lowering strategy is to try to form pairs of input lanes which are; /// targeted at the same half of the final vector, and then use a dword shuffle; /// to place them onto the right half, and finally unpack the paired lanes into; /// their final position.; ///; /// The exact breakdown of how to form these dword pairs and align them on the; /// correct sides is really tricky. See the comments within the function for; /// more of the details.; ///; /// This code also handles repeated 128-bit lanes of v8i16 shuffles, but each; /// lane must shuffle the *exact* same way. In fact, you must pass a v8 Mask to; /// this routine for it to work correctly. To shuffle a 256-bit or 512-bit i16; /// vector, form the analogous 128-bit 8-element Mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:755,Integrability,rout,routine,755,"/// Lowering of single-input v8i16 shuffles is the cornerstone of SSE2; /// shuffle lowering, and the most complex part.; ///; /// The lowering strategy is to try to form pairs of input lanes which are; /// targeted at the same half of the final vector, and then use a dword shuffle; /// to place them onto the right half, and finally unpack the paired lanes into; /// their final position.; ///; /// The exact breakdown of how to form these dword pairs and align them on the; /// correct sides is really tricky. See the comments within the function for; /// more of the details.; ///; /// This code also handles repeated 128-bit lanes of v8i16 shuffles, but each; /// lane must shuffle the *exact* same way. In fact, you must pass a v8 Mask to; /// this routine for it to work correctly. To shuffle a 256-bit or 512-bit i16; /// vector, form the analogous 128-bit 8-element Mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Performance,perform,perform,133,// If we are shuffling values from one half - check how many different DWORD; // pairs we need to create. If only 1 or 2 then we can perform this as a; // PSHUFLW/PSHUFHW + PSHUFD instead of the PSHUFD+PSHUFLW+PSHUFHW chain below.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:363,Availability,Mask,Mask,363,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1223,Availability,Mask,Mask,1223,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1465,Availability,Mask,Mask,1465,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1628,Availability,Mask,Mask,1628,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:634,Safety,avoid,avoid,634,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1759,Testability,log,logic,1759,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,"// Simplify the 1-into-3 and 3-into-1 cases with a single pshufd. For all; // such inputs we can swap two of the dwords across the half mark and end up; // with <=2 inputs to each half in each half. Once there, we can fall through; // to the generic code below. For example:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [0, 1, 2, 7, 4, 5, 6, 3] -----------------> [0, 1, 4, 7, 2, 3, 6, 5]; //; // However in some very rare cases we have a 1-into-3 or 3-into-1 on one half; // and an existing 2-into-2 on the other half. In this case we may have to; // pre-shuffle the 2-into-2 half to avoid turning it into a 3-into-1 or; // 1-into-3 which could cause us to cycle endlessly fixing each side in turn.; // Fortunately, we don't have to handle anything but a 2-into-2 pattern; // because any other situation (including a 3-into-1 or 1-into-3 in the other; // half than the one we target for fixing) will be fixed when we re-enter this; // path. We will also combine away any sequence of PSHUFD instructions that; // result into a single instruction. Here is an example of the tricky case:; //; // Input: [a, b, c, d, e, f, g, h] -PSHUFD[0,2,1,3]-> [a, b, e, f, c, d, g, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -THIS-IS-BAD!!!!-> [5, 7, 1, 0, 4, 7, 5, 3]; //; // This now has a 1-into-3 in the high half! Instead, we do two shuffles:; //; // Input: [a, b, c, d, e, f, g, h] PSHUFHW[0,2,1,3]-> [a, b, c, d, e, g, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 5] -----------------> [3, 7, 1, 0, 2, 7, 3, 6]; //; // Input: [a, b, c, d, e, g, f, h] -PSHUFD[0,2,1,3]-> [a, b, e, g, c, d, f, h]; // Mask: [3, 7, 1, 0, 2, 7, 3, 6] -----------------> [5, 7, 1, 0, 4, 7, 5, 6]; //; // The result is fine to be handled by the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,mask,14,// Adjust the mask to match the new locations of A and B.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Integrability,rout,routine,26,// Recurse back into this routine to re-compute state now that this isn't; // a 3 and 1 problem.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,mask,masks,17,// First fix the masks for all the inputs that are staying in their; // original halves. This will then dictate the targets of the cross-half; // shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:147,Usability,simpl,simplified,147,// Now gather the cross-half inputs and place them into a free dword of; // their target half.; // FIXME: This operation could almost certainly be simplified dramatically to; // look more like the 3-1 fixing operation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,"// If the source half mask maps over the inputs, turn those into; // swaps and use the swapped lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Availability,mask,mask,40,// We have to swap the uses in our half mask in one sweep.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Safety,avoid,avoid,140,// Note that this correctly re-maps both when we do a swap and when; // we observe the other side of the swap above. We rely on that to; // avoid swapping the members of the input list directly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Availability,mask,mask,42,// And just directly shift any other-half mask elements to be same-half; // as we will have mirrored the dword containing the element into the; // same position within that half.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:173,Availability,mask,mask,173,"// We have two non-adjacent or clobbered inputs we need to extract from; // the source half. To do this, we need to map them into some adjacent; // dword slot in the source mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,"// If there is a free slot in the source half mask adjacent to one of; // the inputs, place the other input in it. We use (Index XOR 1) to; // compute an adjacent index.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,mask,43,// We also have to update the final source mask in this case because; // it may need to undo the above swap.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Deployability,update,update,19,// We also have to update the final source mask in this case because; // it may need to undo the above swap.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Usability,undo,undo,88,// We also have to update the final source mask in this case because; // it may need to undo the above swap.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,down,down,23,// Now hoist the DWord down to the right half.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Availability,mask,mask,33,// Do a half shuffle for the low mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,// Do a half shuffle with the high mask after shifting its values down.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Availability,down,down,66,// Do a half shuffle with the high mask after shifting its values down.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Safety,avoid,avoiding,67,"/// Helper to form a PSHUFB-based shuffle+blend, opportunistically avoiding the; /// blend if only one input is used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:226,Integrability,rout,routine,226,"/// Generic lowering of 8-lane i16 shuffles.; ///; /// This handles both single-input shuffles and combined shuffle/blends with; /// two inputs. The single input shuffles are immediately delegated to; /// a dedicated lowering routine.; ///; /// The blends are lowered in one of three fundamental ways. If there are few; /// enough inputs, it delegates to a basic UNPCK-based strategy. If the shuffle; /// of the input is significantly cheaper when lowered as an interleaving of; /// the two inputs, try to interleave them. Otherwise, blend the low and high; /// halves of the inputs separately (making them have relatively few inputs); /// and then concatenate them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,// Make a copy of the mask so it can be modified.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,// Try to use byte shift instructions to mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,mask,10,// Adjust mask to correct indices for the second input.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Safety,detect,detect,126,"/// Generic lowering of v16i8 shuffles.; ///; /// This is a hybrid strategy to lower v16i8 vectors. It first attempts to; /// detect any complexity reducing interleaving. If that doesn't help, it uses; /// UNPCK to spread the i8 elements across two i16-element vectors, and uses; /// the existing lowering for v8i16 blends on each half, finally PACK-ing them; /// back together.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:139,Energy Efficiency,efficient,efficiently,139,"// Check whether we can widen this to an i16 shuffle by duplicating bytes.; // Notably, this handles splat and partial-splat shuffles more efficiently.; // However, it only makes sense if the pre-duplication shuffle simplifies; // things significantly. Currently, this means we need to be able to; // express the pre-duplication shuffle as an i16 shuffle.; //; // FIXME: We should check for other patterns which can be widened into an; // i16 shuffle as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:216,Usability,simpl,simplifies,216,"// Check whether we can widen this to an i16 shuffle by duplicating bytes.; // Notably, this handles splat and partial-splat shuffles more efficiently.; // However, it only makes sense if the pre-duplication shuffle simplifies; // things significantly. Currently, this means we need to be able to; // express the pre-duplication shuffle as an i16 shuffle.; //; // FIXME: We should check for other patterns which can be widened into an; // i16 shuffle as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Usability,simpl,simple,55,"// We can't place the inputs into a single half with a simple i16 shuffle, so bail.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update the lane map based on the mapping we ended up with.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,// Try to use byte shift instructions to mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:689,Availability,mask,mask,689,"// Check for SSSE3 which lets us lower all v16i8 shuffles much more directly; // with PSHUFB. It is important to do this before we attempt to generate any; // blends but after all of the single-input lowerings. If the single input; // lowerings can find an instruction sequence that is faster than a PSHUFB, we; // want to preserve that and we can DAG combine any longer sequences into; // a PSHUFB in the end. But once we start blending from multiple inputs,; // the complexity of DAG combining bad patterns back into PSHUFB is too high,; // and there are *very* few patterns that would actually be faster than the; // PSHUFB approach because of its ability to zero lanes.; //; // If the mask is a binary compaction, we can more efficiently perform this; // as a PACKUS(AND(),AND()) - which is quicker than UNPACK(PSHUFB(),PSHUFB()).; //; // FIXME: The only exceptions to the above are blends which are exact; // interleavings with direct instructions supporting them. We currently don't; // handle those well here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:730,Energy Efficiency,efficient,efficiently,730,"// Check for SSSE3 which lets us lower all v16i8 shuffles much more directly; // with PSHUFB. It is important to do this before we attempt to generate any; // blends but after all of the single-input lowerings. If the single input; // lowerings can find an instruction sequence that is faster than a PSHUFB, we; // want to preserve that and we can DAG combine any longer sequences into; // a PSHUFB in the end. But once we start blending from multiple inputs,; // the complexity of DAG combining bad patterns back into PSHUFB is too high,; // and there are *very* few patterns that would actually be faster than the; // PSHUFB approach because of its ability to zero lanes.; //; // If the mask is a binary compaction, we can more efficiently perform this; // as a PACKUS(AND(),AND()) - which is quicker than UNPACK(PSHUFB(),PSHUFB()).; //; // FIXME: The only exceptions to the above are blends which are exact; // interleavings with direct instructions supporting them. We currently don't; // handle those well here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:742,Performance,perform,perform,742,"// Check for SSSE3 which lets us lower all v16i8 shuffles much more directly; // with PSHUFB. It is important to do this before we attempt to generate any; // blends but after all of the single-input lowerings. If the single input; // lowerings can find an instruction sequence that is faster than a PSHUFB, we; // want to preserve that and we can DAG combine any longer sequences into; // a PSHUFB in the end. But once we start blending from multiple inputs,; // the complexity of DAG combining bad patterns back into PSHUFB is too high,; // and there are *very* few patterns that would actually be faster than the; // PSHUFB approach because of its ability to zero lanes.; //; // If the mask is a binary compaction, we can more efficiently perform this; // as a PACKUS(AND(),AND()) - which is quicker than UNPACK(PSHUFB(),PSHUFB()).; //; // FIXME: The only exceptions to the above are blends which are exact; // interleavings with direct instructions supporting them. We currently don't; // handle those well here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Safety,avoid,avoids,92,"// If both V1 and V2 are in use and we can use a direct blend or an unpack,; // do so. This avoids using them to handle blends-with-zero which is; // important as a single pshufb is significantly faster for that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Energy Efficiency,efficient,efficient,126,"// We can use an unpack to do the blending rather than an or in some; // cases. Even though the or may be (very minorly) more efficient, we; // preference this lowering because there are common cases where part of; // the complexity of the shuffles goes away when we do the final blend as; // an unpack.; // FIXME: It might be worth trying to detect if the unpack-feeding; // shuffles will both be pshufb, in which case we shouldn't bother with; // this.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:343,Safety,detect,detect,343,"// We can use an unpack to do the blending rather than an or in some; // cases. Even though the or may be (very minorly) more efficient, we; // preference this lowering because there are common cases where part of; // the complexity of the shuffles goes away when we do the final blend as; // an unpack.; // FIXME: It might be worth trying to detect if the unpack-feeding; // shuffles will both be pshufb, in which case we shouldn't bother with; // this.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:223,Energy Efficiency,efficient,efficiently,223,// Check whether a compaction lowering can be done. This handles shuffles; // which take every Nth element for some even N. See the helper function for; // details.; //; // We special case these as they can be particularly efficiently handled with; // the PACKUSB instruction on x86 and they show up in common patterns of; // rearranging bytes to truncate wide elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Energy Efficiency,power,power,23,// NumEvenDrops is the power of two stride of the elements. Another way of; // thinking about it is that we need to drop the even elements this many; // times to get the original input.; // First we need to zero all the dropped bytes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Availability,mask,mask,71,"// Check if any of the odd lanes in the v16i8 are used. If not, we can mask; // them out and avoid using UNPCK{L,H} to extract the elements of V as; // i16s.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Safety,avoid,avoid,93,"// Check if any of the odd lanes in the v16i8 are used. If not, we can mask; // them out and avoid using UNPCK{L,H} to extract the elements of V as; // i16s.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Availability,mask,mask,9,// Use a mask to drop the high bytes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,masks,14,// Squash the masks to point directly into VLoHalf.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Availability,down,down,100,/// Dispatching routine to lower various 128-bit x86 vector shuffles.; ///; /// This routine breaks down the specific type of 128-bit shuffle and; /// dispatches to the lowering routines accordingly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Integrability,rout,routine,16,/// Dispatching routine to lower various 128-bit x86 vector shuffles.; ///; /// This routine breaks down the specific type of 128-bit shuffle and; /// dispatches to the lowering routines accordingly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Integrability,rout,routine,85,/// Dispatching routine to lower various 128-bit x86 vector shuffles.; ///; /// This routine breaks down the specific type of 128-bit shuffle and; /// dispatches to the lowering routines accordingly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:178,Integrability,rout,routines,178,/// Dispatching routine to lower various 128-bit x86 vector shuffles.; ///; /// This routine breaks down the specific type of 128-bit shuffle and; /// dispatches to the lowering routines accordingly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Integrability,rout,routine,12,"/// Generic routine to split vector shuffle into half-sized shuffles.; ///; /// This routine just extracts two subvectors, shuffles them independently, and; /// then concatenates them back together. This should work effectively with all; /// AVX vector shuffle types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Integrability,rout,routine,85,"/// Generic routine to split vector shuffle into half-sized shuffles.; ///; /// This routine just extracts two subvectors, shuffles them independently, and; /// then concatenates them back together. This should work effectively with all; /// AVX vector shuffle types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:109,Availability,mask,masks,109,"// Because the lowering happens after all combining takes place, we need to; // manually combine these blend masks as much as possible so that we create; // a minimal number of high-level vector shuffle nodes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,down,down,43,// We only use half of V1 so map the usage down into the final blend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Availability,mask,mask,69,// We only use half of V1 so map the usage down into the final blend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,down,down,43,// We only use half of V2 so map the usage down into the final blend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Availability,mask,mask,69,// We only use half of V2 so map the usage down into the final blend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Modifiability,Extend,Extend,70,"// Lower as SHUFPD(VPERM2F128(V1, V2), VPERM2F128(V1, V2)).; // TODO: Extend to support v8f32 (+ 512-bit shuffles).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Performance,perform,perform,71,"// As SHUFPD uses a single LHS/RHS element per lane, we can always; // perform the shuffle once the lanes have been shuffled in place.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:143,Modifiability,extend,extended,143,// If we're only shuffling a single lowest lane and the rest are identity; // then don't bother.; // TODO - isShuffleMaskInputInPlace could be extended to something like; // this.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,"// Avoid returning the same shuffle operation. For example,; // t7: v16i16 = vector_shuffle<8,9,10,11,4,5,6,7,0,1,2,3,12,13,14,15> t5,; // undef:v16i16",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Modifiability,variab,variable,41,"// If that doesn't work and we have fast variable cross-lane shuffle,; // attempt 32-bit sublanes (vpermd).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,/// Helper to get compute inlane shuffle mask for a complete shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Availability,mask,mask,69,/// Helper to get compute inlane shuffle mask for a complete shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Availability,mask,mask,61,"// If we're not using both lanes in each lane and the inlane mask is not; // repeating, then we're better off splitting.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Performance,load,load,55,// Attempt to match VBROADCAST*128 subvector broadcast load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:72,Availability,mask,mask,72,"// If either input operand is a zero vector, use VPERM2X128 because its mask; // allows us to replace the zero input with an implicit zero.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Performance,load,load,46,"// With AVX1, use vperm2f128 (below) to allow load folding. Otherwise,; // this will likely become vinsertf128 which can't fold a 256-bit memop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:101,Availability,mask,mask,101,"// Otherwise form a 128-bit permutation. After accounting for undefs,; // convert the 64-bit shuffle mask selection values into 128-bit; // selection bits by dividing the indexes by 2 and shifting into positions; // defined by a vperm2*128 instruction's immediate control byte.; // The immediate permute control byte looks like this:; // [1:0] - select 128 bits from sources for low half of destination; // [2] - ignore; // [3] - zero low half of destination; // [5:4] - select 128 bits from sources for high half of destination; // [6] - ignore; // [7] - zero high half of destination",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,mask,23,// Check the immediate mask and replace unused sources with undef.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Availability,mask,mask,64,"// If this lane has two sources, see if it fits with the repeat mask so far.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Merge this lane mask into the final repeat mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Merge this lane mask into the final repeat mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Merge this lane mask into the final repeat mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Merge this lane mask into the final repeat mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,mask,25,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Availability,mask,mask,118,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:193,Availability,mask,mask,193,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:221,Availability,mask,mask,221,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:123,Security,access,accesses,123,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:251,Security,access,access,251,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:433,Security,access,accessed,433,"/// If the input shuffle mask results in a vector that is undefined in all upper; /// or lower half elements and that mask accesses only 2 halves of the; /// shuffle's operands, return true. A mask of half the width with mask indexes; /// adjusted to access the extracted halves of the original shuffle operands is; /// returned in HalfMask. HalfIdx1 and HalfIdx2 return whether the upper or; /// lower half of each input operand is accessed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Availability,mask,mask,76,"// We can shuffle with up to 2 half vectors, set the new 'half'; // shuffle mask accordingly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:208,Energy Efficiency,efficient,efficiently,208,/// Lower shuffles where an entire half of a 256 or 512-bit vector is UNDEF.; /// This allows for fast cases such as subvector extraction/insertion; /// or shuffling smaller vector types which can lower more efficiently.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Energy Efficiency,efficient,efficient,12,// AVX2 has efficient 32/64-bit element cross-lane shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Energy Efficiency,efficient,efficient,14,// AVX512 has efficient cross-lane shuffles for all legal 512-bit types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Availability,mask,masks,122,"// AVX2 has efficient 64-bit element cross-lane shuffles.; // TODO: Refine to account for unary shuffle, splat, and other masks?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Energy Efficiency,efficient,efficient,12,"// AVX2 has efficient 64-bit element cross-lane shuffles.; // TODO: Refine to account for unary shuffle, splat, and other masks?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Energy Efficiency,efficient,efficient,14,// AVX512 has efficient cross-lane shuffles for all legal 512-bit types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:137,Availability,mask,mask,137,/// Handle case where shuffle sources are coming from the same 128-bit lane and; /// every lane can be represented as the same repeating mask - allowing us to; /// shuffle the sources with the repeating shuffle and then permute the result; /// to the destination lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,"// Avoid returning the same shuffle operation. For example,; // v8i32 = vector_shuffle<0,1,0,1,0,1,0,1> t5, undef:v8i32",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,mask,23,// Bail if the shuffle mask doesn't cross 128-bit lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Availability,mask,mask,51,// Bail if we already have a repeated lane shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Availability,mask,mask,31,"// Helper to look for repeated mask in each split sublane, and that those; // sublanes can then be permuted into place.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Availability,mask,mask,107,"// Check that all the sources are coming from the same lane and see if we; // can form a repeating shuffle mask (local to each sub-lane). At the same; // time, determine the source sub-lane for each destination sub-lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,"// Extract the sub-lane mask, check that it all comes from the same lane; // and normalize the mask entries to come from the first lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:95,Availability,mask,mask,95,"// Extract the sub-lane mask, check that it all comes from the same lane; // and normalize the mask entries to come from the first lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Availability,mask,masks,60,// Attempt to match against the candidate repeated sub-lane masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,// Merge the sub-lane mask into the matching repeated sub-lane mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Availability,mask,mask,63,// Merge the sub-lane mask into the matching repeated sub-lane mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Usability,simpl,simplify,93,// Track the top most source sub-lane - by setting the remaining to; // UNDEF we can greatly simplify shuffle matching.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Availability,mask,mask,58,// Bail if we failed to find a matching repeated sub-lane mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Availability,mask,mask,30,// Create a repeating shuffle mask for the entire vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,"// Avoid returning the same shuffle operation.; // v8i32 = vector_shuffle<0,1,4,5,2,3,6,7> t5, undef:v8i32",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:165,Modifiability,variab,variable,165,"// On AVX2 targets we can permute 256-bit vectors as 64-bit sub-lanes; // (with PERMQ/PERMPD). On AVX2/AVX512BW targets, permuting 32-bit sub-lanes,; // even with a variable shuffle, can be worth it for v32i8/v64i8 vectors.; // Otherwise we can only permute whole 128-bit lanes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,"// Mask for V8F64: 0/1, 8/9, 2/3, 10/11, 4/5, ..; // Mask for V4F64; 0/1, 4/5, 2/3, 6/7..",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Availability,Mask,Mask,53,"// Mask for V8F64: 0/1, 8/9, 2/3, 10/11, 4/5, ..; // Mask for V4F64; 0/1, 4/5, 2/3, 6/7..",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:522,Availability,mask,masks,522,"// a = shuffle v1, v2, mask1 ; interleaving lower lanes of v1 and v2; // b = shuffle v1, v2, mask2 ; interleaving higher lanes of v1 and v2; // =>; // ul = unpckl v1, v2; // uh = unpckh v1, v2; // a = vperm ul, uh; // b = vperm ul, uh; //; // Pattern-match interleave(256b v1, 256b v2) -> 512b v3 and lower it into unpck; // and permute. We cannot directly match v3 because it is split into two; // 256-bit vectors in earlier isel stages. Therefore, this function matches a; // pair of 256-bit shuffles and makes sure the masks are consecutive.; //; // Once unpck and permute nodes are created, the permute corresponding to this; // shuffle is returned, while the other permute replaces the other half of the; // shuffle in the selection dag.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Availability,avail,available,158,/// Handle lowering of 4-lane 64-bit floating point shuffles.; ///; /// Also ends up handling lowering of 4-lane 64-bit integer shuffles when AVX2; /// isn't available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,masks,38,// Use low duplicate instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,"// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle. However, if we have AVX2 and either inputs are already in place,; // we will be able to shuffle even across lanes the other input in a single; // instruction so skip this pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Integrability,rout,routine,70,/// Handle lowering of 4-lane 64-bit integer shuffles.; ///; /// This routine is only called when we have AVX2 and thus a reasonable; /// instruction set for v4i64 shuffling..,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Performance,latency,latency,92,"// When the shuffle is mirrored between the 128-bit lanes of the unit, we; // can use lower latency instructions that will operate on both lanes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,"// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle. However, if we have AVX2 and either inputs are already in place,; // we will be able to shuffle even across lanes the other input in a single; // instruction so skip this pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Availability,avail,available,158,/// Handle lowering of 8-lane 32-bit floating point shuffles.; ///; /// Also ends up handling lowering of 8-lane 32-bit integer shuffles when AVX2; /// isn't available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,"// If the shuffle mask is repeated in each 128-bit lane, we have many more; // options to efficiently lower the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Energy Efficiency,efficient,efficiently,90,"// If the shuffle mask is repeated in each 128-bit lane, we have many more; // options to efficiently lower the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,masks,43,// Use even/odd duplicate instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:115,Availability,mask,mask,115,// If we have a single input shuffle with different shuffle patterns in the; // two 128-bit lanes use the variable mask to VPERMILPS.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Modifiability,variab,variable,106,// If we have a single input shuffle with different shuffle patterns in the; // two 128-bit lanes use the variable mask to VPERMILPS.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,Mask,Mask,25,// For non-AVX512 if the Mask is of 16bit elements in lane then try to split; // since after split we get a more efficient code using vpunpcklwd and; // vpunpckhwd instrs than vblend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Energy Efficiency,efficient,efficient,113,// For non-AVX512 if the Mask is of 16bit elements in lane then try to split; // since after split we get a more efficient code using vpunpcklwd and; // vpunpckhwd instrs than vblend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Integrability,rout,routine,70,/// Handle lowering of 8-lane 32-bit integer shuffles.; ///; /// This routine is only called when we have AVX2 and thus a reasonable; /// instruction set for v8i32 shuffling..,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,Mask,Mask,25,// For non-AVX512 if the Mask is of 16bit elements in lane then try to split; // since after split we get a more efficient code than vblend by using; // vpunpcklwd and vpunpckhwd instrs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Energy Efficiency,efficient,efficient,113,// For non-AVX512 if the Mask is of 16bit elements in lane then try to split; // since after split we get a more efficient code than vblend by using; // vpunpcklwd and vpunpckhwd instrs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// If the shuffle mask is repeated in each 128-bit lane we can use more; // efficient instructions that mirror the shuffles across the two 128-bit; // lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Energy Efficiency,efficient,efficient,76,// If the shuffle mask is repeated in each 128-bit lane we can use more; // efficient instructions that mirror the shuffles across the two 128-bit; // lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:115,Modifiability,variab,variable,115,// Try to produce a fixed cross-128-bit lane permute followed by unpack; // because that should be faster than the variable permute alternatives.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Integrability,rout,routine,71,/// Handle lowering of 16-lane 16-bit integer shuffles.; ///; /// This routine is only called when we have AVX2 and thus a reasonable; /// instruction set for v16i16 shuffling..,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:115,Modifiability,variab,variable,115,// Try to produce a fixed cross-128-bit lane permute followed by unpack; // because that should be faster than the variable permute alternatives.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Availability,avail,available,58,// There are no generalized cross-lane shuffle operations available on i16; // element types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Availability,mask,mask,51,"// As this is a single-input shuffle, the repeated mask should be; // a strictly valid v8i16 mask that we can pass through to the v8i16; // lowering to handle even the v16 case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Availability,mask,mask,93,"// As this is a single-input shuffle, the repeated mask should be; // a strictly valid v8i16 mask that we can pass through to the v8i16; // lowering to handle even the v16 case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Integrability,rout,routine,70,/// Handle lowering of 32-lane 8-bit integer shuffles.; ///; /// This routine is only called when we have AVX2 and thus a reasonable; /// instruction set for v32i8 shuffling..,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Availability,avail,available,58,// There are no generalized cross-lane shuffle operations available on i8; // element types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:115,Modifiability,variab,variable,115,// Try to produce a fixed cross-128-bit lane permute followed by unpack; // because that should be faster than the variable permute alternatives.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Availability,down,down,106,/// High-level routine to lower various 256-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 256-bit x86 vector; /// shuffle or splits it into two 128-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:259,Availability,avail,available,259,/// High-level routine to lower various 256-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 256-bit x86 vector; /// shuffle or splits it into two 128-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Integrability,rout,routine,15,/// High-level routine to lower various 256-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 256-bit x86 vector; /// shuffle or splits it into two 128-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Integrability,rout,routine,84,/// High-level routine to lower various 256-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 256-bit x86 vector; /// shuffle or splits it into two 128-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:193,Integrability,rout,routines,193,"// There is a really nice hard cut-over between AVX1 and AVX2 that means we; // can check for those subtargets here and avoid much of the subtarget; // querying in the per-vector-type lowering routines. With AVX1 we have; // essentially *zero* ability to manipulate a 256-bit vector with integer; // types. Since we'll use floating point types there eventually, just; // immediately cast everything to a float and operate entirely in that domain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,Safety,avoid,avoid,120,"// There is a really nice hard cut-over between AVX1 and AVX2 that means we; // can check for those subtargets here and avoid much of the subtarget; // querying in the per-vector-type lowering routines. With AVX1 we have; // essentially *zero* ability to manipulate a 256-bit vector with integer; // types. Since we'll use floating point types there eventually, just; // immediately cast everything to a float and operate entirely in that domain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,avail,available,26,"// No floating point type available, if we can't use the bit operations; // for masking/blending then decompose into 128-bit vectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Availability,mask,masking,80,"// No floating point type available, if we can't use the bit operations; // for masking/blending then decompose into 128-bit vectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,masks,38,// Use low duplicate instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,"// If the shuffle mask is repeated in each 128-bit lane, we have many more; // options to efficiently lower the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Energy Efficiency,efficient,efficiently,90,"// If the shuffle mask is repeated in each 128-bit lane, we have many more; // options to efficiently lower the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,masks,43,// Use even/odd duplicate instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Availability,mask,mask,129,"// If we have a single input shuffle with different shuffle patterns in the; // 128-bit lanes and don't lane cross, use variable mask VPERMILPS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,Modifiability,variab,variable,120,"// If we have a single input shuffle with different shuffle patterns in the; // 128-bit lanes and don't lane cross, use variable mask VPERMILPS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Performance,latency,latency,92,"// When the shuffle is mirrored between the 128-bit lanes of the unit, we; // can use lower latency instructions that will operate on all four; // 128-bit lanes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// If the shuffle mask is repeated in each 128-bit lane we can use more; // efficient instructions that mirror the shuffles across the four 128-bit; // lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Energy Efficiency,efficient,efficient,76,// If the shuffle mask is repeated in each 128-bit lane we can use more; // efficient instructions that mirror the shuffles across the four 128-bit; // lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Availability,mask,mask,51,"// As this is a single-input shuffle, the repeated mask should be; // a strictly valid v8i16 mask that we can pass through to the v8i16; // lowering to handle even the v32 case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Availability,mask,mask,93,"// As this is a single-input shuffle, the repeated mask should be; // a strictly valid v8i16 mask that we can pass through to the v8i16; // lowering to handle even the v32 case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,masks,41,// Use dedicated unpack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,masks,39,// Use dedicated pack instructions for masks that match their pattern.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Try to create an in-lane repeating shuffle mask and then shuffle the; // results into the target lanes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify this by merging 128-bit lanes to enable a lane-based; // shuffle.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Availability,down,down,106,/// High-level routine to lower various 512-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 512-bit x86 vector; /// shuffle or splits it into two 256-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:259,Availability,avail,available,259,/// High-level routine to lower various 512-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 512-bit x86 vector; /// shuffle or splits it into two 256-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Integrability,rout,routine,15,/// High-level routine to lower various 512-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 512-bit x86 vector; /// shuffle or splits it into two 256-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Integrability,rout,routine,84,/// High-level routine to lower various 512-bit x86 vector shuffles.; ///; /// This routine either breaks down the specific type of a 512-bit x86 vector; /// shuffle or splits it into two 256-bit shuffles and fuses the results back; /// together based on the available instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,masking,25,// Try using bit ops for masking and blending before falling back to; // splitting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:2,Usability,Simpl,SimpleOnly,2,/*SimpleOnly*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:290,Availability,avail,available,290,"// Dispatch to each element type for lowering. If we don't have support for; // specific element type shuffles at 512 bits, immediately split them and; // lower them. Each lowering routine of a given type is allowed to assume that; // the requisite ISA extensions for that element type are available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:181,Integrability,rout,routine,181,"// Dispatch to each element type for lowering. If we don't have support for; // specific element type shuffles at 512 bits, immediately split them and; // lower them. Each lowering routine of a given type is allowed to assume that; // the requisite ISA extensions for that element type are available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Usability,simpl,simplified,140,// Determine if this shuffle can be implemented with a KSHIFT instruction.; // Returns the shift amount if possible or -1 if not. This is a simplified; // version of matchShuffleAsShift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Availability,mask,masks,100,"// Lower vXi1 vector shuffles.; // There is no a dedicated instruction on AVX-512 that shuffles the masks.; // The only way to shuffle bits is to sign-extend the mask vector to SIMD; // vector, shuffle and then truncate it back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:162,Availability,mask,mask,162,"// Lower vXi1 vector shuffles.; // There is no a dedicated instruction on AVX-512 that shuffles the masks.; // The only way to shuffle bits is to sign-extend the mask vector to SIMD; // vector, shuffle and then truncate it back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:151,Modifiability,extend,extend,151,"// Lower vXi1 vector shuffles.; // There is no a dedicated instruction on AVX-512 that shuffles the masks.; // The only way to shuffle bits is to sign-extend the mask vector to SIMD; // vector, shuffle and then truncate it back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Availability,mask,mask,40,// Grab the source from the first valid mask. All subsequent elements need; // to use this same source.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Energy Efficiency,power,power,13,// Clip to a power 2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Usability,simpl,simple,9,// Try a simple shift right with undef elements. Later we'll try with zeros.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Performance,perform,performing,12,"// If we're performing an unary shuffle on a SETCC result, try to shuffle the; // ops instead.; // TODO: What other unary shuffles would benefit from this?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Availability,avail,available,94,"// Take 512-bit type, unless we are avoiding 512-bit types and have the; // 256-bit operation available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Safety,avoid,avoiding,36,"// Take 512-bit type, unless we are avoiding 512-bit types and have the; // 256-bit operation available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Availability,avail,available,94,"// Take 512-bit type, unless we are avoiding 512-bit types and have the; // 256-bit operation available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Safety,avoid,avoiding,36,"// Take 512-bit type, unless we are avoiding 512-bit types and have the; // 256-bit operation available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Modifiability,extend,extended,15,// i1 was sign extended we can use X86ISD::CVT2MASK.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Availability,mask,mask,53,/// Helper function that returns true if the shuffle mask should be; /// commuted to improve canonicalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Availability,mask,masked-mov,113,"// If vec width < 512, widen i8/i16 even with BWI as blendd/blendps/blendpd; // are preferable to blendw/blendvb/masked-mov.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Modifiability,extend,extend,61,// TODO: Currently we only check limited opcode. We probably extend; // it to all binary operation by checking TLI.isBinOp().,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:229,Integrability,rout,routines,229,"/// Top-level lowering for x86 vector shuffles.; ///; /// This handles decomposition, canonicalization, and lowering of all x86; /// vector shuffles. Most of the specific lowering strategies are encapsulated; /// above in helper routines. The canonicalization attempts to widen shuffles; /// to involve fewer lanes of wider elements, consolidate symmetric patterns; /// s.t. only one of the two inputs needs to be tested, etc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:414,Testability,test,tested,414,"/// Top-level lowering for x86 vector shuffles.; ///; /// This handles decomposition, canonicalization, and lowering of all x86; /// vector shuffles. Most of the specific lowering strategies are encapsulated; /// above in helper routines. The canonicalization attempts to widen shuffles; /// to involve fewer lanes of wider elements, consolidate symmetric patterns; /// s.t. only one of the two inputs needs to be tested, etc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,masks,23,// Check for non-undef masks pointing at an undef vector and make the masks; // undef as well. This makes it easier to match the shuffle based solely on; // the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Availability,mask,masks,70,// Check for non-undef masks pointing at an undef vector and make the masks; // undef as well. This makes it easier to match the shuffle based solely on; // the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:161,Availability,mask,mask,161,// Check for non-undef masks pointing at an undef vector and make the masks; // undef as well. This makes it easier to match the shuffle based solely on; // the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Availability,mask,mask,29,// Check for illegal shuffle mask element index values.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:155,Usability,simpl,simple,155,// We actually see shuffles that are entirely re-arrangements of a set of; // zero inputs. This mostly happens while decomposing complex shuffles into; // simple ones. Directly lower these as a buildvector of zeros.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,mask,mask,11,// Shuffle mask widening should not interfere with a broadcast opportunity; // by obfuscating the operands with bitcasts.; // TODO: Avoid lowering directly from this top-level function: make this; // a query (canLowerAsBroadcast) and defer lowering to the type-based calls.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:132,Safety,Avoid,Avoid,132,// Shuffle mask widening should not interfere with a broadcast opportunity; // by obfuscating the operands with bitcasts.; // TODO: Avoid lowering directly from this top-level function: make this; // a query (canLowerAsBroadcast) and defer lowering to the type-based calls.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,Mask,Mask,18,// Modify the new Mask to take all zeros from the all-zero vector.; // Choose indices that are blend-friendly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Availability,Mask,Mask,94,// Canonicalize the shuffle with any horizontal ops inputs.; // NOTE: This may update Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Deployability,update,update,79,// Canonicalize the shuffle with any horizontal ops inputs.; // NOTE: This may update Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Integrability,rout,routine,61,"// For each vector width, delegate to a specialized lowering routine.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Performance,optimiz,optimized,64,// A vselect where all conditions and data are constants can be optimized into; // a single vector load by SelectionDAGLegalize::ExpandBUILD_VECTOR().,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Performance,load,load,99,// A vselect where all conditions and data are constants can be optimized into; // a single vector load by SelectionDAGLegalize::ExpandBUILD_VECTOR().,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,mask,43,"// If this VSELECT has a vector if i1 as a mask, it will be directly matched; // with patterns on the mask registers on AVX-512.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Availability,mask,mask,102,"// If this VSELECT has a vector if i1 as a mask, it will be directly matched; // with patterns on the mask registers on AVX-512.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Variab,Variable,3,// Variable blends are only legal from SSE4.1 onward.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Availability,mask,mask-based,126,"// If the VSELECT is on a 512-bit type, we have to convert a non-i1 condition; // into an i1 condition so that we can use the mask-based 512-bit blend; // instructions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,mask,mask,11,// Build a mask by testing the condition against zero.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Testability,test,testing,19,// Build a mask by testing the condition against zero.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,mask,38,// Now return a new VSELECT using the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Availability,mask,mask,30,// SEXT/TRUNC cases where the mask doesn't match the destination size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:97,Modifiability,extend,extend,97,"// If IdxVal is 0, it's cheaper to do a move instead of a pextrb, unless; // we're going to zero extend the register or fold the store.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,mask,25,"/// Extract one bit from mask vector, like v16i1 or v8i1.; /// AVX-512 feature.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,mask,38,"// variable index can't be handled in mask registers,; // extend vector to VR512/128",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,variab,variable,3,"// variable index can't be handled in mask registers,; // extend vector to VR512/128",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Modifiability,extend,extend,58,"// variable index can't be handled in mask registers,; // extend vector to VR512/128",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extending,3,// Extending v8i1/v16i1 to 512-bit get better performance on KNL; // than extending to 128/256bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Modifiability,extend,extending,74,// Extending v8i1/v16i1 to 512-bit get better performance on KNL; // than extending to 128/256bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Performance,perform,performance,46,// Extending v8i1/v16i1 to 512-bit get better performance on KNL; // than extending to 128/256bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to natively supported kshift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Performance,throughput,throughput,54,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:124,Performance,throughput,throughput,124,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:166,Performance,perform,performance,166,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:338,Performance,Throughput,Throughput,338,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:366,Performance,Throughput,Throughput,366,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:377,Performance,Bottleneck,Bottleneck,377,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:721,Performance,Throughput,Throughput,721,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:749,Performance,Throughput,Throughput,749,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:760,Performance,Bottleneck,Bottleneck,760,"// Its more profitable to go through memory (1 cycles throughput); // than using VMOVD + VPERMV/PSHUFB sequence (2/3 cycles throughput); // IACA tool was used to get performance estimation; // (https://software.intel.com/en-us/articles/intel-architecture-code-analyzer); //; // example : extractelement <16 x i8> %a, i32 %i; //; // Block Throughput: 3.00 Cycles; // Throughput Bottleneck: Port5; //; // | Num Of | Ports pressure in cycles | |; // | Uops | 0 - DV | 5 | 6 | 7 | |; // ---------------------------------------------; // | 1 | | 1.0 | | | CP | vmovd xmm1, edi; // | 1 | | 1.0 | | | CP | vpshufb xmm0, xmm0, xmm1; // | 2 | 1.0 | 1.0 | | | CP | vpextrb eax, xmm0, 0x0; // Total Num Of Uops: 4; //; //; // Block Throughput: 1.00 Cycles; // Throughput Bottleneck: PORT2_AGU, PORT3_AGU, Port4; //; // | | Ports pressure in cycles | |; // |Uops| 1 | 2 - D |3 - D | 4 | 5 | |; // ---------------------------------------------------------; // |2^ | | 0.5 | 0.5 |1.0| |CP| vmovaps xmmword ptr [rsp-0x18], xmm0; // |1 |0.5| | | |0.5| | lea rax, ptr [rsp-0x18]; // |1 | |0.5, 0.5|0.5, 0.5| | |CP| mov al, byte ptr [rdi+rax*1]; // Total Num Of Uops: 4",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:101,Availability,mask,mask,101,// Find IdxVal modulo ElemsPerChunk. Since ElemsPerChunk is a power of 2; // this can be done with a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Energy Efficiency,power,power,62,// Find IdxVal modulo ElemsPerChunk. Since ElemsPerChunk is a power of 2; // this can be done with a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:97,Modifiability,extend,extend,97,"// If IdxVal is 0, it's cheaper to do a move instead of a pextrw, unless; // we're going to zero extend the register or fold the store (SSE41 only).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,"/// Insert one bit to mask vector, like v16i1 or v8i1.; /// AVX-512 feature.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,Extend,Extend,23,"// Non constant index. Extend source and destination,; // insert element and then truncate the result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Variab,Variable,3,"// Variable insertion indices, usually we're better off spilling to stack,; // but AVX512 can use a variable compare+select by comparing against all; // possible vector indices, and FP insertion has less gpr->simd traffic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Modifiability,variab,variable,100,"// Variable insertion indices, usually we're better off spilling to stack,; // but AVX512 can use a variable compare+select by comparing against all; // possible vector indices, and FP insertion has less gpr->simd traffic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Energy Efficiency,efficient,efficiently,30,// See if we can do this more efficiently with a blend shuffle with a; // rematerializable vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Energy Efficiency,efficient,efficiently,62,"// With a 256-bit vector, we can insert into the zero element efficiently; // using a blend if we have AVX or AVX2 and the right data type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:96,Availability,mask,mask,96,// Insert the element into the desired chunk.; // Since NumEltsIn128 is a power of 2 we can use mask instead of modulo.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Energy Efficiency,power,power,74,// Insert the element into the desired chunk.; // Since NumEltsIn128 is a power of 2 we can use mask instead of modulo.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Modifiability,extend,extend,64,"// We can't directly insert an i8 or i16 into a vector, so zero extend; // it to i32 first.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:425,Availability,mask,mask,425,"// Bits [7:6] of the constant are the source select. This will always be; // zero here. The DAG Combiner may combine an extract_elt index into; // these bits. For example (insert (extract, 3), 2) could be matched by; // putting the '3' into bits [7:6] of X86ISD::INSERTPS.; // Bits [5:4] of the constant are the destination select. This is the; // value of the incoming immediate.; // Bits [3:0] of the constant are the zero mask. The DAG Combiner may; // combine either bitwise AND or insert of float 0.0 to set these bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:236,Performance,perform,performance,236,"// If this is an insertion of 32-bits into the low 32-bits of; // a vector, we prefer to generate a blend with immediate rather; // than an insertps. Blends are simpler operations in hardware and so; // will always have equal or better performance than insertps.; // But if optimizing for size and there's a load folding opportunity,; // generate insertps because blendps does not have a 32-bit memory; // operand form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:274,Performance,optimiz,optimizing,274,"// If this is an insertion of 32-bits into the low 32-bits of; // a vector, we prefer to generate a blend with immediate rather; // than an insertps. Blends are simpler operations in hardware and so; // will always have equal or better performance than insertps.; // But if optimizing for size and there's a load folding opportunity,; // generate insertps because blendps does not have a 32-bit memory; // operand form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:308,Performance,load,load,308,"// If this is an insertion of 32-bits into the low 32-bits of; // a vector, we prefer to generate a blend with immediate rather; // than an insertps. Blends are simpler operations in hardware and so; // will always have equal or better performance than insertps.; // But if optimizing for size and there's a load folding opportunity,; // generate insertps because blendps does not have a 32-bit memory; // operand form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:161,Usability,simpl,simpler,161,"// If this is an insertion of 32-bits into the low 32-bits of; // a vector, we prefer to generate a blend with immediate rather; // than an insertps. Blends are simpler operations in hardware and so; // will always have equal or better performance than insertps.; // But if optimizing for size and there's a load folding opportunity,; // generate insertps because blendps does not have a 32-bit memory; // operand form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Usability,simpl,simplifies,60,// It's always cheaper to replace a xor+movd with xorps and simplifies further; // combines.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Usability,simpl,simple,74,// Lower a node with an INSERT_SUBVECTOR opcode. This may result in a; // simple superregister reference or explicit instructions to insert; // the upper bits of a vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to natively supported kshift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Integrability,wrap,wrapper,27,// Returns the appropriate wrapper opcode for a global reference.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Integrability,wrap,wrapped,106,"// ConstantPool, JumpTable, GlobalAddress, and ExternalSymbol are lowered as; // their target counterpart wrapped in the X86ISD::Wrapper node. Suppose N is; // one of the above mentioned nodes. It has to be wrapped because otherwise; // Select(N) returns N. So the raw TargetGlobalAddress nodes, etc. can only; // be used to form addressing mode. These wrapped nodes will be selected; // into MOV32ri.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Integrability,Wrap,Wrapper,129,"// ConstantPool, JumpTable, GlobalAddress, and ExternalSymbol are lowered as; // their target counterpart wrapped in the X86ISD::Wrapper node. Suppose N is; // one of the above mentioned nodes. It has to be wrapped because otherwise; // Select(N) returns N. So the raw TargetGlobalAddress nodes, etc. can only; // be used to form addressing mode. These wrapped nodes will be selected; // into MOV32ri.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:207,Integrability,wrap,wrapped,207,"// ConstantPool, JumpTable, GlobalAddress, and ExternalSymbol are lowered as; // their target counterpart wrapped in the X86ISD::Wrapper node. Suppose N is; // one of the above mentioned nodes. It has to be wrapped because otherwise; // Select(N) returns N. So the raw TargetGlobalAddress nodes, etc. can only; // be used to form addressing mode. These wrapped nodes will be selected; // into MOV32ri.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:353,Integrability,wrap,wrapped,353,"// ConstantPool, JumpTable, GlobalAddress, and ExternalSymbol are lowered as; // their target counterpart wrapped in the X86ISD::Wrapper node. Suppose N is; // one of the above mentioned nodes. It has to be wrapped because otherwise; // Select(N) returns N. So the raw TargetGlobalAddress nodes, etc. can only; // be used to form addressing mode. These wrapped nodes will be selected; // into MOV32ri.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Integrability,wrap,wrapper,39,"// If this is a direct call, avoid the wrapper if we don't need to do any; // loads or adds. This allows SDAG ISel to match direct calls.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Performance,load,loads,78,"// If this is a direct call, avoid the wrapper if we don't need to do any; // loads or adds. This allows SDAG ISel to match direct calls.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Safety,avoid,avoid,29,"// If this is a direct call, avoid the wrapper if we don't need to do any; // loads or adds. This allows SDAG ISel to match direct calls.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Performance,load,load,30,"// For globals that require a load from a stub to get the address, emit the; // load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Performance,load,load,80,"// For globals that require a load from a stub to get the address, emit the; // load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Testability,stub,stub,42,"// For globals that require a load from a stub to get the address, emit the; // load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Availability,redundant,redundant,52,// Note: the CleanupLocalDynamicTLSPass will remove redundant computations; // of Base.; // Build x@dtpoff.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,redund,redundant,52,// Note: the CleanupLocalDynamicTLSPass will remove redundant computations; // of Base.; // Build x@dtpoff.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Security,access,accesses,12,"// Most TLS accesses are not RIP relative, even on x86-64. One exception is; // initialexec.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Modifiability,variab,variable,35,// The address of the thread local variable is the add of the thread; // pointer with the offset of the variable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:104,Modifiability,variab,variable,104,// The address of the thread local variable is the add of the thread; // pointer with the offset of the variable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Performance,Load,Load,118,"// Just use the implicit TLS architecture; // Need to generate something similar to:; // mov rdx, qword [gs:abs 58H]; Load pointer to ThreadLocalStorage; // ; from TEB; // mov ecx, dword [rel _tls_index]: Load index (from C runtime); // mov rcx, qword [rdx+rcx*8]; // mov eax, .tls$:tlsvar; // [rax+rcx] contains the address; // Windows 64bit: gs:0x58; // Windows 32bit: fs:__tls_array",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:205,Performance,Load,Load,205,"// Just use the implicit TLS architecture; // Need to generate something similar to:; // mov rdx, qword [gs:abs 58H]; Load pointer to ThreadLocalStorage; // ; from TEB; // mov ecx, dword [rel _tls_index]: Load index (from C runtime); // mov rcx, qword [rdx+rcx*8]; // mov eax, .tls$:tlsvar; // [rax+rcx] contains the address; // Windows 64bit: gs:0x58; // Windows 32bit: fs:__tls_array",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:116,Availability,avail,available,116,"// Get the Thread Pointer, which is %fs:__tls_array (32-bit) or; // %gs:0x58 (64-bit). On MinGW, __tls_array is not available, so directly; // use its literal value of 0x2C.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,variab,variable,23,// Load the _tls_index variable,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the _tls_index variable,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Modifiability,variab,variable,35,// The address of the thread local variable is the add of the thread; // pointer with the offset of the variable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:104,Modifiability,variab,variable,104,// The address of the thread local variable is the add of the thread; // pointer with the offset of the variable.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:135,Safety,avoid,avoid,135,"/// Given a scalar cast operation that is extracted from a vector, try to; /// vectorize the cast op followed by extraction. This will avoid an expensive; /// round-trip between XMM and GPR.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,enhance,enhanced,23,// TODO: This could be enhanced to handle smaller integer types by peeking; // through an extend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Modifiability,extend,extend,90,// TODO: This could be enhanced to handle smaller integer types by peeking; // through an extend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:127,Safety,avoid,avoid,127,"/// Given a scalar cast to FP with a cast to integer operand (almost an ftrunc),; /// try to vectorize the cast ops. This will avoid an expensive round-trip; /// between XMM and GPR.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:183,Performance,perform,performance,183,"// sint_to_fp (fp_to_sint X) --> extelt (sint_to_fp (fp_to_sint (s2v X))), 0; //; // We are not defining the high elements (for example, zero them) because; // that could nullify any performance advantage that we hoped to gain from; // this vector op hack. We do not expect any adverse effects (like denorm; // penalties) with cast ops.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,avoid,avoid,52,// Need to concat with zero vector for strict fp to avoid spurious; // exceptions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Modifiability,extend,extend,60,// Note: Since v2f64 is a legal type. We don't need to zero extend the; // source for strict FP.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Safety,avoid,avoiding,90,"// Bitcasting to f64 here allows us to do a single 64-bit store from; // an SSE register, avoiding the store forwarding penalty that would come; // with two 32-bit stores.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the 64-bit value into an XMM register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the 32-bit value into an XMM register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Performance,load,load,10,// Or the load with the bias.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,"// Zero extend to 2i64, OR with the floating point representation of 2^52.; // This gives us the floating point equivalent of 2^52 + the i32 integer; // since double has 52-bits of mantissa. Then subtract 2^52 in floating; // point leaving just our i32 integers in double format.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,avoid,avoid,52,// Need to concat with zero vector for strict fp to avoid spurious; // exceptions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Safety,abort,abort,80,"// If we convert to something else than the supported type, e.g., to v4f64,; // abort early.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:149,Safety,avoid,avoid,149,"// float4 fhi = (float4) hi - (0x1.0p39f + 0x1.0p23f);; // NOTE: By using fsub of a positive constant instead of fadd of a negative; // constant, we avoid reassociation in MachineCombiner when unsafe-fp-math is; // enabled. See PR24512.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:193,Safety,unsafe,unsafe-fp-math,193,"// float4 fhi = (float4) hi - (0x1.0p39f + 0x1.0p23f);; // NOTE: By using fsub of a positive constant instead of fadd of a negative; // constant, we avoid reassociation in MachineCombiner when unsafe-fp-math is; // enabled. See PR24512.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Safety,avoid,avoiding,90,"// Bitcasting to f64 here allows us to do a single 64-bit store from; // an SSE register, avoiding the store forwarding penalty that would come; // with two 32-bit stores.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:50,Energy Efficiency,power,power,50,"// For i64 source, we need to add the appropriate power of 2 if the input; // was negative. We must be careful to do the computation in x87 extended; // precision, not in SSE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Modifiability,extend,extended,140,"// For i64 source, we need to add the appropriate power of 2 if the input; // was negative. We must be careful to do the computation in x87 extended; // precision, not in SSE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,extend,extending,23,"// Load the value out, extending it from f32 to f80.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,"// Load the value out, extending it from f32 to f80.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend everything to 80 bits to force it to be done on x87.; // TODO: Are there any fast-math-flags to propagate here?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Integrability,rout,routine,58,// f16 must be promoted before using the lowering in this routine.; // fp128 does not use this lowering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Performance,load,load,49,// We lower FP->int64 into FISTP64 followed by a load from a temporary; // stack slot.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:496,Energy Efficiency,power,power,496,"//; // Conversion to unsigned i64 is implemented with a select,; // depending on whether the source value fits in the range; // of a signed i64. Let Thresh be the FP equivalent of; // 0x8000000000000000ULL.; //; // Adjust = (Value >= Thresh) ? 0x80000000 : 0;; // FltOfs = (Value >= Thresh) ? 0x80000000 : 0;; // FistSrc = (Value - FltOfs);; // Fist-to-mem64 FistSrc; // Add 0 or 0x800...0ULL to the 64-bit result, which is equivalent; // to XOR'ing the high 32 bits with Adjust.; //; // Being a power of 2, Thresh is exactly representable in all FP formats.; // For X87 we'd like to use the smallest FP type for this constant, but; // for DAG type consistency we have to match the FP operand type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Integrability,depend,depending,68,"//; // Conversion to unsigned i64 is implemented with a select,; // depending on whether the source value fits in the range; // of a signed i64. Let Thresh be the FP equivalent of; // 0x8000000000000000ULL.; //; // Adjust = (Value >= Thresh) ? 0x80000000 : 0;; // FltOfs = (Value >= Thresh) ? 0x80000000 : 0;; // FistSrc = (Value - FltOfs);; // Fist-to-mem64 FistSrc; // Add 0 or 0x800...0ULL to the 64-bit result, which is equivalent; // to XOR'ing the high 32 bits with Adjust.; //; // Being a power of 2, Thresh is exactly representable in all FP formats.; // For X87 we'd like to use the smallest FP type for this constant, but; // for DAG type consistency we have to match the FP operand type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,redundant,redundant,23,"// FIXME This causes a redundant load/store if the SSE-class value is already; // in memory, such as if it is on the callstack.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Performance,load,load,33,"// FIXME This causes a redundant load/store if the SSE-class value is already; // in memory, such as if it is on the callstack.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Safety,redund,redundant,23,"// FIXME This causes a redundant load/store if the SSE-class value is already; // in memory, such as if it is on the callstack.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,// Optimize vectors in AVX mode:; //; // v8i16 -> v8i32; // Use vpmovzwd for 4 lower elements v8i16 -> v4i32.; // Use vpunpckhwd for 4 upper elements v8i16 -> v4i32.; // Concat upper and lower parts.; //; // v4i32 -> v4i64; // Use vpmovzdq for 4 lower elements v4i32 -> v2i64.; // Use vpunpckhdq for 4 upper elements v4i32 -> v2i64.; // Concat upper and lower parts.; //,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:125,Performance,optimiz,optimize,125,"// Short-circuit if we can determine that each 128-bit half is the same value.; // Otherwise, this is difficult to match and optimize.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,mask,38,// Helper to split and extend a v16i1 mask to v16i8 or v16i16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,extend,extend,23,// Helper to split and extend a v16i1 mask to v16i8 or v16i16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Performance,load,load,105,"// For all vectors, but vXi8 we can just emit a sign_extend and a shift. This; // avoids a constant pool load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:82,Safety,avoid,avoids,82,"// For all vectors, but vXi8 we can just emit a sign_extend and a shift. This; // avoids a constant pool load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend VT if BWI is not supported.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Safety,avoid,avoided,22,"// If v16i32 is to be avoided, we'll need to split and concatenate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Modifiability,extend,extend,25,// Truncate if we had to extend above.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Availability,mask,mask,140,"// 256-bit PACK(ARG0, ARG1) leaves us with ((LO0,LO1),(HI0,HI1)),; // so we need to shuffle to get ((LO0,HI0),(LO1,HI1)).; // Scale shuffle mask to avoid bitcasts and help ComputeNumSignBits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:148,Safety,avoid,avoid,148,"// 256-bit PACK(ARG0, ARG1) leaves us with ((LO0,LO1),(HI0,HI1)),; // so we need to shuffle to get ((LO0,HI0),(LO1,HI1)).; // Scale shuffle mask to avoid bitcasts and help ComputeNumSignBits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid CONCAT_VECTORS on sub-128bit nodes as these can fail after; // type legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,"/// Truncate using inreg zero extension (AND mask) and X86ISD::PACKUS.; /// e.g. trunc <8 x i32> X to <8 x i16> -->; /// MaskX = X & 0xffff (clear high bits to prevent saturation); /// packus (extract_subv MaskX, 0), (extract_subv MaskX, 1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,Availability,Mask,MaskX,121,"/// Truncate using inreg zero extension (AND mask) and X86ISD::PACKUS.; /// e.g. trunc <8 x i32> X to <8 x i16> -->; /// MaskX = X & 0xffff (clear high bits to prevent saturation); /// packus (extract_subv MaskX, 0), (extract_subv MaskX, 1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:206,Availability,Mask,MaskX,206,"/// Truncate using inreg zero extension (AND mask) and X86ISD::PACKUS.; /// e.g. trunc <8 x i32> X to <8 x i16> -->; /// MaskX = X & 0xffff (clear high bits to prevent saturation); /// packus (extract_subv MaskX, 0), (extract_subv MaskX, 1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:231,Availability,Mask,MaskX,231,"/// Truncate using inreg zero extension (AND mask) and X86ISD::PACKUS.; /// e.g. trunc <8 x i32> X to <8 x i16> -->; /// MaskX = X & 0xffff (clear high bits to prevent saturation); /// packus (extract_subv MaskX, 0), (extract_subv MaskX, 1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:141,Usability,clear,clear,141,"/// Truncate using inreg zero extension (AND mask) and X86ISD::PACKUS.; /// e.g. trunc <8 x i32> X to <8 x i16> -->; /// MaskX = X & 0xffff (clear high bits to prevent saturation); /// packus (extract_subv MaskX, 0), (extract_subv MaskX, 1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:145,Availability,Mask,Masks,145,"// Truncate with PACKUS if we are truncating a vector with leading zero; // bits that extend all the way to the packed/truncated value.; // e.g. Masks, zext_in_reg, etc.; // Pre-SSE41 we can only use PACKUSWB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Modifiability,extend,extend,86,"// Truncate with PACKUS if we are truncating a vector with leading zero; // bits that extend all the way to the packed/truncated value.; // e.g. Masks, zext_in_reg, etc.; // Pre-SSE41 we can only use PACKUSWB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Modifiability,extend,extend,78,"// Truncate with PACKSS if we are truncating a vector with sign-bits; // that extend all the way to the packed/truncated value.; // e.g. Comparison result, sext_in_reg, etc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:201,Usability,simpl,simplifications,201,// Don't use PACKSS for vXi64 -> vXi32 truncations unless we're dealing with; // a sign splat (or AVX512 VPSRAQ support). ComputeNumSignBits struggles to; // see through BITCASTs later on and combines/simplifications can't then use; // it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:151,Usability,Simpl,SimplifyDemandedBits,151,// If we have a srl that only generates signbits that we will discard in; // the truncation then we can use PACKSS by converting the srl to a sra.; // SimplifyDemandedBits often relaxes sra to srl so we need to reverse it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Modifiability,extend,extended,49,/// This function lowers a vector truncation of 'extended sign-bits' or; /// 'extended zero-bits' values.; /// vXi16/vXi32/vXi64 to vXi8/vXi16/vXi32 into X86ISD::PACKSS/PACKUS operations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Modifiability,extend,extended,78,/// This function lowers a vector truncation of 'extended sign-bits' or; /// 'extended zero-bits' values.; /// vXi16/vXi32/vXi64 to vXi8/vXi16/vXi32 into X86ISD::PACKSS/PACKUS operations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Testability,TEST,TESTD,42,// Shift LSB to MSB and use VPMOVB/W2M or TESTD/Q.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Modifiability,extend,extended,16,"// Use TESTD/Q, extended vector to packed dword/qword.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Testability,TEST,TESTD,7,"// Use TESTD/Q, extended vector to packed dword/qword.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,Modifiability,extend,extend,121,"// We need to change to a wider element type that we have support for.; // For 8 element vectors this is easy, we either extend to v8i32 or v8i64.; // For 16 element vectors we extend to v16i32 unless we are explicitly; // trying to avoid 512-bit vectors. If we are avoiding 512-bit vectors; // we need to split into two 8 element vectors which we can extend to v8i32,; // truncate and concat the results. There's an additional complication if; // the original type is v16i8. In that case we can't split the v16i8; // directly, so we need to shuffle high elements to low and use; // sign_extend_vector_inreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:177,Modifiability,extend,extend,177,"// We need to change to a wider element type that we have support for.; // For 8 element vectors this is easy, we either extend to v8i32 or v8i64.; // For 16 element vectors we extend to v16i32 unless we are explicitly; // trying to avoid 512-bit vectors. If we are avoiding 512-bit vectors; // we need to split into two 8 element vectors which we can extend to v8i32,; // truncate and concat the results. There's an additional complication if; // the original type is v16i8. In that case we can't split the v16i8; // directly, so we need to shuffle high elements to low and use; // sign_extend_vector_inreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:352,Modifiability,extend,extend,352,"// We need to change to a wider element type that we have support for.; // For 8 element vectors this is easy, we either extend to v8i32 or v8i64.; // For 16 element vectors we extend to v16i32 unless we are explicitly; // trying to avoid 512-bit vectors. If we are avoiding 512-bit vectors; // we need to split into two 8 element vectors which we can extend to v8i32,; // truncate and concat the results. There's an additional complication if; // the original type is v16i8. In that case we can't split the v16i8; // directly, so we need to shuffle high elements to low and use; // sign_extend_vector_inreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:233,Safety,avoid,avoid,233,"// We need to change to a wider element type that we have support for.; // For 8 element vectors this is easy, we either extend to v8i32 or v8i64.; // For 16 element vectors we extend to v16i32 unless we are explicitly; // trying to avoid 512-bit vectors. If we are avoiding 512-bit vectors; // we need to split into two 8 element vectors which we can extend to v8i32,; // truncate and concat the results. There's an additional complication if; // the original type is v16i8. In that case we can't split the v16i8; // directly, so we need to shuffle high elements to low and use; // sign_extend_vector_inreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:266,Safety,avoid,avoiding,266,"// We need to change to a wider element type that we have support for.; // For 8 element vectors this is easy, we either extend to v8i32 or v8i64.; // For 16 element vectors we extend to v16i32 unless we are explicitly; // trying to avoid 512-bit vectors. If we are avoiding 512-bit vectors; // we need to split into two 8 element vectors which we can extend to v8i32,; // truncate and concat the results. There's an additional complication if; // the original type is v16i8. In that case we can't split the v16i8; // directly, so we need to shuffle high elements to low and use; // sign_extend_vector_inreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:159,Safety,avoid,avoid,159,// word to byte only under BWI. Otherwise we have to promoted to v16i32; // and then truncate that. But we should only do that if we haven't been; // asked to avoid 512-bit vectors. The actual promotion to v16i32 will be; // handled by isel patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,mask,14,// The PSHUFB mask:,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,Performance,optimiz,optimized,121,"// We can leverage the specific way the ""cvttps2dq/cvttpd2dq"" instruction; // behaves on out of range inputs to generate optimized conversions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:349,Availability,mask,masking,349,"// The ""CVTTP2SI"" instruction conveniently sets the sign bit if; // and only if the value was out of range. So we can use that; // as our indicator that we rather use ""Big"" instead of ""Small"".; //; // Use ""Small"" if ""IsOverflown"" has all bits cleared; // and ""0x80000000 | Big"" if all bits in ""IsOverflown"" are set.; // AVX1 can't use the signsplat masking for 256-bit vectors - we have to; // use the slightly slower blendv select instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:243,Usability,clear,cleared,243,"// The ""CVTTP2SI"" instruction conveniently sets the sign bit if; // and only if the value was out of range. So we can use that; // as our indicator that we rather use ""Big"" instead of ""Small"".; //; // Use ""Small"" if ""IsOverflown"" has all bits cleared; // and ""0x80000000 | Big"" if all bits in ""IsOverflown"" are set.; // AVX1 can't use the signsplat masking for 256-bit vectors - we have to; // use the slightly slower blendv select instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,avoid,avoid,52,// Need to concat with zero vector for strict fp to avoid spurious; // exceptions.; // TODO: Should we just do this for non-strict as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,avoid,avoid,52,// Need to concat with zero vector for strict fp to avoid spurious; // exceptions.; // TODO: Should we just do this for non-strict as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Safety,avoid,avoid,52,// Need to concat with zero vector for strict fp to avoid spurious; // exceptions.; // TODO: Should we just do this for non-strict as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Performance,optimiz,optimized,12,// Generate optimized instructions for pre AVX512 unsigned conversions from; // vXf32 to vXi32.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,Performance,optimiz,optimized,121,"// We can leverage the specific way the ""cvttss2si/cvttsd2si"" instruction; // behaves on out of range inputs to generate optimized conversions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:243,Usability,clear,cleared,243,"// The ""CVTTS2SI"" instruction conveniently sets the sign bit if; // and only if the value was out of range. So we can use that; // as our indicator that we rather use ""Big"" instead of ""Small"".; //; // Use ""Small"" if ""IsOverflown"" has all bits cleared; // and ""0x80000000 | Big"" if all bits in ""IsOverflown"" are set.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Integrability,rout,routine,58,// f16 must be promoted before using the lowering in this routine.; // fp128 does not use this lowering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:145,Availability,avail,available,145,"// Let f16->f80 get lowered to a libcall, except for darwin, where we should; // lower it to an fp_extend via f32 (as only f16<>f32 libcalls are available)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Integrability,Depend,Depending,4,"/// Depending on uarch and/or optimizing for size, we might prefer to use a; /// vector operation in place of the typical scalar operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Performance,optimiz,optimizing,30,"/// Depending on uarch and/or optimizing for size, we might prefer to use a; /// vector operation in place of the typical scalar operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Integrability,Depend,Depending,4,"/// Depending on uarch and/or optimizing for size, we might prefer to use a; /// vector operation in place of the typical scalar operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Performance,optimiz,optimizing,30,"/// Depending on uarch and/or optimizing for size, we might prefer to use a; /// vector operation in place of the typical scalar operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Availability,mask,mask,55,/// The only differences between FABS and FNEG are the mask and the logic op.; /// FNEG also has a folding opportunity for FNEG(FABS(x)).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Testability,log,logic,68,/// The only differences between FABS and FNEG are the mask and the logic op.; /// FNEG also has a folding opportunity for FNEG(FABS(x)).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Availability,mask,mask,129,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:356,Availability,mask,mask,356,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:392,Availability,mask,mask,392,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Performance,Optimiz,OptimizeForSize,34,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:380,Performance,load,load,380,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:222,Testability,log,logical,222,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:301,Testability,log,logic,301,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:410,Testability,log,logic,410,"// FIXME: Use function attribute ""OptimizeForSize"" and/or CodeGenOptLevel to; // decide if we should generate a 16-byte constant mask when we only need 4 or; // 8 bytes for the scalar case.; // There are no scalar bitwise logical SSE/AVX instructions, so we; // generate a 16-byte vector constant and logic op even for the scalar case.; // Using a 16-byte mask allows folding the load of the mask with; // the logic op, so it can save (~4 bytes) on code size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,mask,13,"// For FABS, mask is 0x7f...; for FNEG, mask is 0x80...",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Availability,mask,mask,40,"// For FABS, mask is 0x7f...; for FNEG, mask is 0x80...",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,extend,extend,23,"// For the scalar case extend to a 128-bit vector, perform the logic op,; // and extract the scalar result back out.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Performance,perform,perform,51,"// For the scalar case extend to a 128-bit vector, perform the logic op,; // and extract the scalar result back out.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Testability,log,logic,63,"// For the scalar case extend to a 128-bit vector, perform the logic op,; // and extract the scalar result back out.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Modifiability,extend,extend,35,"// If the sign operand is smaller, extend it first.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Perform,Perform,3,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:239,Performance,load,load,239,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:304,Performance,Optimiz,OptimizeForSize,304,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:186,Safety,avoid,avoid,186,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Testability,log,logic,22,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Testability,log,logic,93,"// Perform all scalar logic operations as 16-byte vectors because there are no; // scalar FP logic instructions in SSE.; // TODO: This isn't necessary. If we used scalar types, we might avoid some; // unnecessary splats, but we might miss load folding opportunities. Should; // this decision be based on OptimizeForSize?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Availability,mask,mask,7,// The mask constants are automatically splatted for vector types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,clear,clear,10,"// First, clear all bits but the sign bit from the second operand (sign).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:116,Testability,log,logic,116,"// Next, clear the sign bit from the first operand (magnitude).; // TODO: If we had general constant folding for FP logic ops, this check; // wouldn't be necessary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Usability,clear,clear,9,"// Next, clear the sign bit from the first operand (magnitude).; // TODO: If we had general constant folding for FP logic ops, this check; // wouldn't be necessary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Modifiability,extend,extend,196,"// If Src is i8, promote it to i32 with any_extend. There is no i8 BT; // instruction. Since the shift amount is in-range-or-undefined, we know; // that doing a bittest on the i32 value is ok. We extend to i32 because; // the encoding for the i16 version is larger than the i32 version.; // Also promote i16 to i32 for performance / code size reason.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:319,Performance,perform,performance,319,"// If Src is i8, promote it to i32 with any_extend. There is no i8 BT; // instruction. Since the shift amount is in-range-or-undefined, we know; // that doing a bittest on the i32 value is ok. We extend to i32 because; // the encoding for the i16 version is larger than the i32 version.; // Also promote i16 to i32 for performance / code size reason.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,extend,extend,34,"// If the operand types disagree, extend the shift amount to match. Since; // BT ignores high bits (like shifts) we can use anyextend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,"// Peek through a mask/modulo operation.; // TODO: DAGCombine fails to do this as it just checks isTruncateFree, but; // we probably need a better IsDesirableToPromoteOp to handle this as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:148,Testability,log,logically-combined,148,// Ignore a comparison with zero because that gets special treatment in; // EmitTest(). But make an exception for the special case of a pair of; // logically-combined vector-sized operands compared to zero. This pattern may; // be generated by the memcmp expansion pass with oversized integer compares; // (see PR33325).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Performance,perform,perform,9,// Don't perform this combine if constructing the vector will be expensive.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:170,Availability,mask,mask,170,// Use XOR (plus OR) and PTEST after SSE4.1 for 128/256-bit operands.; // Use PCMPNEQ (plus OR) and KORTEST for 512-bit operands.; // Otherwise use PCMPEQ (plus AND) and mask testing.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:175,Testability,test,testing,175,// Use XOR (plus OR) and PTEST after SSE4.1 for 128/256-bit operands.; // Use PCMPNEQ (plus OR) and KORTEST for 512-bit operands.; // Otherwise use PCMPEQ (plus AND) and mask testing.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:166,Performance,load,load,166,"// PTEST and MOVMSK are slow on Knights Landing and Knights Mill and widened; // vector registers are essentially free. (Technically, widening registers; // prevents load folding, but the tradeoff is worth it.)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Testability,test,test,78,// Recognize a special case where a vector is casted into wide integer to; // test all 0s.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Availability,mask,masks,30,// Collect the source partial masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Availability,mask,masked,20,"// Without PTEST, a masked v2i64 or-reduction is not faster than; // scalarization.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Availability,down,down,9,// Split down to 128/256/512-bit vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:114,Safety,safe,safely,114,"// If the input vector has vector elements wider than the target test size,; // then cast to <X x i64> so it will safely split.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Testability,test,test,65,"// If the input vector has vector elements wider than the target test size,; // then cast to <X x i64> so it will safely split.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,MASK,MASK,19,"// If ICMP(AND(LHS,MASK),MASK) - reduce using AND splits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,MASK,MASK,25,"// If ICMP(AND(LHS,MASK),MASK) - reduce using AND splits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Energy Efficiency,reduce,reduce,33,"// If ICMP(AND(LHS,MASK),MASK) - reduce using AND splits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,masking,23,"// Check whether we're masking/truncating an OR-reduction result, in which; // case track the masked bits.; // TODO: Add CmpAllOnes support.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Availability,mask,masked,94,"// Check whether we're masking/truncating an OR-reduction result, in which; // case track the masked bits.; // TODO: Add CmpAllOnes support.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:151,Availability,mask,mask,151,"// Match icmp(bitcast(vXi1 trunc(Y)),0) reduction patterns.; // Match icmp(bitcast(vXi1 trunc(Y)),-1) reduction patterns.; // Peek through truncation, mask the LSB and compare against zero/LSB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:181,Testability,test,test,181,"// Transform to an x86-specific ALU node with flags if there is a chance of; // using an RMW op or only the flags are used. Otherwise, leave; // the node alone and emit a 'cmp' or 'test' instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Testability,test,test,41,"/// Emit nodes that will be selected as ""test Op0,Op0"", or something; /// equivalent.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Testability,TEST,TEST,87,"// See if we can use the EFLAGS value from the operand instead of; // doing a separate TEST. TEST always sets OF and CF to 0, so unless; // we prove that the arithmetic won't overflow, we can't use OF or CF.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Testability,TEST,TEST,93,"// See if we can use the EFLAGS value from the operand instead of; // doing a separate TEST. TEST always sets OF and CF to 0, so unless; // we prove that the arithmetic won't overflow, we can't use OF or CF.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Testability,TEST,TEST,35,"// Emit a CMP with 0, which is the TEST pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:127,Modifiability,variab,variable,127,"// NOTICE: In the code below we use ArithOp to hold the arithmetic operation; // which may be the result of a CAST. We use the variable 'Op', which is the; // non-casted variable when we check for possible users.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:170,Modifiability,variab,variable,170,"// NOTICE: In the code below we use ArithOp to hold the arithmetic operation; // which may be the result of a CAST. We use the variable 'Op', which is the; // non-casted variable when we check for possible users.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Testability,TEST,TEST,89,"// If the primary 'and' result isn't used, don't bother using X86ISD::AND,; // because a TEST instruction will be better.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Testability,TEST,TEST,35,"// Emit a CMP with 0, which is the TEST pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:117,Safety,avoid,avoided,117,// Only promote the compare up to I32 if it is a 16 bit operation; // with an immediate. 16 bit immediates are to be avoided.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:420,Performance,throughput,throughput,420,"// SSE1 has rsqrtss and rsqrtps. AVX adds a 256-bit variant for rsqrtps.; // It is likely not profitable to do this for f64 because a double-precision; // rsqrt estimate with refinement on x86 prior to FMA requires at least 16; // instructions: convert to single, rsqrtss, convert back to double, refine; // (3 steps = at least 13 insts). If an 'rsqrtsd' variant was added to the ISA; // along with FMA, this could be a throughput win.; // TODO: SQRT requires SSE2 to prevent the introduction of an illegal v4i32; // after legalize types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:397,Performance,throughput,throughput,397,"// SSE1 has rcpss and rcpps. AVX adds a 256-bit variant for rcpps.; // It is likely not profitable to do this for f64 because a double-precision; // reciprocal estimate with refinement on x86 prior to FMA requires; // 15 instructions: convert to single, rcpss, convert back to double, refine; // (3 steps = 12 insts). If an 'rcpsd' variant was added to the ISA; // along with FMA, this could be a throughput win.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,perform,perform,8,// Only perform this transform if CMOV is supported otherwise the select; // below will become a branch.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Performance,optimiz,optimizing,80,// Use BT if the immediate can't be encoded in a TEST instruction or we; // are optimizing for size and the immedaite won't fit in a byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Testability,TEST,TEST,49,// Use BT if the immediate can't be encoded in a TEST instruction or we; // are optimizing for size and the immedaite won't fit in a byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Performance,perform,performed,36,// Check if pre-AVX condcode can be performed by a single FCMP op.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:72,Availability,mask,mask,72,/// Turns an ISD::CondCode into a value suitable for SSE floating-point mask; /// CMPs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:215,Usability,simpl,simple,215,"/// Given a buildvector constant, return a new vector constant with each element; /// incremented or decremented. If incrementing or decrementing would result in; /// unsigned overflow or underflow or this is not a simple vector constant,; /// return an empty value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid overflow/underflow.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Availability,mask,masked,99,"// If we have a strict compare with a vXi1 result and the input is 128/256; // bits we can't use a masked compare unless we have VLX. If we use a wider; // compare like we do for non-strict, we might trigger spurious exceptions; // from the upper elements. Instead emit a AVX compare and convert to mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:299,Availability,mask,mask,299,"// If we have a strict compare with a vXi1 result and the input is 128/256; // bits we can't use a masked compare unless we have VLX. If we use a wider; // compare like we do for non-strict, we might trigger spurious exceptions; // from the upper elements. Instead emit a AVX compare and convert to mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Availability,mask,masks,113,"// TODO: We could use following steps to handle a quiet compare with; // signaling encodings.; // 1. Get ordered masks from a quiet ISD::SETO; // 2. Use the masks to mask potential unordered elements in operand A, B; // 3. Get the compare results of masked A, B; // 4. Calculating final result using the mask and result from 3; // But currently, we just fall back to scalar operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:157,Availability,mask,masks,157,"// TODO: We could use following steps to handle a quiet compare with; // signaling encodings.; // 1. Get ordered masks from a quiet ISD::SETO; // 2. Use the masks to mask potential unordered elements in operand A, B; // 3. Get the compare results of masked A, B; // 4. Calculating final result using the mask and result from 3; // But currently, we just fall back to scalar operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:166,Availability,mask,mask,166,"// TODO: We could use following steps to handle a quiet compare with; // signaling encodings.; // 1. Get ordered masks from a quiet ISD::SETO; // 2. Use the masks to mask potential unordered elements in operand A, B; // 3. Get the compare results of masked A, B; // 4. Calculating final result using the mask and result from 3; // But currently, we just fall back to scalar operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:250,Availability,mask,masked,250,"// TODO: We could use following steps to handle a quiet compare with; // signaling encodings.; // 1. Get ordered masks from a quiet ISD::SETO; // 2. Use the masks to mask potential unordered elements in operand A, B; // 3. Get the compare results of masked A, B; // 4. Calculating final result using the mask and result from 3; // But currently, we just fall back to scalar operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:304,Availability,mask,mask,304,"// TODO: We could use following steps to handle a quiet compare with; // signaling encodings.; // 1. Get ordered masks from a quiet ISD::SETO; // 2. Use the masks to mask potential unordered elements in operand A, B; // 3. Get the compare results of masked A, B; // 4. Calculating final result using the mask and result from 3; // But currently, we just fall back to scalar operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Deployability,update,update,40,"// LT_OS; // FIXME: It seems we need to update the flags of all new strict nodes.; // Otherwise, mayRaiseFPException in MI will return false due to; // NoFPExcept = false by default. However, I didn't find it in other; // patches.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:222,Deployability,patch,patches,222,"// LT_OS; // FIXME: It seems we need to update the flags of all new strict nodes.; // Otherwise, mayRaiseFPException in MI will return false due to; // NoFPExcept = false by default. However, I didn't find it in other; // patches.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Testability,log,logic,106,"// In the two cases not handled by SSE compare predicates (SETUEQ/SETONE),; // emit two comparisons and a logic op to tie them together.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:75,Availability,mask,mask,75,// We emitted a compare with an XMM/YMM result. Finish converting to a; // mask register using a vptestm.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:132,Performance,optimiz,optimized,132,"// If this is SSE/AVX CMPP, bitcast the result back to integer to match; // the result type of SETCC. The bitcast is expected to be optimized; // away during combining/isel.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,"// In AVX-512 architecture setcc returns mask with i1 elements,; // But there is no compare instruction for i8 and i16 elements in KNL.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Energy Efficiency,power,power-of-,42,"// (X & Y) != 0 --> (X & Y) == Y iff Y is power-of-2.; // Revert part of the simplifySetCCWithAnd combine, to avoid an invert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:110,Safety,avoid,avoid,110,"// (X & Y) != 0 --> (X & Y) == Y iff Y is power-of-2.; // Revert part of the simplifySetCCWithAnd combine, to avoid an invert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Usability,simpl,simplifySetCCWithAnd,77,"// (X & Y) != 0 --> (X & Y) == Y iff Y is power-of-2.; // Revert part of the simplifySetCCWithAnd combine, to avoid an invert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Energy Efficiency,power,power-of-,60,"// ICMP_EQ(AND(X,C),C) -> SRA(SHL(X,LOG2(C)),BW-1) iff C is power-of-2.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Safety,avoid,avoid,67,"// If we have a limit constant, try to form PCMPGT (signed cmp) to avoid; // not-of-PCMPEQ:; // X != INT_MIN --> X >s INT_MIN; // X != INT_MAX --> X <s INT_MAX --> INT_MAX >s X; // +X != 0 --> +X >s 0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:185,Usability,simpl,simplifications,185,"// If both operands are known non-negative, then an unsigned compare is the; // same as a signed compare and there's no need to flip signbits.; // TODO: We could check for more general simplifications here since we're; // computing known bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Safety,avoid,avoid,89,"// If we have a constant operand, increment/decrement it and change the; // condition to avoid an invert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Performance,perform,perform,49,"// If the logical-not of the result is required, perform that now.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Testability,log,logical-not,10,"// If the logical-not of the result is required, perform that now.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,avail,available,43,"// Check that the operation in question is available (most are plain SSE2,; // but PCMPGTQ and PCMPEQQ have different requirements).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Testability,test,test,29,// Special case for sign bit test. We can use a v4i32 PCMPGT and shuffle; // the odd elements over the even elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Performance,perform,performing,105,"// Since SSE has no unsigned integer comparisons, we need to flip the sign; // bits of the inputs before performing those operations. The lower; // compare is always unsigned.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,masks,10,// Create masks for only the low parts/high parts of the 64 bit integers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Availability,avail,available,40,// If pcmpeqq is missing but pcmpeqd is available synthesize pcmpeqq with; // pcmpeqd + pshufd + pand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Performance,perform,performing,105,"// Since SSE has no unsigned integer comparisons, we need to flip the sign; // bits of the inputs before performing those operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Performance,perform,perform,49,"// If the logical-not of the result is required, perform that now.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Testability,log,logical-not,10,"// If the logical-not of the result is required, perform that now.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize to BT if possible.; // Lower (X & (1 << N)) == 0 to BT(X, N).; // Lower ((X >>u N) & 1) != 0 to BT(X, N).; // Lower ((X >>s N) & 1) != 0 to BT(X, N).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Usability,simpl,simplify,54,"// Look for X == 0, X == 1, X != 0, or X != 1. We can simplify some forms; // of these.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:505,Availability,down,down,505,"// Attempt to canonicalize SGT/UGT -> SGE/UGE compares with constant which; // reduces the number of EFLAGs bit reads (the GE conditions don't read ZF),; // this may translate to less uops depending on uarch implementation. The; // equivalent for SLE/ULE -> SLT/ULT isn't likely to happen as we already; // canonicalize to that CondCode.; // NOTE: Only do this if incrementing the constant doesn't increase the bit; // encoding size - so it must either already be a i8 or i32 immediate, or it; // shrinks down to that. We don't do this for any i64's to avoid additional; // constant materializations.; // TODO: Can we move this to TranslateX86CC to handle jumps/branches too?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Energy Efficiency,reduce,reduces,79,"// Attempt to canonicalize SGT/UGT -> SGE/UGE compares with constant which; // reduces the number of EFLAGs bit reads (the GE conditions don't read ZF),; // this may translate to less uops depending on uarch implementation. The; // equivalent for SLE/ULE -> SLT/ULT isn't likely to happen as we already; // canonicalize to that CondCode.; // NOTE: Only do this if incrementing the constant doesn't increase the bit; // encoding size - so it must either already be a i8 or i32 immediate, or it; // shrinks down to that. We don't do this for any i64's to avoid additional; // constant materializations.; // TODO: Can we move this to TranslateX86CC to handle jumps/branches too?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:189,Integrability,depend,depending,189,"// Attempt to canonicalize SGT/UGT -> SGE/UGE compares with constant which; // reduces the number of EFLAGs bit reads (the GE conditions don't read ZF),; // this may translate to less uops depending on uarch implementation. The; // equivalent for SLE/ULE -> SLT/ULT isn't likely to happen as we already; // canonicalize to that CondCode.; // NOTE: Only do this if incrementing the constant doesn't increase the bit; // encoding size - so it must either already be a i8 or i32 immediate, or it; // shrinks down to that. We don't do this for any i64's to avoid additional; // constant materializations.; // TODO: Can we move this to TranslateX86CC to handle jumps/branches too?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:553,Safety,avoid,avoid,553,"// Attempt to canonicalize SGT/UGT -> SGE/UGE compares with constant which; // reduces the number of EFLAGs bit reads (the GE conditions don't read ZF),; // this may translate to less uops depending on uarch implementation. The; // equivalent for SLE/ULE -> SLT/ULT isn't likely to happen as we already; // canonicalize to that CondCode.; // NOTE: Only do this if incrementing the constant doesn't increase the bit; // encoding size - so it must either already be a i8 or i32 immediate, or it; // shrinks down to that. We don't do this for any i64's to avoid additional; // constant materializations.; // TODO: Can we move this to TranslateX86CC to handle jumps/branches too?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Testability,log,logical,35,/// Return true if opcode is a X86 logical comparison.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Availability,avail,available,87,// Lower FP selects into a CMP/AND/ANDN/OR sequence when the necessary SSE ops; // are available or VBLENDV if AVX is available.; // Otherwise FP cmovs get lowered into a less efficient branch sequence later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Availability,avail,available,118,// Lower FP selects into a CMP/AND/ANDN/OR sequence when the necessary SSE ops; // are available or VBLENDV if AVX is available.; // Otherwise FP cmovs get lowered into a less efficient branch sequence later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:176,Energy Efficiency,efficient,efficient,176,// Lower FP selects into a CMP/AND/ANDN/OR sequence when the necessary SSE ops; // are available or VBLENDV if AVX is available.; // Otherwise FP cmovs get lowered into a less efficient branch sequence later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Modifiability,variab,variable,32,"// If we have AVX, we can use a variable vector select (VBLENDV) instead; // of 3 logic instructions for size savings and potentially speed.; // Unfortunately, there is no scalar form of VBLENDV.; // If either operand is a +0.0 constant, don't try this. We can expect to; // optimize away at least one of the logic instructions later in that; // case, so that sequence would be faster than a variable blend.; // BLENDV was introduced with SSE 4.1, but the 2 register form implicitly; // uses XMM0 as the selection register. That may need just as many; // instructions as the AND/ANDN/OR sequence due to register moves, so; // don't bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:392,Modifiability,variab,variable,392,"// If we have AVX, we can use a variable vector select (VBLENDV) instead; // of 3 logic instructions for size savings and potentially speed.; // Unfortunately, there is no scalar form of VBLENDV.; // If either operand is a +0.0 constant, don't try this. We can expect to; // optimize away at least one of the logic instructions later in that; // case, so that sequence would be faster than a variable blend.; // BLENDV was introduced with SSE 4.1, but the 2 register form implicitly; // uses XMM0 as the selection register. That may need just as many; // instructions as the AND/ANDN/OR sequence due to register moves, so; // don't bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:275,Performance,optimiz,optimize,275,"// If we have AVX, we can use a variable vector select (VBLENDV) instead; // of 3 logic instructions for size savings and potentially speed.; // Unfortunately, there is no scalar form of VBLENDV.; // If either operand is a +0.0 constant, don't try this. We can expect to; // optimize away at least one of the logic instructions later in that; // case, so that sequence would be faster than a variable blend.; // BLENDV was introduced with SSE 4.1, but the 2 register form implicitly; // uses XMM0 as the selection register. That may need just as many; // instructions as the AND/ANDN/OR sequence due to register moves, so; // don't bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:82,Testability,log,logic,82,"// If we have AVX, we can use a variable vector select (VBLENDV) instead; // of 3 logic instructions for size savings and potentially speed.; // Unfortunately, there is no scalar form of VBLENDV.; // If either operand is a +0.0 constant, don't try this. We can expect to; // optimize away at least one of the logic instructions later in that; // case, so that sequence would be faster than a variable blend.; // BLENDV was introduced with SSE 4.1, but the 2 register form implicitly; // uses XMM0 as the selection register. That may need just as many; // instructions as the AND/ANDN/OR sequence due to register moves, so; // don't bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:309,Testability,log,logic,309,"// If we have AVX, we can use a variable vector select (VBLENDV) instead; // of 3 logic instructions for size savings and potentially speed.; // Unfortunately, there is no scalar form of VBLENDV.; // If either operand is a +0.0 constant, don't try this. We can expect to; // optimize away at least one of the logic instructions later in that; // case, so that sequence would be faster than a variable blend.; // BLENDV was introduced with SSE 4.1, but the 2 register form implicitly; // uses XMM0 as the selection register. That may need just as many; // instructions as the AND/ANDN/OR sequence due to register moves, so; // don't bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Performance,optimiz,optimized,102,"// Convert to vectors, do a VSELECT, and convert back to scalar.; // All of the conversions should be optimized away.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:59,Availability,mask,masked,59,// AVX512 fallback is to lower selects of scalar floats to masked moves.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Deployability,update,updated,24,"// If the condition was updated, it's possible that the operands of the; // select were also updated (for example, EmitTest has a RAUW). Refresh; // the local references to the select operands in case they got stale.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Deployability,update,updated,93,"// If the condition was updated, it's possible that the operands of the; // select were also updated (for example, EmitTest has a RAUW). Refresh; // the local references to the select operands in case they got stale.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:207,Performance,optimiz,optimizeCompareInst,207,"// Special handling for __builtin_ffs(X) - 1 pattern which looks like; // (select (seteq X, 0), -1, (cttz_zero_undef X)). Disable the special; // handle to keep the CMP with 0. This should be removed by; // optimizeCompareInst by using the flags from the BSR/TZCNT used for the; // cttz_zero_undef.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Availability,mask,mask,122,"// 'X - 1' sets the carry flag if X == 0.; // '0 - X' sets the carry flag if X != 0.; // Convert the carry flag to a -1/0 mask with sbb:; // select (X != 0), -1, Y --> 0 - X; or (sbb), Y; // select (X == 0), Y, -1 --> 0 - X; or (sbb), Y; // select (X != 0), Y, -1 --> X - 1; or (sbb), Y; // select (X == 0), -1, Y --> X - 1; or (sbb), Y",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,mask,mask,11,// we need mask of all zeros or ones with same size of the other; // operands.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,// Mask & z,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:171,Availability,mask,mask,171,"// smax(x, 0); // (select (x < 0), x, 0) -> ((x >> (size_in_bits(x)-1))) & x; //; // If the comparison is testing for a positive value, we have to invert; // the sign bit mask, so only do that transform if the target has a; // bitwise 'and not' instruction (the invert is free).; // (select (x > 0), x, 0) -> (~(x >> (size_in_bits(x)-1))) & x",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Testability,test,testing,106,"// smax(x, 0); // (select (x < 0), x, 0) -> ((x >> (size_in_bits(x)-1))) & x; //; // If the comparison is testing for a positive value, we have to invert; // the sign bit mask, so only do that transform if the target has a; // bitwise 'and not' instruction (the invert is free).; // (select (x > 0), x, 0) -> (~(x >> (size_in_bits(x)-1))) & x",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Safety,avoid,avoids,133,// X86 doesn't have an i8 cmov. If both operands are the result of a truncate; // widen the cmov and push the truncate through. This avoids introducing a new; // branch during isel and doesn't add any extensions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Safety,avoid,avoid,26,// Exclude CopyFromReg to avoid partial register stalls.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:96,Performance,load,load,96,"// Or finally, promote i8 cmovs if we have CMOV,; // or i16 cmovs if it won't prevent folding a load.; // FIXME: we should not limit promotion of i8 case to only when the CMOV is; // legal, but EmitLoweredSelect() can not deal with these extensions; // being inserted between two CMOV's. (in i16 case too TBN); // https://bugs.llvm.org/show_bug.cgi?id=40974",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend VT if the scalar type is i8/i16 and BWI is not supported.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Safety,avoid,avoided,22,"// If v16i32 is to be avoided, we'll need to split and concatenate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Modifiability,extend,extend,25,// Truncate if we had to extend i16/i8 above.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Modifiability,extend,extend,84,"// Lowering for SIGN_EXTEND_VECTOR_INREG and ZERO_EXTEND_VECTOR_INREG.; // For sign extend this needs to handle all vector sizes and SSE4.1 and; // non-SSE4.1 targets. For zero extend this should only handle inputs of; // MVT::v64i8 when BWI is not supported, but AVX512 is.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:177,Modifiability,extend,extend,177,"// Lowering for SIGN_EXTEND_VECTOR_INREG and ZERO_EXTEND_VECTOR_INREG.; // For sign extend this needs to handle all vector sizes and SSE4.1 and; // non-SSE4.1 targets. For zero extend this should only handle inputs of; // MVT::v64i8 when BWI is not supported, but AVX512 is.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Modifiability,extend,extends,74,// FIXME: Apparently we create inreg operations that could be regular; // extends.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Modifiability,extend,extend,36,// We should only get here for sign extend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Modifiability,extend,extend,69,"// If the source elements are already all-signbits, we don't need to extend,; // just splat the elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Modifiability,extend,extend,54,// pre-SSE41 targets unpack lower lanes and then sign-extend using SRAI.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,avail,available,19,"// As SRAI is only available on i16/i32 types, we expand only up to i32; // and handle i64 separately.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Build a shuffle mask that takes each input element and places it in the; // MSBs of the new element size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:160,Availability,mask,mask,160,"// Optimize vectors in AVX mode; // Sign extend v8i16 to v8i32 and; // v4i32 to v4i64; //; // Divide input vector into two parts; // for v4i32 the high shuffle mask will be {2, 3, -1, -1}; // use vpmovsx instruction to extend v4i32 -> v2i64; v8i16 -> v4i32; // concat the vectors to original VT",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Modifiability,extend,extend,41,"// Optimize vectors in AVX mode; // Sign extend v8i16 to v8i32 and; // v4i32 to v4i64; //; // Divide input vector into two parts; // for v4i32 the high shuffle mask will be {2, 3, -1, -1}; // use vpmovsx instruction to extend v4i32 -> v2i64; v8i16 -> v4i32; // concat the vectors to original VT",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:219,Modifiability,extend,extend,219,"// Optimize vectors in AVX mode; // Sign extend v8i16 to v8i32 and; // v4i32 to v4i64; //; // Divide input vector into two parts; // for v4i32 the high shuffle mask will be {2, 3, -1, -1}; // use vpmovsx instruction to extend v4i32 -> v2i64; v8i16 -> v4i32; // concat the vectors to original VT",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize vectors in AVX mode; // Sign extend v8i16 to v8i32 and; // v4i32 to v4i64; //; // Divide input vector into two parts; // for v4i32 the high shuffle mask will be {2, 3, -1, -1}; // use vpmovsx instruction to extend v4i32 -> v2i64; v8i16 -> v4i32; // concat the vectors to original VT",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:124,Safety,avoid,avoids,124,"// If this is a 256-bit store of concatenated ops, we are better off splitting; // that store into two 128-bit stores. This avoids spurious use of 256-bit ops; // and each half can execute independently. Some cores would split the op into; // halves anyway, so the concat (vinsertf128) is purely an extra op.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Availability,avail,available,64,"// Lower vector extended loads using a shuffle. If SSSE3 is not available we; // may emit an illegal shuffle but the expansion is still better than scalar; // code. We generate sext/sext_invec for SEXTLOADs if it's available, otherwise; // we'll emit a shuffle and a arithmetic shift.; // FIXME: Is the expansion actually better than scalar code? It doesn't seem so.; // TODO: It is possible to support ZExt by zeroing the undef values during; // the shuffle phase or after the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:215,Availability,avail,available,215,"// Lower vector extended loads using a shuffle. If SSSE3 is not available we; // may emit an illegal shuffle but the expansion is still better than scalar; // code. We generate sext/sext_invec for SEXTLOADs if it's available, otherwise; // we'll emit a shuffle and a arithmetic shift.; // FIXME: Is the expansion actually better than scalar code? It doesn't seem so.; // TODO: It is possible to support ZExt by zeroing the undef values during; // the shuffle phase or after the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Modifiability,extend,extended,16,"// Lower vector extended loads using a shuffle. If SSSE3 is not available we; // may emit an illegal shuffle but the expansion is still better than scalar; // code. We generate sext/sext_invec for SEXTLOADs if it's available, otherwise; // we'll emit a shuffle and a arithmetic shift.; // FIXME: Is the expansion actually better than scalar code? It doesn't seem so.; // TODO: It is possible to support ZExt by zeroing the undef values during; // the shuffle phase or after the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,load,loads,25,"// Lower vector extended loads using a shuffle. If SSSE3 is not available we; // may emit an illegal shuffle but the expansion is still better than scalar; // code. We generate sext/sext_invec for SEXTLOADs if it's available, otherwise; // we'll emit a shuffle and a arithmetic shift.; // FIXME: Is the expansion actually better than scalar code? It doesn't seem so.; // TODO: It is possible to support ZExt by zeroing the undef values during; // the shuffle phase or after the shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Performance,load,loads,69,"// Without AVX512DQ, we need to use a scalar type for v2i1/v4i1/v8i1 loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Testability,test,test,105,"// For FCMP_OEQ, we can emit; // two branches instead of an explicit AND instruction with a; // separate test. However, we only do this if this block doesn't; // have a fall-through edge, because this requires an explicit; // jmp when the condition is false.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:104,Testability,test,test,104,"// For FCMP_UNE, we can emit; // two branches instead of an explicit OR instruction with a; // separate test.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:303,Energy Efficiency,allocate,allocated,303,// Lower dynamic stack allocation to _alloca call for Cygwin/Mingw targets.; // Calls to _alloca are needed to probe the stack when allocating more than 4k; // bytes in one go. Touching the stack at 4K increments is necessary to ensure; // that the guard pages used by the OS virtual memory manager are allocated in; // correct sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:109,Usability,simpl,simple,109,// Decide which area this value should be read from.; // TODO: Implement the AMD64 ABI in its entirety. This simple; // selection mechanism works only for the basic types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Modifiability,Variab,Variable,64,"// Insert VAARG node into the DAG; // VAARG returns two values: Variable Argument Address, Chain",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the next argument and return it,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Modifiability,variab,variable,27,// Helper to get immediate/variable SSE shift opcode from other shift opcodes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,mask,mask,17,"// See if we can mask off the upper elements using the existing source node.; // The shift uses the entire lower 64-bits of the amount vector, so no need to; // do this for vXi64 types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Modifiability,extend,extend,57,"// If the shift amount has come from a scalar, then zero-extend the scalar; // before moving to the vector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,masked,38,"// See if the shift amount is already masked (e.g. for rotation modulo),; // then we can zero-extend it by setting all the other mask elements to; // zero.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Availability,mask,mask,129,"// See if the shift amount is already masked (e.g. for rotation modulo),; // then we can zero-extend it by setting all the other mask elements to; // zero.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Modifiability,extend,extend,94,"// See if the shift amount is already masked (e.g. for rotation modulo),; // then we can zero-extend it by setting all the other mask elements to; // zero.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Availability,mask,masking,87,"// Zero-extend bottom element to v2i64 vector type, either by extension or; // shuffle masking.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,"// Zero-extend bottom element to v2i64 vector type, either by extension or; // shuffle masking.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,Mask,Mask,11,/// Return Mask with the necessary casting or extending; /// for \p Mask according to \p MaskVT when lowering masking intrinsics,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Availability,Mask,Mask,68,/// Return Mask with the necessary casting or extending; /// for \p Mask according to \p MaskVT when lowering masking intrinsics,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Availability,Mask,MaskVT,89,/// Return Mask with the necessary casting or extending; /// for \p Mask according to \p MaskVT when lowering masking intrinsics,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:110,Availability,mask,masking,110,/// Return Mask with the necessary casting or extending; /// for \p Mask according to \p MaskVT when lowering masking intrinsics,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Modifiability,extend,extending,46,/// Return Mask with the necessary casting or extending; /// for \p Mask according to \p MaskVT when lowering masking intrinsics,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Modifiability,extend,extend,47,"// In case 32bit mode, bitcast i64 is illegal, extend/split it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Availability,Mask,MaskVT,16,"// In case when MaskVT equals v2i1 or v4i1, low 2 or 4 elements; // are extracted by EXTRACT_SUBVECTOR.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,Mask,Mask,26,"/// Return (and \p Op, \p Mask) for compare instructions or; /// (vselect \p Mask, \p Op, \p PreservedSrc) for others along with the; /// necessary casting or extending for \p Mask when lowering masking intrinsics",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Availability,Mask,Mask,77,"/// Return (and \p Op, \p Mask) for compare instructions or; /// (vselect \p Mask, \p Op, \p PreservedSrc) for others along with the; /// necessary casting or extending for \p Mask when lowering masking intrinsics",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:176,Availability,Mask,Mask,176,"/// Return (and \p Op, \p Mask) for compare instructions or; /// (vselect \p Mask, \p Op, \p PreservedSrc) for others along with the; /// necessary casting or extending for \p Mask when lowering masking intrinsics",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:195,Availability,mask,masking,195,"/// Return (and \p Op, \p Mask) for compare instructions or; /// (vselect \p Mask, \p Op, \p PreservedSrc) for others along with the; /// necessary casting or extending for \p Mask when lowering masking intrinsics",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:159,Modifiability,extend,extending,159,"/// Return (and \p Op, \p Mask) for compare instructions or; /// (vselect \p Mask, \p Op, \p PreservedSrc) for others along with the; /// necessary casting or extending for \p Mask when lowering masking intrinsics",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Availability,Mask,Mask,86,"/// Creates an SDNode for a predicated scalar operation.; /// \returns (X86vselect \p Mask, \p Op, \p PreservedSrc).; /// The mask is coming as MVT::i8 and it should be transformed; /// to MVT::v1i1 while lowering masking intrinsics.; /// The main difference between ScalarMaskingNode and VectorMaskingNode is using; /// ""X86select"" instead of ""vselect"". We just can't create the ""vselect"" node; /// for a scalar instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Availability,mask,mask,126,"/// Creates an SDNode for a predicated scalar operation.; /// \returns (X86vselect \p Mask, \p Op, \p PreservedSrc).; /// The mask is coming as MVT::i8 and it should be transformed; /// to MVT::v1i1 while lowering masking intrinsics.; /// The main difference between ScalarMaskingNode and VectorMaskingNode is using; /// ""X86select"" instead of ""vselect"". We just can't create the ""vselect"" node; /// for a scalar instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:214,Availability,mask,masking,214,"/// Creates an SDNode for a predicated scalar operation.; /// \returns (X86vselect \p Mask, \p Op, \p PreservedSrc).; /// The mask is coming as MVT::i8 and it should be transformed; /// to MVT::v1i1 while lowering masking intrinsics.; /// The main difference between ScalarMaskingNode and VectorMaskingNode is using; /// ""X86select"" instead of ""vselect"". We just can't create the ""vselect"" node; /// for a scalar instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:160,Availability,recover,recover,160,"/// When the MSVC runtime transfers control to us, either to an outlined; /// function or when returning to a parent frame after catching an exception, we; /// recover the parent frame pointer by doing arithmetic on the incoming EBP.; /// Here's the math:; /// RegNodeBase = EntryEBP - RegNodeSize; /// ParentFP = RegNodeBase - ParentFrameOffset; /// Subtracting RegNodeSize takes us to the offset of the registration node, and; /// subtracting the offset (negative on x86) takes us back to the parent FP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:160,Safety,recover,recover,160,"/// When the MSVC runtime transfers control to us, either to an outlined; /// function or when returning to a parent frame after catching an exception, we; /// recover the parent frame pointer by doing arithmetic on the incoming EBP.; /// Here's the math:; /// RegNodeBase = EntryEBP - RegNodeSize; /// ParentFP = RegNodeBase - ParentFrameOffset; /// Subtracting RegNodeSize takes us to the offset of the registration node, and; /// subtracting the offset (negative on x86) takes us back to the parent FP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:111,Performance,optimiz,optimized,111,"// It's possible that the parent function no longer has a personality function; // if the exceptional code was optimized away, in which case we just return; // the incoming EBP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Safety,detect,detect,13,// Helper to detect if the operand is CUR_DIRECTION rounding mode.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Clear,Clear,3,// Clear the NO_EXC bit and check remaining bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Clear,Clear,3,// Clear the NO_EXC bit and check remaining bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Integrability,depend,dependency,15,// Avoid false dependency.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid false dependency.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Clear,Clear,3,// Clear the upper bits of the rounding immediate so that the legacy; // intrinsic can't trigger the scaling behavior of VRNDSCALE.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Clear,Clear,3,// Clear the upper bits of the rounding immediate so that the legacy; // intrinsic can't trigger the scaling behavior of VRNDSCALE.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Integrability,depend,dependency,15,// Break false dependency.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Testability,test,testp,53,"// Don't custom lower most intrinsics.; // ptest and testp intrinsics. The intrinsic these come from are designed to; // return an integer value, not just an instruction so lower it to the ptest; // or testp pattern and a setcc for the result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:202,Testability,test,testp,202,"// Don't custom lower most intrinsics.; // ptest and testp intrinsics. The intrinsic these come from are designed to; // return an integer value, not just an instruction so lower it to the ptest; // or testp pattern and a setcc for the result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Usability,simpl,simple,14,"// Generate a simple absolute symbol reference. This intrinsic is only; // supported on 32-bit Windows, which isn't PIC.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Integrability,depend,depending,63,"// Returns one of the stack, base, or frame pointer registers, depending on; // which is used to reference local variables.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Modifiability,variab,variables,113,"// Returns one of the stack, base, or frame pointer registers, depending on; // which is used to reference local variables.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Availability,mask,masked,66,// Clamp out of bounds shift amounts since they will otherwise be masked; // to 8-bits which may make it no longer out of bounds.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Integrability,depend,dependency,91,"// If source is undef or we know it won't be used, use a zero vector; // to break register dependency.; // TODO: use undef instead and let BreakFalseDeps deal with it?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Availability,mask,mask,8,// Cast mask to an integer type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Availability,mask,mask,69,// We support two versions of the gather intrinsics. One with scalar mask and; // one with vXi1 mask. Convert scalar to vXi1 if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:96,Availability,mask,mask,96,// We support two versions of the gather intrinsics. One with scalar mask and; // one with vXi1 mask. Convert scalar to vXi1 if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Integrability,depend,dependency,91,"// If source is undef or we know it won't be used, use a zero vector; // to break register dependency.; // TODO: use undef instead and let BreakFalseDeps deal with it?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Availability,mask,mask,70,// We support two versions of the scatter intrinsics. One with scalar mask and; // one with vXi1 mask. Convert scalar to vXi1 if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:97,Availability,mask,mask,97,// We support two versions of the scatter intrinsics. One with scalar mask and; // one with vXi1 mask. Convert scalar to vXi1 if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Performance,load,loaded,102,// The processor's time-stamp counter (a 64-bit MSR) is stored into the; // EDX:EAX registers. EDX is loaded with the high-order 32 bits of the MSR; // and the EAX register is loaded with the low-order 32 bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:176,Performance,load,loaded,176,// The processor's time-stamp counter (a 64-bit MSR) is stored into the; // EDX:EAX registers. EDX is loaded with the high-order 32 bits of the MSR; // and the EAX register is loaded with the low-order 32 bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Performance,load,loads,22,// Instruction RDTSCP loads the IA32:TSC_AUX_MSR (address C000_0103H) into; // the ECX register. Add 'ecx' explicitly to the chain.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Availability,Mask,Masked,9,/// Emit Masked Truncating Store with signed or unsigned saturation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Modifiability,extend,extended,24,"// 32-bit so no special extended frame, create or reuse an existing; // stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,mask,13,"//gather(v1, mask, index, base, scale);",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Availability,mask,mask,16,"//scatter(base, mask, index, v1, scale);",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Energy Efficiency,Monitor,Monitoring,20,// Read Performance Monitoring Counters.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,Perform,Performance,8,// Read Performance Monitoring Counters.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Performance,perform,performance,45,// RDPMC uses ECX to select the index of the performance counter to read.; // RDPRU uses ECX to select the processor register to read.; // XGETBV uses ECX to select the index of the XCR register to return.; // The result is stored into registers EDX:EAX.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,load,load,8,// Just load the return address.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Performance,Load,Load,18,// REX prefix; // Load the pointer to the nested function into R11.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the 'nest' parameter value into R10.; // R10 is specified in X86CallingConv.td,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:296,Performance,perform,perform,296,"/*; The rounding mode is in bits 11:10 of FPSR, and has the following; settings:; 00 Round to nearest; 01 Round to -inf; 10 Round to +inf; 11 Round to 0. GET_ROUNDING, on the other hand, expects the following:; -1 Undefined; 0 Round to 0; 1 Round to nearest; 2 Round to +inf; 3 Round to -inf. To perform the conversion, we use a packed lookup table of the four 2-bit; values that we can index by FPSP[11:10]; 0x2d --> (0b00,10,11,01) --> (0,2,3,1) >> FPSR[11:10]. (0x2d >> ((FPSR & 0xc00) >> 9)) & 3; */",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load FP Control Word from stack slot,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,// Mask and turn the control bits into a shift for the lookup table.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Energy Efficiency,allocate,allocate,70,// FP control word may be set only from data in memory. So we need to allocate; // stack space to save/load FP control word.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Performance,load,load,103,// FP control word may be set only from data in memory. So we need to allocate; // stack space to save/load FP control word.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load FP Control Word from stack slot and clear RM field (bits 11:10).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Usability,clear,clear,44,// Load FP Control Word from stack slot and clear RM field (bits 11:10).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:325,Integrability,depend,depending,325,"// Need to convert argument into bits of control word:; // 0 Round to 0 -> 11; // 1 Round to nearest -> 00; // 2 Round to +inf -> 10; // 3 Round to -inf -> 01; // The 2-bit value needs then to be shifted so that it occupies bits 11:10.; // To make the conversion, put all these values into a value 0xc9 and shift; // it left depending on the rounding mode:; // (0xc9 << 4) & 0xc00 = X86::rmTowardZero; // (0xc9 << 6) & 0xc00 = X86::rmToNearest; // ...; // (0xc9 << (2 * NewRM + 4)) & 0xc00",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update rounding mode bits and store the new FP Control Word into stack.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load FP control word from the slot.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load MXCSR from stack slot and clear RM field (bits 14:13).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Usability,clear,clear,34,// Load MXCSR from stack slot and clear RM field (bits 14:13).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update rounding mode bits and store the new FP Control Word into stack.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load MXCSR from the slot.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Availability,mask,mask,33,"// FNSTENV changes the exception mask, so load back the stored environment.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Performance,load,load,42,"// FNSTENV changes the exception mask, so load back the stored environment.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load MXCSR from memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,mask,25,"// x87 FPU Control Word: mask all floating-point exceptions, sets rounding to; // nearest. FPU precision is set to 53 bits on Windows and 64 bits otherwise; // for compatibility with glibc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,mask,10,"// MXCSR: mask all floating-point exceptions, sets rounding to nearest, clear; // all exceptions, sets DAZ and FTZ to 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:72,Usability,clear,clear,72,"// MXCSR: mask all floating-point exceptions, sets rounding to nearest, clear; // all exceptions, sets DAZ and FTZ to 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:233,Performance,perform,perform,233,"/// Lower a vector CTLZ using native supported vector CTLZ instruction.; //; // i8/i16 vector implemented using dword LZCNT vector instruction; // ( sub(trunc(lzcnt(zext32(x)))) ). In case zext32(x) is illegal,; // split the vector, perform operation on it's Lo a Hi part and; // concatenate the results.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:266,Availability,mask,masking,266,"// Begin by bitcasting the input to byte vector, then split those bytes; // into lo/hi nibbles and use the PSHUFB LUT to perform CLTZ on each of them.; // If the hi input nibble is zero then we add both results together, otherwise; // we just take the hi result (by masking the lo result to zero before the; // add).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,Performance,perform,perform,121,"// Begin by bitcasting the input to byte vector, then split those bytes; // into lo/hi nibbles and use the PSHUFB LUT to perform CLTZ on each of them.; // If the hi input nibble is zero then we add both results together, otherwise; // we just take the hi result (by masking the lo result to zero before the; // add).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Availability,Mask,Mask,86,// Move the upper/lower halves to the lower bits as we'll be extending to; // NextVT. Mask the lower result to zero if HiZ is true and add the results; // together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Modifiability,extend,extending,61,// Move the upper/lower halves to the lower bits as we'll be extending to; // NextVT. Mask the lower result to zero if HiZ is true and add the results; // together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero extend to i32 since there is not an i8 bsr.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid the generic expansion with min/max if we don't have pminu*/pmaxu*.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:272,Performance,load,load,272,"// Handle a special-case with a bit-hack instead of cmp+select:; // usubsat X, SMIN --> (X ^ SMIN) & (X s>> BW-1); // If the target can use VPTERNLOG, DAGToDAG will match this as; // ""vpsra + vpternlog"" which is better than ""vpmax + vpsub"" with a; // ""broadcast"" constant load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Availability,mask,mask,68,"// Extract the lo/hi parts to any extend to i16.; // We're going to mask off the low byte of each result element of the; // pmullw, so it doesn't matter what's in the high byte of each 16-bit; // element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,extend,extend,34,"// Extract the lo/hi parts to any extend to i16.; // We're going to mask off the low byte of each result element of the; // pmullw, so it doesn't matter what's in the high byte of each 16-bit; // element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,mask,13,"// Multiply, mask the lower 8bits of the lo/hi results and pack.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:307,Modifiability,extend,extend,307,"// For vXi8 we will unpack the low and high half of each 128 bit lane to widen; // to a vXi16 type. Do the multiplies, shift the results and pack the half; // lane results back together.; // We'll take different approaches for signed and unsigned.; // For unsigned we'll use punpcklbw/punpckhbw to put zero extend the bytes; // and use pmullw to calculate the full 16-bit product.; // For signed we'll use punpcklbw/punpckbw to extend the bytes to words and; // shift them left into the upper byte of each word. This allows us to use; // pmulhw to calculate the full 16-bit product. This trick means we don't; // need to sign extend the bytes to use pmullw.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:428,Modifiability,extend,extend,428,"// For vXi8 we will unpack the low and high half of each 128 bit lane to widen; // to a vXi16 type. Do the multiplies, shift the results and pack the half; // lane results back together.; // We'll take different approaches for signed and unsigned.; // For unsigned we'll use punpcklbw/punpckhbw to put zero extend the bytes; // and use pmullw to calculate the full 16-bit product.; // For signed we'll use punpcklbw/punpckbw to extend the bytes to words and; // shift them left into the upper byte of each word. This allows us to use; // pmulhw to calculate the full 16-bit product. This trick means we don't; // need to sign extend the bytes to use pmullw.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:626,Modifiability,extend,extend,626,"// For vXi8 we will unpack the low and high half of each 128 bit lane to widen; // to a vXi16 type. Do the multiplies, shift the results and pack the half; // lane results back together.; // We'll take different approaches for signed and unsigned.; // For unsigned we'll use punpcklbw/punpckhbw to put zero extend the bytes; // and use pmullw to calculate the full 16-bit product.; // For signed we'll use punpcklbw/punpckbw to extend the bytes to words and; // shift them left into the upper byte of each word. This allows us to use; // pmulhw to calculate the full 16-bit product. This trick means we don't; // need to sign extend the bytes to use pmullw.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Modifiability,extend,extend,58,"// If the RHS is a constant, manually unpackl/unpackh and extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:274,Performance,perform,perform,274,"// PMULxD operations multiply each even value (starting at 0) of LHS with; // the related value of RHS and produce a widen result.; // E.g., PMULUDQ <4 x i32> <a|b|c|d>, <4 x i32> <e|f|g|h>; // => <2 x i64> <ae|cg>; //; // In other word, to have all the results, we need to perform two PMULxD:; // 1. one with the even values.; // 2. one with the odd values.; // To achieve #2, with need to place the odd values at an even position.; //; // Place the odd value at an even position (basically, shift all values 1; // step to the left):",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Availability,down,down,92,"// Lower v16i8/v32i8 as extension to v8i16/v16i16 vector pairs, multiply,; // logical shift down the upper half and pack back to i8.; // With SSE41 we can use sign/zero extend, but for pre-SSE41 we unpack; // and then ashr/lshr the upper bits down to the lower bits before multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:243,Availability,down,down,243,"// Lower v16i8/v32i8 as extension to v8i16/v16i16 vector pairs, multiply,; // logical shift down the upper half and pack back to i8.; // With SSE41 we can use sign/zero extend, but for pre-SSE41 we unpack; // and then ashr/lshr the upper bits down to the lower bits before multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:169,Modifiability,extend,extend,169,"// Lower v16i8/v32i8 as extension to v8i16/v16i16 vector pairs, multiply,; // logical shift down the upper half and pack back to i8.; // With SSE41 we can use sign/zero extend, but for pre-SSE41 we unpack; // and then ashr/lshr the upper bits down to the lower bits before multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Testability,log,logical,78,"// Lower v16i8/v32i8 as extension to v8i16/v16i16 vector pairs, multiply,; // logical shift down the upper half and pack back to i8.; // With SSE41 we can use sign/zero extend, but for pre-SSE41 we unpack; // and then ashr/lshr the upper bits down to the lower bits before multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Availability,down,down,85,// Rather the truncating try to do the compare on vXi16 or vXi32.; // Shift the high down filling with sign bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,extend,extend,39,// We can't do a vXi16 compare so sign extend to v16i32.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,extend,extend,39,// We can't do a vXi16 compare so sign extend to v16i32.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Modifiability,variab,variable,25,"// The shift amount is a variable, but it is the same for all vector lanes.; // These instructions are defined together with shift-immediate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Modifiability,variab,variable-shift,53,// Return true if the required (according to Opcode) variable-shift form is; // natively supported by the Subtarget,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,// Optimize shl/srl/sra with constant shift amount.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:152,Safety,safe,safe,152,"// R may be undef at run-time, but (shl R, 1) must be an even number (LSB; // must be 0). (add undef, undef) however can be any value. To make this; // safe, we must freeze R to ensure that register allocation uses the same; // register for an undefined value. This ensures that the result will; // still be even and preserves the original semantics.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Performance,perform,performed,23,// i64 SRA needs to be performed as partial shifts.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simple,3,// Simple i8 add case,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:152,Safety,safe,safe,152,"// R may be undef at run-time, but (shl R, 1) must be an even number (LSB; // must be 0). (add undef, undef) however can be any value. To make this; // safe, we must freeze R to ensure that register allocation uses the same; // register for an undefined value. This ensures that the result will; // still be even and preserves the original semantics.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Availability,mask,mask,60,// XOP can shift v16i8 directly instead of as shift v8i16 + mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Availability,Mask,Mask,42,"// ashr(R, Amt) === sub(xor(lshr(R, Amt), Mask), Mask)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Availability,Mask,Mask,49,"// ashr(R, Amt) === sub(xor(lshr(R, Amt), Mask), Mask)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,// vXi8 shifts - shift as v8i16 + mask result.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,mask,14,// Create the mask using vXi16 shifts. For shift-rights we need to move; // the upper byte down before splatting the vXi8 mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Availability,down,down,91,// Create the mask using vXi16 shifts. For shift-rights we need to move; // the upper byte down before splatting the vXi8 mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Availability,mask,mask,122,// Create the mask using vXi16 shifts. For shift-rights we need to move; // the upper byte down before splatting the vXi8 mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Safety,safe,safe,99,"// ashr(R, Amt) === sub(xor(lshr(R, Amt), SignMask), SignMask); // SignMask = lshr(SignBit, Amt) - safe to do this with PSRLW.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Modifiability,variab,variable,33,"// If the target doesn't support variable shifts, use either FP conversion; // or integer multiplication to avoid shifting each element individually.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:108,Safety,avoid,avoid,108,"// If the target doesn't support variable shifts, use either FP conversion; // or integer multiplication to avoid shifting each element individually.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Performance,perform,perform,29,// AVX2 can more effectively perform this as a zext/trunc to/from v8i32.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Modifiability,variab,variable,19,// XOP has 128-bit variable logical/arithmetic shifts.; // +ve/-ve Amt = shift left/right.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Testability,log,logical,28,// XOP has 128-bit variable logical/arithmetic shifts.; // +ve/-ve Amt = shift left/right.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Energy Efficiency,efficient,efficiently,34,// 2i64 vector logical shifts can efficiently avoid scalarization - do the; // shifts per-lane and then shuffle the partial results back together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Safety,avoid,avoid,46,// 2i64 vector logical shifts can efficiently avoid scalarization - do the; // shifts per-lane and then shuffle the partial results back together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Testability,log,logical,15,// 2i64 vector logical shifts can efficiently avoid scalarization - do the; // shifts per-lane and then shuffle the partial results back together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Availability,mask,mask,66,// Only perform this blend if we can perform it without loading a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,perform,perform,8,// Only perform this blend if we can perform it without loading a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Performance,perform,perform,37,// Only perform this blend if we can perform it without loading a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Performance,load,loading,56,// Only perform this blend if we can perform it without loading a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:175,Modifiability,extend,extend,175,"// If possible, lower this packed shift into a vector multiply instead of; // expanding it into a sequence of scalar shifts.; // For v32i8 cases, it might be quicker to split/extend to vXi16 shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Energy Efficiency,efficient,efficiently,38,"// Constant ISD::SRL can be performed efficiently on vXi16 vectors as we; // can replace with ISD::MULHU, creating scale factor from (NumEltBits - Amt).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Performance,perform,performed,28,"// Constant ISD::SRL can be performed efficiently on vXi16 vectors as we; // can replace with ISD::MULHU, creating scale factor from (NumEltBits - Amt).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Energy Efficiency,efficient,efficiently,38,"// Constant ISD::SRA can be performed efficiently on vXi16 vectors as we; // can replace with ISD::MULHS, creating scale factor from (NumEltBits - Amt).; // TODO: Special case handling for shift by 0/1, really we can afford either; // of these cases in pre-SSE41/XOP/AVX512 but not both.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Performance,perform,performed,28,"// Constant ISD::SRA can be performed efficiently on vXi16 vectors as we; // can replace with ISD::MULHS, creating scale factor from (NumEltBits - Amt).; // TODO: Special case handling for shift by 0/1, really we can afford either; // of these cases in pre-SSE41/XOP/AVX512 but not both.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:146,Modifiability,extend,extend,146,"// v4i32 Non Uniform Shifts.; // If the shift amount is constant we can shift each lane using the SSE2; // immediate shifts, else we need to zero-extend each lane to the lower i64; // and shift using the SSE2 variable shifts.; // The separate results can then be blended together.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:209,Modifiability,variab,variable,209,"// v4i32 Non Uniform Shifts.; // If the shift amount is constant we can shift each lane using the SSE2; // immediate shifts, else we need to zero-extend each lane to the lower i64; // and shift using the SSE2 variable shifts.; // The separate results can then be blended together.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:148,Modifiability,extend,extending,148,"// The SSE2 shifts use the lower i64 as the same shift amount for; // all lanes and the upper i64 is ignored. On AVX we're better off; // just zero-extending, but for SSE just duplicating the top 16-bits is; // cheaper and has the same effect for out of range values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Modifiability,extend,extending,14,"// It's worth extending once and using the vXi16/vXi32 shifts for smaller; // types, but without AVX512 the extra overheads to get from vXi8 to vXi32; // make the existing SSE solution better.; // NOTE: We honor prefered vector width before promoting to 512-bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Energy Efficiency,efficient,efficiently,42,// Constant ISD::SRA/SRL can be performed efficiently on vXi8 vectors as we; // extend to vXi16 to perform a MUL scale effectively as a MUL_LOHI.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Modifiability,extend,extend,80,// Constant ISD::SRA/SRL can be performed efficiently on vXi8 vectors as we; // extend to vXi16 to perform a MUL scale effectively as a MUL_LOHI.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Performance,perform,performed,32,// Constant ISD::SRA/SRL can be performed efficiently on vXi8 vectors as we; // extend to vXi16 to perform a MUL scale effectively as a MUL_LOHI.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Performance,perform,perform,99,// Constant ISD::SRA/SRL can be performed efficiently on vXi8 vectors as we; // extend to vXi16 to perform a MUL scale effectively as a MUL_LOHI.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend constant shift amount to vXi16 (it doesn't matter if the type; // isn't legal).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Availability,mask,masked,76,// On AVX512BW targets we make use of the fact that VSELECT lowers; // to a masked blend which selects bytes based just on the sign bit; // extracted to a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:155,Availability,mask,mask,155,// On AVX512BW targets we make use of the fact that VSELECT lowers; // to a masked blend which selects bytes based just on the sign bit; // extracted to a mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Testability,test,test,27,"// On pre-SSE41 targets we test for the sign bit by comparing to; // zero - a negative value will set all bits of the lanes to true; // and VSELECT uses that in its OR(AND(V0,C),AND(V1,~C)) lowering.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Turn 'a' into a mask suitable for VSELECT: a = a << 5;; // We can safely do this using i16 shifts as we're only interested in; // the 3 lower bits of each byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Safety,safe,safely,69,// Turn 'a' into a mask suitable for VSELECT: a = a << 5;; // We can safely do this using i16 shifts as we're only interested in; // the 3 lower bits of each byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Modifiability,extend,extend,103,// For SRA we need to unpack each byte to the higher byte of a i16 vector; // so we can correctly sign extend. We don't care what happens to the; // lower byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Safety,safe,safely,102,"// Logical shift the result back to the lower byte, leaving a zero upper; // byte meaning that we can safely pack with PACKUSWB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,Log,Logical,3,"// Logical shift the result back to the lower byte, leaving a zero upper; // byte meaning that we can safely pack with PACKUSWB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:127,Energy Efficiency,reduce,reduce,127,"// If we have a constant shift amount, the non-SSE41 path is best as; // avoiding bitcasts make it easier to constant fold and reduce to PBLENDW.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Safety,avoid,avoiding,73,"// If we have a constant shift amount, the non-SSE41 path is best as; // avoiding bitcasts make it easier to constant fold and reduce to PBLENDW.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Turn 'a' into a mask suitable for VSELECT: a = a << 12;,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Availability,mask,mask,51,// On SSE41 targets we need to replicate the shift mask in both; // bytes for PBLENDVB.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Energy Efficiency,efficient,efficiently,39,// Constant vXi16 funnel shifts can be efficiently handled by default.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Availability,mask,mask,7,// Pre-mask the amount modulo using the wider vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Energy Efficiency,efficient,efficiently,38,// Uniform vXi16 funnel shifts can be efficiently handled by default.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Performance,optimiz,optimizing,45,// Expand slow SHLD/SHRD cases if we are not optimizing for size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Modifiability,variab,variable,26,// XOP has 128-bit vector variable + immediate rotates.; // +ve/-ve Amt = rotate left/right - just need to handle ISD::ROTL.; // XOP implicitly uses modulo rotation amounts.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Modifiability,variab,variable,25,// Use general rotate by variable (per-element).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Performance,perform,perform,17,// See if we can perform this by widening to vXi16 or vXi32.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Testability,test,test,27,"// On pre-SSE41 targets we test for the sign bit by comparing to; // zero - a negative value will set all bits of the lanes to true; // and VSELECT uses that in its OR(AND(V0,C),AND(V1,~C)) lowering.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Turn 'a' into a mask suitable for VSELECT: a = a << 5;; // We can safely do this using i16 shifts as we're only interested in; // the 3 lower bits of each byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Safety,safe,safely,69,// Turn 'a' into a mask suitable for VSELECT: a = a << 5;; // We can safely do this using i16 shifts as we're only interested in; // the 3 lower bits of each byte.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,variab,variable,39,// Fallback for splats + all supported variable shifts.; // Fallback for non-constants AVX2 vXi16 as well.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Performance,perform,perform,17,// v8i16/v16i16: perform unsigned multiply hi/lo and OR the results.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:137,Integrability,wrap,wrapped,137,// v4i32: make use of the PMULUDQ instruction to multiply 2 lanes of v4i32; // to v2i64 results at a time. The upper 32-bits contain the wrapped bits; // that can then be OR'd with the lower 32-bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:138,Availability,avail,available,138,"/// Returns true if the operand type is exactly twice the native width, and; /// the corresponding cmpxchg8b or cmpxchg16b instruction is available.; /// Used to know whether to use cmpxchg8/16b when expanding atomic operations; /// (otherwise we leave them alone to become __sync_fetch_and_... calls).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Availability,avail,available,107,"// Note: this turns large loads into lock cmpxchg8b/16b.; // TODO: In 32-bit mode, use MOVLPS when SSE1 is available?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Performance,load,loads,26,"// Note: this turns large loads into lock cmpxchg8b/16b.; // TODO: In 32-bit mode, use MOVLPS when SSE1 is available?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Performance,load,load,27,"// If this a 64 bit atomic load on a 32-bit target and SSE2 is enabled, we; // can use movq to do the load. If we have X87 we can load into an 80-bit; // X87 register and store it to a stack temporary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Performance,load,load,102,"// If this a 64 bit atomic load on a 32-bit target and SSE2 is enabled, we; // can use movq to do the load. If we have X87 we can load into an 80-bit; // X87 register and store it to a stack temporary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:130,Performance,load,load,130,"// If this a 64 bit atomic load on a 32-bit target and SSE2 is enabled, we; // can use movq to do the load. If we have X87 we can load into an 80-bit; // X87 register and store it to a stack temporary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Energy Efficiency,power,power,19,// Check if V is a power of 2 or NOT power of 2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Energy Efficiency,power,power,37,// Check if V is a power of 2 or NOT power of 2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Energy Efficiency,power,power,22,// Check if V is some power of 2 pattern known to be non-zero,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Energy Efficiency,power,power,87,// We can only use 1 << X without more sophisticated analysis. C << X where; // C is a power of 2 but not 1 can result in zero which cannot be translated; // to bittest. Likewise any C >> X (either arith or logical) can be zero.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:207,Testability,log,logical,207,// We can only use 1 << X without more sophisticated analysis. C << X where; // C is a power of 2 but not 1 can result in zero which cannot be translated; // to bittest. Likewise any C >> X (either arith or logical) can be zero.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Energy Efficiency,power,power,106,"// Todo(1): The cmpxchg case is pretty costly so matching `BLSI(X)`, `X &; // -X` and some other provable power of 2 patterns that we can use CTZ on; // may be profitable.; // Todo(2): It may be possible in some cases to prove that Shl(C, X) is; // non-zero even where C != 1. Likewise LShr(C, X) and AShr(C, X) may also; // be provably a non-zero power of 2.; // Todo(3): ROTL and ROTR patterns on a power of 2 C should also be; // transformable to bittest.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:348,Energy Efficiency,power,power,348,"// Todo(1): The cmpxchg case is pretty costly so matching `BLSI(X)`, `X &; // -X` and some other provable power of 2 patterns that we can use CTZ on; // may be profitable.; // Todo(2): It may be possible in some cases to prove that Shl(C, X) is; // non-zero even where C != 1. Likewise LShr(C, X) and AShr(C, X) may also; // be provably a non-zero power of 2.; // Todo(3): ROTL and ROTR patterns on a power of 2 C should also be; // transformable to bittest.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:401,Energy Efficiency,power,power,401,"// Todo(1): The cmpxchg case is pretty costly so matching `BLSI(X)`, `X &; // -X` and some other provable power of 2 patterns that we can use CTZ on; // may be profitable.; // Todo(2): It may be possible in some cases to prove that Shl(C, X) is; // non-zero even where C != 1. Likewise LShr(C, X) and AShr(C, X) may also; // be provably a non-zero power of 2.; // Todo(3): ROTL and ROTR patterns on a power of 2 C should also be; // transformable to bittest.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:271,Integrability,depend,depending,271,"// If the atomicrmw's result is used by a single bit AND, we may use; // bts/btr/btc instruction for these operations.; // Note: InstCombinePass can cause a de-optimization here. It replaces the; // SETCC(And(AtomicRMW(P, power_of_2), power_of_2)) with LShr and Xor; // (depending on CC). This pattern can only use bts/btr/btc but we don't; // detect it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:160,Performance,optimiz,optimization,160,"// If the atomicrmw's result is used by a single bit AND, we may use; // bts/btr/btc instruction for these operations.; // Note: InstCombinePass can cause a de-optimization here. It replaces the; // SETCC(And(AtomicRMW(P, power_of_2), power_of_2)) with LShr and Xor; // (depending on CC). This pattern can only use bts/btr/btc but we don't; // detect it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:344,Safety,detect,detect,344,"// If the atomicrmw's result is used by a single bit AND, we may use; // bts/btr/btc instruction for these operations.; // Note: InstCombinePass can cause a de-optimization here. It replaces the; // SETCC(And(AtomicRMW(P, power_of_2), power_of_2)) with LShr and Xor; // (depending on CC). This pattern can only use bts/btr/btc but we don't; // detect it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,redundant,redundant,13,"// This is a redundant AND, it should get cleaned up elsewhere.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Safety,redund,redundant,13,"// This is a redundant AND, it should get cleaned up elsewhere.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Availability,mask,masking,28,// If atomic AND need to be masking all be one bit and testing the one bit; // unset in the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Availability,mask,mask,92,// If atomic AND need to be masking all be one bit and testing the one bit; // unset in the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Testability,test,testing,55,// If atomic AND need to be masking all be one bit and testing the one bit; // unset in the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Testability,test,testing,43,// If atomic XOR/OR need to be setting and testing the same bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:75,Availability,mask,mask,75,// BT{S|R|C} on memory operand don't modulo bit position so we need to; // mask it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Availability,mask,mask,99,// Todo(1): In many cases it may be provable that SI is less than; // ShiftBits in which case this mask is unnecessary; // Todo(2): In the fairly idiomatic case of P[X / sizeof_bits(X)] OP 1; // << (X % sizeof_bits(X)) we can drop the shift mask and AGEN in; // favor of just a raw BT{S|R|C}.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:241,Availability,mask,mask,241,// Todo(1): In many cases it may be provable that SI is less than; // ShiftBits in which case this mask is unnecessary; // Todo(2): In the fairly idiomatic case of P[X / sizeof_bits(X)] OP 1; // << (X % sizeof_bits(X)) we can drop the shift mask and AGEN in; // favor of just a raw BT{S|R|C}.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Availability,avail,available,61,"// If the operand is too big, we must see if cmpxchg8/16b is available; // and default to library calls otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:128,Performance,load,loads,128,"// Accesses larger than the native width are turned into cmpxchg/libcalls, so; // there is no benefit in turning such RMWs into loads, and it is actually; // harmful as it introduces a mfence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Security,Access,Accesses,3,"// Accesses larger than the native width are turned into cmpxchg/libcalls, so; // there is no benefit in turning such RMWs into loads, and it is actually; // harmful as it introduces a mfence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Availability,avail,available,88,"// If this is a canonical idempotent atomicrmw w/no uses, we have a better; // lowering available in lowerAtomicArith.; // TODO: push more cases through this path.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Deployability,Release,Release,64,// We must restrict the ordering to avoid generating loads with Release or; // ReleaseAcquire orderings.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Deployability,Release,ReleaseAcquire,79,// We must restrict the ordering to avoid generating loads with Release or; // ReleaseAcquire orderings.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Performance,load,loads,53,// We must restrict the ordering to avoid generating loads with Release or; // ReleaseAcquire orderings.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Safety,avoid,avoid,36,// We must restrict the ordering to avoid generating loads with Release or; // ReleaseAcquire orderings.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:226,Deployability,release,release,226,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Performance,load,load,14,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:291,Performance,load,load,291,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:405,Performance,load,load,405,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:477,Performance,optimiz,optimization,477,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:490,Usability,clear,clearly,490,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:577,Usability,clear,clear,577,"// Before the load we need a fence. Here is an example lifted from; // http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf showing why a fence; // is required:; // Thread 0:; // x.store(1, relaxed);; // r1 = y.fetch_add(0, release);; // Thread 1:; // y.fetch_add(42, acquire);; // r2 = x.load(relaxed);; // r1 = r2 = 0 is impossible, but becomes possible if the idempotent rmw is; // lowered to just a load without a fence. A mfence flushes the store buffer,; // making the optimization clearly correct.; // FIXME: it is required if isReleaseOrStronger(Order) but it is not clear; // otherwise, we might be able to be more aggressive on relaxed idempotent; // rmw. In practice, they do not look useful, so we don't try to be; // especially clever.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Integrability,wrap,wrap,102,"// FIXME: we could just insert an ISD::MEMBARRIER here, except we are at; // the IR level, so we must wrap it in an intrinsic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Performance,cache,cache-line,84,"// FIXME: it might make sense to use a locked operation here but on a; // different cache-line to prevent cache-line bouncing. In practice it; // is probably a small win, and x86 processors without mfence are rare; // enough that we do not bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Performance,cache,cache-line,106,"// FIXME: it might make sense to use a locked operation here but on a; // different cache-line to prevent cache-line bouncing. In practice it; // is probably a small win, and x86 processors without mfence are rare; // enough that we do not bother.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Performance,load,load,34,// Finally we can emit the atomic load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:218,Performance,cache,cache,218,"/// Emit a locked operation on a stack location which does not change any; /// memory location, but does involve a lock prefix. Location is chosen to be; /// a) very likely accessed only by a single thread to minimize cache traffic,; /// and b) definitely dereferenceable. Returns the new Chain result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:173,Security,access,accessed,173,"/// Emit a locked operation on a stack location which does not change any; /// memory location, but does involve a lock prefix. Location is chosen to be; /// a) very likely accessed only by a single thread to minimize cache traffic,; /// and b) definitely dereferenceable. Returns the new Chain result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:783,Energy Efficiency,allocate,allocate,783,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:907,Integrability,depend,dependence,907,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1430,Integrability,depend,dependencies,1430,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:332,Performance,Load,Loads,332,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:794,Performance,cache,cache,794,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1264,Performance,cache,cache,1264,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1165,Security,access,accesses,1165,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1353,Testability,benchmark,benchmark,1353,"// Implementation notes:; // 1) LOCK prefix creates a full read/write reordering barrier for memory; // operations issued by the current processor. As such, the location; // referenced is not relevant for the ordering properties of the instruction.; // See: Intel 64 and IA-32 ArchitecturesSoftware Developers Manual,; // 8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions; // 2) Using an immediate operand appears to be the best encoding choice; // here since it doesn't require an extra register.; // 3) OR appears to be very slightly faster than ADD. (Though, the difference; // is small enough it might just be measurement noise.); // 4) When choosing offsets, there are several contributing factors:; // a) If there's no redzone, we default to TOS. (We could allocate a cache; // line aligned stack object to improve this case.); // b) To minimize our chances of introducing a false dependence, we prefer; // to offset the stack usage from TOS slightly.; // c) To minimize concerns about cross thread stack usage - in particular,; // the idiomatic MyThreadPool.run([&StackVars]() {...}) pattern which; // captures state in the TOS frame and accesses it from many threads -; // we want to use an offset such that the offset is in a distinct cache; // line from the TOS frame.; //; // For a general discussion of the tradeoffs and benchmark results, see:; // https://shipilev.net/blog/2014/on-the-fence-with-dependencies/",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:440,Availability,mask,masked,440,"// Implement a lookup table in register by using an algorithm based on:; // http://wm.ite.pl/articles/sse-popcount.html; //; // The general idea is that every lower byte nibble in the input vector is an; // index into a in-register pre-computed pop count table. We then split up the; // input vector in two new ones: (1) a vector with only the shifted-right; // higher nibbles for each byte and (2) a vector with the lower nibbles (and; // masked out higher ones) for each byte. PSHUFB is used separately with both; // to index the in-register table. Next, both are added and the result is a; // i8 vector where each element contains the pop count for input byte.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,mask,43,"// The input vector is used as the shuffle mask that index elements into the; // LUT. After counting low and high nibbles, add the vector to obtain the; // final pop count per i8 element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:83,Deployability,update,updated,83,// Please ensure that any codegen change from LowerVectorCTPOP is reflected in; // updated cost models in X86TTIImpl::getIntrinsicInstrCost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Performance,perform,perform,78,"// For scalars, its still beneficial to transfer to/from the SIMD unit to; // perform the BITREVERSE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Performance,perform,perform,79,"// VPPERM reverses the bits of a byte with the permute Op (2 << 5), and we; // perform the BSWAP in the shuffle.; // Its best to shuffle using the second operand as this will implicitly allow; // memory folding for multiple vectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Perform,Perform,3,// Perform BITREVERSE using PSHUFB lookups. Each byte is split into; // two nibbles and a PSHUFB lookup to find the bitreverse of each; // 0-15 value (moved to the other nibble).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Testability,TEST,TEST,71,// Special case. If the input fits in 8-bits we can use a single 8-bit TEST.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to the original type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,extend,extend,39,"// If the input is 16-bits, we need to extend to use an i32 shift below.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to the original type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:316,Performance,load,load,316,"// On X86, the only ordering which actually requires an instruction is; // seq_cst which isn't SingleThread, everything just needs to be preserved; // during codegen and then dropped. Note that we expect (but don't assume),; // that orderings other than seq_cst and acq_rel have been canonicalized to; // a store or load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Performance,cache,cache,66,// Prefer a locked operation against a stack location to minimize cache; // traffic. This assumes that stack locations are very likely to be; // accessed only by the owning thread.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:145,Security,access,accessed,145,// Prefer a locked operation against a stack location to minimize cache; // traffic. This assumes that stack locations are very likely to be; // accessed only by the owning thread.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Performance,load,load,9,// First load this into an 80-bit X87 register using a stack temporary.; // This will put the whole integer into the significand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,optimiz,optimize,8,"// Only optimize x86_64 for now. i386 is a bit messy. For f32,; // the small struct {f32, f32} is returned in (eax, edx). For f64,; // the results are returned via SRet in memory.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,masked,14,// Handle AVX masked loads which don't support passthru other than 0.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Performance,load,loads,21,// Handle AVX masked loads which don't support passthru other than 0.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,// Mask element has to be i1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,// Mask element has to be i1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Integrability,depend,dependency,9,// Break dependency on the data register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:217,Testability,log,logically,217,"// TODO: Eventually, the lowering of these nodes should be informed by or; // deferred to the GC strategy for the function in which they appear. For; // now, however, they must be lowered to something. Since they are logically; // no-ops in the case of a null GC strategy (or a GC strategy which does not; // require special handling for these nodes), lower them as literal NOOPs for; // the time being.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Modifiability,extend,extend,73,"// Bit count should fit in 32-bits, extract it as that and then zero; // extend to i64. Otherwise we end up extracting bits 63:32 separately.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Safety,avoid,avoid,33,// Pre-promote these to vXi16 to avoid op legalization thinking all 16; // elements are needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Performance,optimiz,optimize,103,// If this RHS is a constant splat vector we can widen this and let; // division/remainder by constant optimize it.; // TODO: Can we do something for non-splat?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Safety,avoid,avoid,196,// The generic legalizer will try to widen the input type to the same; // number of elements as the widened result type. But this isn't always; // the best thing so do some custom legalization to avoid some cases.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Performance,perform,perform,47,// See if there are sufficient leading bits to perform a PACKUS/PACKSS.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Safety,avoid,avoid,37,// 128 bit and smaller inputs should avoid truncate all together and; // just use a build_vector that will become a shuffle.; // TODO: Widen and use a shuffle directly?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Modifiability,extend,extend,31,// Custom split this so we can extend i8/i16->i32 invec. This is better; // since sign_extend_inreg i8/i16->i64 requires an extend to i32 using; // sra. Then extending from i32 to i64 using pcmpgt. By custom splitting; // we allow the sra from the extend to i32 to be shared by the split.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:124,Modifiability,extend,extend,124,// Custom split this so we can extend i8/i16->i32 invec. This is better; // since sign_extend_inreg i8/i16->i64 requires an extend to i32 using; // sra. Then extending from i32 to i64 using pcmpgt. By custom splitting; // we allow the sra from the extend to i32 to be shared by the split.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Modifiability,extend,extending,158,// Custom split this so we can extend i8/i16->i32 invec. This is better; // since sign_extend_inreg i8/i16->i64 requires an extend to i32 using; // sra. Then extending from i32 to i64 using pcmpgt. By custom splitting; // we allow the sra from the extend to i32 to be shared by the split.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:248,Modifiability,extend,extend,248,// Custom split this so we can extend i8/i16->i32 invec. This is better; // since sign_extend_inreg i8/i16->i64 requires an extend to i32 using; // sra. Then extending from i32 to i64 using pcmpgt. By custom splitting; // we allow the sra from the extend to i32 to be shared by the split.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Modifiability,extend,extend,53,// Perform custom splitting instead of the two stage extend we would get; // by default.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Perform,Perform,3,// Perform custom splitting instead of the two stage extend we would get; // by default.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Testability,assert,assert,122,"// Preserve what we know about the size of the original result. If the; // result is v2i32, we have to manually widen the assert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:253,Safety,safe,safely,253,// Otherwise we can defer to the generic legalizer which will widen; // the input as well. This will be further widened during op; // legalization to v8i32<-v8f64.; // For strict nodes we'll need to widen ourselves.; // FIXME: Fix the type legalizer to safely widen strict nodes?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Safety,avoid,avoid,39,// Custom widen strict v2i32->v2f32 to avoid scalarization.; // FIXME: Should generic type legalizer do this?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:98,Safety,avoid,avoids,98,// We use an alternative sequence for SSE1 that extracts as v2f32 and; // then casts to i64. This avoids a 128-bit stack temporary being; // created by type legalization if we were to cast v4f32->v2i64.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Performance,load,load,9,// First load this into an 80-bit X87 register. This will put the whole; // integer into the significand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:188,Performance,load,load,188,// Now store the X87 register to a stack temporary and convert to i64.; // This store is not atomic and doesn't need to be.; // FIXME: We don't need a stack temporary if the result of the load; // is already being stored. We could just directly store there.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Performance,load,load,11,// Finally load the value back from the stack temporary and return it.; // This load is not atomic and doesn't need to be.; // This load will be further type legalized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Performance,load,load,80,// Finally load the value back from the stack temporary and return it.; // This load is not atomic and doesn't need to be.; // This load will be further type legalized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:132,Performance,load,load,132,// Finally load the value back from the stack temporary and return it.; // This load is not atomic and doesn't need to be.; // This load will be further type legalized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Availability,avail,available,33,// TODO: Use MOVLPS when SSE1 is available?; // Delegate to generic TypeLegalization. Situations we can really handle; // should have already been dealt with by AtomicExpandPass.cpp.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,"// We need to widen the mask, but the instruction will only use 2; // of its elements. So we can use undef.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Performance,load,load,18,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Performance,load,loads,62,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:206,Performance,load,load,206,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Safety,avoid,avoids,78,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Safety,avoid,avoids,133,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Performance,load,load,94,"/// Return true if the addressing mode represented by AM is legal for this; /// target, for a load/store of the specified type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Modifiability,extend,extended,21,// X86 allows a sign-extended 32-bit immediate field as a displacement.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Performance,load,load,51,"// If a reference to this global requires an extra load, we can't fold it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,avail,available,22,"// If lower 4G is not available, then we must use rip-relative addressing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Modifiability,variab,variable,35,// XOP has v16i8/v8i16/v4i32/v2i64 variable vector shifts.; // Splitting for v32i8/v16i16 on XOP+AVX2 targets is still preferred.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Modifiability,variab,variable,65,// AVX2 has vpsllv[dq] instructions (and other shifts) that make variable; // shifts just as cheap as scalar ones.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Testability,test,test,84,// These are non-commutative binops.; // TODO: Add more X86ISD opcodes once we have test coverage.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Testability,test,test,46,// TODO: Add more X86ISD opcodes once we have test coverage.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Availability,down,down,102,"// Assuming the caller doesn't have a zeroext or signext return parameter,; // truncation all the way down to i1 is valid.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Modifiability,extend,extends,26,// x86-64 implicitly zero-extends 32-bit results in 64-bit registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Modifiability,extend,extends,26,// x86-64 implicitly zero-extends 32-bit results in 64-bit registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,extend,extending,34,"// X86 has 8, 16, and 32-bit zero-extending loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Performance,load,loads,44,"// X86 has 8, 16, and 32-bit zero-extending loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Modifiability,variab,variable,99,"// A uniform shift amount in a vector shift or funnel shift may be much; // cheaper than a generic variable vector shift, so make that pattern visible; // to SDAG by sinking the shuffle instruction next to the shift.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Modifiability,extend,extending,15,// There is no extending load for vXi1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,load,load,25,// There is no extending load for vXi1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:119,Availability,mask,masks,119,"/// Targets can use this to indicate that they only support *some*; /// VECTOR_SHUFFLE operations, those with specific masks.; /// By default, if a target supports the VECTOR_SHUFFLE node, all mask values; /// are assumed to be legal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:193,Availability,mask,mask,193,"/// Targets can use this to indicate that they only support *some*; /// VECTOR_SHUFFLE operations, those with specific masks.; /// By default, if a target supports the VECTOR_SHUFFLE node, all mask values; /// are assumed to be legal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Availability,mask,mask,106,// We only care that the types being shuffled are legal. The lowering can; // handle any possible shuffle mask that results.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Availability,avail,available,126,// Don't convert an 'and' into a shuffle that we don't directly support.; // vpblendw and vpshufb for 256-bit vectors are not available on AVX1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Availability,mask,masks,48,"// Just delegate to the generic legality, clear masks aren't special.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Usability,clear,clear,42,"// Just delegate to the generic legality, clear masks aren't special.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Testability,log,logic,38,"// Otherwise, fallback on the generic logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid 8 and 16 bit types because they increase the chance for unnecessary; // zero-extensions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Energy Efficiency,Schedul,Scheduler,89,//===----------------------------------------------------------------------===//; // X86 Scheduler Hooks; //===----------------------------------------------------------------------===//; // Returns true if EFLAG is consumed after this iterator in the rest of the; // basic block or any successors of the basic block.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Safety,abort,abortion,66,// thisMBB:; // xbegin fallMBB; // # fallthrough to mainMBB; // # abortion to fallMBB,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Performance,load,loading,44,// Clone the MMO into two separate MMOs for loading and storing,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the offset value into a register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero-extend the offset,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Performance,Load,Load,46,//; // Emit code to use overflow area; //; // Load the overflow_area address into a register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,rewrite,rewrite,23,// Add this PHI to the rewrite table.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1178,Performance,perform,perform,1178,"// To ""insert"" a SELECT_CC instruction, we actually have to insert the; // diamond control-flow pattern. The incoming instruction knows the; // destination vreg to set, the condition code register to branch on, the; // true/false values to select between and a branch opcode to use.; // ThisMBB:; // ...; // TrueVal = ...; // cmpTY ccX, r1, r2; // bCC copy1MBB; // fallthrough --> FalseMBB; // This code lowers all pseudo-CMOV instructions. Generally it lowers these; // as described above, by inserting a BB, and then making a PHI at the join; // point to select the true and false operands of the CMOV in the PHI.; //; // The code also handles two different cases of multiple CMOV opcodes; // in a row.; //; // Case 1:; // In this case, there are multiple CMOVs in a row, all which are based on; // the same condition setting (or the exact opposite condition setting).; // In this case we can lower all the CMOVs using a single inserted BB, and; // then make a number of PHIs at the join point to model the CMOVs. The only; // trickiness here, is that in a case like:; //; // t2 = CMOV cond1 t1, f1; // t3 = CMOV cond1 t2, f2; //; // when rewriting this into PHIs, we have to perform some renaming on the; // temps since you cannot have a PHI operand refer to a PHI result earlier; // in the same block. The ""simple"" but wrong lowering would be:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t2(BB1), f2(BB2); //; // but clearly t2 is not defined in BB1, so that is incorrect. The proper; // renaming is to note that on the path through BB1, t2 is really just a; // copy of t1, and do that renaming, properly generating:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t1(BB1), f2(BB2); //; // Case 2:; // CMOV ((CMOV F, T, cc1), T, cc2) is checked here and handled by a separate; // function - EmitLoweredCascadedSelect.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1311,Usability,simpl,simple,1311,"// To ""insert"" a SELECT_CC instruction, we actually have to insert the; // diamond control-flow pattern. The incoming instruction knows the; // destination vreg to set, the condition code register to branch on, the; // true/false values to select between and a branch opcode to use.; // ThisMBB:; // ...; // TrueVal = ...; // cmpTY ccX, r1, r2; // bCC copy1MBB; // fallthrough --> FalseMBB; // This code lowers all pseudo-CMOV instructions. Generally it lowers these; // as described above, by inserting a BB, and then making a PHI at the join; // point to select the true and false operands of the CMOV in the PHI.; //; // The code also handles two different cases of multiple CMOV opcodes; // in a row.; //; // Case 1:; // In this case, there are multiple CMOVs in a row, all which are based on; // the same condition setting (or the exact opposite condition setting).; // In this case we can lower all the CMOVs using a single inserted BB, and; // then make a number of PHIs at the join point to model the CMOVs. The only; // trickiness here, is that in a case like:; //; // t2 = CMOV cond1 t1, f1; // t3 = CMOV cond1 t2, f2; //; // when rewriting this into PHIs, we have to perform some renaming on the; // temps since you cannot have a PHI operand refer to a PHI result earlier; // in the same block. The ""simple"" but wrong lowering would be:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t2(BB1), f2(BB2); //; // but clearly t2 is not defined in BB1, so that is incorrect. The proper; // renaming is to note that on the path through BB1, t2 is really just a; // copy of t1, and do that renaming, properly generating:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t1(BB1), f2(BB2); //; // Case 2:; // CMOV ((CMOV F, T, cc1), T, cc2) is checked here and handled by a separate; // function - EmitLoweredCascadedSelect.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1424,Usability,clear,clearly,1424,"// To ""insert"" a SELECT_CC instruction, we actually have to insert the; // diamond control-flow pattern. The incoming instruction knows the; // destination vreg to set, the condition code register to branch on, the; // true/false values to select between and a branch opcode to use.; // ThisMBB:; // ...; // TrueVal = ...; // cmpTY ccX, r1, r2; // bCC copy1MBB; // fallthrough --> FalseMBB; // This code lowers all pseudo-CMOV instructions. Generally it lowers these; // as described above, by inserting a BB, and then making a PHI at the join; // point to select the true and false operands of the CMOV in the PHI.; //; // The code also handles two different cases of multiple CMOV opcodes; // in a row.; //; // Case 1:; // In this case, there are multiple CMOVs in a row, all which are based on; // the same condition setting (or the exact opposite condition setting).; // In this case we can lower all the CMOVs using a single inserted BB, and; // then make a number of PHIs at the join point to model the CMOVs. The only; // trickiness here, is that in a case like:; //; // t2 = CMOV cond1 t1, f1; // t3 = CMOV cond1 t2, f2; //; // when rewriting this into PHIs, we have to perform some renaming on the; // temps since you cannot have a PHI operand refer to a PHI result earlier; // in the same block. The ""simple"" but wrong lowering would be:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t2(BB1), f2(BB2); //; // but clearly t2 is not defined in BB1, so that is incorrect. The proper; // renaming is to note that on the path through BB1, t2 is really just a; // copy of t1, and do that renaming, properly generating:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t1(BB1), f2(BB2); //; // Case 2:; // CMOV ((CMOV F, T, cc1), T, cc2) is checked here and handled by a separate; // function - EmitLoweredCascadedSelect.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:139,Energy Efficiency,reduce,reduces,139,"// Check for case 1, where there are multiple CMOVs with the same condition; // first. Of the two cases of multiple CMOV lowerings, case 1 reduces the; // number of jumps the most.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,test,test,3,// test rsp size,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:98,Energy Efficiency,allocate,allocate,98,"// Touch the block then extend it. This is done on the opposite side of; // static probe where we allocate then touch, to avoid the need of probing the; // tail of the static alloca. Possible scenarios are:; //; // + ---- <- ------------ <- ------------- <- ------------ +; // | |; // [free probe] -> [page alloc] -> [alloc probe] -> [tail alloc] + -> [dyn probe] -> [page alloc] -> [dyn probe] -> [tail alloc] +; // | |; // + <- ----------- <- ------------ <- ----------- <- ------------ +; //; // The property we want to enforce is to never have more than [page alloc] between two probes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Modifiability,extend,extend,24,"// Touch the block then extend it. This is done on the opposite side of; // static probe where we allocate then touch, to avoid the need of probing the; // tail of the static alloca. Possible scenarios are:; //; // + ---- <- ------------ <- ------------- <- ------------ +; // | |; // [free probe] -> [page alloc] -> [alloc probe] -> [tail alloc] + -> [dyn probe] -> [page alloc] -> [dyn probe] -> [tail alloc] +; // | |; // + <- ----------- <- ------------ <- ----------- <- ------------ +; //; // The property we want to enforce is to never have more than [page alloc] between two probes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Safety,avoid,avoid,122,"// Touch the block then extend it. This is done on the opposite side of; // static probe where we allocate then touch, to avoid the need of probing the; // tail of the static alloca. Possible scenarios are:; //; // + ---- <- ------------ <- ------------- <- ------------ +; // | |; // [free probe] -> [page alloc] -> [alloc probe] -> [tail alloc] + -> [dyn probe] -> [page alloc] -> [dyn probe] -> [tail alloc] +; // | |; // + <- ----------- <- ------------ <- ----------- <- ------------ +; //; // The property we want to enforce is to never have more than [page alloc] between two probes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:109,Energy Efficiency,Allocate,Allocate,109,"// BB:; // ... [Till the alloca]; // If stacklet is not large enough, jump to mallocMBB; //; // bumpMBB:; // Allocate by subtracting from RSP; // Jump to continueMBB; //; // mallocMBB:; // Allocate by call to runtime; //; // continueMBB:; // ...; // [rest of original BB]; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:189,Energy Efficiency,Allocate,Allocate,189,"// BB:; // ... [Till the alloca]; // If stacklet is not large enough, jump to mallocMBB; //; // bumpMBB:; // Allocate by subtracting from RSP; // Jump to continueMBB; //; // mallocMBB:; // Allocate by call to runtime; //; // continueMBB:; // ...; // [rest of original BB]; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Usability,simpl,simply,11,"// bumpMBB simply decreases the stack pointer, since we know the current; // stacklet has enough space.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Energy Efficiency,allocate,allocate,37,// Calls into a routine in libgcc to allocate more space from the heap.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Integrability,rout,routine,16,// Calls into a routine in libgcc to allocate more space from the heap.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:212,Integrability,wrap,wrapping,212,"// So, here we replace TLSADDR with the sequence:; // adjust_stackdown -> TLSADDR -> adjust_stackup.; // We need this because TLSADDR is lowered into calls; // inside MC, therefore without the two markers shrink-wrapping; // may push the prologue/epilogue pass them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Performance,load,load,77,"// This is pretty easy. We're taking the value that we received from; // our load from the relocation, sticking it in either RDI (x86-64); // or EAX and doing an indirect call. The return value will then; // be in the normal return register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// Get a register mask for the lowered call.; // FIXME: The 32-bit calls have non-standard calling conventions. Use a; // proper register mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:138,Availability,mask,mask,138,// Get a register mask for the lowered call.; // FIXME: The 32-bit calls have non-standard calling conventions. Use a; // proper register mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:264,Deployability,configurat,configuration,264,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:355,Deployability,patch,patching,355,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:264,Modifiability,config,configuration,264,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:433,Performance,load,loaded,433,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Usability,simpl,simplify,126,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,avail,available,11,"// Find an available scratch register to hold the callee. On 64-bit, we can; // just use R11, but we scan for uses anyway to ensure we don't generate; // incorrect code. On 32-bit, we use one of EAX, ECX, or EDX that isn't; // already a register use operand to the call to hold the callee. If none; // are available, use EDI instead. EDI is chosen because EBX is the PIC base; // register and ESI is the base pointer to realigned stack frames with VLAs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:306,Availability,avail,available,306,"// Find an available scratch register to hold the callee. On 64-bit, we can; // just use R11, but we scan for uses anyway to ensure we don't generate; // incorrect code. On 32-bit, we use one of EAX, ECX, or EDX that isn't; // already a register use operand to the call to hold the callee. If none; // are available, use EDI instead. EDI is chosen because EBX is the PIC base; // register and ESI is the base pointer to realigned stack frames with VLAs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,avail,available,39,// Choose the first remaining non-zero available register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:178,Performance,perform,performs,178,"/// SetJmp implies future control flow change upon calling the corresponding; /// LongJmp.; /// Instead of using the 'return' instruction, the long jump fixes the stack and; /// performs an indirect branch. To do so it uses the registers that were stored; /// in the jump buffer (when calling SetJmp).; /// In case the shadow stack is enabled we need to fix it as well, because some; /// return addresses will be skipped.; /// The function will save the SSP for future fixing in the function; /// emitLongJmpShadowStackFix.; /// \sa emitLongJmpShadowStackFix; /// \param [in] MI The temporary Machine Instruction for the builtin.; /// \param [in] MBB The Machine Basic Block that will be modified.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:272,Performance,load,load,272,"// For v = setjmp(buf), we generate; //; // thisMBB:; // buf[LabelOffset] = restoreMBB <-- takes address of restoreMBB; // SjLjSetup restoreMBB; //; // mainMBB:; // v_main = 0; //; // sinkMBB:; // v = phi(main, restore); //; // restoreMBB:; // if base pointer being used, load it from frame; // v_restore = 1",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:274,Performance,perform,perform,274,/// Fix the shadow stack using the previously saved SSP pointer.; /// \sa emitSetJmpShadowStackFix; /// \param [in] MI The temporary Machine Instruction for the builtin.; /// \param [in] MBB The Machine Basic Block that will be modified.; /// \return The sink MBB that will perform the future indirect branch.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Testability,test,test,57,"// checkSspMBB:; // xor vreg1, vreg1; // rdssp vreg1; // test vreg1, vreg1; // je sinkMBB # Jump if Shadow Stack is not supported; // fallMBB:; // mov buf+24/12(%rip), vreg2; // sub vreg1, vreg2; // jbe sinkMBB # No need to fix the Shadow Stack; // fixShadowMBB:; // shr 3/2, vreg2; // incssp vreg2 # fix the SSP according to the lower 8 bits; // shr 8, vreg2; // je sinkMBB; // fixShadowLoopPrepareMBB:; // shl vreg2; // mov 128, vreg3; // fixShadowLoopMBB:; // incssp vreg3; // dec vreg2; // jne fixShadowLoopMBB # Iterate until you finish fixing; // # the Shadow Stack; // sinkMBB:",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Deployability,update,updated,20,"// Since FP is only updated here but NOT referenced, it's treated as GPR.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// Add a register mask with no preserved registers. This results in all; // registers being marked as clobbered.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Safety,Avoid,Avoid,10,// FIXME: Avoid quadratic complexity.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Modifiability,extend,extended,60,// Change the floating point control register to use double extended; // precision when performing the addition.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Performance,perform,performing,88,// Change the floating point control register to use double extended; // precision when performing the addition.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the old value of the control word...,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Modifiability,extend,extended,61,// OR 0b11 into bit 8 and 9. 0b11 is the encoding for double extended; // precision.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the old value of the control word...,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:274,Energy Efficiency,allocate,allocate,274,"// In addition to 4 E[ABCD] registers implied by encoding, CMPXCHG8B; // requires a memory operand. If it happens that current architecture is; // i686 and for current function we need a base pointer; // - which is ESI for i686 - register allocator would not be able to; // allocate registers for an address in form of X(%reg, %reg, Y); // - there never would be enough unreserved registers during regalloc; // (without the need for base ptr the only option would be X(%edi, %esi, Y).; // We are giving a hand to register allocator by precomputing the address in; // a new vreg using LEA.; // If it is not i686 or there is no base pointer - nothing to do here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:123,Testability,assert,assert,123,"// Even though this code does not necessarily needs the base pointer to; // be ESI, we check for that. The reason: if this assert fails, there are; // some changes happened in the compiler base pointer handling, which most; // probably have to be addressed somehow here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simple,3,"// Simple case, just copy the virtual register to RBX.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Performance,Optimiz,Optimization,89,//===----------------------------------------------------------------------===//; // X86 Optimization Hooks; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Modifiability,extend,extend,79,"// If the constant is only all signbits in the active bits, then we should; // extend it to the entire constant to allow it act as a boolean constant; // vector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Modifiability,extend,extend,57,"// For vectors - if we have a constant, then try to sign extend.; // TODO: Handle AND cases.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,optimiz,optimize,8,// Only optimize Ands to prevent shrinking a constant that could be; // matched by movzx.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Clear,Clear,3,// Clear all non-demanded bits initially.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Availability,mask,mask,32,// Find the width of the shrunk mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,mask,10,// If the mask is all 0s there's nothing to do here.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Energy Efficiency,power,power,17,"// Find the next power of 2 width, rounding up to a byte.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,mask,mask,36,// Calculate a possible zero extend mask for this constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Modifiability,extend,extend,29,// Calculate a possible zero extend mask for this constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Availability,mask,mask,29,"// If we aren't changing the mask, just return true to keep it and prevent; // the caller from optimizing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:95,Performance,optimiz,optimizing,95,"// If we aren't changing the mask, just return true to keep it and prevent; // the caller from optimizing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Availability,mask,mask,21,// Make sure the new mask can be represented by a combination of mask bits; // and non-demanded bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Availability,mask,mask,65,// Make sure the new mask can be represented by a combination of mask bits; // and non-demanded bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,// Replace the constant with the zero extend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Modifiability,extend,extend,38,// Replace the constant with the zero extend mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,log,logical,16,// Out of range logical bit shifts are guaranteed to be zero.; // Out of range arithmetic bit shifts splat the sign bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Availability,mask,mask,31,// Zeros are retained from the mask operand. But not ones.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Availability,mask,mask,67,// The result will have at least as many trailing zeros as the non-mask; // operand since bits can only map to the same or higher bit position.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Availability,mask,mask,71,// The result has as many leading zeros as the number of zeroes in the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Modifiability,extend,extend,48,// PACKSS is just a truncation if the sign bits extend to the packed size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Safety,detect,detect,13,"// Helper to detect PACKSSDW(BITCAST(PACKSSDW(X)),BITCAST(PACKSSDW(Y))); // patterns often used to compact vXi64 allsignbit patterns.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Availability,failure,failure,133,// Helper to look for a normal load that can be narrowed into a vzload with the; // specified VT and memory VT. Returns SDValue() on failure.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Performance,load,load,31,// Helper to look for a normal load that can be narrowed into a vzload with the; // specified VT and memory VT. Returns SDValue() on failure.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Performance,load,load,16,// Can't if the load is volatile or atomic.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,mask,39,// Attempt to match a combined shuffle mask against supported unary shuffle; // instructions.; // TODO: Investigate sharing more of this with shuffle lowering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Modifiability,extend,extending,51,// Match against a VZEXT_MOVL vXi32 and vXi16 zero-extending instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:188,Performance,load,load,188,// Check if we have SSE3 which will let us use MOVDDUP etc. The; // instructions are no slower than UNPCKLPD but has the option to; // fold the input operand into even an unaligned memory load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,mask,39,// Attempt to match a combined shuffle mask against supported unary immediate; // permute instructions.; // TODO: Investigate sharing more of this with shuffle lowering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Integrability,depend,depending,113,// We are checking for shuffle match or shift match. Loop twice so we can; // order which we try and match first depending on target preference.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,mask,23,// Narrow the repeated mask to create 32-bit element permutes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,// Attempt to match a combined unary shuffle mask against supported binary; // shuffle instructions.; // TODO: Investigate sharing more of this with shuffle lowering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Modifiability,extend,extend,32,// Use PACKSSWD if the signbits extend to the lowest 16-bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Performance,perform,performing,42,// Attempt to match against a OR if we're performing a blend shuffle and the; // non-blended source element is zero in each case.; // TODO: Handle cases where V1/V2 sizes doesn't match SizeInBits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Usability,Simpl,SimplifyDemandedVectorElts,103,// FIXME: handle mismatched sizes?; // TODO: investigate if `ISD::OR` handling in; // `TargetLowering::SimplifyDemandedVectorElts` can be improved instead.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,"// Match each half of the repeated mask, to determine if its just; // referencing one of the vectors, is zeroable or entirely undef.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:262,Availability,mask,mask,262,"/// Combine an arbitrary chain of shuffles into a single instruction if; /// possible.; ///; /// This is the leaf of the recursive combine below. When we have found some; /// chain of single-use x86 shuffle instructions and accumulated the combined; /// shuffle mask represented by them, this will try to pattern match that mask; /// into either a single instruction if there is a special purpose instruction; /// for this operation, or into a PSHUFB instruction which is a fully general; /// instruction but should only be used to replace chains over a certain depth.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:324,Availability,mask,mask,324,"/// Combine an arbitrary chain of shuffles into a single instruction if; /// possible.; ///; /// This is the leaf of the recursive combine below. When we have found some; /// chain of single-use x86 shuffle instructions and accumulated the combined; /// shuffle mask represented by them, this will try to pattern match that mask; /// into either a single instruction if there is a special purpose instruction; /// for this operation, or into a PSHUFB instruction which is a fully general; /// instruction but should only be used to replace chains over a certain depth.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Availability,mask,mask,56,// Don't combine if we are a AVX512/EVEX target and the mask element size; // is different from the root element size - this would prevent writemasks; // from being reused.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:176,Availability,mask,mask,176,// If we are shuffling a splat (and not introducing zeros) then we can just; // use it directly. This works for smaller elements as well as they already; // repeat across each mask element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Usability,simpl,simplified,91,// See if the shuffle is a hidden identity shuffle - repeated args in HOPs; // etc. can be simplified.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// Narrow shuffle mask to v4x128.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Availability,mask,mask,105,// FIXME: Is there a better way to do this? is256BitLaneRepeatedShuffleMask; // doesn't work because our mask is for 128 bits and we don't have an MVT; // to match that.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:190,Performance,optimiz,optimizing,190,"// Nothing to do!; // If we have AVX2, prefer to use VPERMQ/VPERMPD for unary shuffles unless; // we need to use the zeroing feature.; // Prefer blends for sequential shuffles unless we are optimizing for size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Availability,mask,masks,7,"// For masks that have been widened to 128-bit elements or more,; // narrow back down to 64-bit elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Availability,down,down,81,"// For masks that have been widened to 128-bit elements or more,; // narrow back down to 64-bit elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Availability,mask,masked,7,"// For masked shuffles, we're trying to match the root width for better; // writemask folding, attempt to scale the mask.; // TODO - variable shuffles might need this to be widened again.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:116,Availability,mask,mask,116,"// For masked shuffles, we're trying to match the root width for better; // writemask folding, attempt to scale the mask.; // TODO - variable shuffles might need this to be widened again.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Modifiability,variab,variable,133,"// For masked shuffles, we're trying to match the root width for better; // writemask folding, attempt to scale the mask.; // TODO - variable shuffles might need this to be widened again.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Availability,mask,mask,27,// Determine the effective mask value type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Availability,mask,mask,20,// Only allow legal mask types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,// Attempt to match the mask against known shuffle patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,// Determine zeroable mask elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Performance,load,loading,87,// Attempt to match against broadcast-from-vector.; // Limit AVX1 to cases where we're loading+broadcasting a scalar element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Availability,Mask,MaskVT,57,"// Typically from here on, we need an integer version of MaskVT.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Availability,mask,mask,63,// Depth threshold above which we can efficiently use variable mask shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Energy Efficiency,efficient,efficiently,38,// Depth threshold above which we can efficiently use variable mask shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Modifiability,variab,variable,54,// Depth threshold above which we can efficiently use variable mask shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,mask,mask,18,// Adjust shuffle mask - replace SM_SentinelZero with second source index.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Availability,mask,mask,68,"// See if we can combine a single input shuffle with zeros to a bit-mask,; // which is much simpler than any shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Usability,simpl,simpler,92,"// See if we can combine a single input shuffle with zeros to a bit-mask,; // which is much simpler than any shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:115,Availability,mask,mask,115,// If we have a single input shuffle with different shuffle patterns in the; // the 128-bit lanes use the variable mask to VPERMILPS.; // TODO Combine other mask types at higher depths.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:157,Availability,mask,mask,157,// If we have a single input shuffle with different shuffle patterns in the; // the 128-bit lanes use the variable mask to VPERMILPS.; // TODO Combine other mask types at higher depths.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:106,Modifiability,variab,variable,106,// If we have a single input shuffle with different shuffle patterns in the; // the 128-bit lanes use the variable mask to VPERMILPS.; // TODO Combine other mask types at higher depths.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Availability,Mask,Mask,86,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:130,Availability,Mask,Mask,130,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Availability,mask,mask,81,"// If we have 3 or more shuffle instructions or a chain involving a variable; // mask, we can replace them with a single PSHUFB instruction profitably.; // Intel's manuals suggest only using PSHUFB if doing so replacing 5; // instructions, but in practice PSHUFB tends to be *very* fast so we're; // more aggressive.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Modifiability,variab,variable,68,"// If we have 3 or more shuffle instructions or a chain involving a variable; // mask, we can replace them with a single PSHUFB instruction profitably.; // Intel's manuals suggest only using PSHUFB if doing so replacing 5; // instructions, but in practice PSHUFB tends to be *very* fast so we're; // more aggressive.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,Mask,Mask,10,"// VPPERM Mask Operation; // Bits[4:0] - Byte Index (0 - 31); // Bits[7:5] - Permute Operation (0 - Source byte, 4 - ZERO)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:174,Availability,mask,mask,174,"// Combine an arbitrary chain of shuffles + extract_subvectors into a single; // instruction if possible.; //; // Wrapper for combineX86ShuffleChain that extends the shuffle mask to a larger; // type size to attempt to combine:; // shuffle(extract_subvector(x,c1),extract_subvector(y,c2),m1); // -->; // extract_subvector(shuffle(x,y,m2),0)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:114,Integrability,Wrap,Wrapper,114,"// Combine an arbitrary chain of shuffles + extract_subvectors into a single; // instruction if possible.; //; // Wrapper for combineX86ShuffleChain that extends the shuffle mask to a larger; // type size to attempt to combine:; // shuffle(extract_subvector(x,c1),extract_subvector(y,c2),m1); // -->; // extract_subvector(shuffle(x,y,m2),0)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:154,Modifiability,extend,extends,154,"// Combine an arbitrary chain of shuffles + extract_subvectors into a single; // instruction if possible.; //; // Wrapper for combineX86ShuffleChain that extends the shuffle mask to a larger; // type size to attempt to combine:; // shuffle(extract_subvector(x,c1),extract_subvector(y,c2),m1); // -->; // extract_subvector(shuffle(x,y,m2),0)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Availability,mask,mask,14,// Create new mask for larger type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,// Attempt to peek through inputs and adjust mask when we extract from an; // upper subvector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Availability,mask,mask,53,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,Availability,mask,masks,120,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:199,Availability,mask,mask,199,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:266,Availability,mask,mask,266,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:292,Availability,mask,mask,292,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:243,Energy Efficiency,reduce,reduce,243,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:307,Performance,perform,performs,307,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Safety,detect,detect,113,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,masks,38,// Canonicalization of binary shuffle masks to improve pattern matching by; // commuting the inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Availability,mask,mask,37,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This may update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Availability,Mask,Mask,107,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This may update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Deployability,update,update,88,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This may update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Usability,simpl,simplify,112,"// Use SHUFPS for the permute so this will work on SSE2 targets,; // shuffle combining and domain handling will simplify this later on.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Performance,perform,perform,118,// Canonicalize binary shuffles of horizontal ops that use the; // same sources to an unary shuffle.; // TODO: Try to perform this fold even if the shuffle remains.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:192,Availability,mask,mask,192,// Attempt to constant fold all of the constant source ops.; // Returns true if the entire shuffle is folded to a constant.; // TODO: Extend this to merge multiple constant Ops and update the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:181,Deployability,update,update,181,// Attempt to constant fold all of the constant source ops.; // Returns true if the entire shuffle is folded to a constant.; // TODO: Extend this to merge multiple constant Ops and update the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:134,Modifiability,Extend,Extend,134,// Attempt to constant fold all of the constant source ops.; // Returns true if the entire shuffle is folded to a constant.; // TODO: Extend this to merge multiple constant Ops and update the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:146,Availability,mask,mask,146,"// If we're optimizing for size, only fold if at least one of the constants is; // only used once or the combined shuffle has included a variable mask; // shuffle, this is to avoid constant pool bloat.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:137,Modifiability,variab,variable,137,"// If we're optimizing for size, only fold if at least one of the constants is; // only used once or the combined shuffle has included a variable mask; // shuffle, this is to avoid constant pool bloat.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Performance,optimiz,optimizing,12,"// If we're optimizing for size, only fold if at least one of the constants is; // only used once or the combined shuffle has included a variable mask; // shuffle, this is to avoid constant pool bloat.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:175,Safety,avoid,avoid,175,"// If we're optimizing for size, only fold if at least one of the constants is; // only used once or the combined shuffle has included a variable mask; // shuffle, this is to avoid constant pool bloat.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,mask,mask,46,// Shuffle the constant bits according to the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:884,Availability,avail,available,884,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1580,Availability,redundant,redundant,1580,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1725,Availability,redundant,redundant,1725,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:188,Performance,optimiz,optimized,188,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:951,Safety,avoid,avoid,951,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1580,Safety,redund,redundant,1580,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1725,Safety,redund,redundant,1725,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:360,Usability,simpl,simpler,360,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1611,Usability,simpl,simplify,1611,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Usability,simpl,simple,24,// Bail if we hit a non-simple non-vector.; // FIXME: Just bail on f16 for now.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,mask,mask,26,// Create a demanded elts mask from the referenced elements of Op.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,mask,mask,26,// Extract target shuffle mask and resolve sentinels and inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Availability,mask,mask,78,"// If the shuffle result was smaller than the root, we need to adjust the; // mask indices and pad the mask with undefs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Availability,mask,mask,103,"// If the shuffle result was smaller than the root, we need to adjust the; // mask indices and pad the mask with undefs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,mask,masks,26,// We don't need to merge masks if the root is empty.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Safety,avoid,avoiding,35,"// Add the inputs to the Ops list, avoiding duplicates.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Availability,mask,mask,112,"// This function can be performance-critical, so we rely on the power-of-2; // knowledge that we have about the mask sizes to replace div/rem ops with; // bit-masks and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:159,Availability,mask,masks,159,"// This function can be performance-critical, so we rely on the power-of-2; // knowledge that we have about the mask sizes to replace div/rem ops with; // bit-masks and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Energy Efficiency,power,power-of-,64,"// This function can be performance-critical, so we rely on the power-of-2; // knowledge that we have about the mask sizes to replace div/rem ops with; // bit-masks and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Performance,perform,performance-critical,24,"// This function can be performance-critical, so we rely on the power-of-2; // knowledge that we have about the mask sizes to replace div/rem ops with; // bit-masks and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,"// Merge this shuffle operation's mask into our accumulated mask. Note that; // this shuffle's mask will be the first applied to the input, followed by; // the root mask to get us all the way to the root value arrangement. The; // reason for this order is that we are recursing up the operation chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Availability,mask,mask,60,"// Merge this shuffle operation's mask into our accumulated mask. Note that; // this shuffle's mask will be the first applied to the input, followed by; // the root mask to get us all the way to the root value arrangement. The; // reason for this order is that we are recursing up the operation chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:95,Availability,mask,mask,95,"// Merge this shuffle operation's mask into our accumulated mask. Note that; // this shuffle's mask will be the first applied to the input, followed by; // the root mask to get us all the way to the root value arrangement. The; // reason for this order is that we are recursing up the operation chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:165,Availability,mask,mask,165,"// Merge this shuffle operation's mask into our accumulated mask. Note that; // this shuffle's mask will be the first applied to the input, followed by; // the root mask to get us all the way to the root value arrangement. The; // reason for this order is that we are recursing up the operation chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Availability,mask,mask,31,// Just insert the scaled root mask value if it references an input other; // than the SrcOp we're currently inserting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Availability,mask,mask,55,// Peek through vector widenings and set out of bounds mask indices to undef.; // TODO: Can resolveTargetShuffleInputsAndMask do some of this?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update the list of shuffle nodes that have been combined so far.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:300,Modifiability,variab,variable,300,"// See if we can recurse into each shuffle source op (if it's a target; // shuffle). The source op should only be generally combined if it either has; // a single use (i.e. current Op) or all its users have already been combined,; // if not then we can still combine but should prevent generation of variable; // shuffles to avoid constant pool bloat.; // Don't recurse if we already have more source ops than we can combine in; // the remaining recursion depth.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:325,Safety,avoid,avoid,325,"// See if we can recurse into each shuffle source op (if it's a target; // shuffle). The source op should only be generally combined if it either has; // a single use (i.e. current Op) or all its users have already been combined,; // if not then we can still combine but should prevent generation of variable; // shuffles to avoid constant pool bloat.; // Don't recurse if we already have more source ops than we can combine in; // the remaining recursion depth.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Modifiability,variab,variable,103,// If constant fold failed and we only have constants - then we have; // multiple uses by a single non-variable shuffle - just bail.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Availability,mask,mask,37,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This will update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:108,Availability,Mask,Mask,108,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This will update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Deployability,update,update,89,// Canonicalize the combined shuffle mask chain with horizontal ops.; // NOTE: This will update the Ops and Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Availability,mask,mask,66,// Try to refine our inputs given our knowledge of target shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,mask,25,// What range of shuffle mask element values results in picking from Op?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Availability,mask,mask,48,"// Which elements of Op do we demand, given the mask's granularity?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,mask,mask,17,// We padded the mask with undefs. But we now need to undo that.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Usability,undo,undo,54,// We padded the mask with undefs. But we now need to undo that.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Availability,mask,mask,65,"// The Op itself may be of different VT, so we need to scale the mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Usability,simpl,simplified,23,"// Can this operand be simplified any further, given it's demanded elements?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:148,Safety,avoid,avoid,148,"// FIXME: should we rerun resolveTargetShuffleInputsAndMask() now?; // Widen any subvector shuffle inputs we've collected.; // TODO: Remove this to avoid generating temporary nodes, we should only; // widen once combineX86ShuffleChain has found a match.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Availability,mask,mask,48,// We can only combine unary and binary shuffle mask cases.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Availability,mask,mask,53,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,Availability,mask,masks,120,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:199,Availability,mask,mask,199,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:266,Availability,mask,mask,266,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:292,Availability,mask,mask,292,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:243,Energy Efficiency,reduce,reduce,243,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:307,Performance,perform,performs,307,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Safety,detect,detect,113,"// Minor canonicalization of the accumulated shuffle mask to make it easier; // to match below. All this does is detect masks with sequential pairs of; // elements, and shrink them to the half-width mask. It does this in a loop; // so it will reduce the size of the mask to the minimal width mask which; // performs an equivalent shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,masks,38,// Canonicalization of binary shuffle masks to improve pattern matching by; // commuting the inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Integrability,wrap,wrapper,17,/// Helper entry wrapper to combineX86ShufflesRecursively.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,/// Get the PSHUF-style mask from PSHUF node.; ///; /// This is a very minor wrapper around getTargetShuffleMask to easy forming v4; /// PSHUF-style masks that can be reused with such instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:149,Availability,mask,masks,149,/// Get the PSHUF-style mask from PSHUF node.; ///; /// This is a very minor wrapper around getTargetShuffleMask to easy forming v4; /// PSHUF-style masks that can be reused with such instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Integrability,wrap,wrapper,77,/// Get the PSHUF-style mask from PSHUF node.; ///; /// This is a very minor wrapper around getTargetShuffleMask to easy forming v4; /// PSHUF-style masks that can be reused with such instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Availability,mask,mask,67,"// If we have more than 128-bits, only the low 128-bits of shuffle mask; // matter. Check that the upper masks are repeats and remove them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Availability,mask,masks,105,"// If we have more than 128-bits, only the low 128-bits of shuffle mask; // matter. Check that the upper masks are repeats and remove them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Availability,mask,mask,21,// Merge this node's mask and our incoming mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,mask,43,// Merge this node's mask and our incoming mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Performance,load,loads,33,"// Attempt to commute shufps LHS loads:; // permilps(shufps(load(),x)) --> permilps(shufps(x,load()))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Performance,load,load,60,"// Attempt to commute shufps LHS loads:; // permilps(shufps(load(),x)) --> permilps(shufps(x,load()))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Performance,load,load,93,"// Attempt to commute shufps LHS loads:; // permilps(shufps(load(),x)) --> permilps(shufps(x,load()))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Testability,log,logical,66,"// Ensure we only shuffle whole vector src elements, unless its a logical; // binops where we can more aggressively move shuffles from dst to src.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Availability,mask,masks,60,// TODO: Handle v4f64 permutes with different low/high lane masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Performance,load,load,43,// Turn a 128-bit MOVDDUP of a full vector load into movddup+vzload.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Usability,simpl,simplify,52,"// If broadcasting from another shuffle, attempt to simplify it.; // TODO - we really need a general SimplifyDemandedVectorElts mechanism.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:101,Usability,Simpl,SimplifyDemandedVectorElts,101,"// If broadcasting from another shuffle, attempt to simplify it.; // TODO - we really need a general SimplifyDemandedVectorElts mechanism.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Energy Efficiency,Reduce,Reduce,3,// Reduce broadcast source vector to lowest 128-bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Performance,load,loads,63,"// vbroadcast(scalarload X) -> vbroadcast_load X; // For float loads, extract other uses of the scalar from the broadcast.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Performance,load,load,10,"// If the load value is used only by N, replace it via CombineTo N.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Performance,load,load,57,"// Due to isTypeDesirableForOp, we won't always shrink a load truncated to; // i16. So shrink it ourselves if we can make a broadcast_load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,extend,extending,34,// If this is a truncate of a non extending load we can just narrow it to; // use a broadcast_load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Performance,load,load,44,// If this is a truncate of a non extending load we can just narrow it to; // use a broadcast_load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Performance,load,load,28,"// If this is a truncate of load that has been shifted right, we can; // offset the pointer and use a narrower load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:111,Performance,load,load,111,"// If this is a truncate of load that has been shifted right, we can; // offset the pointer and use a narrower load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Performance,load,load,38,// Make sure the shift amount and the load size are divisible by 16.; // Don't do this if the load is volatile or atomic.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Performance,load,load,94,// Make sure the shift amount and the load size are divisible by 16.; // Don't do this if the load is volatile or atomic.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Performance,load,load,21,// vbroadcast(vector load X) -> vbroadcast_load,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Performance,load,load,14,// Unless the load is volatile or atomic.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Performance,load,load,37,"// If this a vzmovl of a full vector load, replace it with a vzload, unless; // the load is volatile.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Performance,load,load,84,"// If this a vzmovl of a full vector load, replace it with a vzload, unless; // the load is volatile.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:154,Usability,Simpl,SimplifyDemandedVectorElts,154,"// If this a VZEXT_MOVL of a VBROADCAST_LOAD, we don't need the broadcast; // and can just use a VZEXT_LOAD.; // FIXME: Is there some way to do this with SimplifyDemandedVectorElts?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,"// Load a scalar integer constant directly to XMM instead of transferring an; // immediate value from GPR.; // vzext_movl (scalar_to_vector C) --> load [C,0...]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:147,Performance,load,load,147,"// Load a scalar integer constant directly to XMM instead of transferring an; // immediate value from GPR.; // vzext_movl (scalar_to_vector C) --> load [C,0...]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the vector constant from constant pool.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:247,Energy Efficiency,reduce,reduces,247,// Pull subvector inserts into undef through VZEXT_MOVL by making it an; // insert into a zero vector. This helps get VZEXT_MOVL closer to; // scalar_to_vectors where 256/512 are canonicalized to an insert and a; // 128-bit scalar_to_vector. This reduces the number of isel patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Availability,mask,mask,118,"// blend(bitcast(x),bitcast(y)) -> bitcast(blend(x,y)) to narrower types.; // TODO: Handle MVT::v16i16 repeated blend mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Security,access,access,112,"// If we're permuting the upper 256-bits subvectors of a concatenation, then; // see if we can peek through and access the subvector directly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,mask,mask,11,// 512-bit mask uses 4 x i2 indices - if the msb is always set then only the; // upper subvector is used.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:54,Integrability,depend,dependency,54,// Zero/UNDEF insertion - zero out element and remove dependency.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,mask,19,// Update insertps mask srcidx and reference the source input directly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update insertps mask srcidx and reference the source input directly.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,mask,mask,17,// If the target mask is undef/zero then we must zero the element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Performance,load,load,51,"// If we're inserting an element from a vbroadcast load, fold the; // load into the X86insertps instruction. We need to convert the scalar; // load to a vector and clear the source lane of the INSERTPS control.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Performance,load,load,70,"// If we're inserting an element from a vbroadcast load, fold the; // load into the X86insertps instruction. We need to convert the scalar; // load to a vector and clear the source lane of the INSERTPS control.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:143,Performance,load,load,143,"// If we're inserting an element from a vbroadcast load, fold the; // load into the X86insertps instruction. We need to convert the scalar; // load to a vector and clear the source lane of the INSERTPS control.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:164,Usability,clear,clear,164,"// If we're inserting an element from a vbroadcast load, fold the; // load into the X86insertps instruction. We need to convert the scalar; // load to a vector and clear the source lane of the INSERTPS control.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Usability,simpl,simplifications,12,// Look for simplifications involving one or two shuffle instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Energy Efficiency,reduce,reduces,15,// See if this reduces to a PSHUFD which is no more expensive and can; // combine with more operations. Note that it has to at least flip the; // dwords as otherwise it would have been removed as a no-op.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Availability,mask,mask,16,// Map the word mask through the DWord mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,mask,39,// Map the word mask through the DWord mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,mask,mask,26,"/// Checks if the shuffle mask takes subsequent elements; /// alternately from two vectors.; /// For example <0, 5, 2, 7> or <8, 1, 10, 3, 12, 5, 14, 7> are both correct.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:114,Availability,mask,mask,114,// We only handle target-independent shuffles.; // FIXME: It would be easy and harmless to use the target shuffle mask; // extraction tool to support more.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:114,Availability,mask,mask,114,// We only handle target-independent shuffles.; // FIXME: It would be easy and harmless to use the target shuffle mask; // extraction tool to support more.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Availability,mask,mask,29,// Check for correct shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Availability,mask,mask,29,"// Construct the new shuffle mask. Elements from the first source retain their; // index, but elements from the second source no longer need to skip an undef.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,// Check if the shuffle mask accesses only the low half of each input vector; // (half-index output is 0 or 2).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Security,access,accesses,29,// Check if the shuffle mask accesses only the low half of each input vector; // (half-index output is 0 or 2).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Performance,load,load,36,// Attempt to combine into a vector load/broadcast.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,Availability,mask,mask,63,"// For AVX2, we sometimes want to combine; // (vector_shuffle <mask> (concat_vectors t1, undef); // (concat_vectors t2, undef)); // Into:; // (vector_shuffle <mask> (concat_vectors t1, t2), undef); // Since the latter can be efficiently lowered with VPERMD/VPERMQ",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:159,Availability,mask,mask,159,"// For AVX2, we sometimes want to combine; // (vector_shuffle <mask> (concat_vectors t1, undef); // (concat_vectors t2, undef)); // Into:; // (vector_shuffle <mask> (concat_vectors t1, t2), undef); // Since the latter can be efficiently lowered with VPERMD/VPERMQ",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:225,Energy Efficiency,efficient,efficiently,225,"// For AVX2, we sometimes want to combine; // (vector_shuffle <mask> (concat_vectors t1, undef); // (concat_vectors t2, undef)); // Into:; // (vector_shuffle <mask> (concat_vectors t1, t2), undef); // Since the latter can be efficiently lowered with VPERMD/VPERMQ",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,// Simplify source operands based on shuffle mask.; // TODO - merge this into combineX86ShufflesRecursively.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify source operands based on shuffle mask.; // TODO - merge this into combineX86ShufflesRecursively.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:134,Performance,Perform,Perform,134,"// Canonicalize SHUFFLE(UNARYOP(X)) -> UNARYOP(SHUFFLE(X)).; // Canonicalize SHUFFLE(BINOP(X,Y)) -> BINOP(SHUFFLE(X),SHUFFLE(Y)).; // Perform this after other shuffle combines to allow inner shuffles to be; // combined away first.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,mask,masks,36,// Simplify variable target shuffle masks based on the demanded elements.; // TODO: Handle DemandedBits in mask indices as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Availability,mask,mask,107,// Simplify variable target shuffle masks based on the demanded elements.; // TODO: Handle DemandedBits in mask indices as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Modifiability,variab,variable,12,// Simplify variable target shuffle masks based on the demanded elements.; // TODO: Handle DemandedBits in mask indices as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify variable target shuffle masks based on the demanded elements.; // TODO: Handle DemandedBits in mask indices as well?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Availability,mask,mask,71,// If we're demanding all elements don't bother trying to simplify the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Usability,simpl,simplify,58,// If we're demanding all elements don't bother trying to simplify the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Availability,mask,mask,56,// Attempt to generically simplify the variable shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,variab,variable,39,// Attempt to generically simplify the variable shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Usability,simpl,simplify,26,// Attempt to generically simplify the variable shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Availability,mask,mask,62,// Attempt to extract+simplify a (constant pool load) shuffle mask.; // TODO: Support other types from getTargetShuffleMaskIndices?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Performance,load,load,48,// Attempt to extract+simplify a (constant pool load) shuffle mask.; // TODO: Support other types from getTargetShuffleMaskIndices?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Usability,simpl,simplify,22,// Attempt to extract+simplify a (constant pool load) shuffle mask.; // TODO: Support other types from getTargetShuffleMaskIndices?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Availability,mask,mask,12,// Simplify mask if we have an undemanded element that is not undef.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify mask if we have an undemanded element that is not undef.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Performance,load,load,67,// Generate new constant pool entry + legalize immediately for the load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Usability,simpl,simplify,51,"// If this is ((X >>u C1) << ShAmt), see if we can simplify this into a; // single shift. We can do this if the bottom bits (which are shifted; // out) are never demanded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Usability,simpl,simplify,51,"// If this is ((X << C1) >>u ShAmt), see if we can simplify this into a; // single shift. We can do this if the top bits (which are shifted; // out) are never demanded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Performance,load,load,87,// If upper demanded elements are not demanded then simplify to a; // scalar_to_vector(load()).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Usability,simpl,simplify,52,// If upper demanded elements are not demanded then simplify to a; // scalar_to_vector(load()).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify PERMPD/PERMQ to extract_subvector.; // TODO: This should be done in shuffle combining.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify VPERM2F128/VPERM2I128 to extract_subvector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Usability,simpl,simplification,78,"// For splats, unless we *only* demand the 0'th element,; // stop attempts at simplification here, we aren't going to improve things,; // this is better than any potential shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Availability,mask,mask,27,// Get target/faux shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Availability,mask,mask,20,// Check if shuffle mask can be simplified to undef/zero/identity.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Usability,simpl,simplified,32,// Check if shuffle mask can be simplified to undef/zero/identity.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Usability,simpl,simplify,14,// Attempt to simplify inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:216,Energy Efficiency,reduce,reduce,216,"// If we don't demand all elements, then attempt to combine to a simpler; // shuffle.; // We need to convert the depth to something combineX86ShufflesRecursively; // can handle - so pretend its Depth == 0 again, and reduce the max depth; // to match. This prevents combineX86ShuffleChain from returning a; // combined shuffle that's the same as the original root, causing an; // infinite loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Usability,simpl,simpler,65,"// If we don't demand all elements, then attempt to combine to a simpler; // shuffle.; // We need to convert the depth to something combineX86ShufflesRecursively; // can handle - so pretend its Depth == 0 again, and reduce the max depth; // to match. This prevents combineX86ShuffleChain from returning a; // combined shuffle that's the same as the original root, causing an; // infinite loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,"// Simplify the input, using demanded bit information.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Availability,mask,mask,9,// Don't mask bits on 32-bit AVX512 targets which might lose a broadcast.; // FIXME: Can we bound this better?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Usability,simpl,simplify,43,"// If the RHS is a constant, see if we can simplify it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Usability,simpl,simplify,51,"// If this is ((X >>u C1) << ShAmt), see if we can simplify this into a; // single shift. We can do this if the bottom bits (which are shifted; // out) are never demanded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Usability,simpl,simplify,100,// If we demand no bits from the vector then we must have demanded; // bits from the implict zext - simplify to zero.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Safety,avoid,avoid,14,// Attempt to avoid multi-use ops if we don't need anything from them.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Usability,Simpl,SimplifyDemandedBits,36,// TODO - add general PACKSS/PACKUS SimplifyDemandedBits support.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Safety,avoid,avoid,14,// Attempt to avoid multi-use os if we don't need anything from it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTPS,3,// TESTPS/TESTPD only demands the sign bits of ALL the elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Testability,TEST,TESTPD,10,// TESTPS/TESTPD only demands the sign bits of ALL the elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Usability,Simpl,SimplifyDemandedBits,9,// NOTE: SimplifyDemandedBits won't do this for constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Availability,mask,mask,79,"// If the demanded bits has leading zeroes, we don't demand those from the; // mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,mask,mask,36,// The number of possible 1s in the mask determines the number of LSBs of; // operand 0 used. Undemanded bits from the mask don't matter so filter; // them before counting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:119,Availability,mask,mask,119,// The number of possible 1s in the mask determines the number of LSBs of; // operand 0 used. Undemanded bits from the mask don't matter so filter; // them before counting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Availability,mask,mask,32,"// Zeroes are retained from the mask, but not ones.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Availability,mask,mask,67,// The result will have at least as many trailing zeros as the non-mask; // operand since bits can only map to the same or higher bit position.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Modifiability,extend,extended,112,// iff we only need the sign bit then we can use the source directly.; // TODO: generalize where we only demand extended signbits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Security,access,accessed,51,// Bitmask that indicates which ops have only been accessed 'inline'.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Modifiability,extend,extend,91,"// If the upper ops of a concatenation are undef, then try to bitcast the; // lower op and extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:487,Modifiability,extend,extending,487,"// There are MOVMSK flavors for types v16i8, v32i8, v4f32, v8f32, v4f64 and; // v8f64. So all legal 128-bit and 256-bit vectors are covered except for; // v8i16 and v16i16.; // For these two cases, we can shuffle the upper element bytes to a; // consecutive sequence at the start of the vector and treat the results as; // v16i8 or v32i8, and for v16i8 this is the preferable solution. However,; // for v16i16 this is not the case, because the shuffle is expensive, so we; // avoid sign-extending to this type entirely.; // For example, t0 := (v8i16 sext(v8i1 x)) needs to be shuffled as:; // (v16i8 shuffle <0,2,4,6,8,10,12,14,u,u,...,u> (v16i8 bitcast t0), undef)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:476,Safety,avoid,avoid,476,"// There are MOVMSK flavors for types v16i8, v32i8, v4f32, v8f32, v4f64 and; // v8f64. So all legal 128-bit and 256-bit vectors are covered except for; // v8i16 and v16i16.; // For these two cases, we can shuffle the upper element bytes to a; // consecutive sequence at the start of the vector and treat the results as; // v16i8 or v32i8, and for v16i8 this is the preferable solution. However,; // for v16i16 this is not the case, because the shuffle is expensive, so we; // avoid sign-extending to this type entirely.; // For example, t0 := (v8i16 sext(v8i1 x)) needs to be shuffled as:; // (v16i8 shuffle <0,2,4,6,8,10,12,14,u,u,...,u> (v16i8 bitcast t0), undef)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,Modifiability,extend,extend,69,"// For cases such as (i4 bitcast (v4i1 setcc v4i64 v1, v2)); // sign-extend to a 256-bit operation to avoid truncation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Safety,avoid,avoid,102,"// For cases such as (i4 bitcast (v4i1 setcc v4i64 v1, v2)); // sign-extend to a 256-bit operation to avoid truncation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Modifiability,extend,extend,70,"// For cases such as (i8 bitcast (v8i1 setcc v8i32 v1, v2)),; // sign-extend to a 256-bit operation to match the compare.; // If the setcc operand is 128-bit, prefer sign-extending to 128-bit over; // 256-bit because the shuffle is cheaper than sign extending the result of; // the compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:171,Modifiability,extend,extending,171,"// For cases such as (i8 bitcast (v8i1 setcc v8i32 v1, v2)),; // sign-extend to a 256-bit operation to match the compare.; // If the setcc operand is 128-bit, prefer sign-extending to 128-bit over; // 256-bit because the shuffle is cheaper than sign extending the result of; // the compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:250,Modifiability,extend,extending,250,"// For cases such as (i8 bitcast (v8i1 setcc v8i32 v1, v2)),; // sign-extend to a 256-bit operation to match the compare.; // If the setcc operand is 128-bit, prefer sign-extending to 128-bit over; // 256-bit because the shuffle is cheaper than sign extending the result of; // the compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Modifiability,extend,extend,92,"// For the case (i16 bitcast (v16i1 setcc v16i16 v1, v2)),; // it is not profitable to sign-extend to 256-bit because this will; // require an extra cross-lane shuffle which is more expensive than; // truncating the result of the compare to 128-bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Testability,log,logic,12,// Look for logic ops.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,mask,39,// Make sure we have a bitcast between mask registers and a scalar type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:237,Availability,down,down,237,"// Recursive function that attempts to find if a bool vector node was originally; // a vector/float/double that got truncated/extended/bitcast to/from a scalar; // integer. If so, replace the scalar ops with bool vector equivalents back down; // the chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Modifiability,extend,extended,126,"// Recursive function that attempts to find if a bool vector node was originally; // a vector/float/double that got truncated/extended/bitcast to/from a scalar; // integer. If so, replace the scalar ops with bool vector equivalents back down; // the chain.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Modifiability,extend,extended,36,"// If we find a suitable source, an extended scalar becomes a subvector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Safety,avoid,avoid,102,"// If this is a bitcast between a MVT::v4i1/v2i1 and an illegal integer; // type, widen both sides to avoid a trip through memory.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Safety,avoid,avoid,102,"// If this is a bitcast between a MVT::v4i1/v2i1 and an illegal integer; // type, widen both sides to avoid a trip through memory.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:136,Availability,down,down,136,// Use zeros for the widening if we already have some zeroes. This can; // allow SimplifyDemandedBits to remove scalar ANDs that may be down; // stream of this.; // FIXME: It might make sense to detect a concat_vectors with a mix of; // zeroes and undef and turn it into insert_subvector for i1 vectors as; // a separate combine. What we can't do is canonicalize the operands of; // such a concat or we'll get into a loop with SimplifyDemandedBits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:195,Safety,detect,detect,195,// Use zeros for the widening if we already have some zeroes. This can; // allow SimplifyDemandedBits to remove scalar ANDs that may be down; // stream of this.; // FIXME: It might make sense to detect a concat_vectors with a mix of; // zeroes and undef and turn it into insert_subvector for i1 vectors as; // a separate combine. What we can't do is canonicalize the operands of; // such a concat or we'll get into a loop with SimplifyDemandedBits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Usability,Simpl,SimplifyDemandedBits,81,// Use zeros for the widening if we already have some zeroes. This can; // allow SimplifyDemandedBits to remove scalar ANDs that may be down; // stream of this.; // FIXME: It might make sense to detect a concat_vectors with a mix of; // zeroes and undef and turn it into insert_subvector for i1 vectors as; // a separate combine. What we can't do is canonicalize the operands of; // such a concat or we'll get into a loop with SimplifyDemandedBits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:427,Usability,Simpl,SimplifyDemandedBits,427,// Use zeros for the widening if we already have some zeroes. This can; // allow SimplifyDemandedBits to remove scalar ANDs that may be down; // stream of this.; // FIXME: It might make sense to detect a concat_vectors with a mix of; // zeroes and undef and turn it into insert_subvector for i1 vectors as; // a separate combine. What we can't do is canonicalize the operands of; // such a concat or we'll get into a loop with SimplifyDemandedBits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:135,Energy Efficiency,efficient,efficient,135,"// Since MMX types are special and don't usually play with other vector types,; // it's better to handle them early to be sure we emit efficient code by; // avoiding store-load conversions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:172,Performance,load,load,172,"// Since MMX types are special and don't usually play with other vector types,; // it's better to handle them early to be sure we emit efficient code by; // avoiding store-load conversions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:157,Safety,avoid,avoiding,157,"// Since MMX types are special and don't usually play with other vector types,; // it's better to handle them early to be sure we emit efficient code by; // avoiding store-load conversions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect MMX constant vectors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect bitcasts to x86mmx low word.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect bitcasts of 64-bit build vectors and convert to a; // MMX UNPCK/PSHUFW which takes MMX type inputs with the value in the; // lowest element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect bitcasts between element or subvector extraction to x86mmx.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect bitcasts from FP_TO_SINT to x86mmx.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Safety,avoid,avoids,140,// Look for MOVMSK that is maybe truncated and then bitcasted to vXi1.; // Turn it into a sign bit compare that produces a k-register. This avoids; // a trip through a GPR.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Availability,mask,mask,51,// Try to remove bitcasts from input and output of mask arithmetic to; // remove GPR<->K-register crossings.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Performance,load,load,158,"// Convert a bitcasted integer logic operation that has one bitcasted; // floating-point operand into a floating-point logic operation. This may; // create a load of a constant, but that is cheaper than materializing the; // constant in an integer register and transferring it to an SSE register or; // transferring the SSE operand to integer register and back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Testability,log,logic,31,"// Convert a bitcasted integer logic operation that has one bitcasted; // floating-point operand into a floating-point logic operation. This may; // create a load of a constant, but that is cheaper than materializing the; // constant in an integer register and transferring it to an SSE register or; // transferring the SSE operand to integer register and back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:119,Testability,log,logic,119,"// Convert a bitcasted integer logic operation that has one bitcasted; // floating-point operand into a floating-point logic operation. This may; // create a load of a constant, but that is cheaper than materializing the; // constant in an integer register and transferring it to an SSE register or; // transferring the SSE operand to integer register and back.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Testability,log,logic,11,"// bitcast(logic(bitcast(X), Y)) --> logic'(X, bitcast(Y))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Testability,log,logic,37,"// bitcast(logic(bitcast(X), Y)) --> logic'(X, bitcast(Y))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Testability,log,logic,11,"// bitcast(logic(X, bitcast(Y))) --> logic'(bitcast(X), Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Testability,log,logic,37,"// bitcast(logic(X, bitcast(Y))) --> logic'(bitcast(X), Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Modifiability,extend,extend,33,// The operand1 should be signed extend,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:116,Modifiability,extend,extended,116,"// (dpbusd (zext a), (sext, b)). Since the first operand should be unsigned; // value, we need to check Op0 is zero extended value. Op1 should be signed; // value, so we just check the signed bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Safety,detect,detect,21,"// Given a ABS node, detect the following pattern:; // (ABS (SUB (ZERO_EXTEND a), (ZERO_EXTEND b))).; // This is useful as it is the input into a SAD pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Modifiability,extend,extended,45,// Check if the operands of the sub are zero-extended from vectors of i8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend or truncate to MVT::i8 first.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:230,Energy Efficiency,reduce,reduce,230,"// VPDPBUSD(<16 x i32>C, <16 x i8>A, <16 x i8>B). For each dst element; // C[0] = C[0] + A[0]B[0] + A[1]B[1] + A[2]B[2] + A[3]B[3].; // The src A, B element type is i8, but the dst C element type is i32.; // When we calculate the reduce stage, we use src vector type vXi8 for it; // so we need logbias 2 to avoid extra 2 stages.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:307,Safety,avoid,avoid,307,"// VPDPBUSD(<16 x i32>C, <16 x i8>A, <16 x i8>B). For each dst element; // C[0] = C[0] + A[0]B[0] + A[1]B[1] + A[2]B[2] + A[3]B[3].; // The src A, B element type is i8, but the dst C element type is i32.; // When we calculate the reduce stage, we use src vector type vXi8 for it; // so we need logbias 2 to avoid extra 2 stages.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:294,Testability,log,logbias,294,"// VPDPBUSD(<16 x i32>C, <16 x i8>A, <16 x i8>B). For each dst element; // C[0] = C[0] + A[0]B[0] + A[1]B[1] + A[2]B[2] + A[3]B[3].; // The src A, B element type is i8, but the dst C element type is i32.; // When we calculate the reduce stage, we use src vector type vXi8 for it; // so we need logbias 2 to avoid extra 2 stages.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Modifiability,extend,extend,9,"// ""Zero-extend"" the i8 vectors. This is not a per-element zext, rather we; // fill in the missing vector elements with 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Modifiability,extend,extend,9,"// ""Zero-extend"" the i8 vectors. This is not a per-element zext, rather we; // fill in the missing vector elements with 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Availability,down,down,28,"// First, reduce the source down to 128-bit, applying BinOp to lo/hi.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Energy Efficiency,reduce,reduce,10,"// First, reduce the source down to 128-bit, applying BinOp to lo/hi.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Availability,mask,mask,73,"// PHMINPOSUW applies to UMIN(v8i16), for SMIN/SMAX/UMAX we must apply a mask; // to flip the value accordingly.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Availability,down,down,103,"// For v16i8 cases we need to perform UMIN on pairs of byte elements,; // shuffling each upper element down and insert zeros. This means that the; // v16i8 UMIN will leave the upper element as zero, performing zero-extension; // ready for the PHMINPOS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Performance,perform,perform,30,"// For v16i8 cases we need to perform UMIN on pairs of byte elements,; // shuffling each upper element down and insert zeros. This means that the; // v16i8 UMIN will leave the upper element as zero, performing zero-extension; // ready for the PHMINPOS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:199,Performance,perform,performing,199,"// For v16i8 cases we need to perform UMIN on pairs of byte elements,; // shuffling each upper element down and insert zeros. This means that the; // v16i8 UMIN will leave the upper element as zero, performing zero-extension; // ready for the PHMINPOS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Perform,Perform,3,"// Perform the PHMINPOS on a v8i16 vector,",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:227,Energy Efficiency,reduce,reduce,227,"// Make sure this isn't a vector of 1 element. The perf win from using; // MOVMSK diminishes with less elements in the reduction, but it is; // generally better to get the comparison over to the GPRs as soon as; // possible to reduce the number of vector ops.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:108,Availability,mask,mask,108,"// The setcc produces an i8 of 0/1, so extend that to the result width and; // negate to get the final 0/-1 mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Modifiability,extend,extend,39,"// The setcc produces an i8 of 0/1, so extend that to the result width and; // negate to get the final 0/-1 mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:146,Modifiability,extend,extended,146,"// We can't combine to vpdpbusd for zext, because each of the 4 multiplies; // done by vpdpbusd compute a signed 16-bit product that will be sign extended; // before adding into the accumulator.; // TODO:; // We also need to verify that the multiply has at least 2x the number of bits; // of the input. We shouldn't match; // (sign_extend (mul (vXi9 (zext (vXi8 X))), (vXi9 (zext (vXi8 Y)))).; // if (Root && (Root.getOpcode() == ISD::SIGN_EXTEND)); // Root = Root.getOperand(0);; // If there was a match, we want Root to be a mul.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Modifiability,extend,extend,28,// Check whether we have an extend and mul pattern,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Modifiability,extend,extended,38,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:163,Modifiability,extend,extend,163,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Modifiability,extend,extend,196,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:275,Modifiability,extend,extend,275,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:300,Modifiability,extend,extend,300,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:312,Modifiability,extend,extends,312,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:392,Modifiability,extend,extend,392,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:72,Safety,detect,detectZextAbsDiff,72,"// The operand is expected to be zero extended from i8; // (verified in detectZextAbsDiff).; // In order to convert to i64 and above, additional any/zero/sign; // extend is expected.; // The zero extend from 32 bit has no mathematical effect on the result.; // Also the sign extend is basically zero extend; // (extends the sign bit which is zero).; // So it is correct to skip the sign/zero extend instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,// Don't attempt this for boolean mask vectors or unknown extraction indices.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Performance,load,load,57,"// If we're extracting a single element from a broadcast load and there are; // no other users, just create a single load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:117,Performance,load,load,117,"// If we're extracting a single element from a broadcast load and there are; // no other users, just create a single load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:101,Integrability,depend,depending,101,"// We can only legally extract other elements from 128-bit vectors and in; // certain circumstances, depending on SSE-level.; // TODO: Investigate float/double extraction if it will be just stored.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,// Resolve the target shuffle inputs and mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Availability,mask,mask,39,// Attempt to narrow/widen the shuffle mask to the correct size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Availability,Mask,Mask,12,// Simplify Mask based on demanded element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify Mask based on demanded element.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Modifiability,extend,extend,60,"// If narrowing/widening failed, see if we can extract+zero-extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Performance,perform,perform,105,"/// Extracting a scalar FP value from vector element 0 is free, so extract each; /// operand first, then perform the math as a scalar op.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:125,Modifiability,enhance,enhancements,125,"// TODO: This switch could include FNEG and the x86-specific FP logic ops; // (FAND, FANDN, FOR, FXOR). But that may require enhancements to avoid; // missed load folding and fma+fneg combining.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Performance,load,load,158,"// TODO: This switch could include FNEG and the x86-specific FP logic ops; // (FAND, FANDN, FOR, FXOR). But that may require enhancements to avoid; // missed load folding and fma+fneg combining.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:141,Safety,avoid,avoid,141,"// TODO: This switch could include FNEG and the x86-specific FP logic ops; // (FAND, FANDN, FOR, FXOR). But that may require enhancements to avoid; // missed load folding and fma+fneg combining.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Testability,log,logic,64,"// TODO: This switch could include FNEG and the x86-specific FP logic ops; // (FAND, FANDN, FOR, FXOR). But that may require enhancements to avoid; // missed load folding and fma+fneg combining.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,"// Extend v4i8/v8i8 vector to v16i8, with undef upper 64-bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:183,Performance,perform,perform,183,"// See if we can use vXi8 PSADBW add reduction for larger zext types.; // If the source vector values are 0-255, then we can use PSADBW to; // sum+zext v8i8 subvectors to vXi64, then perform the reduction.; // TODO: See if its worth avoiding vXi16/i32 truncations?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:233,Safety,avoid,avoiding,233,"// See if we can use vXi8 PSADBW add reduction for larger zext types.; // If the source vector values are 0-255, then we can use PSADBW to; // sum+zext v8i8 subvectors to vXi64, then perform the reduction.; // TODO: See if its worth avoiding vXi16/i32 truncations?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,Performance,perform,performing,49,// TODO: We could truncate to vXi16/vXi32 before performing the reduction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:248,Modifiability,extend,extend,248,"// 256-bit horizontal instructions operate on 128-bit chunks rather than; // across the whole vector, so we need an extract + hop preliminary stage.; // This is the only step where the operands of the hop are not the same value.; // TODO: We could extend this to handle 512-bit or even longer vectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:216,Performance,load,loading,216,"/// Detect vector gather/scatter index generation and convert it from being a; /// bunch of shuffles and extracts into a somewhat faster sequence.; /// For i686, the best sequence is apparently storing the value and loading; /// scalars back, while for x64 we should use 64-bit extracts and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Safety,Detect,Detect,4,"/// Detect vector gather/scatter index generation and convert it from being a; /// bunch of shuffles and extracts into a somewhat faster sequence.; /// For i686, the best sequence is apparently storing the value and loading; /// scalars back, while for x64 we should use 64-bit extracts and shifts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:108,Availability,mask,masks,108,// Convert extract_element(bitcast(<X x i1>) -> bitcast(extract_subvector()).; // Improves lowering of bool masks on rust which splits them into byte array.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect mmx extraction of all bits as a i64. It works better as a bitcast.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect mmx to i32 conversion through a v2i32 elt extract.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Performance,optimiz,optimize,14,"// Attempt to optimize ADD/FADD/MUL reductions with HADD, promotion etc..",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Testability,test,testing,88,"// Attempt to extract a i1 element by using MOVMSK to extract the signbits; // and then testing the relevant element.; //; // Note that we only combine extracts on the *same* result number, i.e.; // t0 = merge_values a0, a1, a2, a3; // i1 = extract_vector_elt t0, Constant:i64<2>; // i1 = extract_vector_elt t0, Constant:i64<3>; // but not; // i1 = extract_vector_elt t0:1, Constant:i64<2>; // since the latter would need its own MOVMSK.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Availability,Mask,MaskIdx,26,"// extractelement vXi1 X, MaskIdx --> ((movmsk X) & Mask) == Mask; // Mask = 1 << MaskIdx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:52,Availability,Mask,Mask,52,"// extractelement vXi1 X, MaskIdx --> ((movmsk X) & Mask) == Mask; // Mask = 1 << MaskIdx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Availability,Mask,Mask,61,"// extractelement vXi1 X, MaskIdx --> ((movmsk X) & Mask) == Mask; // Mask = 1 << MaskIdx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Availability,Mask,Mask,70,"// extractelement vXi1 X, MaskIdx --> ((movmsk X) & Mask) == Mask; // Mask = 1 << MaskIdx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:82,Availability,Mask,MaskIdx,82,"// extractelement vXi1 X, MaskIdx --> ((movmsk X) & Mask) == Mask; // Mask = 1 << MaskIdx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Performance,load,loaded,29,"// If this extract is from a loaded vector value and will be used as an; // integer, that requires a potentially expensive XMM -> GPR transfer.; // Additionally, if we can convert to a scalar integer load, that will likely; // be folded into a subsequent integer op.; // Note: Unlike the related fold for this in DAGCombiner, this is not limited; // to a single-use of the loaded vector. For the reasons above, we; // expect this to be profitable even if it creates an extra load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:200,Performance,load,load,200,"// If this extract is from a loaded vector value and will be used as an; // integer, that requires a potentially expensive XMM -> GPR transfer.; // Additionally, if we can convert to a scalar integer load, that will likely; // be folded into a subsequent integer op.; // Note: Unlike the related fold for this in DAGCombiner, this is not limited; // to a single-use of the loaded vector. For the reasons above, we; // expect this to be profitable even if it creates an extra load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:373,Performance,load,loaded,373,"// If this extract is from a loaded vector value and will be used as an; // integer, that requires a potentially expensive XMM -> GPR transfer.; // Additionally, if we can convert to a scalar integer load, that will likely; // be folded into a subsequent integer op.; // Note: Unlike the related fold for this in DAGCombiner, this is not limited; // to a single-use of the loaded vector. For the reasons above, we; // expect this to be profitable even if it creates an extra load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:475,Performance,load,load,475,"// If this extract is from a loaded vector value and will be used as an; // integer, that requires a potentially expensive XMM -> GPR transfer.; // Additionally, if we can convert to a scalar integer load, that will likely; // be folded into a subsequent integer op.; // Note: Unlike the related fold for this in DAGCombiner, this is not limited; // to a single-use of the loaded vector. For the reasons above, we; // expect this to be profitable even if it creates an extra load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Modifiability,extend,extending,22,// Input type must be extending a bool vector (bit-casted from a scalar; // integer) to legal integer types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Availability,down,down,92,"// If the scalar integer is greater than the vector element size, then we; // must split it down into sub-sections for broadcasting. For example:; // i16 -> v16i8 (i16 -> v8i16 -> v16i8) with 2 sub-sections.; // i32 -> v32i8 (i32 -> v8i32 -> v32i8) with 4 sub-sections.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:229,Performance,load,load,229,"// If we have register broadcast instructions, use the scalar size as the; // element type for the shuffle. Then cast to the wider element type. The; // widened bits won't be used, and this might allow the use of a broadcast; // load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:50,Modifiability,extend,extend,50,"// For smaller scalar integers, we can simply any-extend it to the vector; // element size (we don't care about the upper bits) and broadcast it to all; // elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:39,Usability,simpl,simply,39,"// For smaller scalar integers, we can simply any-extend it to the vector; // element size (we don't care about the upper bits) and broadcast it to all; // elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Availability,mask,mask,8,"// Now, mask the relevant bit in each element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Modifiability,extend,extend,35,// Compare against the bitmask and extend the result.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Availability,down,down,58,"// For SEXT, this is now done, otherwise shift the result down for; // zero-extension.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Testability,log,logic,100,"/// If a vector select has an operand that is -1 or 0, try to simplify the; /// select to a bitwise logic operation.; /// TODO: Move to DAGCombiner, possibly using TargetLowering::hasAndNot()?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Usability,simpl,simplify,62,"/// If a vector select has an operand that is -1 or 0, try to simplify the; /// select to a bitwise logic operation.; /// TODO: Move to DAGCombiner, possibly using TargetLowering::hasAndNot()?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Testability,assert,assert,88,// TODO: Use isNullOrNullSplat() to distinguish constants with undefs?; // TODO: Can we assert that both operands are not zeros (because that should; // get simplified at node creation time)?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:157,Usability,simpl,simplified,157,// TODO: Use isNullOrNullSplat() to distinguish constants with undefs?; // TODO: Can we assert that both operands are not zeros (because that should; // get simplified at node creation time)?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Availability,mask,mask,45,"// To use the condition operand as a bitwise mask, it must have elements that; // are the same size as the select elements. Ie, the condition operand must; // have already been promoted from the IR select condition type <N x i1>.; // Don't check if the types themselves are equal because that excludes; // vector floating-point selects.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Testability,log,logical,56,// Cond value must be 'sign splat' to be converted to a logical op.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Testability,log,logic,51,"// We're going to use the condition bit in math or logic ops. We could allow; // this with a wider condition value (post-legalization it becomes an i8),; // but if nothing is creating selects that late, it doesn't matter.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:5,Energy Efficiency,power,power-of-,5,"// A power-of-2 multiply is just a shift. LEA also cheaply handles multiply by; // 3, 5, or 9 with i32/i64, so those get transformed too.; // TODO: For constants that overflow or do not differ by power-of-2 or small; // multiplier, convert to 'and' + 'add'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Energy Efficiency,power,power-of-,196,"// A power-of-2 multiply is just a shift. LEA also cheaply handles multiply by; // 3, 5, or 9 with i32/i64, so those get transformed too.; // TODO: For constants that overflow or do not differ by power-of-2 or small; // multiplier, convert to 'and' + 'add'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Energy Efficiency,efficient,efficient,18,"// We have a more efficient lowering for ""(X == 0) ? Y : -1"" using SBB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Modifiability,variab,variable,107,"/// If this is a *dynamic* select (non-constant condition) and we can match; /// this node with one of the variable blend instructions, restructure the; /// condition so that blends can use the high (sign) bit of each element.; /// This function will also call SimplifyDemandedBits on already created; /// BLENDV to perform additional simplifications.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:316,Performance,perform,perform,316,"/// If this is a *dynamic* select (non-constant condition) and we can match; /// this node with one of the variable blend instructions, restructure the; /// condition so that blends can use the high (sign) bit of each element.; /// This function will also call SimplifyDemandedBits on already created; /// BLENDV to perform additional simplifications.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:261,Usability,Simpl,SimplifyDemandedBits,261,"/// If this is a *dynamic* select (non-constant condition) and we can match; /// this node with one of the variable blend instructions, restructure the; /// condition so that blends can use the high (sign) bit of each element.; /// This function will also call SimplifyDemandedBits on already created; /// BLENDV to perform additional simplifications.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:335,Usability,simpl,simplifications,335,"/// If this is a *dynamic* select (non-constant condition) and we can match; /// this node with one of the variable blend instructions, restructure the; /// condition so that blends can use the high (sign) bit of each element.; /// This function will also call SimplifyDemandedBits on already created; /// BLENDV to perform additional simplifications.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Availability,avail,available,29,// Dynamic blending was only available from SSE4.1 onward.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,avail,available,24,// Byte blends are only available in AVX2,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:138,Availability,mask,mask-registers,138,// Don't optimize before the condition has been transformed to a legal type; // and don't ever optimize vector selects that map to AVX512 mask-registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Performance,optimiz,optimize,9,// Don't optimize before the condition has been transformed to a legal type; // and don't ever optimize vector selects that map to AVX512 mask-registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:95,Performance,optimiz,optimize,95,// Don't optimize before the condition has been transformed to a legal type; // and don't ever optimize vector selects that map to AVX512 mask-registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Deployability,Update,Update,102,"// If we changed the computation somewhere in the DAG, this change will; // affect all users of Cond. Update all the nodes so that we do not use; // the generic VSELECT anymore. Otherwise, we may perform wrong; // optimizations as we messed with the actual expectation for the vector; // boolean values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Performance,perform,perform,196,"// If we changed the computation somewhere in the DAG, this change will; // affect all users of Cond. Update all the nodes so that we do not use; // the generic VSELECT anymore. Otherwise, we may perform wrong; // optimizations as we messed with the actual expectation for the vector; // boolean values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:214,Performance,optimiz,optimizations,214,"// If we changed the computation somewhere in the DAG, this change will; // affect all users of Cond. Update all the nodes so that we do not use; // the generic VSELECT anymore. Otherwise, we may perform wrong; // optimizations as we messed with the actual expectation for the vector; // boolean values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Usability,simpl,simplify,42,// Otherwise we can still at least try to simplify multiple use bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:324,Availability,mask,mask,324,"// Try to match:; // (or (and (M, (sub 0, X)), (pandn M, X))); // which is a special case of:; // (select M, (sub 0, X), X); // Per:; // http://graphics.stanford.edu/~seander/bithacks.html#ConditionalNegate; // We know that, if fNegate is 0 or 1:; // (fNegate ? -v : v) == ((v ^ -fNegate) + fNegate); //; // Here, we have a mask, M (all 1s or 0), and, similarly, we know that:; // ((M & 1) ? -X : X) == ((X ^ -(M & 1)) + (M & 1)); // ( M ? -X : X) == ((X ^ M ) + (M & 1)); // This lets us transform our vselect to:; // (add (xor X, M), (and M, 1)); // And further to:; // (sub (xor X, M), M)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Availability,mask,mask,55,"// Commute LHS and RHS to create opportunity to select mask instruction.; // (vselect M, L, R) -> (vselect ~M, R, L)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Performance,optimiz,optimize,60,// Try simplification again because we use this function to optimize; // BLENDV nodes that are not handled by the generic combiner.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:7,Usability,simpl,simplification,7,// Try simplification again because we use this function to optimize; // BLENDV nodes that are not handled by the generic combiner.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Availability,avail,available,18,"// When avx512 is available the lhs operand of select instruction can be; // folded with mask instruction, while the rhs operand can't. Commute the; // lhs and rhs of the select instruction to create the opportunity of; // folding.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Availability,mask,mask,89,"// When avx512 is available the lhs operand of select instruction can be; // folded with mask instruction, while the rhs operand can't. Commute the; // lhs and rhs of the select instruction to create the opportunity of; // folding.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Availability,mask,masks,112,"// Attempt to combine (select M, (sub 0, X), X) -> (sub (xor X, M), M).; // Limit this to cases of non-constant masks that createShuffleMaskFromVSELECT; // can't catch, plus vXi8 cases where we'd likely end up with BLENDV.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Availability,mask,mask,40,"// getConstVector sets negative shuffle mask values as undef, so ensure; // we hardcode SM_SentinelZero values to zero (0x80).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:229,Safety,unsafe,unsafe-math,229,"// If we have SSE[12] support, try to form min/max nodes. SSE min/max; // instructions match the semantics of the common C idiom x<y?x:y but not; // x<=y?x:y, because of how they handle negative zero (which can be; // ignored in unsafe-math mode).; // We also try to create v2f32 min/max nodes, which we later widen to v4f32.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Availability,mask,mask,8,"// Some mask scalar intrinsics rely on checking if only one bit is set; // and implement it in C code like this:; // A[0] = (U & 1) ? A[0] : W[0];; // This creates some redundant instructions that break pattern matching.; // fold (select (setcc (and (X, 1), 0, seteq), Y, Z)) -> select(and(X, 1),Z,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:169,Availability,redundant,redundant,169,"// Some mask scalar intrinsics rely on checking if only one bit is set; // and implement it in C code like this:; // A[0] = (U & 1) ? A[0] : W[0];; // This creates some redundant instructions that break pattern matching.; // fold (select (setcc (and (X, 1), 0, seteq), Y, Z)) -> select(and(X, 1),Z,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:169,Safety,redund,redundant,169,"// Some mask scalar intrinsics rely on checking if only one bit is set; // and implement it in C code like this:; // A[0] = (U & 1) ? A[0] : W[0];; // This creates some redundant instructions that break pattern matching.; // fold (select (setcc (and (X, 1), 0, seteq), Y, Z)) -> select(and(X, 1),Z,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:255,Modifiability,extend,extend,255,"// v16i8 (select v16i1, v16i8, v16i8) does not have a proper; // lowering on KNL. In this case we convert it to; // v16i8 (select v16i8, v16i8, v16i8) and use AVX instruction.; // The same situation all vectors of i8 and i16 without BWI.; // Make sure we extend these even before type legalization gets a chance to; // split wide vectors.; // Since SKX these selects have a proper lowering.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Availability,mask,mask,77,"// AVX512 - Extend select with zero to merge with target shuffle.; // select(mask, extract_subvector(shuffle(x)), zero) -->; // extract_subvector(select(insert_subvector(mask), shuffle(x), zero)); // TODO - support non target shuffles as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:170,Availability,mask,mask,170,"// AVX512 - Extend select with zero to merge with target shuffle.; // select(mask, extract_subvector(shuffle(x)), zero) -->; // extract_subvector(select(insert_subvector(mask), shuffle(x), zero)); // TODO - support non target shuffles as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Modifiability,Extend,Extend,12,"// AVX512 - Extend select with zero to merge with target shuffle.; // select(mask, extract_subvector(shuffle(x)), zero) -->; // extract_subvector(select(insert_subvector(mask), shuffle(x), zero)); // TODO - support non target shuffles as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:324,Testability,test,testl,324,"// Canonicalize min/max:; // (x > 0) ? x : 0 -> (x >= 0) ? x : 0; // (x < -1) ? x : -1 -> (x <= -1) ? x : -1; // This allows use of COND_S / COND_NS (see TranslateX86CC) which eliminates; // the need for an extra compare against zero. e.g.; // (a - b) > 0 : (a - b) ? 0 -> (a - b) >= 0 : (a - b) ? 0; // subl %esi, %edi; // testl %edi, %edi; // movl $0, %eax; // cmovgl %edi, %eax; // =>; // xorl %eax, %eax; // subl %esi, $edi; // cmovsl %eax, %edi; //; // We can also canonicalize; // (x s> 1) ? x : 1 -> (x s>= 1) ? x : 1 -> (x s> 0) ? x : 1; // (x u> 1) ? x : 1 -> (x u>= 1) ? x : 1 -> (x != 0) ? x : 1; // This allows the use of a test instruction for the compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:636,Testability,test,test,636,"// Canonicalize min/max:; // (x > 0) ? x : 0 -> (x >= 0) ? x : 0; // (x < -1) ? x : -1 -> (x <= -1) ? x : -1; // This allows use of COND_S / COND_NS (see TranslateX86CC) which eliminates; // the need for an extra compare against zero. e.g.; // (a - b) > 0 : (a - b) ? 0 -> (a - b) >= 0 : (a - b) ? 0; // subl %esi, %edi; // testl %edi, %edi; // movl $0, %eax; // cmovgl %edi, %eax; // =>; // xorl %eax, %eax; // subl %esi, $edi; // cmovsl %eax, %edi; //; // We can also canonicalize; // (x s> 1) ? x : 1 -> (x s>= 1) ? x : 1 -> (x s> 0) ? x : 1; // (x u> 1) ? x : 1 -> (x u>= 1) ? x : 1 -> (x != 0) ? x : 1; // This allows the use of a test instruction for the compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Availability,mask,masking,126,// Check if the first operand is all zeros and Cond type is vXi1.; // If this an avx512 target we can improve the use of zero masking by; // swapping the operands and inverting the condition.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:58,Availability,mask,mask,58,// Attempt to convert a (vXi1 bitcast(iX Cond)) selection mask before it might; // get split by legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Performance,optimiz,optimize,10,// Try to optimize vXi1 selects if both operands are either all constants or; // bitcasts from scalar integer type. In that case we can convert the operands; // to integer and use an integer select which will be converted to a CMOV.; // We need to take a little bit of care to avoid creating an i64 type after; // type legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:277,Safety,avoid,avoid,277,// Try to optimize vXi1 selects if both operands are either all constants or; // bitcasts from scalar integer type. In that case we can convert the operands; // to integer and use an integer select which will be converted to a CMOV.; // We need to take a little bit of care to avoid creating an i64 type after; // type legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:59,Availability,mask,mask,59,"// If this is ""((X & C) == 0) ? Y : Z"" and C is a constant mask vector of; // single bits, then invert the predicate and swap the select operands.; // This can lower using a vector shift bit-hack rather than mask and compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:208,Availability,mask,mask,208,"// If this is ""((X & C) == 0) ? Y : Z"" and C is a constant mask vector of; // single bits, then invert the predicate and swap the select operands.; // This can lower using a vector shift bit-hack rather than mask and compare.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,mask,13,// The 'and' mask must be composed of power-of-2 constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Energy Efficiency,power,power-of-,38,// The 'and' mask must be composed of power-of-2 constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Availability,mask,mask,48,"// If we have a non-splat but still powers-of-2 mask, AVX1 can use pmulld; // and AVX2 can use vpsllv{dq}. 8-bit lacks a proper shift or multiply.; // 16-bit lacks a proper blendv.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Energy Efficiency,power,powers-of-,36,"// If we have a non-splat but still powers-of-2 mask, AVX1 can use pmulld; // and AVX2 can use vpsllv{dq}. 8-bit lacks a proper shift or multiply.; // 16-bit lacks a proper blendv.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,mask,43,// Create a left-shift constant to get the mask bits over to the sign-bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:174,Deployability,update,updated,174,"// Can't replace the cmp if it has more uses than the one we're looking at.; // FIXME: We would like to be able to handle this, but would need to make sure; // all uses were updated.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,rewrite,rewrite,34,"// The CC is fine, but we need to rewrite the LHS of the comparison as an; // atomic sub.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Testability,test,test,27,"// Check whether a boolean test is testing a boolean value generated by; // X86ISD::SETCC. If so, return the operand of that SETCC and proper condition; // code.; //; // Simplify the following patterns:; // (Op (CMP (SETCC Cond EFLAGS) 1) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 0) NEQ); // to (Op EFLAGS Cond); //; // (Op (CMP (SETCC Cond EFLAGS) 0) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 1) NEQ); // to (Op EFLAGS !Cond); //; // where Op could be BRCOND or CMOV.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Testability,test,testing,35,"// Check whether a boolean test is testing a boolean value generated by; // X86ISD::SETCC. If so, return the operand of that SETCC and proper condition; // code.; //; // Simplify the following patterns:; // (Op (CMP (SETCC Cond EFLAGS) 1) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 0) NEQ); // to (Op EFLAGS Cond); //; // (Op (CMP (SETCC Cond EFLAGS) 0) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 1) NEQ); // to (Op EFLAGS !Cond); //; // where Op could be BRCOND or CMOV.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:170,Usability,Simpl,Simplify,170,"// Check whether a boolean test is testing a boolean value generated by; // X86ISD::SETCC. If so, return the operand of that SETCC and proper condition; // code.; //; // Simplify the following patterns:; // (Op (CMP (SETCC Cond EFLAGS) 1) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 0) NEQ); // to (Op EFLAGS Cond); //; // (Op (CMP (SETCC Cond EFLAGS) 0) EQ) or; // (Op (CMP (SETCC Cond EFLAGS) 1) NEQ); // to (Op EFLAGS !Cond); //; // where Op could be BRCOND or CMOV.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Modifiability,extend,extended,92,// Check CMP operands. One of them should be 0 or 1 and the other should be; // an SetCC or extended from it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Safety,unsafe,unsafe,65,"// Since SETCC_CARRY gives output based on R = CF ? ~0 : 0, it's unsafe to; // simplify it if the result of SETCC_CARRY is not canonicalized to 0 or 1,; // i.e. it's a comparison against true but the result of SETCC_CARRY is not; // truncated to i1 using 'and'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Usability,simpl,simplify,79,"// Since SETCC_CARRY gives output based on R = CF ? ~0 : 0, it's unsafe to; // simplify it if the result of SETCC_CARRY is not canonicalized to 0 or 1,; // i.e. it's a comparison against true but the result of SETCC_CARRY is not; // truncated to i1 using 'and'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Safety,avoid,avoid,81,"/// If we are inverting an PTEST/TESTP operand, attempt to adjust the CC; /// to avoid the inversion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Testability,TEST,TESTP,33,"/// If we are inverting an PTEST/TESTP operand, attempt to adjust the CC; /// to avoid the inversion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:9,Testability,TEST,TESTP,9,// PTEST/TESTP sets EFLAGS as:; // TESTZ: ZF = (Op0 & Op1) == 0; // TESTC: CF = (~Op0 & Op1) == 0; // TESTNZC: ZF == 0 && CF == 0,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Testability,TEST,TESTZ,35,// PTEST/TESTP sets EFLAGS as:; // TESTZ: ZF = (Op0 & Op1) == 0; // TESTC: CF = (~Op0 & Op1) == 0; // TESTNZC: ZF == 0 && CF == 0,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Testability,TEST,TESTC,68,// PTEST/TESTP sets EFLAGS as:; // TESTZ: ZF = (Op0 & Op1) == 0; // TESTC: CF = (~Op0 & Op1) == 0; // TESTNZC: ZF == 0 && CF == 0,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Testability,TEST,TESTNZC,102,// PTEST/TESTP sets EFLAGS as:; // TESTZ: ZF = (Op0 & Op1) == 0; // TESTC: CF = (~Op0 & Op1) == 0; // TESTNZC: ZF == 0 && CF == 0,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TEST,3,"// TEST*(~X,Y) == TEST*(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Testability,TEST,TEST,18,"// TEST*(~X,Y) == TEST*(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,test,testc,3,// testc -> testz.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Testability,test,testz,12,// testc -> testz.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Testability,test,testc,4,// !testc -> !testz.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Testability,test,testz,14,// !testc -> !testz.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,test,testz,3,// testz -> testc.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Testability,test,testc,12,// testz -> testc.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Testability,test,testz,4,// !testz -> !testc.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Testability,test,testc,14,// !testz -> !testc.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,test,testnzc,3,// testnzc -> testnzc (no change).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Testability,test,testnzc,14,// testnzc -> testnzc (no change).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTC,3,"// TESTC(X,~X) == TESTC(X,-1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Testability,TEST,TESTC,18,"// TESTC(X,~X) == TESTC(X,-1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(X,~Y) == TESTC(Y,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Testability,TEST,TESTC,18,"// TESTZ(X,~Y) == TESTC(Y,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(AND(X,Y),AND(X,Y)) == TESTZ(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Testability,TEST,TESTZ,31,"// TESTZ(AND(X,Y),AND(X,Y)) == TESTZ(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(AND(~X,Y),AND(~X,Y)) == TESTC(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Testability,TEST,TESTC,33,"// TESTZ(AND(~X,Y),AND(~X,Y)) == TESTC(X,Y)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Energy Efficiency,efficient,efficiently,85,"// If every element is an all-sign value, see if we can use TESTP/MOVMSK; // to more efficiently extract the sign bits and compare that.; // TODO: Handle TESTC with comparison inversion.; // TODO: Can we remove SimplifyMultipleUseDemandedBits and rely on; // TESTP/MOVMSK combines to make sure its never worse than PTEST?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Testability,TEST,TESTP,60,"// If every element is an all-sign value, see if we can use TESTP/MOVMSK; // to more efficiently extract the sign bits and compare that.; // TODO: Handle TESTC with comparison inversion.; // TODO: Can we remove SimplifyMultipleUseDemandedBits and rely on; // TESTP/MOVMSK combines to make sure its never worse than PTEST?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:154,Testability,TEST,TESTC,154,"// If every element is an all-sign value, see if we can use TESTP/MOVMSK; // to more efficiently extract the sign bits and compare that.; // TODO: Handle TESTC with comparison inversion.; // TODO: Can we remove SimplifyMultipleUseDemandedBits and rely on; // TESTP/MOVMSK combines to make sure its never worse than PTEST?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:259,Testability,TEST,TESTP,259,"// If every element is an all-sign value, see if we can use TESTP/MOVMSK; // to more efficiently extract the sign bits and compare that.; // TODO: Handle TESTC with comparison inversion.; // TODO: Can we remove SimplifyMultipleUseDemandedBits and rely on; // TESTP/MOVMSK combines to make sure its never worse than PTEST?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:211,Usability,Simpl,SimplifyMultipleUseDemandedBits,211,"// If every element is an all-sign value, see if we can use TESTP/MOVMSK; // to more efficiently extract the sign bits and compare that.; // TODO: Handle TESTC with comparison inversion.; // TODO: Can we remove SimplifyMultipleUseDemandedBits and rely on; // TESTP/MOVMSK combines to make sure its never worse than PTEST?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(-1,X) == TESTZ(X,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Testability,TEST,TESTZ,18,"// TESTZ(-1,X) == TESTZ(X,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(X,-1) == TESTZ(X,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Testability,TEST,TESTZ,18,"// TESTZ(X,-1) == TESTZ(X,X)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Testability,TEST,TESTZ,3,"// TESTZ(OR(LO(X),HI(X)),OR(LO(Y),HI(Y))) -> TESTZ(X,Y); // TODO: Add COND_NE handling?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Testability,TEST,TESTZ,45,"// TESTZ(OR(LO(X),HI(X)),OR(LO(Y),HI(Y))) -> TESTZ(X,Y); // TODO: Add COND_NE handling?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Usability,simpl,simplify,14,// Attempt to simplify the MOVMSK input based on the comparison type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Testability,test,tests,140,"// TODO: Check more combining cases for me.; // Here we check the cmp use number to decide do combining or not.; // Currently we only get 2 tests about combining ""MOVMSK(CONCAT(..))""; // and ""MOVMSK(PCMPEQ(..))"" are fit to use this constraint.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:96,Availability,down,down,96,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:439,Availability,mask,mask,439,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Modifiability,extend,extend,89,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:174,Safety,avoid,avoiding,174,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:202,Security,expose,expose,202,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:223,Usability,Simpl,SimplifyDemandedBits,223,"// See if we can peek through to a vector with a wider element type, if the; // signbits extend down to all the sub-elements as well.; // Calling MOVMSK with the wider type, avoiding the bitcast, helps expose; // potential SimplifyDemandedBits/Elts cases.; // If we looked through a truncate that discard bits, we can't do this; // transform.; // FIXME: We could do this transform for truncates that discarded bits by; // inserting an AND mask between the new MOVMSK and the CMP.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Testability,test,testing,21,// Ensure MOVMSK was testing every signbit of BC.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:123,Availability,mask,mask,123,// See if we can avoid a PACKSS by calling MOVMSK on the sources.; // For vXi16 cases we can use a v2Xi8 PMOVMSKB. We must mask out; // sign bits prior to the comparison with zero unless we know that; // the vXi16 splats the sign bit down to the lower i8 half.; // TODO: Handle all_of patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:234,Availability,down,down,234,// See if we can avoid a PACKSS by calling MOVMSK on the sources.; // For vXi16 cases we can use a v2Xi8 PMOVMSKB. We must mask out; // sign bits prior to the comparison with zero unless we know that; // the vXi16 splats the sign bit down to the lower i8 half.; // TODO: Handle all_of patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Safety,avoid,avoid,17,// See if we can avoid a PACKSS by calling MOVMSK on the sources.; // For vXi16 cases we can use a v2Xi8 PMOVMSKB. We must mask out; // sign bits prior to the comparison with zero unless we know that; // the vXi16 splats the sign bit down to the lower i8 half.; // TODO: Handle all_of patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:271,Availability,mask,mask,271,"// MOVMSK(SHUFFLE(X,u)) -> MOVMSK(X) iff every element is referenced.; // Since we peek through a bitcast, we need to be careful if the base vector; // type has smaller elements than the MOVMSK type. In that case, even if; // all the elements are demanded by the shuffle mask, only the ""high""; // elements which have highbits that align with highbits in the MOVMSK vec; // elements are actually demanded. A simplification of spurious operations; // on the ""low"" elements take place during other simplifications.; //; // For example:; // MOVMSK64(BITCAST(SHUF32 X, (1,0,3,2))) even though all the elements are; // demanded, because we are swapping around the result can change.; //; // To address this, we check that we can scale the shuffle mask to MOVMSK; // element width (this will ensure ""high"" elements match). Its slightly overly; // conservative, but fine for an edge case fold.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:741,Availability,mask,mask,741,"// MOVMSK(SHUFFLE(X,u)) -> MOVMSK(X) iff every element is referenced.; // Since we peek through a bitcast, we need to be careful if the base vector; // type has smaller elements than the MOVMSK type. In that case, even if; // all the elements are demanded by the shuffle mask, only the ""high""; // elements which have highbits that align with highbits in the MOVMSK vec; // elements are actually demanded. A simplification of spurious operations; // on the ""low"" elements take place during other simplifications.; //; // For example:; // MOVMSK64(BITCAST(SHUF32 X, (1,0,3,2))) even though all the elements are; // demanded, because we are swapping around the result can change.; //; // To address this, we check that we can scale the shuffle mask to MOVMSK; // element width (this will ensure ""high"" elements match). Its slightly overly; // conservative, but fine for an edge case fold.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:407,Usability,simpl,simplification,407,"// MOVMSK(SHUFFLE(X,u)) -> MOVMSK(X) iff every element is referenced.; // Since we peek through a bitcast, we need to be careful if the base vector; // type has smaller elements than the MOVMSK type. In that case, even if; // all the elements are demanded by the shuffle mask, only the ""high""; // elements which have highbits that align with highbits in the MOVMSK vec; // elements are actually demanded. A simplification of spurious operations; // on the ""low"" elements take place during other simplifications.; //; // For example:; // MOVMSK64(BITCAST(SHUF32 X, (1,0,3,2))) even though all the elements are; // demanded, because we are swapping around the result can change.; //; // To address this, we check that we can scale the shuffle mask to MOVMSK; // element width (this will ensure ""high"" elements match). Its slightly overly; // conservative, but fine for an edge case fold.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:495,Usability,simpl,simplifications,495,"// MOVMSK(SHUFFLE(X,u)) -> MOVMSK(X) iff every element is referenced.; // Since we peek through a bitcast, we need to be careful if the base vector; // type has smaller elements than the MOVMSK type. In that case, even if; // all the elements are demanded by the shuffle mask, only the ""high""; // elements which have highbits that align with highbits in the MOVMSK vec; // elements are actually demanded. A simplification of spurious operations; // on the ""low"" elements take place during other simplifications.; //; // For example:; // MOVMSK64(BITCAST(SHUF32 X, (1,0,3,2))) even though all the elements are; // demanded, because we are swapping around the result can change.; //; // To address this, we check that we can scale the shuffle mask to MOVMSK; // element width (this will ensure ""high"" elements match). Its slightly overly; // conservative, but fine for an edge case fold.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Testability,TEST,TESTPS,26,"// MOVMSKPS(V) !=/== 0 -> TESTPS(V,V); // MOVMSKPD(V) !=/== 0 -> TESTPD(V,V); // MOVMSKPS(V) !=/== -1 -> TESTPS(V,V); // MOVMSKPD(V) !=/== -1 -> TESTPD(V,V); // iff every element is referenced.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:65,Testability,TEST,TESTPD,65,"// MOVMSKPS(V) !=/== 0 -> TESTPS(V,V); // MOVMSKPD(V) !=/== 0 -> TESTPD(V,V); // MOVMSKPS(V) !=/== -1 -> TESTPS(V,V); // MOVMSKPD(V) !=/== -1 -> TESTPD(V,V); // iff every element is referenced.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Testability,TEST,TESTPS,105,"// MOVMSKPS(V) !=/== 0 -> TESTPS(V,V); // MOVMSKPD(V) !=/== 0 -> TESTPD(V,V); // MOVMSKPS(V) !=/== -1 -> TESTPS(V,V); // MOVMSKPD(V) !=/== -1 -> TESTPD(V,V); // iff every element is referenced.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:145,Testability,TEST,TESTPD,145,"// MOVMSKPS(V) !=/== 0 -> TESTPS(V,V); // MOVMSKPD(V) !=/== 0 -> TESTPD(V,V); // MOVMSKPS(V) !=/== -1 -> TESTPS(V,V); // MOVMSKPD(V) !=/== -1 -> TESTPD(V,V); // iff every element is referenced.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Performance,Optimiz,Optimize,4,"/// Optimize an EFLAGS definition used according to the condition code \p CC; /// into a simpler EFLAGS value, potentially returning a new \p CC and replacing; /// uses of chain values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:89,Usability,simpl,simpler,89,"/// Optimize an EFLAGS definition used according to the condition code \p CC; /// into a simpler EFLAGS value, potentially returning a new \p CC and replacing; /// uses of chain values.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Performance,Optimiz,Optimize,4,"/// Optimize X86ISD::CMOV [LHS, RHS, CONDCODE (e.g. X86::COND_NE), CONDVAL]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify the EFLAGS and condition code operands.; // We can't always do this as FCMOV only supports a subset of X86 cond.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Performance,optimiz,optimizations,73,"// If this is a select between two integer constants, try to do some; // optimizations. Note that the operands are ordered the opposite of SELECT; // operands.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:83,Energy Efficiency,efficient,efficient,83,// Optimize C ? 8 : 0 -> zext(setcc(C)) << 3. Likewise for any pow2/0.; // This is efficient for any integer data type (including i8/i16) and; // shift amount.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,// Optimize C ? 8 : 0 -> zext(setcc(C)) << 3. Likewise for any pow2/0.; // This is efficient for any integer data type (including i8/i16) and; // shift amount.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero extend the condition if needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Energy Efficiency,efficient,efficient,61,"// Optimize Cond ? cst+1 : cst -> zext(setcc(C)+cst. This is efficient; // for any integer data type, including i8/i16.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize Cond ? cst+1 : cst -> zext(setcc(C)+cst. This is efficient; // for any integer data type, including i8/i16.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero extend the condition if needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:97,Energy Efficiency,efficient,efficient,97,"// Optimize cases that will turn into an LEA instruction. This requires; // an i32 or i64 and an efficient multiplier (1, 2, 3, 4, 5, 8, 9).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize cases that will turn into an LEA instruction. This requires; // an i32 or i64 and an efficient multiplier (1, 2, 3, 4, 5, 8, 9).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero extend the condition if needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Performance,optimiz,optimization,56,// the DCI.xxxx conditions are provided to postpone the optimization as; // late as possible.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:550,Energy Efficiency,reduce,reduces,550,"// Fold and/or of setcc's to double CMOV:; // (CMOV F, T, ((cc1 | cc2) != 0)) -> (CMOV (CMOV F, T, cc1), T, cc2); // (CMOV F, T, ((cc1 & cc2) != 0)) -> (CMOV (CMOV T, F, !cc1), F, !cc2); //; // This combine lets us generate:; // cmovcc1 (jcc1 if we don't have CMOV); // cmovcc2 (same); // instead of:; // setcc1; // setcc2; // and/or; // cmovne (jne if we don't have CMOV); // When we can't use the CMOV instruction, it might increase branch; // mispredicts.; // When we can use CMOV, or when there is no mispredict, this improves; // throughput and reduces register pressure.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:535,Performance,throughput,throughput,535,"// Fold and/or of setcc's to double CMOV:; // (CMOV F, T, ((cc1 | cc2) != 0)) -> (CMOV (CMOV F, T, cc1), T, cc2); // (CMOV F, T, ((cc1 & cc2) != 0)) -> (CMOV (CMOV T, F, !cc1), F, !cc2); //; // This combine lets us generate:; // cmovcc1 (jcc1 if we don't have CMOV); // cmovcc2 (same); // instead of:; // setcc1; // setcc2; // and/or; // cmovne (jne if we don't have CMOV); // When we can't use the CMOV instruction, it might increase branch; // mispredicts.; // When we can use CMOV, or when there is no mispredict, this improves; // throughput and reduces register pressure.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:151,Energy Efficiency,efficient,efficient,151,"/// When the operands of vector mul are extended from smaller size values,; /// like i8 and i16, the type of mul may be shrinked to generate more; /// efficient code. Two typical patterns are handled:; /// Pattern1:; /// %2 = sext/zext <N x i8> %1 to <N x i32>; /// %4 = sext/zext <N x i8> %3 to <N x i32>; // or %4 = build_vector <N x i32> %C1, ..., %CN (%C1..%CN are constants); /// %5 = mul <N x i32> %2, %4; ///; /// Pattern2:; /// %2 = zext/sext <N x i16> %1 to <N x i32>; /// %4 = zext/sext <N x i16> %3 to <N x i32>; /// or %4 = build_vector <N x i32> %C1, ..., %CN (%C1..%CN are constants); /// %5 = mul <N x i32> %2, %4; ///; /// There are four mul shrinking modes:; /// If %2 == sext32(trunc8(%2)), i.e., the scalar value range of %2 is; /// -128 to 128, and the scalar value range of %4 is also -128 to 128,; /// generate pmullw+sext32 for it (MULS8 mode).; /// If %2 == zext32(trunc8(%2)), i.e., the scalar value range of %2 is; /// 0 to 255, and the scalar value range of %4 is also 0 to 255,; /// generate pmullw+zext32 for it (MULU8 mode).; /// If %2 == sext32(trunc16(%2)), i.e., the scalar value range of %2 is; /// -32768 to 32767, and the scalar value range of %4 is also -32768 to 32767,; /// generate pmullw+pmulhw for it (MULS16 mode).; /// If %2 == zext32(trunc16(%2)), i.e., the scalar value range of %2 is; /// 0 to 65535, and the scalar value range of %4 is also 0 to 65535,; /// generate pmullw+pmulhuw for it (MULU16 mode).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Modifiability,extend,extended,40,"/// When the operands of vector mul are extended from smaller size values,; /// like i8 and i16, the type of mul may be shrinked to generate more; /// efficient code. Two typical patterns are handled:; /// Pattern1:; /// %2 = sext/zext <N x i8> %1 to <N x i32>; /// %4 = sext/zext <N x i8> %3 to <N x i32>; // or %4 = build_vector <N x i32> %C1, ..., %CN (%C1..%CN are constants); /// %5 = mul <N x i32> %2, %4; ///; /// Pattern2:; /// %2 = zext/sext <N x i16> %1 to <N x i32>; /// %4 = zext/sext <N x i16> %3 to <N x i32>; /// or %4 = build_vector <N x i32> %C1, ..., %CN (%C1..%CN are constants); /// %5 = mul <N x i32> %2, %4; ///; /// There are four mul shrinking modes:; /// If %2 == sext32(trunc8(%2)), i.e., the scalar value range of %2 is; /// -128 to 128, and the scalar value range of %4 is also -128 to 128,; /// generate pmullw+sext32 for it (MULS8 mode).; /// If %2 == zext32(trunc8(%2)), i.e., the scalar value range of %2 is; /// 0 to 255, and the scalar value range of %4 is also 0 to 255,; /// generate pmullw+zext32 for it (MULU8 mode).; /// If %2 == sext32(trunc16(%2)), i.e., the scalar value range of %2 is; /// -32768 to 32767, and the scalar value range of %4 is also -32768 to 32767,; /// generate pmullw+pmulhw for it (MULS16 mode).; /// If %2 == zext32(trunc16(%2)), i.e., the scalar value range of %2 is; /// 0 to 65535, and the scalar value range of %4 is also 0 to 65535,; /// generate pmullw+pmulhuw for it (MULU16 mode).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Energy Efficiency,power,power,31,"// Another trick. If this is a power 2 + 2/4/8, we can use a shift followed; // by a single LEA.; // First check if this a sum of two power of 2s because that's easy. Then; // count how many zeros are up to the first bit.; // TODO: We can do this even without LEA at a cost of two shifts and an add.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:134,Energy Efficiency,power,power,134,"// Another trick. If this is a power 2 + 2/4/8, we can use a shift followed; // by a single LEA.; // First check if this a sum of two power of 2s because that's easy. Then; // count how many zeros are up to the first bit.; // TODO: We can do this even without LEA at a cost of two shifts and an add.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,Energy Efficiency,reduce,reduce,77,"// If we are zero/sign extending two steps without SSE4.1, its better to; // reduce the vmul width instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Modifiability,extend,extending,23,"// If we are zero/sign extending two steps without SSE4.1, its better to; // reduce the vmul width instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:72,Energy Efficiency,reduce,reduce,72,"// If we are sign extending a wide vector without SSE4.1, its better to reduce; // the vmul width instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Modifiability,extend,extending,18,"// If we are sign extending a wide vector without SSE4.1, its better to reduce; // the vmul width instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,down,down,25,// Sign bits must extend down to the lowest i16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Modifiability,extend,extend,18,// Sign bits must extend down to the lowest i16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Safety,safe,safely,81,"// At least one of the elements must be zero in the upper 17 bits, or can be; // safely made zero without altering the final result.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Availability,Mask,Mask,3,// Mask off upper 16-bits of sign-extended constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Modifiability,extend,extended,34,// Mask off upper 16-bits of sign-extended constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize a single multiply with constant into two operations in order to; // implement it with two cheaper instructions, e.g. LEA + SHL, LEA + LEA.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Energy Efficiency,power,power,61,"// For negative multiply amounts, only allow MulAmt2 to be a power of 2.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Modifiability,extend,extends,20,// Peek through the extends.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:108,Availability,mask,mask,108,"// We can handle cases concerning bit-widening nodes containing setcc_c if; // we carefully interrogate the mask to make sure we are semantics; // preserving.; // The transform is not safe if the result of C1 << C2 exceeds the bitwidth; // of the underlying setcc_c operation if the setcc_c was zero extended.; // Consider the following example:; // zext(setcc_c) -> i32 0x0000FFFF; // c1 -> i32 0x0000FFFF; // c2 -> i32 0x00000001; // (shl (and (setcc_c), c1), c2) -> i32 0x0001FFFE; // (and setcc_c, (c1 << c2)) -> i32 0x0000FFFE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:300,Modifiability,extend,extended,300,"// We can handle cases concerning bit-widening nodes containing setcc_c if; // we carefully interrogate the mask to make sure we are semantics; // preserving.; // The transform is not safe if the result of C1 << C2 exceeds the bitwidth; // of the underlying setcc_c operation if the setcc_c was zero extended.; // Consider the following example:; // zext(setcc_c) -> i32 0x0000FFFF; // c1 -> i32 0x0000FFFF; // c2 -> i32 0x00000001; // (shl (and (setcc_c), c1), c2) -> i32 0x0001FFFE; // (and setcc_c, (c1 << c2)) -> i32 0x0000FFFE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:184,Safety,safe,safe,184,"// We can handle cases concerning bit-widening nodes containing setcc_c if; // we carefully interrogate the mask to make sure we are semantics; // preserving.; // The transform is not safe if the result of C1 << C2 exceeds the bitwidth; // of the underlying setcc_c operation if the setcc_c was zero extended.; // Consider the following example:; // zext(setcc_c) -> i32 0x0000FFFF; // c1 -> i32 0x0000FFFF; // c2 -> i32 0x00000001; // (shl (and (setcc_c), c1), c2) -> i32 0x0001FFFE; // (and setcc_c, (c1 << c2)) -> i32 0x0000FFFE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:171,Integrability,depend,depending,171,"// fold (SRA (SHL X, ShlConst), SraConst); // into (SHL (sext_in_reg X), ShlConst - SraConst); // or (sext_in_reg X); // or (SRA (sext_in_reg X), SraConst - ShlConst); // depending on relation between SraConst and ShlConst.; // We only do this if (Size - ShlConst) is equal to 8, 16 or 32. That allows; // us to do the sext_in_reg from corresponding bit.; // sexts in X86 are MOVs. The MOVs have the same code size; // as above SHIFTs (only SHIFT on 1 has lower code size).; // However the MOVs have 2 advantages to a SHIFT:; // 1. MOVs can write to a register that differs from source; // 2. MOVs accept memory operands",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:155,Safety,avoid,avoid,155,"// Try to improve a sequence of srl (and X, C1), C2 by inverting the order.; // TODO: This is a generic DAG combine that became an x86-only combine to; // avoid shortcomings in other folds such as bswap, bit-test ('bt'), and; // and-not ('andn').",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:208,Testability,test,test,208,"// Try to improve a sequence of srl (and X, C1), C2 by inverting the order.; // TODO: This is a generic DAG combine that became an x86-only combine to; // avoid shortcomings in other folds such as bswap, bit-test ('bt'), and; // and-not ('andn').",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:33,Availability,mask,mask,33,"// If we can shrink the constant mask below 8-bits or 32-bits, then this; // transform should reduce code size. It may also enable secondary transforms; // from improved known-bits analysis or instruction selection.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:94,Energy Efficiency,reduce,reduce,94,"// If we can shrink the constant mask below 8-bits or 32-bits, then this; // transform should reduce code size. It may also enable secondary transforms; // from improved known-bits analysis or instruction selection.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Modifiability,extend,extend,36,"// If this can be matched by a zero extend, don't optimize.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:50,Performance,optimiz,optimize,50,"// If this can be matched by a zero extend, don't optimize.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:177,Safety,avoid,avoid,177,"// Attempt to fold HOP(LOSUBVECTOR(SHUFFLE(X)),HISUBVECTOR(SHUFFLE(X))); // to SHUFFLE(HOP(LOSUBVECTOR(X),HISUBVECTOR(X))), this is mainly for; // truncation trees that help us avoid lane crossing shuffles.; // TODO: There's a lot more we can do for PACK/HADD style shuffle combines.; // TODO: We don't handle vXf64 shuffles yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:84,Performance,perform,perform,84,"// If either/both ops are a shuffle that can scale to v2x64,; // then see if we can perform this as a v4x32 post shuffle.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Modifiability,EXTEND,EXTEND,20,"// Try to fold PACK(EXTEND(X),EXTEND(Y)) -> CONCAT(X,Y) subvectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Modifiability,EXTEND,EXTEND,30,"// Try to fold PACK(EXTEND(X),EXTEND(Y)) -> CONCAT(X,Y) subvectors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect constant shift amounts.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,log,logical,16,// Out of range logical bit shifts are guaranteed to be zero.; // Out of range arithmetic bit shifts splat the sign bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,log,logical,16,// Out of range logical bit shifts are guaranteed to be zero.; // Out of range arithmetic bit shifts splat the sign bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Testability,log,logical,30,// We can decode 'whole byte' logical bit shifts as shuffles.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Safety,detect,detect,14,"// Attempt to detect an expanded vXi64 SIGN_EXTEND_INREG vXi1 pattern, and; // convert to a splatted v2Xi32 SIGN_EXTEND_INREG pattern:; // psrad(pshufd(psllq(X,63),1,1,3,3),31) ->; // pshufd(psrad(pslld(X,31),31),0,0,2,2).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Usability,Simpl,SimplifyDemandedBits,51,"// Undef elements need to fold to 0. It's possible SimplifyDemandedBits; // created an undef input due to no input bits being demanded, but user; // still expects 0 in other bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,log,logic,16,"// Fold (shift (logic X, C2), C1) -> (logic (shift X, C1), (shift C2, C1)); // Don't break NOT patterns.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Testability,log,logic,38,"// Fold (shift (logic X, C2), C1) -> (logic (shift X, C1), (shift C2, C1)); // Don't break NOT patterns.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Modifiability,rewrite,rewrite,113,"/// Recognize the distinctive (AND (setcc ...) (setcc ..)) where both setccs; /// reference the same FP CMP, and rewrite for CMPEQSS and friends. Likewise for; /// OR -> CMPNEQSS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,Testability,log,logical,80,"// Try to widen AND, OR and XOR nodes to VT in order to remove casts around; // logical operations, like in the example below.; // or (and (truncate x, truncate y)),; // (xor (truncate z, build_vector (constants))); // Given a target type \p VT, we generate; // or (and x, y), (xor z, zext(build_vector (constants))); // given x, y and z are of type \p VT. We can do so, if operands are either; // truncates from VT types, the second operand is a vector of constants or can; // be recursively promoted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Safety,avoid,avoid,22,// Limit recursion to avoid excessive compile times.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:364,Availability,mask,mask,364,"// On AVX/AVX2 the type v8i1 is legalized to v8i16, which is an XMM sized; // register. In most cases we actually compare or select YMM-sized registers; // and mixing the two types creates horrible code. This method optimizes; // some of the transition sequences.; // Even with AVX-512 this is still useful for removing casts around logical; // operations on vXi1 mask types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:216,Performance,optimiz,optimizes,216,"// On AVX/AVX2 the type v8i1 is legalized to v8i16, which is an XMM sized; // register. In most cases we actually compare or select YMM-sized registers; // and mixing the two types creates horrible code. This method optimizes; // some of the transition sequences.; // Even with AVX-512 this is still useful for removing casts around logical; // operations on vXi1 mask types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:333,Testability,log,logical,333,"// On AVX/AVX2 the type v8i1 is legalized to v8i16, which is an XMM sized; // register. In most cases we actually compare or select YMM-sized registers; // and mixing the two types creates horrible code. This method optimizes; // some of the transition sequences.; // Even with AVX-512 this is still useful for removing casts around logical; // operations on vXi1 mask types.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:164,Safety,avoid,avoid,164,"/// If both input operands of a logic op are being cast from floating-point; /// types or FP compares, try to convert this into a floating-point logic node; /// to avoid unnecessary moves from SSE to integer registers.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Testability,log,logic,32,"/// If both input operands of a logic op are being cast from floating-point; /// types or FP compares, try to convert this into a floating-point logic node; /// to avoid unnecessary moves from SSE to integer registers.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:145,Testability,log,logic,145,"/// If both input operands of a logic op are being cast from floating-point; /// types or FP compares, try to convert this into a floating-point logic node; /// to avoid unnecessary moves from SSE to integer registers.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Testability,log,logic,34,"// Convert scalar FP compares and logic to vector compares (COMIS* to CMPS*); // and vector logic:; // logic (setcc N00, N01), (setcc N10, N11) -->; // extelt (logic (setcc (s2v N00), (s2v N01)), setcc (s2v N10), (s2v N11))), 0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Testability,log,logic,92,"// Convert scalar FP compares and logic to vector compares (COMIS* to CMPS*); // and vector logic:; // logic (setcc N00, N01), (setcc N10, N11) -->; // extelt (logic (setcc (s2v N00), (s2v N01)), setcc (s2v N10), (s2v N11))), 0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Testability,log,logic,103,"// Convert scalar FP compares and logic to vector compares (COMIS* to CMPS*); // and vector logic:; // logic (setcc N00, N01), (setcc N10, N11) -->; // extelt (logic (setcc (s2v N00), (s2v N01)), setcc (s2v N10), (s2v N11))), 0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:160,Testability,log,logic,160,"// Convert scalar FP compares and logic to vector compares (COMIS* to CMPS*); // and vector logic:; // logic (setcc N00, N01), (setcc N10, N11) -->; // extelt (logic (setcc (s2v N00), (s2v N01)), setcc (s2v N10), (s2v N11))), 0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:75,Energy Efficiency,reduce,reduce,75,"// Attempt to fold BITOP(MOVMSK(X),MOVMSK(Y)) -> MOVMSK(BITOP(X,Y)); // to reduce XMM->GPR traffic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:118,Usability,Simpl,SimplifyUsingDistributiveLaws,118,"// Attempt to fold BITOP(SHIFT(X,Z),SHIFT(Y,Z)) -> SHIFT(BITOP(X,Y),Z).; // NOTE: This is a very limited case of what SimplifyUsingDistributiveLaws; // handles in InstCombine.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Availability,mask,mask,81,"/// If this is a zero/all-bits result that is bitwise-anded with a low bits; /// mask. (Mask == 1 for the x86 lowering of a SETCC + ZEXT), replace the 'and'; /// with a shift-right to eliminate loading the vector constant mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Availability,Mask,Mask,88,"/// If this is a zero/all-bits result that is bitwise-anded with a low bits; /// mask. (Mask == 1 for the x86 lowering of a SETCC + ZEXT), replace the 'and'; /// with a shift-right to eliminate loading the vector constant mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:222,Availability,mask,mask,222,"/// If this is a zero/all-bits result that is bitwise-anded with a low bits; /// mask. (Mask == 1 for the x86 lowering of a SETCC + ZEXT), replace the 'and'; /// with a shift-right to eliminate loading the vector constant mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:194,Performance,load,loading,194,"/// If this is a zero/all-bits result that is bitwise-anded with a low bits; /// mask. (Mask == 1 for the x86 lowering of a SETCC + ZEXT), replace the 'and'; /// with a shift-right to eliminate loading the vector constant mask value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Availability,mask,masking,43,"// Try to convert an ""is positive"" signbit masking operation into arithmetic; // shift and ""andn"". This saves a materialization of a -1 vector constant.; // The ""is negative"" variant should be handled more generally because it only; // requires ""and"" rather than ""andn"":; // and (pcmpgt X, -1), Y --> pandn (vsrai X, BitWidth - 1), Y; //; // This is limited to the original type to avoid producing even more bitcasts.; // If the bitcasts can't be eliminated, then it is unlikely that this fold; // will be profitable.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:382,Safety,avoid,avoid,382,"// Try to convert an ""is positive"" signbit masking operation into arithmetic; // shift and ""andn"". This saves a materialization of a -1 vector constant.; // The ""is negative"" variant should be handled more generally because it only; // requires ""and"" rather than ""andn"":; // and (pcmpgt X, -1), Y --> pandn (vsrai X, BitWidth - 1), Y; //; // This is limited to the original type to avoid producing even more bitcasts.; // If the bitcasts can't be eliminated, then it is unlikely that this fold; // will be profitable.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Performance,load,load,86,"// This function recognizes cases where X86 bzhi instruction can replace and; // 'and-load' sequence.; // In case of loading integer value from an array of constants which is defined; // as follows:; //; // int array[SIZE] = {0x0, 0x1, 0x3, 0x7, 0xF ..., 2^(SIZE-1) - 1}; //; // then applying a bitwise and on the result with another input.; // It's equivalent to performing bzhi (zero high bits) on the input, with the; // same index of the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:117,Performance,load,loading,117,"// This function recognizes cases where X86 bzhi instruction can replace and; // 'and-load' sequence.; // In case of loading integer value from an array of constants which is defined; // as follows:; //; // int array[SIZE] = {0x0, 0x1, 0x3, 0x7, 0xF ..., 2^(SIZE-1) - 1}; //; // then applying a bitwise and on the result with another input.; // It's equivalent to performing bzhi (zero high bits) on the input, with the; // same index of the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:364,Performance,perform,performing,364,"// This function recognizes cases where X86 bzhi instruction can replace and; // 'and-load' sequence.; // In case of loading integer value from an array of constants which is defined; // as follows:; //; // int array[SIZE] = {0x0, 0x1, 0x3, 0x7, 0xF ..., 2^(SIZE-1) - 1}; //; // then applying a bitwise and on the result with another input.; // It's equivalent to performing bzhi (zero high bits) on the input, with the; // same index of the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:442,Performance,load,load,442,"// This function recognizes cases where X86 bzhi instruction can replace and; // 'and-load' sequence.; // In case of loading integer value from an array of constants which is defined; // as follows:; //; // int array[SIZE] = {0x0, 0x1, 0x3, 0x7, 0xF ..., 2^(SIZE-1) - 1}; //; // then applying a bitwise and on the result with another input.; // It's equivalent to performing bzhi (zero high bits) on the input, with the; // same index of the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Performance,load,load,36,// continue if the operand is not a load instruction,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Performance,load,load,57,"// Do the transformation (For 32-bit type):; // -> (and (load arr[idx]), inp); // <- (and (srl 0xFFFFFFFF, (sub 32, idx))); // that will be replaced with one bzhi instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:93,Availability,mask,mask,93,"// Look for (and (bitcast (vXi1 (concat_vectors (vYi1 setcc), undef,))), C); // Where C is a mask containing the same number of bits as the setcc and; // where the setcc will freely 0 upper bits of k-register. We can replace the; // undef in the concat with 0s and remove the AND. This mainly helps with; // v2i1/v4i1 setcc being casted to scalar.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,// The RHS of the AND should be a mask with as many bits as SubVec.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Performance,optimiz,optimization,87,// We don't want to go crazy with the recursion here. This isn't a super; // important optimization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Safety,avoid,avoid,43,// If this is SSE1 only convert to FAND to avoid scalarization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:186,Usability,undo,undo,186,// InstCombine converts:; // `(-x << C0) & C1`; // to; // `(x * (Pow2_Ceil(C1) - (1 << C0))) & C1`; // This saves an IR instruction but on x86 the neg/shift version is preferable; // so undo the transform.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Availability,mask,mask,81,"// fold (and (mul x, c1), c2) -> (mul x, (and c1, c2)); // iff c2 is all/no bits mask - i.e. a select-with-zero mask.; // TODO: Handle PMULDQ/PMULUDQ/VPMADDWD/VPMADDUBSW?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:112,Availability,mask,mask,112,"// fold (and (mul x, c1), c2) -> (mul x, (and c1, c2)); // iff c2 is all/no bits mask - i.e. a select-with-zero mask.; // TODO: Handle PMULDQ/PMULUDQ/VPMADDWD/VPMADDUBSW?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Modifiability,variab,variable,90,"// Fold AND(SRL(X,Y),1) -> SETCC(BT(X,Y), COND_B) iff Y is not a constant; // avoids slow variable shift (moving shift amount to ECX etc.)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Safety,avoid,avoids,78,"// Fold AND(SRL(X,Y),1) -> SETCC(BT(X,Y), COND_B) iff Y is not a constant; // avoids slow variable shift (moving shift amount to ECX etc.)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,"// If either operand is a constant mask, then only the elements that aren't; // zero are actually demanded by the other operand.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,masks,35,// Check that the constant bitmask masks whole bytes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Availability,mask,mask,25,// Create a root shuffle mask from the byte mask and the extracted index.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,Availability,mask,mask,44,// Create a root shuffle mask from the byte mask and the extracted index.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:122,Availability,mask,mask,122,"// On XOP we'll lower to PCMOV so accept one use. With AVX512, we can use; // VPTERNLOG. Otherwise only do this if either mask has multiple uses already.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,mask,masks,36,// Attempt to extract constant byte masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:90,Availability,avail,available,90,// Emit a VPTERNLOG node directly - 0xCA is the imm code for A?B:C.; // VPTERNLOG is only available as vXi32/64-bit types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,MASK,MASK,24,"// Try to match OR(AND(~MASK,X),AND(MASK,Y)) logic pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,MASK,MASK,36,"// Try to match OR(AND(~MASK,X),AND(MASK,Y)) logic pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,Testability,log,logic,45,"// Try to match OR(AND(~MASK,X),AND(MASK,Y)) logic pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,mask,23,// Check to see if the mask appeared in both the AND and ANDNP.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:27,Availability,Mask,Mask,27,"// Validate that X, Y, and Mask are bitcasts, and see through them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Security,Validat,Validate,3,"// Validate that X, Y, and Mask are bitcasts, and see through them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Availability,avail,available,20,// PBLENDVB is only available on SSE 4.1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Modifiability,extend,extend,18,// Check the zero extend is extending to 32-bit or more. The code generated by; // srl(ctlz) for 16-bit or less variants of the pattern would require extra; // instructions to clear the upper bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Modifiability,extend,extending,28,// Check the zero extend is extending to 32-bit or more. The code generated by; // srl(ctlz) for 16-bit or less variants of the pattern would require extra; // instructions to clear the upper bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:176,Usability,clear,clear,176,// Check the zero extend is extending to 32-bit or more. The code generated by; // srl(ctlz) for 16-bit or less variants of the pattern would require extra; // instructions to clear the upper bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,masked,10,"/// Fold ""masked merge"" expressions like `(m & x) | (~m & y)` into the; /// equivalent `((x ^ y) & m) ^ y)` pattern.; /// This is typically a better representation for targets without a fused; /// ""and-not"" operation. This function is intended to be called from a; /// `TargetLowering::PerformDAGCombine` callback on `ISD::OR` nodes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:286,Performance,Perform,PerformDAGCombine,286,"/// Fold ""masked merge"" expressions like `(m & x) | (~m & y)` into the; /// equivalent `((x ^ y) & m) ^ y)` pattern.; /// This is typically a better representation for targets without a fused; /// ""and-not"" operation. This function is intended to be called from a; /// `TargetLowering::PerformDAGCombine` callback on `ISD::OR` nodes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,masked-merge,13,// Note that masked-merge variants using XOR or ADD expressions are; // normalized to OR by InstCombine so we only check for OR.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Testability,TEST,TEST,140,"/// If this is an add or subtract where one operand is produced by a cmp+setcc,; /// then try to convert it to an ADC or SBB. This replaces TEST+SET+{ADD/SUB}; /// with CMP+{ADC, SBB}.; /// Also try (ADD/SUB)+(AND(SRL,1)) bit extraction pattern with BT+{ADC, SBB}.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Safety,avoid,avoid,51,"// If X is -1 or 0, then we have an opportunity to avoid constants required in; // the general case below.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:51,Safety,avoid,avoid,51,"// If X is -1 or 0, then we have an opportunity to avoid constants required in; // the general case below.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Testability,TEST,TEST,140,"/// If this is an add or subtract where one operand is produced by a cmp+setcc,; /// then try to convert it to an ADC or SBB. This replaces TEST+SET+{ADD/SUB}; /// with CMP+{ADC, SBB}.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Safety,avoid,avoid,42,// If this is SSE1 only convert to FOR to avoid scalarization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,"// If either operand is a constant mask, then only the elements that aren't; // allones are actually demanded by the other operand.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Availability,mask,masked,19,"// We should fold ""masked merge"" patterns when `andn` is not available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Availability,avail,available,61,"// We should fold ""masked merge"" patterns when `andn` is not available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,test,tests,16,"/// Try to turn tests against the signbit in the form of:; /// XOR(TRUNCATE(SRL(X, size(X)-1)), 1); /// into:; /// SETGT(X, -1)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Performance,perform,performing,16,// We should be performing an xor against a truncated shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Performance,perform,performing,20,// Make sure we are performing an xor against one.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,Modifiability,extend,extends,21,// SetCC on x86 zero extends so only act on this if it's a logical shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:59,Testability,log,logical,59,// SetCC on x86 zero extends so only act on this if it's a logical shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Testability,test,tests,16,"/// Turn vector tests of the signbit in the form of:; /// xor (sra X, elt_size(X)-1), -1; /// into:; /// pcmpgt X, -1; ///; /// This should be called before type legalization because the pattern may not; /// persist after that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Safety,Detect,Detect,4,"/// Detect patterns of truncation with unsigned saturation:; ///; /// 1. (truncate (umin (x, unsigned_max_of_dest_type)) to dest_type).; /// Return the source value x to be truncated or SDValue() if the pattern was; /// not matched.; ///; /// 2. (truncate (smin (smax (x, C1), C2)) to dest_type),; /// where C1 >= 0 and C2 is unsigned max of destination type.; ///; /// (truncate (smax (smin (x, C2), C1)) to dest_type); /// where C1 >= 0, C2 is unsigned max of destination type and C1 <= C2.; ///; /// These two patterns are equivalent to:; /// (truncate (umin (smax(x, C1), unsigned_max_of_dest_type)) to dest_type); /// So return the smax(x, C1) value to be truncated or SDValue() if the; /// pattern was not matched.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Safety,Detect,Detect,4,"/// Detect patterns of truncation with signed saturation:; /// (truncate (smin ((smax (x, signed_min_of_dest_type)),; /// signed_max_of_dest_type)) to dest_type); /// or:; /// (truncate (smax ((smin (x, signed_max_of_dest_type)),; /// signed_min_of_dest_type)) to dest_type).; /// With MatchPackUS, the smax/smin range is [0, unsigned_max_of_dest_type].; /// Return the source value to be truncated or SDValue() if the pattern was not; /// matched.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,avail,available,35,"// vXi32 truncate instructions are available with AVX512F.; // vXi16 truncate instructions are only available with AVX512BW.; // For 256-bit or smaller vectors, we require VLX.; // FIXME: We could widen truncates to 512 to remove the VLX restriction.; // If the result type is 256-bits or larger and we have disable 512-bit; // registers, we should go ahead and use the pack instructions if possible.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Availability,avail,available,100,"// vXi32 truncate instructions are available with AVX512F.; // vXi16 truncate instructions are only available with AVX512BW.; // For 256-bit or smaller vectors, we require VLX.; // FIXME: We could widen truncates to 512 to remove the VLX restriction.; // If the result type is 256-bits or larger and we have disable 512-bit; // registers, we should go ahead and use the pack instructions if possible.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,perform,performed,25,"// vXi32 -> vXi8 must be performed as PACKUSWB(PACKSSDW,PACKSSDW).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:149,Energy Efficiency,efficient,efficient,149,"/// This function detects the AVG pattern between vectors of unsigned i8/i16,; /// which is c = (a + b + 1) / 2, and replace this operation with the efficient; /// ISD::AVGCEILU (AVG) instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Safety,detect,detects,18,"/// This function detects the AVG pattern between vectors of unsigned i8/i16,; /// which is c = (a + b + 1) / 2, and replace this operation with the efficient; /// ISD::AVGCEILU (AVG) instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,"// Detect the following pattern:; //; // %1 = zext <N x i8> %a to <N x i32>; // %2 = zext <N x i8> %b to <N x i32>; // %3 = add nuw nsw <N x i32> %1, <i32 1 x N>; // %4 = add nuw nsw <N x i32> %3, %2; // %5 = lshr <N x i32> %N, <i32 1 x N>; // %6 = trunc <N x i32> %5 to <N x i8>; //; // In AVX512, the last instruction can also be a trunc store.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Detect,Detect,3,// Detect a pattern of a + b + 1 where the order doesn't matter.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Energy Efficiency,power,power-of-,12,"// Pad to a power-of-2 vector, split+apply and extract the original vector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Safety,detect,detected,18,"// The pattern is detected. Subtract one from the constant vector, then; // demote it and emit X86ISD::AVG instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Safety,detect,detected,18,"// The pattern is detected, emit X86ISD::AVG instruction(s).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Performance,load,loads,41,"// For chips with slow 32-byte unaligned loads, break the 32-byte operation; // into two 16-byte operations. Also split non-temporal aligned loads on; // pre-AVX2 targets as 32-byte loads will lower to regular temporal loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:141,Performance,load,loads,141,"// For chips with slow 32-byte unaligned loads, break the 32-byte operation; // into two 16-byte operations. Also split non-temporal aligned loads on; // pre-AVX2 targets as 32-byte loads will lower to regular temporal loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:182,Performance,load,loads,182,"// For chips with slow 32-byte unaligned loads, break the 32-byte operation; // into two 16-byte operations. Also split non-temporal aligned loads on; // pre-AVX2 targets as 32-byte loads will lower to regular temporal loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:219,Performance,load,loads,219,"// For chips with slow 32-byte unaligned loads, break the 32-byte operation; // into two 16-byte operations. Also split non-temporal aligned loads on; // pre-AVX2 targets as 32-byte loads will lower to regular temporal loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Performance,load,load,15,"// Bool vector load - attempt to cast to an integer, as we have good; // (vXiY *ext(vXi1 bitcast(iX))) handling.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Performance,load,load,14,"// If we also load/broadcast this to a wider type, then just extract the; // lowest subvector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Performance,load,loading,17,// See if we are loading a constant that matches in the lower; // bits of a longer constant (but from a different constant pool ptr).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:71,Performance,load,load,71,// Cast ptr32 and ptr64 pointers to the default address space before a load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:117,Availability,mask,mask,117,"// This needs to be a build vector of booleans.; // TODO: Checking for the i1 type matches the IR definition for the mask,; // but the mask check could be loosened to i8 or other types. That might; // also require checking more than 'allOnesValue'; eg, the x86 HW; // instructions only require that the MSB is set for each mask element.; // The ISD::MSTORE comments/definition do not specify how the mask operand; // is formatted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:135,Availability,mask,mask,135,"// This needs to be a build vector of booleans.; // TODO: Checking for the i1 type matches the IR definition for the mask,; // but the mask check could be loosened to i8 or other types. That might; // also require checking more than 'allOnesValue'; eg, the x86 HW; // instructions only require that the MSB is set for each mask element.; // The ISD::MSTORE comments/definition do not specify how the mask operand; // is formatted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:323,Availability,mask,mask,323,"// This needs to be a build vector of booleans.; // TODO: Checking for the i1 type matches the IR definition for the mask,; // but the mask check could be loosened to i8 or other types. That might; // also require checking more than 'allOnesValue'; eg, the x86 HW; // instructions only require that the MSB is set for each mask element.; // The ISD::MSTORE comments/definition do not specify how the mask operand; // is formatted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:400,Availability,mask,mask,400,"// This needs to be a build vector of booleans.; // TODO: Checking for the i1 type matches the IR definition for the mask,; // but the mask check could be loosened to i8 or other types. That might; // also require checking more than 'allOnesValue'; eg, the x86 HW; // instructions only require that the MSB is set for each mask element.; // The ISD::MSTORE comments/definition do not specify how the mask operand; // is formatted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:12,Availability,mask,masked,12,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Availability,mask,mask,74,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Availability,mask,mask,107,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Performance,load,load,26,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:187,Performance,load,load,187,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:300,Security,access,access,300,"/// Given a masked memory load/store operation, return true if it has one mask; /// bit set. If it has one mask bit set, then also return the memory address of; /// the scalar element to load/store, the vector index to insert/extract that; /// scalar element, and the alignment for the scalar memory access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:70,Availability,mask,mask,70,// Get the address of the one scalar element that is specified by the mask; // using the appropriate offset from the base pointer.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:66,Availability,mask,masked,66,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:208,Availability,mask,mask,208,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Modifiability,extend,extending,56,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Performance,load,load,73,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:99,Performance,load,load,99,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:231,Performance,optimiz,optimized,231,"/// If exactly one element of the mask is set for a non-extending masked load,; /// it is a scalar load and vector insert.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Availability,mask,mask,56,// Load the one scalar element that is specified by the mask using the; // appropriate offset from the base pointer.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Load,Load,3,// Load the one scalar element that is specified by the mask using the; // appropriate offset from the base pointer.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Performance,load,loaded,14,// Insert the loaded element into the appropriate place in the vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:133,Availability,mask,masked,133,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Performance,load,loading,13,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:98,Performance,load,load,98,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:140,Performance,load,load,140,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:163,Performance,load,load,163,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Safety,safe,safe,68,"// If we are loading the first and last elements of a vector, it is safe and; // always faster to load the whole vector. Replace the masked load with a; // vector load and select.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:13,Availability,mask,masked,13,"// Convert a masked load with a constant mask into a masked load and a select.; // This allows the select operation to use a faster kind of select instruction; // (for example, vblendvps -> vblendps).; // Don't try this if the pass-through operand is already undefined. That would; // cause an infinite loop because that's what we're about to create.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:41,Availability,mask,mask,41,"// Convert a masked load with a constant mask into a masked load and a select.; // This allows the select operation to use a faster kind of select instruction; // (for example, vblendvps -> vblendps).; // Don't try this if the pass-through operand is already undefined. That would; // cause an infinite loop because that's what we're about to create.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,Availability,mask,masked,53,"// Convert a masked load with a constant mask into a masked load and a select.; // This allows the select operation to use a faster kind of select instruction; // (for example, vblendvps -> vblendps).; // Don't try this if the pass-through operand is already undefined. That would; // cause an infinite loop because that's what we're about to create.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Performance,load,load,20,"// Convert a masked load with a constant mask into a masked load and a select.; // This allows the select operation to use a faster kind of select instruction; // (for example, vblendvps -> vblendps).; // Don't try this if the pass-through operand is already undefined. That would; // cause an infinite loop because that's what we're about to create.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Performance,load,load,60,"// Convert a masked load with a constant mask into a masked load and a select.; // This allows the select operation to use a faster kind of select instruction; // (for example, vblendvps -> vblendps).; // Don't try this if the pass-through operand is already undefined. That would; // cause an infinite loop because that's what we're about to create.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,mask,masked,11,// The new masked load has an undef pass-through operand. The select uses the; // original pass-through operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Performance,load,load,18,// The new masked load has an undef pass-through operand. The select uses the; // original pass-through operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Availability,mask,mask,38,// TODO: Expanding load with constant mask may be optimized as well.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Performance,load,load,19,// TODO: Expanding load with constant mask may be optimized as well.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:50,Performance,optimiz,optimized,50,// TODO: Expanding load with constant mask may be optimized as well.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,mask,10,"// If the mask value has been legalized to a non-boolean vector, try to; // simplify ops leading up to it. We only demand the MSB of each lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Usability,simpl,simplify,76,"// If the mask value has been legalized to a non-boolean vector, try to; // simplify ops leading up to it. We only demand the MSB of each lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Availability,mask,mask,34,"/// If exactly one element of the mask is set for a non-truncating masked store,; /// it is a vector extract and scalar store.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Availability,mask,masked,67,"/// If exactly one element of the mask is set for a non-truncating masked store,; /// it is a vector extract and scalar store.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:212,Availability,mask,mask,212,"/// If exactly one element of the mask is set for a non-truncating masked store,; /// it is a vector extract and scalar store.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:235,Performance,optimiz,optimized,235,"/// If exactly one element of the mask is set for a non-truncating masked store,; /// it is a vector extract and scalar store.; /// Note: It is expected that the degenerate cases of an all-zeros or all-ones; /// mask have already been optimized in IR, so we don't bother with those here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,mask,10,"// If the mask value has been legalized to a non-boolean vector, try to; // simplify ops leading up to it. We only demand the MSB of each lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:76,Usability,simpl,simplify,76,"// If the mask value has been legalized to a non-boolean vector, try to; // simplify ops leading up to it. We only demand the MSB of each lane.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,Safety,avoid,avoid,92,"// If this is a store of a scalar_to_vector to v1i1, just use a scalar store.; // This will avoid a copy to k-register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,Integrability,Bridg,Bridge,87,"// If we are saving a 32-byte vector and 32-byte stores are slow, such as on; // Sandy Bridge, perform two 16-byte stores.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:95,Performance,perform,perform,95,"// If we are saving a 32-byte vector and 32-byte stores are slow, such as on; // Sandy Bridge, perform two 16-byte stores.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:100,Modifiability,extend,extending,100,"// Try to optimize v16i16->v16i8 truncating stores when BWI is not; // supported, but avx512f is by extending to v16i32 and truncating.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Performance,optimiz,optimize,10,"// Try to optimize v16i16->v16i8 truncating stores when BWI is not; // supported, but avx512f is by extending to v16i32 and truncating.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize trunc store (of multiple scalars) to shuffle and store.; // First, pack all of the elements in one place. Next, store to memory; // in fewer chunks.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Safety,detect,detect,19,"// Check if we can detect an AVG pattern from the truncation. If yes,; // replace the trunc store by a normal store with the result of X86ISD::AVG; // instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Performance,load,load,8,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:42,Performance,load,load,42,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:289,Performance,load,load,289,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:320,Performance,load,load,320,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,Safety,avoid,avoids,60,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Performance,load,loaded,62,// Avoid the transformation if there are multiple uses of the loaded value.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid the transformation if there are multiple uses of the loaded value.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Performance,load,load,26,// Lower to a single movq load/store pair.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Performance,load,load,17,// Make sure new load is placed in same chain order.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:258,Integrability,depend,dependencies,258,"// This is similar to the above case, but here we handle a scalar 64-bit; // integer store that is extracted from a vector on a 32-bit target.; // If we have SSE2, then we can treat it like a floating-point double; // to get past legalization. The execution dependencies fixup pass will; // choose the optimal machine instruction for the store if this really is; // an integer or v2f32 rather than an f64.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:724,Availability,avail,available,724,"/// Return 'true' if this vector operation is ""horizontal""; /// and return the operands for the horizontal operation in LHS and RHS. A; /// horizontal operation performs the binary operation on successive elements; /// of its first operand, then on successive elements of its second operand,; /// returning the resulting values in a vector. For example, if; /// A = < float a0, float a1, float a2, float a3 >; /// and; /// B = < float b0, float b1, float b2, float b3 >; /// then the result of doing a horizontal operation on A and B is; /// A horizontal-op B = < a0 op a1, a2 op a3, b0 op b1, b2 op b3 >.; /// In short, LHS and RHS are inspected to see if LHS op RHS is of the form; /// A horizontal-op B, for some already available A and B, and if so then LHS is; /// set to A, RHS to B, and the routine returns 'true'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:798,Integrability,rout,routine,798,"/// Return 'true' if this vector operation is ""horizontal""; /// and return the operands for the horizontal operation in LHS and RHS. A; /// horizontal operation performs the binary operation on successive elements; /// of its first operand, then on successive elements of its second operand,; /// returning the resulting values in a vector. For example, if; /// A = < float a0, float a1, float a2, float a3 >; /// and; /// B = < float b0, float b1, float b2, float b3 >; /// then the result of doing a horizontal operation on A and B is; /// A horizontal-op B = < a0 op a1, a2 op a3, b0 op b1, b2 op b3 >.; /// In short, LHS and RHS are inspected to see if LHS op RHS is of the form; /// A horizontal-op B, for some already available A and B, and if so then LHS is; /// set to A, RHS to B, and the routine returns 'true'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:161,Performance,perform,performs,161,"/// Return 'true' if this vector operation is ""horizontal""; /// and return the operands for the horizontal operation in LHS and RHS. A; /// horizontal operation performs the binary operation on successive elements; /// of its first operand, then on successive elements of its second operand,; /// returning the resulting values in a vector. For example, if; /// A = < float a0, float a1, float a2, float a3 >; /// and; /// B = < float b0, float b1, float b2, float b3 >; /// then the result of doing a horizontal operation on A and B is; /// A horizontal-op B = < a0 op a1, a2 op a3, b0 op b1, b2 op b3 >.; /// In short, LHS and RHS are inspected to see if LHS op RHS is of the form; /// A horizontal-op B, for some already available A and B, and if so then LHS is; /// set to A, RHS to B, and the routine returns 'true'.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Usability,simpl,simplified,61,"// If either operand is undef, bail out. The binop should be simplified.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Availability,mask,mask,23,"// If we have an unary mask, ensure the other op is set to null.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Availability,mask,mask,105,"// If A and B occur in reverse order in RHS, then canonicalize by commuting; // RHS operands and shuffle mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Availability,mask,masks,103,"// LHS and RHS are now:; // LHS = shuffle A, B, LMask; // RHS = shuffle A, B, RMask; // Check that the masks correspond to performing a horizontal operation.; // AVX defines horizontal add/sub to operate independently on 128-bit lanes,; // so we just repeat the inner loop if this is a 256-bit op.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:123,Performance,perform,performing,123,"// LHS and RHS are now:; // LHS = shuffle A, B, LMask; // RHS = shuffle A, B, RMask; // Check that the masks correspond to performing a horizontal operation.; // AVX defines horizontal add/sub to operate independently on 128-bit lanes,; // so we just repeat the inner loop if this is a 256-bit op.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:28,Availability,mask,mask,28,"// Compute the post-shuffle mask index based on where the element; // is stored in the HOP result, and where it needs to be moved to.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid 128-bit multi lane shuffles if pre-AVX2 and FP (integer will split).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Integrability,Wrap,Wrapper,61,"// Try to combine the following nodes; // t29: i64 = X86ISD::Wrapper TargetConstantPool:i64; // <i32 -2147483648[float -0.000000e+00]> 0; // t27: v16i32[v16f32],ch = X86ISD::VBROADCAST_LOAD; // <(load 4 from constant-pool)> t0, t29; // [t30: v16i32 = bitcast t27]; // t6: v16i32 = xor t7, t27[t30]; // t11: v16f32 = bitcast t6; // t21: v16f32 = X86ISD::VFMULC[X86ISD::VCFMULC] t11, t8; // into X86ISD::VFCMULC[X86ISD::VFMULC] if possible:; // t22: v16f32 = bitcast t7; // t23: v16f32 = X86ISD::VFCMULC[X86ISD::VFMULC] t8, t22; // t24: v32f16 = bitcast t23",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,Performance,load,load,196,"// Try to combine the following nodes; // t29: i64 = X86ISD::Wrapper TargetConstantPool:i64; // <i32 -2147483648[float -0.000000e+00]> 0; // t27: v16i32[v16f32],ch = X86ISD::VBROADCAST_LOAD; // <(load 4 from constant-pool)> t0, t29; // [t30: v16i32 = bitcast t27]; // t6: v16i32 = xor t7, t27[t30]; // t11: v16f32 = bitcast t6; // t21: v16f32 = X86ISD::VFMULC[X86ISD::VCFMULC] t11, t8; // into X86ISD::VFCMULC[X86ISD::VFMULC] if possible:; // t22: v16f32 = bitcast t7; // t23: v16f32 = X86ISD::VFCMULC[X86ISD::VFMULC] t8, t22; // t24: v32f16 = bitcast t23",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Usability,simpl,simplify,64,"/// Attempt to pre-truncate inputs to arithmetic ops if it will simplify; /// the codegen.; /// e.g. TRUNC( BINOP( X, Y ) ) --> BINOP( TRUNC( X ), TRUNC( Y ) ); /// TODO: This overlaps with the generic combiner's visitTRUNCATE. Remove; /// anything that is guaranteed to be transformed by DAGCombiner.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Modifiability,extend,extended,24,"// See if this has been extended from a smaller/equal size to; // the truncation size, allowing a truncation to combine with the extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:129,Modifiability,extend,extend,129,"// See if this has been extended from a smaller/equal size to; // the truncation size, allowing a truncation to combine with the extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:61,Performance,perform,perform,61,"// For AVX2+ targets, with the upper bits known zero, we can perform MULHU on; // the (bitcasted) inputs directly, and then cheaply pack/truncate the result; // (upper elts will be zero). Don't attempt this with just AVX512F as MULHU; // will have to split anyway.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Modifiability,extend,extends,20,// Peek through the extends.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,Modifiability,extend,extend,14,// Ensure the extend is from vXi8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Modifiability,extend,extended,20,"// N00/N10 are zero extended. N01/N11 are sign extended.; // For each element, we need to ensure we have an odd element from one vector; // multiplied by the odd element of another vector and the even element from; // one of the same vectors being multiplied by the even element from the; // other vector. So we need to make sure for each element i, this operator; // is being performed:; // A[2 * i] * B[2 * i] + A[2 * i + 1] * B[2 * i + 1]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Modifiability,extend,extended,47,"// N00/N10 are zero extended. N01/N11 are sign extended.; // For each element, we need to ensure we have an odd element from one vector; // multiplied by the odd element of another vector and the even element from; // one of the same vectors being multiplied by the even element from the; // other vector. So we need to make sure for each element i, this operator; // is being performed:; // A[2 * i] * B[2 * i] + A[2 * i + 1] * B[2 * i + 1]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:377,Performance,perform,performed,377,"// N00/N10 are zero extended. N01/N11 are sign extended.; // For each element, we need to ensure we have an odd element from one vector; // multiplied by the odd element of another vector and the even element from; // one of the same vectors being multiplied by the even element from the; // other vector. So we need to make sure for each element i, this operator; // is being performed:; // A[2 * i] * B[2 * i] + A[2 * i + 1] * B[2 * i + 1]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,toler,tolerant,17,// TODO: Be more tolerant to undefs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Safety,detect,detect,10,// Try to detect AVG pattern first.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Safety,detect,detect,10,// Try to detect PMADD,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:50,Safety,Detect,Detect,50,// The bitcast source is a direct mmx result.; // Detect bitcasts between i32 to x86mmx,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:124,Availability,mask,mask,124,"// For a VECTOR_SHUFFLE(VEC1, VEC2), if the VEC2 is undef, then the negate; // of this is VECTOR_SHUFFLE(-VEC1, UNDEF). The mask can be anything here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,Availability,mask,masks,79,"// For XOR and FXOR, we want to check if constant; // bits of Op1 are sign bit masks. For FSUB, we; // have to check if constant bits of Op0 are sign; // bit masks and hence we swap the operands.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:158,Availability,mask,masks,158,"// For XOR and FXOR, we want to check if constant; // bits of Op1 are sign bit masks. For FSUB, we; // have to check if constant bits of Op0 are sign; // bit masks and hence we swap the operands.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Availability,mask,masks,62,// Extract constant bits and see if they are all; // sign bit masks. Ignore the undef elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:197,Availability,avail,available,197,"// If we're negating a FMUL node on a target with FMA, then we can avoid the; // use of a constant by performing (-0 - A*B) instead.; // FIXME: Check rounding control flags as well once it becomes available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,Performance,perform,performing,102,"// If we're negating a FMUL node on a target with FMA, then we can avoid the; // use of a constant by performing (-0 - A*B) instead.; // FIXME: Check rounding control flags as well once it becomes available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Safety,avoid,avoid,67,"// If we're negating a FMUL node on a target with FMA, then we can avoid the; // use of a constant by performing (-0 - A*B) instead.; // FIXME: Check rounding control flags as well once it becomes available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,avail,available,35,"// If we have integer vector types available, use the integer opcodes.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Zero extend to i32 since there is not an i8 bsr.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Safety,avoid,avoid,43,// If this is SSE1 only convert to FXOR to avoid scalarization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,mask,mask,17,"// Handle AVX512 mask widening.; // Fold not(insert_subvector(undef,sub)) -> insert_subvector(undef,not(sub))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:192,Performance,perform,performed,192,"// Fold xor(zext(xor(x,c1)),c2) -> xor(zext(x),xor(zext(c1),c2)); // Fold xor(truncate(xor(x,c1)),c2) -> xor(truncate(x),xor(truncate(c1),c2)); // TODO: Under what circumstances could this be performed in DAGCombine?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Usability,Simpl,Simplify,32,// TODO - Constant Folding.; // Simplify the inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Safety,unsafe,unsafe-math,16,"// If we run in unsafe-math mode, then convert the FMAX and FMIN nodes; // into FMINC and FMAXC, which are Commutative operations.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,load,load,25,// Convert a full vector load into vzload when not all bits are needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,load,load,25,// Convert a full vector load into vzload when not all bits are needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:73,Performance,perform,performed,73,// Constant fold NOT(N0) to allow us to use AND.; // Ensure this is only performed if we can confirm that the bitcasted source; // has oneuse to prevent an infinite loop with canonicalizeBitSelect.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Availability,mask,mask,35,"// If either operand is a constant mask, then only the elements that aren't; // zero are actually demanded by the other operand.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Performance,load,load,25,// Convert a full vector load into vzload when not all bits are needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,Modifiability,extend,extending,56,// Try to combine sext_in_reg of a cmov of constants by extending the constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:109,Modifiability,extend,extended,109,"// The SIGN_EXTEND_INREG to v4i64 is expensive operation on the; // both SSE and AVX2 since there is no sign-extended shift right; // operation on a vector with 64-bit elements.; //(sext_in_reg (v4i64 anyext (v4i32 x )), ExtraVT) ->; // (v4i64 sext (v4i32 sext_in_reg (v4i32 x , ExtraVT)))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,Availability,mask,mask,37,// Attempt to promote any comparison mask ops before moving the; // SIGN_EXTEND_INREG in the way.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:283,Modifiability,extend,extend,283,"/// sext(add_nsw(x, C)) --> add(sext(x), C_sext); /// zext(add_nuw(x, C)) --> add(zext(x), C_zext); /// Promoting a sign/zero extension ahead of a no overflow 'add' exposes; /// opportunities to combine math ops, use an LEA, or use a complex addressing; /// mode. This can eliminate extend, add, and shift instructions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:165,Security,expose,exposes,165,"/// sext(add_nsw(x, C)) --> add(sext(x), C_sext); /// zext(add_nuw(x, C)) --> add(zext(x), C_zext); /// Promoting a sign/zero extension ahead of a no overflow 'add' exposes; /// opportunities to combine math ops, use an LEA, or use a complex addressing; /// mode. This can eliminate extend, add, and shift instructions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:127,Modifiability,extend,extended,127,// Having a constant operand to the 'add' ensures that we are not increasing; // the instruction count because the constant is extended for free below.; // A constant operand can also become the displacement field of an LEA.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:157,Usability,simpl,simpler,157,"// Don't make the 'add' bigger if there's no hope of combining it with some; // other 'add' or 'shl' instruction.; // TODO: It may be profitable to generate simpler LEA instructions in place; // of single 'add' instructions, but the cost model for selecting an LEA; // currently has a high threshold.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,Integrability,wrap,wrap,38,// The wider add is guaranteed to not wrap because both operands are; // sign-extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:78,Modifiability,extend,extended,78,// The wider add is guaranteed to not wrap because both operands are; // sign-extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Only extend to i32 or i64.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,Modifiability,extend,extend,8,// Only extend from i16 unless its a sign_extend from i32. Zext/aext from i32; // are free.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Modifiability,extend,extend,18,"// If this a zero extend to i64, we should only extend to i32 and use a free; // zero extend to finish.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Modifiability,extend,extend,48,"// If this a zero extend to i64, we should only extend to i32 and use a free; // zero extend to finish.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,Modifiability,extend,extend,86,"// If this a zero extend to i64, we should only extend to i32 and use a free; // zero extend to finish.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Modifiability,extend,extending,10,// Finish extending if needed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Modifiability,extend,extends,47,// Only do this combine with AVX512 for vector extends.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:146,Performance,load,loaded,146,"// Inverting a constant vector is profitable if it can be eliminated and the; // inverted vector is already present in DAG. Otherwise, it will be loaded; // anyway.; //; // We determine which of the values can be completely eliminated and invert it.; // If both are eliminable, select a vector with the first negative element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Safety,avoid,avoid,105,"// If the operation allows fast-math and the target does not support FMA,; // split this into mul+add to avoid libcall(s).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:127,Testability,test,tests,127,// (i32 (aext (i8 (x86isd::setcc_carry)))) -> (i32 (x86isd::setcc_carry)); // FIXME: Is this needed? We don't seem to have any tests for it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Energy Efficiency,power,power,15,"// With C as a power of 2 and C != 0 and C != INT_MIN:; // icmp eq Abs(X) C ->; // (icmp eq A, C) | (icmp eq A, -C); // icmp ne Abs(X) C ->; // (icmp ne A, C) & (icmp ne A, -C); // Both of these patterns can be better optimized in; // DAGCombiner::foldAndOrOfSETCC. Note this only applies for scalar; // integers which is checked above.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:218,Performance,optimiz,optimized,218,"// With C as a power of 2 and C != 0 and C != INT_MIN:; // icmp eq Abs(X) C ->; // (icmp eq A, C) | (icmp eq A, -C); // icmp ne Abs(X) C ->; // (icmp ne A, C) & (icmp ne A, -C); // Both of these patterns can be better optimized in; // DAGCombiner::foldAndOrOfSETCC. Note this only applies for scalar; // integers which is checked above.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Performance,optimiz,optimize,17,// We can better optimize this case in DAGCombiner::foldAndOrOfSETCC.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Safety,avoid,avoid,24,// Using temporaries to avoid messing up operand ordering for later; // transformations if this doesn't work.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:244,Availability,mask,mask,244,"// Try and make unsigned vector comparison signed. On pre AVX512 targets there; // only are unsigned comparisons (`PCMPGT`) and on AVX512 its often better to; // use `PCMPGT` if the result is mean to stay in a vector (and if its going to; // a mask, there are signed AVX512 comparisons).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:417,Performance,optimiz,optimization,417,"// If we know LHS/RHS share the same sign bit at each element we can; // make this signed.; // NOTE: `computeKnownBits` on a vector type aggregates common bits; // across all lanes. So a pattern where the sign varies from lane to; // lane, but at each lane Sign(LHS) is known to equal Sign(RHS), will be; // missed. We could get around this by demanding each lane; // independently, but this isn't the most important optimization and; // that may eat into compile time.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Safety,avoid,avoid,85,"// For an SSE1-only target, lower a comparison of v4f32 to X86ISD::CMPP early; // to avoid scalarization via legalization because v4i32 is not a legal type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Perform,Perform,3,// Perform constant folding.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Testability,log,logic,15,"// Fold movmsk(logic(X,C)) -> logic(movmsk(X),C)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Testability,log,logic,30,"// Fold movmsk(logic(X,C)) -> logic(movmsk(X),C)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify the inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify the inputs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Availability,mask,masks,15,// With vector masks we only demand the upper bit of the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Availability,mask,mask,57,// With vector masks we only demand the upper bit of the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:407,Performance,optimiz,optimized,407,"// Shrink constant indices if they are larger than 32-bits.; // Only do this before legalize types since v2i64 could become v2i32.; // FIXME: We could check that the type is legal if we're after legalize; // types, but then we would need to construct test cases where that happens.; // FIXME: We could support more than just constant vectors, but we need to; // careful with costing. A truncate that can be optimized out would be fine.; // Otherwise we might only want to create a truncate if it avoids a split.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:496,Safety,avoid,avoids,496,"// Shrink constant indices if they are larger than 32-bits.; // Only do this before legalize types since v2i64 could become v2i32.; // FIXME: We could check that the type is legal if we're after legalize; // types, but then we would need to construct test cases where that happens.; // FIXME: We could support more than just constant vectors, but we need to; // careful with costing. A truncate that can be optimized out would be fine.; // Otherwise we might only want to create a truncate if it avoids a split.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:251,Testability,test,test,251,"// Shrink constant indices if they are larger than 32-bits.; // Only do this before legalize types since v2i64 could become v2i32.; // FIXME: We could check that the type is legal if we're after legalize; // types, but then we would need to construct test cases where that happens.; // FIXME: We could support more than just constant vectors, but we need to; // careful with costing. A truncate that can be optimized out would be fine.; // Otherwise we might only want to create a truncate if it avoids a split.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Modifiability,extend,extends,24,// Shrink any sign/zero extends from 32 or smaller to larger than 32 if; // there are sufficient sign bits. Only do this before legalize types to; // avoid creating illegal types in truncate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:150,Safety,avoid,avoid,150,// Shrink any sign/zero extends from 32 or smaller to larger than 32 if; // there are sufficient sign bits. Only do this before legalize types to; // avoid creating illegal types in truncate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:262,Integrability,wrap,wrap,262,// Try to move splat constant adders from the index operand to the base; // pointer operand. Taking care to multiply by the scale. We can only do; // this when index element type is the same as the pointer type.; // Otherwise we need to be sure the math doesn't wrap before the scale.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Availability,mask,masks,15,// With vector masks we only demand the upper bit of the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:57,Availability,mask,mask,57,// With vector masks we only demand the upper bit of the mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize RES = X86ISD::SETCC CONDCODE, EFLAG_INPUT",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,// Try to simplify the EFLAGS and condition code operands.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:4,Performance,Optimiz,Optimize,4,/// Optimize branch condition evaluation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Usability,simpl,simplify,10,"// Try to simplify the EFLAGS and condition code operands.; // Make sure to not keep references to operands, as combineSetCCEFLAGS can; // RAUW them under us.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Performance,optimiz,optimize,85,"// Take advantage of vector comparisons (etc.) producing 0 or -1 in each lane; // to optimize away operation when it's from a constant.; //; // The general transformation is:; // UNARYOP(AND(VECTOR_CMP(x,y), constant)) -->; // AND(VECTOR_CMP(x,y), constant2); // constant2 = UNARYOP(constant); // Early exit if this isn't a vector operation, the operand of the; // unary operation isn't a bitwise AND, or if the sizes of the operations; // aren't the same.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:228,Performance,perform,perform,228,"// Now check that the other operand of the AND is a constant. We could; // make the transformation for non-constant splats as well, but it's unclear; // that would be a benefit as it would not eliminate any operations, just; // perform one more step in scalar code before moving to the vector unit.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:74,Performance,optimiz,optimize,74,"// Since UINT_TO_FP is legal (it's marked custom), dag combiner won't; // optimize it to a SINT_TO_FP when the sign bit is known zero. Perform; // the optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:135,Performance,Perform,Perform,135,"// Since UINT_TO_FP is legal (it's marked custom), dag combiner won't; // optimize it to a SINT_TO_FP when the sign bit is known zero. Perform; // the optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:151,Performance,optimiz,optimization,151,"// Since UINT_TO_FP is legal (it's marked custom), dag combiner won't; // optimize it to a SINT_TO_FP when the sign bit is known zero. Perform; // the optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,Performance,optimiz,optimize,16,// First try to optimize away the conversion entirely when it's; // conditionally from a constant. Vectors only.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:15,Testability,test,test,15,// Only handle test patterns.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Testability,log,logical,25,// If we have a constant logical shift that's only used in a comparison; // against zero turn it into an equivalent AND. This allows turning it into; // a TEST instruction later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:155,Testability,TEST,TEST,155,// If we have a constant logical shift that's only used in a comparison; // against zero turn it into an equivalent AND. This allows turning it into; // a TEST instruction later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid undefined shifts.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:138,Testability,TEST,TEST,138,"// If we're extracting from a avx512 bool vector and comparing against zero,; // then try to just bitcast the vector to an integer to use TEST/BT directly.; // (and (extract_elt (kshiftr vXi1, C), 0), 1) -> (and (bc vXi1), 1<<C)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,Modifiability,extend,extend,25,// Peek through any zero-extend if we're only testing for a zero result.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Testability,test,testing,46,// Peek through any zero-extend if we're only testing for a zero result.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:103,Testability,test,test,103,// Skip and with constant. We have special handling for and with immediate; // during isel to generate test instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Safety,avoid,avoid,32,// Use a X86 specific opcode to avoid DAG combine messing with it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:48,Testability,test,test,48,"// For AND, keep a CMP so that we can match the test pattern.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Usability,simpl,simplify,36,"// If we don't use the flag result, simplify back to a generic ADD/SUB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,"// Optimize RES, EFLAGS = X86ISD::ADC LHS, RHS, EFLAGS",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:173,Availability,down,down,173,"// If the LHS and RHS of the ADC node are zero, then it can't overflow and; // the result is either zero or one (depending on the input carry bit).; // Strength reduce this down to a ""set on carry"" aka SETCC_CARRY&1.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:161,Energy Efficiency,reduce,reduce,161,"// If the LHS and RHS of the ADC node are zero, then it can't overflow and; // the result is either zero or one (depending on the input carry bit).; // Strength reduce this down to a ""set on carry"" aka SETCC_CARRY&1.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:113,Integrability,depend,depending,113,"// If the LHS and RHS of the ADC node are zero, then it can't overflow and; // the result is either zero or one (depending on the input carry bit).; // Strength reduce this down to a ""set on carry"" aka SETCC_CARRY&1.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:32,Safety,detect,detect,32,"// Example of pattern we try to detect:; // t := (v8i32 mul (sext (v8i16 x0), (sext (v8i16 x1)))); //(add (build_vector (extract_elt t, 0),; // (extract_elt t, 2),; // (extract_elt t, 4),; // (extract_elt t, 6)),; // (build_vector (extract_elt t, 1),; // (extract_elt t, 3),; // (extract_elt t, 5),; // (extract_elt t, 7)))",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,toler,tolerant,17,// TODO: Be more tolerant to undefs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:34,Safety,safe,safely,34,// Check if the Mul source can be safely shrunk.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:30,Modifiability,extend,extends,30,// All inputs need to be sign extends.; // TODO: Support ZERO_EXTEND from known positive?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Modifiability,extend,extends,20,// Peek through the extends.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Modifiability,extend,extending,11,// Must be extending from vXi16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:319,Performance,perform,performed,319,"// For each element, we need to ensure we have an odd element from one vector; // multiplied by the odd element of another vector and the even element from; // one of the same vectors being multiplied by the even element from the; // other vector. So we need to make sure for each element i, this operator; // is being performed:; // A[2 * i] * B[2 * i] + A[2 * i + 1] * B[2 * i + 1]",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,Availability,toler,tolerant,17,// TODO: Be more tolerant to undefs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:20,Availability,mask,mask,20,// Create a shuffle mask packing the lower elements from each VPMADDWD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:139,Energy Efficiency,reduce,reduce,139,/// CMOV of constants requires materializing constant operands in registers.; /// Try to fold those constants into an 'add' instruction to reduce instruction; /// count. We do this with CMOV rather the generic 'select' because there are; /// earlier folds that may be used to turn select-of-constants into logic hacks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:306,Testability,log,logic,306,/// CMOV of constants requires materializing constant operands in registers.; /// Try to fold those constants into an 'add' instruction to reduce instruction; /// count. We do this with CMOV rather the generic 'select' because there are; /// earlier folds that may be used to turn select-of-constants into logic hacks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Usability,simpl,simplified,40,"// If an operand is zero, add-of-0 gets simplified away, so that's clearly; // better because we eliminate 1-2 instructions. This transform is still; // an improvement without zero operands because we trade 2 move constants and; // 1 add for 2 adds (LEA) as long as the constants can be represented as; // immediate asm operands (fit in 32-bits).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:67,Usability,clear,clearly,67,"// If an operand is zero, add-of-0 gets simplified away, so that's clearly; // better because we eliminate 1-2 instructions. This transform is still; // an improvement without zero operands because we trade 2 move constants and; // 1 add for 2 adds (LEA) as long as the constants can be represented as; // immediate asm operands (fit in 32-bits).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Performance,load,load,18,// Don't remove a load folding opportunity for the add. That would neutralize; // any improvements from removing constant materializations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:226,Safety,avoid,avoid,226,"// We will push the add through the select, but we can potentially do better; // if we know there is another add in the sequence and this is pointer math.; // In that case, we can absorb an add into the trailing memory op and avoid; // a 3-operand LEA which is likely slower than a 2-operand LEA.; // TODO: If target has ""slow3OpsLEA"", do this even without the trailing memop?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:81,Performance,latency,latency,81,"// Due to VADD, VSUB, VMUL can executed on more ports than VINSERT and; // their latency are short, so here we don't replace them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,Performance,load,loads,18,"// Fold subvector loads into one.; // If needed, look through bitcasts to get to the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,Performance,load,load,85,"// Fold subvector loads into one.; // If needed, look through bitcasts to get to the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:35,Performance,load,loads,35,// Attempt to fold target constant loads.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:126,Deployability,Update,Update,126,"// If this simple subvector or scalar/subvector broadcast_load is inserted; // into both halves, use a larger broadcast_load. Update other uses to use; // an extracted subvector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Usability,simpl,simple,11,"// If this simple subvector or scalar/subvector broadcast_load is inserted; // into both halves, use a larger broadcast_load. Update other uses to use; // an extracted subvector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,Availability,mask,mask,36,// First create an identity shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Performance,load,load,26,"// If this is a broadcast load inserted into an upper undef, use a larger; // broadcast load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:88,Performance,load,load,88,"// If this is a broadcast load inserted into an upper undef, use a larger; // broadcast load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:64,Performance,load,load,64,"// If we're splatting the lower half subvector of a full vector load into the; // upper half, attempt to create a subvector broadcast.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:292,Availability,avail,available,292,"/// If we are extracting a subvector of a vector select and the select condition; /// is composed of concatenated vectors, try to narrow the select width. This; /// is a common pattern for AVX1 integer code because 256-bit selects may be; /// legal, but there is almost no integer math/logic available for 256-bit.; /// This function should only be called with legal types (otherwise, the calls; /// to get simple value types will assert).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:286,Testability,log,logic,286,"/// If we are extracting a subvector of a vector select and the select condition; /// is composed of concatenated vectors, try to narrow the select width. This; /// is a common pattern for AVX1 integer code because 256-bit selects may be; /// legal, but there is almost no integer math/logic available for 256-bit.; /// This function should only be called with legal types (otherwise, the calls; /// to get simple value types will assert).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:431,Testability,assert,assert,431,"/// If we are extracting a subvector of a vector select and the select condition; /// is composed of concatenated vectors, try to narrow the select width. This; /// is a common pattern for AVX1 integer code because 256-bit selects may be; /// legal, but there is almost no integer math/logic available for 256-bit.; /// This function should only be called with legal types (otherwise, the calls; /// to get simple value types will assert).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:407,Usability,simpl,simple,407,"/// If we are extracting a subvector of a vector select and the select condition; /// is composed of concatenated vectors, try to narrow the select width. This; /// is a common pattern for AVX1 integer code because 256-bit selects may be; /// legal, but there is almost no integer math/logic available for 256-bit.; /// This function should only be called with legal types (otherwise, the calls; /// to get simple value types will assert).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:128,Modifiability,extend,extended,128,// Note: We assume simple value types because this should only be called with; // legal operations/types.; // TODO: This can be extended to handle extraction to 256-bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:19,Usability,simpl,simple,19,// Note: We assume simple value types because this should only be called with; // legal operations/types.; // TODO: This can be extended to handle extraction to 256-bits.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:460,Performance,load,loads,460,"// For AVX1 only, if we are extracting from a 256-bit and+not (which will; // eventually get combined/lowered into ANDNP) with a concatenated operand,; // split the 'and' into 128-bit ops to avoid the concatenate and extract.; // We let generic combining take over from there to simplify the; // insert/extract and 'not'.; // This pattern emerges during AVX1 legalization. We handle it before lowering; // to avoid complications like splitting constant vector loads.; // Capture the original wide type in the likely case that we need to bitcast; // back to this type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:191,Safety,avoid,avoid,191,"// For AVX1 only, if we are extracting from a 256-bit and+not (which will; // eventually get combined/lowered into ANDNP) with a concatenated operand,; // split the 'and' into 128-bit ops to avoid the concatenate and extract.; // We let generic combining take over from there to simplify the; // insert/extract and 'not'.; // This pattern emerges during AVX1 legalization. We handle it before lowering; // to avoid complications like splitting constant vector loads.; // Capture the original wide type in the likely case that we need to bitcast; // back to this type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:409,Safety,avoid,avoid,409,"// For AVX1 only, if we are extracting from a 256-bit and+not (which will; // eventually get combined/lowered into ANDNP) with a concatenated operand,; // split the 'and' into 128-bit ops to avoid the concatenate and extract.; // We let generic combining take over from there to simplify the; // insert/extract and 'not'.; // This pattern emerges during AVX1 legalization. We handle it before lowering; // to avoid complications like splitting constant vector loads.; // Capture the original wide type in the likely case that we need to bitcast; // back to this type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:279,Usability,simpl,simplify,279,"// For AVX1 only, if we are extracting from a 256-bit and+not (which will; // eventually get combined/lowered into ANDNP) with a concatenated operand,; // split the 'and' into 128-bit ops to avoid the concatenate and extract.; // We let generic combining take over from there to simplify the; // insert/extract and 'not'.; // This pattern emerges during AVX1 legalization. We handle it before lowering; // to avoid complications like splitting constant vector loads.; // Capture the original wide type in the likely case that we need to bitcast; // back to this type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:107,Security,access,access,107,"// If we are extracting from an insert into a larger vector, replace with a; // smaller insert if we don't access less than the original subvector. Don't; // do this for i1 vectors.; // TODO: Relax the matching indices requirement?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:138,Usability,Simpl,SimplifyDemandedVectorElts,138,// If we're extracting an upper subvector from a broadcast we should just; // extract the lowest subvector instead which should allow; // SimplifyDemandedVectorElts do more simplifications.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:173,Usability,simpl,simplifications,173,// If we're extracting an upper subvector from a broadcast we should just; // extract the lowest subvector instead which should allow; // SimplifyDemandedVectorElts do more simplifications.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Availability,mask,mask,22,// Decode the shuffle mask and scale it so its shuffling subvectors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:91,Performance,perform,perform,91,"// If we're extracting the lowest subvector and we're the only user,; // we may be able to perform this with a smaller vector width.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,Testability,log,logical,22,// Always split vXi64 logical shifts where we're extracting the upper 32-bits; // as this is very likely to fold into a shuffle/truncation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:111,Availability,mask,masked,111,"// If this is a scalar to vector to v1i1 from an AND with 1, bypass the and.; // This occurs frequently in our masked scalar intrinsic code and our; // floating point select lowering with AVX512.; // TODO: SimplifyDemandedBits instead?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:206,Usability,Simpl,SimplifyDemandedBits,206,"// If this is a scalar to vector to v1i1 from an AND with 1, bypass the and.; // This occurs frequently in our masked scalar intrinsic code and our; // floating point select lowering with AVX512.; // TODO: SimplifyDemandedBits instead?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Energy Efficiency,Reduce,Reduce,3,// Reduce v2i64 to v4i32 if we don't need the upper bits or are known zero.; // TODO: Move to DAGCombine/SimplifyDemandedBits?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:105,Usability,Simpl,SimplifyDemandedBits,105,// Reduce v2i64 to v4i32 if we don't need the upper bits or are known zero.; // TODO: Move to DAGCombine/SimplifyDemandedBits?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,Testability,test,test,62,// TODO: Handle BroadcastSizeInBits < SizeInBits when we have test; // coverage.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify PMULDQ and PMULUDQ operations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:212,Security,expose,exposes,212,"// If the input is an extend_invec and the SimplifyDemandedBits call didn't; // convert it to any_extend_invec, due to the LegalOperations check, do the; // conversion directly to a vector shuffle manually. This exposes combine; // opportunities missed by combineEXTEND_VECTOR_INREG not calling; // combineX86ShufflesRecursively on SSE4.1 targets.; // FIXME: This is basically a hack around several other issues related to; // ANY_EXTEND_VECTOR_INREG.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,Usability,Simpl,SimplifyDemandedBits,43,"// If the input is an extend_invec and the SimplifyDemandedBits call didn't; // convert it to any_extend_invec, due to the LegalOperations check, do the; // conversion directly to a vector shuffle manually. This exposes combine; // opportunities missed by combineEXTEND_VECTOR_INREG not calling; // combineX86ShufflesRecursively on SSE4.1 targets.; // FIXME: This is basically a hack around several other issues related to; // ANY_EXTEND_VECTOR_INREG.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Usability,Simpl,Simplify,3,// Simplify VPMADDUBSW/VPMADDWD operations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,Performance,load,loads,23,// Try to merge vector loads and extend_inreg to an extload.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Modifiability,EXTEND,EXTEND,46,"// Fold EXTEND_VECTOR_INREG(EXTRACT_SUBVECTOR(EXTEND(X),0)); // -> EXTEND_VECTOR_INREG(X).; // TODO: Handle non-zero subvector indices.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Performance,Optimiz,Optimize,3,// Optimize (fp16_to_fp (fp_to_fp16 X)) to VCVTPS2PH followed by VCVTPH2PS.; // Done as a combine because the lowering for fp16_to_fp and fp_to_fp16 produce; // extra instructions between the conversion due to going to scalar and back.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to the original VT if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to the original VT if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,Performance,load,loads,120,// Try to find a larger VBROADCAST_LOAD/SUBV_BROADCAST_LOAD that we can extract; // from. Limit this to cases where the loads have the same input chain and the; // output chains are unused. This avoids any memory ordering issues.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:195,Safety,avoid,avoids,195,// Try to find a larger VBROADCAST_LOAD/SUBV_BROADCAST_LOAD that we can extract; // from. Limit this to cases where the loads have the same input chain and the; // output chains are unused. This avoids any memory ordering issues.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:11,Availability,down,down,11,// Extract down to real number of elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Performance,load,load,40,// Turn MOVDQ2Q+simple_load into an mmx load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:265,Testability,test,test,265,"// Don't use `NotAnd` as even though `not` is generally shorter code size than; // `add`, `add` can lower to LEA which can save moves / spills. Any case where; // `NotAnd` applies, `AddAnd` does as well.; // TODO: Currently we lower (icmp eq/ne (and ~X, Y), 0) -> `test (not X), Y`,; // if we change that to `andn Y, X` it may be worth prefering `NotAnd` here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Performance,load,load,29,"// Look out for (store (shl (load), x)).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Performance,load,load,29,// Avoid disabling potential load folding opportunities.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Safety,Avoid,Avoid,3,// Avoid disabling potential load folding opportunities.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:143,Testability,log,logical,143,"// FIXME: this should verify that we are targeting a 486 or better. If not,; // we will turn this bswap into something that will be lowered to logical; // ops instead of emitting the bswap asm. For now, we don't support 486 or; // lower so don't worry about this.; // bswap $0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,Availability,mask,masking,10,// AVX512 masking registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:55,Availability,avail,available,55,"// FP X constraints get lowered to SSE1/2 registers if available, otherwise; // 'f' like normal targets.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:29,Deployability,update,update,29,// Get EFLAGS register. Only update chain when copyfrom is glued.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Modifiability,Extend,Extend,3,// Extend to 32-bits,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,Modifiability,extend,extended,40,// Widen to 64 bits here to get it sign extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:26,Performance,load,load,26,"// If we require an extra load to get this address, as in PIC mode, we; // can't accept it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,Availability,mask,mask,24,"/// Check if \p RC is a mask register class.; /// I.e., VK* or one of their variant.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:47,Availability,mask,masked,47,// This register class doesn't allocate k0 for masked vector operation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:31,Energy Efficiency,allocate,allocate,31,// This register class doesn't allocate k0 for masked vector operation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:319,Testability,test,tested,319,"// Handle references to XMM physical registers that got mapped into the; // wrong class. This can happen with constraints like {xmm0} where the; // target independent register mapper will just pick the first match it can; // find, ignoring the required type.; // TODO: Handle f128 and i128 in FR128RegClass after it is tested well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,error,error,46,// Type mismatch and not a clobber: Return an error;,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,Availability,error,error,46,// Type mismatch and not a clobber: Return an error;,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:68,Performance,optimiz,optimizing,68,"// Integer division on x86 is expensive. However, when aggressively optimizing; // for code size, we prefer to use a div instruction, as it is usually smaller; // than the alternative sequence.; // The exception to this is vector division. Since x86 doesn't have vector; // integer division, leaving the division as-is is a loss even in terms of; // size, because it will have to be scalarized, while the alternative code; // sequence can be performed in vector form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:442,Performance,perform,performed,442,"// Integer division on x86 is expensive. However, when aggressively optimizing; // for code size, we prefer to use a div instruction, as it is usually smaller; // than the alternative sequence.; // The exception to this is vector division. Since x86 doesn't have vector; // integer division, leaving the division as-is is a loss even in terms of; // size, because it will have to be scalarized, while the alternative code; // sequence can be performed in vector form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:3,Deployability,Update,Update,3,// Update IsSplitCSR in X86MachineFunctionInfo.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:171,Security,access,access,171,"// Create copy from CSR to a virtual register.; // FIXME: this currently does not emit CFI pseudo-instructions, it works; // fine for CXX_FAST_TLS since the C++-style TLS access functions should be; // nounwind. If we want to generalize this later, we may need to emit; // CFI pseudo-instructions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:45,Integrability,Interface,Interface,45,"//===-- X86ISelLowering.h - X86 DAG Lowering Interface ----------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the interfaces that X86 uses to lower LLVM code into a; // selection DAG.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:405,Integrability,interface,interfaces,405,"//===-- X86ISelLowering.h - X86 DAG Lowering Interface ----------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the interfaces that X86 uses to lower LLVM code into a; // selection DAG.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,log,logical,12,/// Bitwise logical AND of floating point values. This corresponds; /// to X86::ANDPS or X86::ANDPD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,log,logical,12,/// Bitwise logical OR of floating point values. This corresponds; /// to X86::ORPS or X86::ORPD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,log,logical,12,/// Bitwise logical XOR of floating point values. This corresponds; /// to X86::XORPS or X86::XORPD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,log,logical,12,/// Bitwise logical ANDNOT of floating point values. This; /// corresponds to X86::ANDNPS or X86::ANDNPD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:20,Testability,log,logical,20,/// X86 compare and logical compare instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,test,test,12,/// X86 bit-test instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:139,Availability,mask,mask,139,"// R = carry_bit ? ~0 : 0; /// X86 FP SETCC, implemented with CMP{cc}SS/CMP{cc}SD.; /// Operands are two FP values to compare; result is a mask of; /// 0s or 1s. Generally DTRT for C/C++ with NaNs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:61,Availability,mask,mask,61,"/// X86 FP SETCC, similar to above, but with output as an i1 mask and; /// and a version with SAE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:184,Testability,TEST,TEST,184,"/// X86 conditional moves. Operand 0 and operand 1 are the two values; /// to select from. Operand 2 is the condition code, and operand 3 is the; /// flag operand produced by a CMP or TEST instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:220,Testability,TEST,TEST,220,"/// X86 conditional branches. Operand 0 is the chain operand, operand 1; /// is the block to branch if condition is true, operand 2 is the; /// condition code, and operand 3 is the flag operand produced by a CMP; /// or TEST instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:6,Integrability,wrap,wrapper,6,"/// A wrapper node for TargetConstantPool, TargetJumpTable,; /// TargetExternalSymbol, TargetGlobalAddress, TargetGlobalTLSAddress,; /// MCSymbol and TargetBlockAddress.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Integrability,wrap,wrapper,12,/// Special wrapper used under X86-64 PIC mode for RIP; /// relative displacements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:50,Modifiability,extend,extend,50,"/// Extract an 8-bit value from a vector and zero extend it to; /// i32, corresponds to X86::PEXTRB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:50,Modifiability,extend,extend,50,"/// Extract a 16-bit value from a vector and zero extend it to; /// i32, corresponds to X86::PEXTRW.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Testability,Log,Logical,12,/// Bitwise Logical AND NOT of Packed FP values.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:164,Availability,mask,mask,164,"/// Dynamic (non-constant condition) vector blend where only the sign bits; /// of the condition elements are used. This is used to enforce that the; /// condition mask is not valid for generic VSELECT optimizations. This; /// is also used to implement the intrinsics.; /// Operands are in VSELECT order: MASK, TRUE, FALSE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:305,Availability,MASK,MASK,305,"/// Dynamic (non-constant condition) vector blend where only the sign bits; /// of the condition elements are used. This is used to enforce that the; /// condition mask is not valid for generic VSELECT optimizations. This; /// is also used to implement the intrinsics.; /// Operands are in VSELECT order: MASK, TRUE, FALSE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:202,Performance,optimiz,optimizations,202,"/// Dynamic (non-constant condition) vector blend where only the sign bits; /// of the condition elements are used. This is used to enforce that the; /// condition mask is not valid for generic VSELECT optimizations. This; /// is also used to implement the intrinsics.; /// Operands are in VSELECT order: MASK, TRUE, FALSE",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Safety,Detect,Detect,3,// Detect Conflicts Within a Vector,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Availability,Mask,Masked,3,"// Masked version of the above. Used when less than a 128-bit result is; // produced since the mask only applies to the lower elements and can't; // be represented by a select.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:95,Availability,mask,mask,95,"// Masked version of the above. Used when less than a 128-bit result is; // produced since the mask only applies to the lower elements and can't; // be represented by a select.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:196,Availability,MASK,MASK,196,"// Masked version of the above. Used when less than a 128-bit result is; // produced since the mask only applies to the lower elements and can't; // be represented by a select.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:13,Modifiability,extend,extend,13,// Vector FP extend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Availability,Mask,Masked,3,"// Masked version of above. Used for v2f64->v4f32.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:70,Availability,MASK,MASK,70,"// Masked version of above. Used for v2f64->v4f32.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:18,Testability,log,logical,18,// 128-bit vector logical left / right shift,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:10,Modifiability,variab,variable,10,// Vector variable shift,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:13,Availability,mask,mask,13,// Shifts of mask registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:33,Availability,mask,mask,33,/// Vector comparison generating mask bits for fp and; /// integer signed and unsigned data types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:10,Availability,mask,mask,10,// Vector mask comparison generating mask bits for FP values.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:37,Availability,mask,mask,37,// Vector mask comparison generating mask bits for FP values.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:10,Availability,mask,mask,10,// Vector mask comparison with SAE for FP values.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:19,Availability,mask,masks,19,// OR/AND test for masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:10,Testability,test,test,10,// OR/AND test for masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:11,Availability,mask,masks,11,// ADD for masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:46,Availability,Mask,MaskV,46,"// Variable Permute (VPERM).; // Res = VPERMV MaskV, V0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Modifiability,Variab,Variable,3,"// Variable Permute (VPERM).; // Res = VPERMV MaskV, V0",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:58,Availability,Mask,MaskV,58,"// 3-op Variable Permute (VPERMT2).; // Res = VPERMV3 V0, MaskV, V1",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:8,Modifiability,Variab,Variable,8,"// 3-op Variable Permute (VPERMT2).; // Res = VPERMV3 V0, MaskV, V1",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:19,Testability,log,logic,19,// Bitwise ternary logic.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Energy Efficiency,Reduce,Reduce,3,// Reduce - Perform Reduction Transformation on scalar\packed FP.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:12,Performance,Perform,Perform,12,// Reduce - Perform Reduction Transformation on scalar\packed FP.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:131,Availability,mask,mask,131,// RndScale - Round FP Values To Include A Given Number Of Fraction Bits.; // Also used by the legacy (V)ROUND intrinsics where we mask out the; // scaling part of the immediate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Testability,Test,Tests,3,// Tests Types Of a FP Values for packed types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Testability,Test,Tests,3,// Tests Types Of a FP Values for scalar types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:13,Availability,mask,mask,13,// Broadcast mask to vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:18,Testability,log,logical,18,// XOP arithmetic/logical shifts.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:87,Performance,perform,perform,87,// AVX512IFMA multiply and add.; // NOTE: These are different than the instruction and perform; // op0 x op1 + op2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Availability,Mask,Masked,3,"// Masked versions of above. Used for v2f64->v4f32.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:71,Availability,MASK,MASK,71,"// Masked versions of above. Used for v2f64->v4f32.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Availability,Mask,Masked,3,"// Masked version of above.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:47,Availability,MASK,MASK,47,"// Masked version of above.; // SRC, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:18,Modifiability,variab,variable,18,"// For allocating variable amounts of stack space when using; // segmented stacks. Check if the current stacklet has enough space, and; // falls back to heap allocation if not.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:82,Performance,perform,performed,82,"// For allocating stack space when using stack clash protector.; // Allocation is performed by block, and each block is probed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:71,Availability,mask,mask,71,"// SSE42 string comparisons.; // These nodes produce 3 results, index, mask, and flags. X86ISelDAGToDAG; // will emit one or two instructions based on which results are used. If; // flags and index/mask this allows us to use a single instruction since; // we won't have to pick and opcode for flags. Instead we can rely on the; // DAG to CSE everything and decide at isel.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:198,Availability,mask,mask,198,"// SSE42 string comparisons.; // These nodes produce 3 results, index, mask, and flags. X86ISelDAGToDAG; // will emit one or two instructions based on which results are used. If; // flags and index/mask this allows us to use a single instruction since; // we won't have to pick and opcode for flags. Instead we can rely on the; // DAG to CSE everything and decide at isel.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Testability,Test,Test,3,// Test if in transactional execution.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Availability,Mask,Masked,3,"// Masked version of above.; // SRC, RND, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:52,Availability,MASK,MASK,52,"// Masked version of above.; // SRC, RND, PASSTHRU, MASK",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:27,Testability,test,testui,27,// User level interrupts - testui,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Performance,Perform,Perform,3,// Perform an FP80 add after changing precision control in FPCW.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:33,Availability,mask,mask,33,/// Vector comparison generating mask bits for fp and; /// integer signed and unsigned data types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:13,Modifiability,extend,extend,13,// Vector FP extend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:131,Availability,mask,mask,131,// RndScale - Round FP Values To Include A Given Number Of Fraction Bits.; // Also used by the legacy (V)ROUND intrinsics where we mask out the; // scaling part of the immediate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Performance,Perform,Perform,3,// Perform an FP80 add after changing precision control in FPCW.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:36,Modifiability,extend,extend,36,"// Load, scalar_to_vector, and zero extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Performance,Load,Load,3,"// Load, scalar_to_vector, and zero extend.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Performance,Load,Load,3,// Load FP control word from i16 memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:3,Performance,Load,Load,3,// Load x87 FPU environment from memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:35,Modifiability,extend,extending,35,"/// This instruction implements an extending load to FP stack slots.; /// This corresponds to the X86::FLD32m / X86::FLD64m. It takes a chain; /// operand, and ptr to load from. The memory VT specifies the type to; /// load from.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:45,Performance,load,load,45,"/// This instruction implements an extending load to FP stack slots.; /// This corresponds to the X86::FLD32m / X86::FLD64m. It takes a chain; /// operand, and ptr to load from. The memory VT specifies the type to; /// load from.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:167,Performance,load,load,167,"/// This instruction implements an extending load to FP stack slots.; /// This corresponds to the X86::FLD32m / X86::FLD64m. It takes a chain; /// operand, and ptr to load from. The memory VT specifies the type to; /// load from.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:219,Performance,load,load,219,"/// This instruction implements an extending load to FP stack slots.; /// This corresponds to the X86::FLD32m / X86::FLD64m. It takes a chain; /// operand, and ptr to load from. The memory VT specifies the type to; /// load from.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:21,Availability,mask,masked,21,// Vector truncating masked store with unsigned/signed saturation,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:233,Deployability,update,updated,233,"/// Compare and Add if Condition is Met. Compare value in operand 2 with; /// value in memory of operand 1. If condition of operand 4 is met, add; /// value operand 3 to m32 and write new value in operand 1. Operand 2 is; /// always updated with the original value from operand 1.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:7,Availability,mask,mask,7,// Bit mask selecting rounding mode,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:21,Performance,load,load,21,"/// Check if Op is a load operation that could be folded into some other x86; /// instruction as a memory operand. Example: vpaddd (%rdi), %xmm0, %xmm0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:21,Performance,load,load,21,"/// Check if Op is a load operation that could be folded into a vector splat; /// instruction as a memory operand. Example: vbroadcastss 16(%rdi), %xmm2.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:65,Modifiability,extend,extend,65,/// Check if Op is an operation that could be folded into a zero extend x86; /// instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:146,Integrability,interface,interface,146,// end namespace X86; //===--------------------------------------------------------------------===//; // X86 Implementation of the TargetLowering interface,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:37,Performance,load,load,37,"/// Returns true if it's safe to use load / store of the; /// specified type to expand memcpy / memset inline. This is mostly true; /// for all types except for some special cases. For example, on X86; /// targets without SSE2 f64 load / store are done with fldl / fstpl which; /// also does type conversion. Note the specified type doesn't have to be; /// legal as the hook is used before type legalization.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:231,Performance,load,load,231,"/// Returns true if it's safe to use load / store of the; /// specified type to expand memcpy / memset inline. This is mostly true; /// for all types except for some special cases. For example, on X86; /// targets without SSE2 f64 load / store are done with fldl / fstpl which; /// also does type conversion. Note the specified type doesn't have to be; /// legal as the hook is used before type legalization.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:25,Safety,safe,safe,25,"/// Returns true if it's safe to use load / store of the; /// specified type to expand memcpy / memset inline. This is mostly true; /// for all types except for some special cases. For example, on X86; /// targets without SSE2 f64 load / store are done with fldl / fstpl which; /// also does type conversion. Note the specified type doesn't have to be; /// legal as the hook is used before type legalization.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:55,Security,access,accesses,55,"/// Returns true if the target allows unaligned memory accesses of the; /// specified type. Returns whether it is ""fast"" in the last argument.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:45,Security,access,access,45,"/// This function returns true if the memory access is aligned or if the; /// target allows this specific unaligned memory access. If the access is; /// allowed, the optional final parameter returns a relative speed of the; /// access (as defined by the target).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:123,Security,access,access,123,"/// This function returns true if the memory access is aligned or if the; /// target allows this specific unaligned memory access. If the access is; /// allowed, the optional final parameter returns a relative speed of the; /// access (as defined by the target).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:138,Security,access,access,138,"/// This function returns true if the memory access is aligned or if the; /// target allows this specific unaligned memory access. If the access is; /// allowed, the optional final parameter returns a relative speed of the; /// access (as defined by the target).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:228,Security,access,access,228,"/// This function returns true if the memory access is aligned or if the; /// target allows this specific unaligned memory access. If the access is; /// allowed, the optional final parameter returns a relative speed of the; /// access (as defined by the target).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:115,Performance,optimiz,optimizations,115,/// Do not merge vector stores after legalization because that may conflict; /// with x86-specific store splitting optimizations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:240,Safety,avoid,avoids,240,"// If the pair to store is a mixture of float and int values, we will; // save two bitwise instructions and one float-to-int instruction and; // increase one store instruction. There is potentially a more; // significant benefit because it avoids the float->int domain switch; // for input value. So It is more likely a win.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:232,Testability,test,testcase,232,"// If the pair only contains int values, we will save two bitwise; // instructions and increase one store instruction (costing one more; // store buffer). Since the benefit is more blurred so we leave; // such pair out until we get testcase to prove it is a win.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:45,Availability,Mask,Mask,45,/// Determine which of the bits specified in Mask are known to be either; /// zero or one and return them in the KnownZero/KnownOne bitsets.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:194,Availability,error,error,194,"/// Given a physical register constraint; /// (e.g. {edx}), return the register number and the register class for the; /// register. This should only be used for C_Register constraints. On; /// error, this returns a register number of 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:94,Performance,load,load,94,"/// Return true if the addressing mode represented; /// by AM is legal for this target, for a load/store of the specified type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:94,Modifiability,extend,extends,94,"/// Return true if any actual instruction that defines a; /// value of type Ty1 implicit zero-extends the value to Ty2 in the result; /// register. This does not necessarily include registers defined in; /// unknown ways, such as incoming arguments, or copies from unknown; /// virtual registers. Also, if isTruncateFree(Ty2, Ty1) is true, this; /// does not necessarily apply to truncate instructions. e.g. on x86-64,; /// all instructions that define 32-bit values implicit zero-extend the; /// result out to 64 bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:481,Modifiability,extend,extend,481,"/// Return true if any actual instruction that defines a; /// value of type Ty1 implicit zero-extends the value to Ty2 in the result; /// register. This does not necessarily include registers defined in; /// unknown ways, such as incoming arguments, or copies from unknown; /// virtual registers. Also, if isTruncateFree(Ty2, Ty1) is true, this; /// does not necessarily apply to truncate instructions. e.g. on x86-64,; /// all instructions that define 32-bit values implicit zero-extend the; /// result out to 64 bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:80,Modifiability,extend,extend,80,"/// Return true if folding a vector load into ExtVal (a sign, zero, or any; /// extend node) is profitable.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:36,Performance,load,load,36,"/// Return true if folding a vector load into ExtVal (a sign, zero, or any; /// extend node) is profitable.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:164,Performance,load,load,164,"/// Returns true if the target can instruction select the; /// specified FP immediate natively. If false, the legalizer will; /// materialize the FP immediate as a load from a constant pool.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:119,Availability,mask,masks,119,"/// Targets can use this to indicate that they only support *some*; /// VECTOR_SHUFFLE operations, those with specific masks. By default, if a; /// target supports the VECTOR_SHUFFLE node, all mask values are assumed to; /// be legal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:193,Availability,mask,mask,193,"/// Targets can use this to indicate that they only support *some*; /// VECTOR_SHUFFLE operations, those with specific masks. By default, if a; /// target supports the VECTOR_SHUFFLE node, all mask values are assumed to; /// be legal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:160,Energy Efficiency,reduce,reduce,160,"/// If true, then instruction selection should; /// seek to shrink the FP constant of the specified type to a smaller type; /// in order to save space and / or reduce runtime.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:62,Energy Efficiency,reduce,reduce,62,/// Return true if we believe it is correct and profitable to reduce the; /// load node to a smaller type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:78,Performance,load,load,78,/// Return true if we believe it is correct and profitable to reduce the; /// load node to a smaller type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:50,Performance,load,load,50,/// Returns true if it is beneficial to convert a load of a constant; /// to just the constant itself.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:64,Energy Efficiency,power,power,64,"/// Scalar ops always have equal or better analysis/performance/power than; /// the vector equivalent, so this always makes sense if the scalar op is; /// supported.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:52,Performance,perform,performance,52,"/// Scalar ops always have equal or better analysis/performance/power than; /// the vector equivalent, so this always makes sense if the scalar op is; /// supported.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:130,Performance,load,load,130,"// If we can replace more than 2 scalar stores, there will be a reduction; // in instructions even after we add a vector constant load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:57,Performance,cache,cache,57,/// Intel processors have a unified instruction and data cache,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:37,Safety,Safe,SafeStack,37,"/// Return true if the target stores SafeStack pointer at a fixed offset in; /// some non-standard address space, and populates the address space and; /// offset as appropriate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:22,Performance,load,load,22,/// Lower interleaved load(s) into target specific; /// instructions/intrinsics.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:80,Performance,optimiz,optimization,80,// Call lowering helpers.; /// Check whether the call is eligible for tail call optimization. Targets; /// that want to do tail call optimization should implement this function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:133,Performance,optimiz,optimization,133,// Call lowering helpers.; /// Check whether the call is eligible for tail call optimization. Targets; /// that want to do tail call optimization should implement this function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:108,Availability,Mask,MaskedGatherScatterSDNode,108,// end namespace X86; // X86 specific Gather/Scatter nodes.; // The class has the same order of operands as MaskedGatherScatterSDNode for; // convenience.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h:39,Availability,mask,mask,39,/// Generate unpacklo/unpackhi shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:212,Availability,recover,recover,212,"/// Call this when the user attempts to do something unsupported, like; /// returning a double without SSE2 enabled on x86_64. This is not fatal, unlike; /// report_fatal_error, so calling code should attempt to recover without; /// crashing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:212,Safety,recover,recover,212,"/// Call this when the user attempts to do something unsupported, like; /// returning a double without SSE2 enabled on x86_64. This is not fatal, unlike; /// report_fatal_error, so calling code should attempt to recover without; /// crashing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:46,Availability,avail,available,46,// Split v64i1 vectors if we don't have v64i8 available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:46,Availability,avail,available,46,// Split v64i1 vectors if we don't have v64i8 available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:97,Testability,log,logic,97,/// It returns EVT::Other if the type should be determined using generic; /// target-independent logic.; /// For vector ops we check that the overall size isn't larger than our; /// preferred vector width.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:37,Security,access,accesses,37,// FIXME: Check if unaligned 64-byte accesses are slow.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:37,Security,access,accesses,37,// FIXME: Check if unaligned 32-byte accesses are slow.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:104,Performance,load,loads,104,"// Do not use f64 to lower memcpy if source is string constant. It's; // better to use i32 to avoid the loads.; // Also, do not use f64 to lower memset unless this is a memset of zeros.; // The gymnastics of splatting a byte value into an XMM register and then; // only using 8-byte stores (because this is a CPU with slow unaligned; // 16-byte accesses) makes that a loser.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:94,Safety,avoid,avoid,94,"// Do not use f64 to lower memcpy if source is string constant. It's; // better to use i32 to avoid the loads.; // Also, do not use f64 to lower memset unless this is a memset of zeros.; // The gymnastics of splatting a byte value into an XMM register and then; // only using 8-byte stores (because this is a CPU with slow unaligned; // 16-byte accesses) makes that a loser.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:345,Security,access,accesses,345,"// Do not use f64 to lower memcpy if source is string constant. It's; // better to use i32 to avoid the loads.; // Also, do not use f64 to lower memset unless this is a memset of zeros.; // The gymnastics of splatting a byte value into an XMM register and then; // only using 8-byte stores (because this is a CPU with slow unaligned; // 16-byte accesses) makes that a loser.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:53,Security,access,accesses,53,"// This is a compromise. If we reach here, unaligned accesses may be slow on; // this target. However, creating smaller, aligned accesses could be even; // slower and would certainly be a lot more code.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:129,Security,access,accesses,129,"// This is a compromise. If we reach here, unaligned accesses may be slow on; // this target. However, creating smaller, aligned accesses could be even; // slower and would certainly be a lot more code.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:38,Security,access,accesses,38,// TODO: What about AVX-512 (512-bit) accesses?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:127,Availability,down,down,127,"// NT loads can only be vector aligned, so if its less aligned than the; // minimum vector size (which we can split the vector down to), we might as; // well use a regular unaligned vector load.; // We don't have any NT loads pre-SSE41.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:6,Performance,load,loads,6,"// NT loads can only be vector aligned, so if its less aligned than the; // minimum vector size (which we can split the vector down to), we might as; // well use a regular unaligned vector load.; // We don't have any NT loads pre-SSE41.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:189,Performance,load,load,189,"// NT loads can only be vector aligned, so if its less aligned than the; // minimum vector size (which we can split the vector down to), we might as; // well use a regular unaligned vector load.; // We don't have any NT loads pre-SSE41.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:220,Performance,load,loads,220,"// NT loads can only be vector aligned, so if its less aligned than the; // minimum vector size (which we can split the vector down to), we might as; // well use a regular unaligned vector load.; // We don't have any NT loads pre-SSE41.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:14,Security,access,accesses,14,// Misaligned accesses of any size are always allowed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:123,Modifiability,variab,variable,123,"// glibc, bionic, and Fuchsia have a special slot for the stack guard in; // tcbhead_t; use it instead of the usual global variable (see; // sysdeps/{i386,x86_64}/nptl/tls.h)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:25,Modifiability,variab,variable,25,// MSVC CRT has a global variable holding security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:42,Security,secur,security,42,// MSVC CRT has a global variable holding security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:30,Security,validat,validate,30,// MSVC CRT has a function to validate security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:39,Security,secur,security,39,// MSVC CRT has a function to validate security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:25,Modifiability,variab,variable,25,// MSVC CRT has a global variable holding security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:42,Security,secur,security,42,// MSVC CRT has a global variable holding security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:30,Security,validat,validate,30,// MSVC CRT has a function to validate security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:39,Security,secur,security,39,// MSVC CRT has a function to validate security cookie.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:45,Safety,Safe,SafeStack,45,// Android provides a fixed TLS slot for the SafeStack pointer. See the; // definition of TLS_SLOT_SAFESTACK in; // https://android.googlesource.com/platform/bionic/+/master/libc/private/bionic_tls.h,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:83,Testability,test,tests,83,"// FIXME: We should def X86::FPCW for x87 as well. But it affects a lot of lit; // tests at the moment, which is not what we expected.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:11,Availability,mask,masks,11,/// Lowers masks values (v*i1) to the local register values; /// \returns DAG node after lowering to register type,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:13,Availability,error,error,13,// Report an error if we have attempted to return a value via an XMM; // register and SSE was disabled.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:58,Availability,error,error,58,"// When returning a double via an XMM register, report an error if SSE2 is; // not enabled.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:25,Availability,avail,available,25,"// If we don't have SSE2 available, convert to v4f32 so the generated; // register is legal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:23,Deployability,update,updated,23,// Operand #0 = Chain (updated below); // Operand #1 = Bytes To Pop,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:253,Integrability,depend,depending,253,"// Swift calling convention does not require we copy the sret argument; // into %rax/%eax for the return, and SRetReturnReg is not set for Swift.; // All x86 ABIs require that for returning structs by value we copy; // the sret argument into %rax/%eax (depending on ABI) for the return.; // We saved the argument into a virtual register in the entry block,; // so now we copy the value out and into %rax/%eax.; //; // Checking Function.hasStructRetAttr() here is insufficient because the IR; // may not have an explicit sret argument. If FuncInfo.CanLowerReturn is; // false, then an sret argument may be implicitly inserted in the SelDAG. In; // either case FuncInfo->setSRetReturnReg() will have been called.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:139,Deployability,update,updated,139,"// When we have both sret and another return value, we should use the; // original Chain stored in RetOps[0], instead of the current Chain updated; // in the above loop. If we only have sret, RetOps[0] equals to Chain.; // For the case of sret and another return value, we have; // Chain_0 at the function entry; // Chain_1 = getCopyToReg(Chain_0) in the above loop; // If we use Chain_1 in getCopyFromReg, we will have; // Val = getCopyFromReg(Chain_1); // Chain_2 = getCopyToReg(Chain_1, Val) from below; // getCopyToReg(Chain_0) will be glued together with; // getCopyToReg(Chain_1, Val) into Unit A, getCopyFromReg(Chain_1) will be; // in Unit B, and we will have cyclic dependency between Unit A and Unit B:; // Data dependency from Unit B to Unit A due to usage of Val in; // getCopyToReg(Chain_1, Val); // Chain dependency from Unit A to Unit B; // So here, we use RetOps[0] (i.e Chain_0) for getCopyFromReg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:675,Integrability,depend,dependency,675,"// When we have both sret and another return value, we should use the; // original Chain stored in RetOps[0], instead of the current Chain updated; // in the above loop. If we only have sret, RetOps[0] equals to Chain.; // For the case of sret and another return value, we have; // Chain_0 at the function entry; // Chain_1 = getCopyToReg(Chain_0) in the above loop; // If we use Chain_1 in getCopyFromReg, we will have; // Val = getCopyFromReg(Chain_1); // Chain_2 = getCopyToReg(Chain_1, Val) from below; // getCopyToReg(Chain_0) will be glued together with; // getCopyToReg(Chain_1, Val) into Unit A, getCopyFromReg(Chain_1) will be; // in Unit B, and we will have cyclic dependency between Unit A and Unit B:; // Data dependency from Unit B to Unit A due to usage of Val in; // getCopyToReg(Chain_1, Val); // Chain dependency from Unit A to Unit B; // So here, we use RetOps[0] (i.e Chain_0) for getCopyFromReg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:722,Integrability,depend,dependency,722,"// When we have both sret and another return value, we should use the; // original Chain stored in RetOps[0], instead of the current Chain updated; // in the above loop. If we only have sret, RetOps[0] equals to Chain.; // For the case of sret and another return value, we have; // Chain_0 at the function entry; // Chain_1 = getCopyToReg(Chain_0) in the above loop; // If we use Chain_1 in getCopyFromReg, we will have; // Val = getCopyFromReg(Chain_1); // Chain_2 = getCopyToReg(Chain_1, Val) from below; // getCopyToReg(Chain_0) will be glued together with; // getCopyToReg(Chain_1, Val) into Unit A, getCopyFromReg(Chain_1) will be; // in Unit B, and we will have cyclic dependency between Unit A and Unit B:; // Data dependency from Unit B to Unit A due to usage of Val in; // getCopyToReg(Chain_1, Val); // Chain dependency from Unit A to Unit B; // So here, we use RetOps[0] (i.e Chain_0) for getCopyFromReg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:819,Integrability,depend,dependency,819,"// When we have both sret and another return value, we should use the; // original Chain stored in RetOps[0], instead of the current Chain updated; // in the above loop. If we only have sret, RetOps[0] equals to Chain.; // For the case of sret and another return value, we have; // Chain_0 at the function entry; // Chain_1 = getCopyToReg(Chain_0) in the above loop; // If we use Chain_1 in getCopyFromReg, we will have; // Val = getCopyFromReg(Chain_1); // Chain_2 = getCopyToReg(Chain_1, Val) from below; // getCopyToReg(Chain_0) will be glued together with; // getCopyToReg(Chain_1, Val) into Unit A, getCopyFromReg(Chain_1) will be; // in Unit B, and we will have cyclic dependency between Unit A and Unit B:; // Data dependency from Unit B to Unit A due to usage of Val in; // getCopyToReg(Chain_1, Val); // Chain dependency from Unit A to Unit B; // So here, we use RetOps[0] (i.e Chain_0) for getCopyFromReg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Deployability,Update,Update,3,// Update chain.; // Add the glue if we have it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:81,Performance,perform,perform,81,"// If the copy has a glue operand, we conservatively assume it isn't safe to; // perform a tail call.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:69,Safety,safe,safe,69,"// If the copy has a glue operand, we conservatively assume it isn't safe to; // perform a tail call.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:48,Modifiability,extend,extended,48,"// The ABI does not require i1, i8 or i16 to be extended.; //; // On Darwin, there is code in the wild relying on Clang's old behaviour of; // always extending i8/i16 return values, so keep doing that for now.; // (PR26665).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:150,Modifiability,extend,extending,150,"// The ABI does not require i1, i8 or i16 to be extended.; //; // On Darwin, there is code in the wild relying on Clang's old behaviour of; // always extending i8/i16 return values, so keep doing that for now.; // (PR26665).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:52,Availability,mask,mask,52,"/// Reads two 32 bit registers and creates a 64 bit mask value.; /// \param VA The current 32 bit value that need to be assigned.; /// \param NextVA The next 32 bit value that need to be assigned.; /// \param Root The parent DAG node.; /// \param [in,out] InGlue Represents SDvalue in the parent DAG node for; /// glue purposes. In the case the DAG is already using; /// physical register instead of virtual, we should glue; /// our new SDValue to InGlue SDvalue.; /// \return a new SDvalue of size 64bit.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:31,Availability,avail,available,31,// When a physical register is available read the value from it and glue; // the reads together.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:79,Availability,mask,mask,79,/// The function will lower a register of various sizes (8/16/32/64); /// to a mask value of the expected size (v8i1/v16i1/v32i1/v64i1); /// \returns a DAG node contains the operand after lowering to mask type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:200,Availability,mask,mask,200,/// The function will lower a register of various sizes (8/16/32/64); /// to a mask value of the expected size (v8i1/v16i1/v32i1/v64i1); /// \returns a DAG node contains the operand after lowering to mask type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:90,Availability,mask,mask,90,// In some calling conventions we need to remove the used registers; // from the register mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:13,Availability,error,error,13,// Report an error if there was an attempt to return FP values via XMM; // registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP1, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP1, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP1, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP1, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:19,Safety,avoid,avoid,19,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:33,Testability,assert,asserts,33,"// Set reg to FP0, avoid hitting asserts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:15,Availability,mask,mask,15,// promoting a mask type (v*i1) into a register of type i64/i32/i16/i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:298,Integrability,rout,routines,298,"//===----------------------------------------------------------------------===//; // C & StdCall & Fast Calling Convention implementation; //===----------------------------------------------------------------------===//; // StdCall calling convention seems to be standard for many Windows' API; // routines and around. It differs from C calling convention just a little:; // callee should clean up the stack, not caller. Symbols should be also; // decorated in some fancy way :) It doesn't support any vector arguments.; // For info on fast calling convention see Fast Calling Convention (tail call); // implementation LowerX86_32FastCCCallTo.; /// Determines whether Args, either a set of outgoing arguments to a call, or a; /// set of incoming args of a call, contains an sret pointer that the callee; /// pops",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:35,Availability,avail,available,35,"// Not C++20 (yet), so no concepts available.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:39,Performance,load,load,39,// Create the nodes corresponding to a load from this parameter slot.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:114,Availability,mask,mask,114,// If value is passed by pointer we have address passed instead of the value; // itself. No need to extend if the mask value and location share the same; // absolute size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:100,Modifiability,extend,extend,100,// If value is passed by pointer we have address passed instead of the value; // itself. No need to extend if the mask value and location share the same; // absolute size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:136,Performance,optimiz,optimization,136,"// FIXME: For now, all byval parameter objects are marked mutable. This can be; // changed with more analysis.; // In case of tail call optimization mark all arguments mutable. Since they; // could be overwritten by lowering of arguments in case of a tail call.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:54,Performance,perform,perform,54,"// This is an argument in memory. We might be able to perform copy elision.; // If the argument is passed directly in memory without any extension, then we; // can perform copy elision. Large vector types, for example, may be passed; // indirectly by pointer.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:164,Performance,perform,perform,164,"// This is an argument in memory. We might be able to perform copy elision.; // If the argument is passed directly in memory without any extension, then we; // can perform copy elision. Large vector types, for example, may be passed; // indirectly by pointer.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:150,Performance,load,load,150,"// If this is a one-part value or the first part of a multi-part value,; // create a stack object for the entire argument value type and return a; // load from our portion of it. This assumes that if the first part of an; // argument is in memory, the rest will also be in memory.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:211,Performance,load,load,211,"// This is not the first piece of an argument in memory. See if there is; // already a fixed stack object including this offset. If so, assume it; // was created by the PartOffset == 0 branch above and create a load from; // the appropriate offset into it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:40,Modifiability,variab,variable,40,/// This is a helper class for lowering variable arguments parameters.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:9,Modifiability,variab,variable,9,// Lower variable arguments parameters.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:25,Modifiability,variab,variable,25,"// If the function takes variable number of arguments, make a frame index for; // the start of the first vararg value... for expansion of llvm.va_start. We; // can skip this if there are no va_start calls.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:21,Energy Efficiency,allocate,allocated,21,// Get to the caller-allocated home save location. Add 8 to account; // for the return address.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:152,Performance,load,loaded,152,"// For X86-64, if there are vararg parameters that are passed via; // registers, then we must store them to their spots on the stack so; // they may be loaded by dereferencing the result of va_next.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:203,Safety,avoid,avoid,203,// FastRegisterAllocator spills virtual registers at basic; // block boundary. That leads to usages of xmm registers; // outside of check for %al. Pass physical registers to; // VASTART_SAVE_XMM_REGS to avoid unneccessary spilling.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:40,Energy Efficiency,schedul,schedule,40,// FIXME: Can we use a less constrained schedule?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate shadow area for Win64.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:91,Testability,assert,assert,91,"// If this is an 8 or 16-bit value, it is really passed promoted to 32; // bits. Insert an assert[sz]ext to capture this, then truncate to the; // right size.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:15,Availability,mask,mask,15,// Promoting a mask type (v*i1) into a register of type i64/i32/i16/i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:41,Performance,load,load,41,// If value is passed via pointer - do a load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:106,Integrability,depend,depending,106,// All x86 ABIs require that for returning structs by value we copy the; // sret argument into %rax/%eax (depending on ABI) for the return. Save; // the argument into a virtual register so that we can access it from the; // return points.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:201,Security,access,access,201,// All x86 ABIs require that for returning structs by value we copy the; // sret argument into %rax/%eax (depending on ABI) for the return. Save; // the argument into a virtual register so that we can access it from the; // return points.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:31,Availability,error,error,31,// X86 interrupts must pop the error code (and the alignment padding) if; // present.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:108,Energy Efficiency,allocate,allocated,108,"// TODO: Add a mechanism to frame lowering that will allow us to indicate; // that we'd prefer this slot be allocated towards the bottom of the frame; // (i.e. near the stack pointer after allocating the frame). Every; // funclet needs a copy of this slot in its (mostly empty) frame, and the; // offset from the bottom of this and each funclet's frame must be the; // same, so the size of funclets' (mostly empty) frames is dictated by; // how far this slot is from the bottom (since they allocate just enough; // space to accommodate holding this slot at the correct offset).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:490,Energy Efficiency,allocate,allocate,490,"// TODO: Add a mechanism to frame lowering that will allow us to indicate; // that we'd prefer this slot be allocated towards the bottom of the frame; // (i.e. near the stack pointer after allocating the frame). Every; // funclet needs a copy of this slot in its (mostly empty) frame, and the; // offset from the bottom of this and each funclet's frame must be the; // same, so the size of funclets' (mostly empty) frames is dictated by; // how far this slot is from the bottom (since they allocate just enough; // space to accommodate holding this slot at the correct offset).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:11,Performance,load,load,11,/// Emit a load of return address if tail call; /// optimization is performed and it is required.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:52,Performance,optimiz,optimization,52,/// Emit a load of return address if tail call; /// optimization is performed and it is required.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:68,Performance,perform,performed,68,/// Emit a load of return address if tail call; /// optimization is performed and it is required.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Performance,Load,Load,3,"// Load the ""old"" Return address.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:57,Performance,optimiz,optimization,57,/// Emit a store of the return address if tail call; /// optimization is performed and it is required (FPDiff!=0).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:73,Performance,perform,performed,73,/// Emit a store of the return address if tail call; /// optimization is performed and it is required (FPDiff!=0).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:29,Availability,mask,mask,29,"/// Returns a vector_shuffle mask for an movs{s|d}, movd; /// operation of specified width.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:30,Safety,detect,detected,30,// Sibcalls are automatically detected tailcalls which do not require; // ABI changes.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate shadow area for Win64.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:46,Availability,avail,available,46,// This is a sibcall. The memory operands are available in caller's; // own caller's stack.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:69,Energy Efficiency,allocate,allocated,69,"// If we have an inalloca argument, all stack space has already been allocated; // for us and be right at the top of the stack. We don't support multiple; // arguments passed in memory when using inalloca.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Performance,Load,Load,3,// Load return address for tail calls.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:58,Performance,load,loads,58,"// Walk the register/memloc assignments, inserting copies/loads. In the case; // of tail call optimization arguments are handle later.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:94,Performance,optimiz,optimization,94,"// Walk the register/memloc assignments, inserting copies/loads. In the case; // of tail call optimization arguments are handle later.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:510,Availability,down,down,510,// If we are tail calling and generating PIC/GOT style code load the; // address of the callee into ECX. The value in ecx is used as target of; // the tail jump. This is done to circumvent the ebx/callee-saved problem; // for tail calls on PIC/GOT architectures. Normally we would just put the; // address of GOT into ebx and then call target@PLT. But for tail calls; // ebx would be restored (since ebx is callee saved) before jumping to the; // target@PLT.; // Note: The actual moving to ECX is done further down.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:60,Performance,load,load,60,// If we are tail calling and generating PIC/GOT style code load the; // address of the callee into ECX. The value in ecx is used as target of; // the tail jump. This is done to circumvent the ebx/callee-saved problem; // for tail calls on PIC/GOT architectures. Normally we would just put the; // address of GOT into ebx and then call target@PLT. But for tail calls; // ebx would be restored (since ebx is callee saved) before jumping to the; // target@PLT.; // Note: The actual moving to ECX is done further down.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:487,Energy Efficiency,allocate,allocated,487,"// From AMD64 ABI document:; // For calls that may call functions that use varargs or stdargs; // (prototype-less calls or calls to functions containing ellipsis (...) in; // the declaration) %al is used as hidden argument to specify the number; // of SSE registers used. The contents of %al do not need to match exactly; // the number of registers, but must be an ubound on the number of SSE; // registers used and is in the range 0 - 8 inclusive.; // Count the number of XMM registers allocated.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:359,Integrability,depend,depends,359,"// Force all the incoming stack arguments to be loaded from the stack; // before any new outgoing arguments are stored to the stack, because the; // outgoing stack slots may alias the incoming argument stack slots, and; // the alias isn't otherwise explicit. This is slightly more conservative; // than necessary, because it means that each store effectively depends; // on every argument instead of just those arguments it would clobber.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:48,Performance,load,loaded,48,"// Force all the incoming stack arguments to be loaded from the stack; // before any new outgoing arguments are stored to the stack, because the; // outgoing stack slots may alias the incoming argument stack slots, and; // the alias isn't otherwise explicit. This is slightly more conservative; // than necessary, because it means that each store effectively depends; // on every argument instead of just those arguments it would clobber.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:124,Integrability,Wrap,WrapperRIP,124,// Lower direct calls to global addresses and external symbols. Setting; // ForCall to true here has the effect of removing WrapperRIP when possible; // to allow direct calls to be selected without first materializing the; // address into a register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:8,Modifiability,extend,extend,8,// Zero-extend the 32-bit Callee address into a 64-bit according to x32 ABI,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:18,Availability,mask,mask,18,// Add a register mask operand representing the call-preserved registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:133,Availability,mask,mask,133,"// If HasNCSR is asserted (attribute NoCallerSavedRegisters exists),; // use X86_INTR calling convention because it has the same CSR mask; // (same preserved registers).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:17,Testability,assert,asserted,17,"// If HasNCSR is asserted (attribute NoCallerSavedRegisters exists),; // use X86_INTR calling convention because it has the same CSR mask; // (same preserved registers).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:255,Energy Efficiency,allocate,allocate,255,"// If this is an invoke in a 32-bit function using a funclet-based; // personality, assume the function clobbers all registers. If an exception; // is thrown, the runtime will not restore CSRs.; // FIXME: Model this more precisely so that we can register allocate across; // the normal edge and spill and fill across the exceptional edge.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:25,Availability,mask,mask,25,// Define a new register mask from the existing mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:48,Availability,mask,mask,48,// Define a new register mask from the existing mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:94,Availability,mask,mask,94,// In some calling conventions we need to remove the used physical registers; // from the reg mask. Create a new RegMask for such calling conventions.; // RegMask for calling conventions that disable only return registers (e.g.; // preserve_most) will be modified later in LowerCallResult.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:22,Availability,Mask,Mask,22,// Allocate a new Reg Mask and copy Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:36,Availability,Mask,Mask,36,// Allocate a new Reg Mask and copy Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate a new Reg Mask and copy Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:55,Availability,mask,mask,55,// Create the RegMask Operand according to our updated mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:47,Deployability,update,updated,47,// Create the RegMask Operand according to our updated mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:54,Availability,mask,mask,54,// Create the RegMask Operand according to the static mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:421,Performance,optimiz,optimization,421,"//===----------------------------------------------------------------------===//; // Fast Calling Convention (tail call) implementation; //===----------------------------------------------------------------------===//; // Like std call, callee cleans arguments, convention except that ECX is; // reserved for storing the tail called function address. Only 2 registers are; // free for argument passing (inreg). Tail call optimization is performed; // provided:; // * tailcallopt is enabled; // * caller/callee are fastcc; // On X86_64 architecture with GOT-style position independent code only local; // (within module) calls are supported at the moment.; // To keep the stack aligned according to platform abi the function; // GetAlignedArgumentStackSize ensures that argument delta is always multiples; // of stack alignment. (Dynamic linkers need this - Darwin's dyld for example); // If a tail called function callee has more arguments than the caller the; // caller needs to make sure that there is room to move the RETADDR to. This is; // achieved by reserving an area the size of the argument delta right after the; // original RETADDR, but before the saved framepointer or the spilled registers; // e.g. caller(arg1, arg2) calls callee(arg1, arg2,arg3,arg4); // stack layout:; // arg1; // arg2; // RETADDR; // [ new RETADDR; // move area ]; // (possible EBP); // ESI; // EDI; // local1 ..; /// Make the stack size align e.g 16n + 12 aligned for a 16-byte align; /// requirement.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:437,Performance,perform,performed,437,"//===----------------------------------------------------------------------===//; // Fast Calling Convention (tail call) implementation; //===----------------------------------------------------------------------===//; // Like std call, callee cleans arguments, convention except that ECX is; // reserved for storing the tail called function address. Only 2 registers are; // free for argument passing (inreg). Tail call optimization is performed; // provided:; // * tailcallopt is enabled; // * caller/callee are fastcc; // On X86_64 architecture with GOT-style position independent code only local; // (within module) calls are supported at the moment.; // To keep the stack aligned according to platform abi the function; // GetAlignedArgumentStackSize ensures that argument delta is always multiples; // of stack alignment. (Dynamic linkers need this - Darwin's dyld for example); // If a tail called function callee has more arguments than the caller the; // caller needs to make sure that there is room to move the RETADDR to. This is; // achieved by reserving an area the size of the argument delta right after the; // original RETADDR, but before the saved framepointer or the spilled registers; // e.g. caller(arg1, arg2) calls callee(arg1, arg2,arg3,arg4); // stack layout:; // arg1; // arg2; // RETADDR; // [ new RETADDR; // move area ]; // (possible EBP); // ESI; // EDI; // local1 ..; /// Make the stack size align e.g 16n + 12 aligned for a 16-byte align; /// requirement.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:60,Availability,avail,available,60,/// Return true if the given stack call argument is already available in the; /// same position (relatively) of the caller's incoming argument stack.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:53,Performance,optimiz,optimization,53,/// Check whether the call is eligible for tail call optimization. Targets; /// that want to do tail call optimization should implement this function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:106,Performance,optimiz,optimization,106,/// Check whether the call is eligible for tail call optimization. Targets; /// that want to do tail call optimization should implement this function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:155,Performance,perform,perform,155,"// If the function return type is x86_fp80 and the callee return type is not,; // then the FP_EXTEND of the call result is not a nop. It's not safe to; // perform a tailcall optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:174,Performance,optimiz,optimization,174,"// If the function return type is x86_fp80 and the callee return type is not,; // then the FP_EXTEND of the call result is not a nop. It's not safe to; // perform a tailcall optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:143,Safety,safe,safe,143,"// If the function return type is x86_fp80 and the callee return type is not,; // then the FP_EXTEND of the call result is not a nop. It's not safe to; // perform a tailcall optimization here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:34,Performance,perform,perform,34,// Look for obvious safe cases to perform tail call optimization that do not; // require ABI changes. This is what gcc calls sibcall.; // Can't do sibcall if stack needs to be dynamically re-aligned. PEI needs to; // emit a special epilogue.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:52,Performance,optimiz,optimization,52,// Look for obvious safe cases to perform tail call optimization that do not; // require ABI changes. This is what gcc calls sibcall.; // Can't do sibcall if stack needs to be dynamically re-aligned. PEI needs to; // emit a special epilogue.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:20,Safety,safe,safe,20,// Look for obvious safe cases to perform tail call optimization that do not; // require ABI changes. This is what gcc calls sibcall.; // Can't do sibcall if stack needs to be dynamically re-aligned. PEI needs to; // emit a special epilogue.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:22,Performance,optimiz,optimization,22,// Also avoid sibcall optimization if we're an sret return fn and the callee; // is incompatible. See comment in LowerReturn about why hasStructRetAttr is; // insufficient.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:8,Safety,avoid,avoid,8,// Also avoid sibcall optimization if we're an sret return fn and the callee; // is incompatible. See comment in LowerReturn about why hasStructRetAttr is; // insufficient.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:18,Performance,optimiz,optimize,18,// Do not sibcall optimize vararg calls unless all arguments are passed via; // registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Performance,Optimiz,Optimizing,3,// Optimizing for varargs on Win64 is unlikely to be safe without; // additional testing.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:53,Safety,safe,safe,53,// Optimizing for varargs on Win64 is unlikely to be safe without; // additional testing.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:81,Testability,test,testing,81,// Optimizing for varargs on Win64 is unlikely to be safe without; // additional testing.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:142,Performance,optimiz,optimize,142,"// If the call result is in ST0 / ST1, it needs to be popped off the x87; // stack. Therefore, if it's not used by the call it is not safe to optimize; // this into a sibcall.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:134,Safety,safe,safe,134,"// If the call result is in ST0 / ST1, it needs to be popped off the x87; // stack. Therefore, if it's not used by the call it is not safe to optimize; // this into a sibcall.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate shadow area for Win64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:94,Energy Efficiency,allocate,allocate,94,"// If the tailcall address may be in a register, then make sure it's; // possible to register allocate for it. In 32-bit, the call address can; // only target EAX, EDX, or ECX since the tail call must be scheduled after; // callee-saved registers are restored. These happen to be the same; // registers used to pass 'inreg' arguments so watch out for those.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:204,Energy Efficiency,schedul,scheduled,204,"// If the tailcall address may be in a register, then make sure it's; // possible to register allocate for it. In 32-bit, the call address can; // only target EAX, EDX, or ECX since the tail call must be scheduled after; // callee-saved registers are restored. These happen to be the same; // registers used to pass 'inreg' arguments so watch out for those.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:425,Integrability,Inject,Injection,425,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:1769,Modifiability,plugin,plugin,1769,"Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell LLVM that the function was modified.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:52,Performance,load,load,52,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:414,Performance,Load,Load,414,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:470,Performance,load,load,470,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:554,Performance,load,loaded,554,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:613,Performance,load,loaded,613,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:1116,Performance,perform,performance,1116,"or x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell LLVM that the function was modified.; ///; //===------------------",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:1128,Performance,concurren,concurrent,1128,"or x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell LLVM that the function was modified.; ///; //===------------------",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:425,Security,Inject,Injection,425,"//==-- X86LoadValueInjectionLoadHardening.cpp - LVI load hardening for x86 --=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: This pass finds Load Value Injection (LVI) gadgets consisting; /// of a load from memory (i.e., SOURCE), and any operation that may transmit; /// the value loaded from memory over a covert channel, or use the value loaded; /// from memory to determine a branch/call target (i.e., SINK). After finding; /// all such gadgets in a given function, the pass minimally inserts LFENCE; /// instructions in such a manner that the following property is satisfied: for; /// all SOURCE+SINK pairs, all paths in the CFG from SOURCE to SINK contain at; /// least one LFENCE instruction. The algorithm that implements this minimal; /// insertion is influenced by an academic paper that minimally inserts memory; /// fences for high-performance concurrent programs:; /// http://www.cs.ucr.edu/~lesani/companion/oopsla15/OOPSLA15.pdf; /// The algorithm implemented in this pass is as follows:; /// 1. Build a condensed CFG (i.e., a GadgetGraph) consisting only of the; /// following components:; /// - SOURCE instructions (also includes function arguments); /// - SINK instructions; /// - Basic block entry points; /// - Basic block terminators; /// - LFENCE instructions; /// 2. Analyze the GadgetGraph to determine which SOURCE+SINK pairs (i.e.,; /// gadgets) are already mitigated by existing LFENCEs. If all gadgets have been; /// mitigated, go to step 6.; /// 3. Use a heuristic or plugin to approximate minimal LFENCE insertion.; /// 4. Insert one LFENCE along each CFG edge that was cut in step 3.; /// 5. Go to step 2.; /// 6. If any LFENCEs were inserted, return `true` from runOnMachineFunction(); /// to tell",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:56,Performance,load,loaded,56,"// We naively assume that an instruction propagates any loaded; // uses to all defs unless the instruction is a call, in which; // case all arguments will be treated as gadget sources during; // analysis of the callee function.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:24,Performance,load,load,24,"// Found a transmitting load -- no need to continue; // traversing its defs (i.e., this load will become; // a new gadget source anyways).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:88,Performance,load,load,88,"// Found a transmitting load -- no need to continue; // traversing its defs (i.e., this load will become; // a new gadget source anyways).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:9,Modifiability,inherit,inherits,9,// `Def` inherits all of its child defs' transmitters.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:102,Energy Efficiency,efficient,efficient,102,"// For each gadget edge, make cuts that guarantee the gadget will be; // mitigated. A computationally efficient way to achieve this is to either:; // (a) cut all egress CFG edges from the gadget source, or; // (b) cut all ingress CFG edges to the gadget sink.; //; // Moreover, the algorithm tries not to make a cut into a loop by preferring; // to make a (b)-type cut if the gadget source resides at a greater loop depth; // than the gadget sink, or an (a)-type cut otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:32,Availability,redundant,redundant,32,// Ensure this insertion is not redundant (two LFENCEs in sequence).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:32,Safety,redund,redundant,32,// Ensure this insertion is not redundant (two LFENCEs in sequence).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp:562,Availability,avail,available,562,"//===-- X86LoadValueInjectionRetHardening.cpp - LVI RET hardening for x86 --==//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// Description: Replaces every `ret` instruction with the sequence:; /// ```; /// pop <scratch-reg>; /// lfence; /// jmp *<scratch-reg>; /// ```; /// where `<scratch-reg>` is some available scratch register, according to the; /// calling convention of the function being mitigated.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp:23,Availability,avail,available,23,"// In case there is no available scratch register, we can still read; // from RSP to assert that RSP points to a valid page. The write to RSP; // is also helpful because it verifies that the stack's write; // permissions are intact.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp:85,Testability,assert,assert,85,"// In case there is no available scratch register, we can still read; // from RSP to assert that RSP points to a valid page. The write to RSP; // is also helpful because it verifies that the stack's write; // permissions are intact.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionRetHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:951,Energy Efficiency,allocate,allocate,951,"//===-- X86LowerAMXIntrinsics.cpp -X86 Scalarize AMX Intrinsics------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform amx intrinsics to scalar operations.; /// This pass is always enabled and it skips when it is not -O0 and has no; /// optnone attributes. With -O0 or optnone attribute, the def of shape to amx; /// intrinsics is near the amx intrinsics code. We are not able to find a; /// point which post-dominate all the shape and dominate all amx intrinsics.; /// To decouple the dependency of the shape, we transform amx intrinsics; /// to scalar operation, so that compiling doesn't fail. In long term, we; /// should improve fast register allocation to allocate amx register.; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:775,Integrability,depend,dependency,775,"//===-- X86LowerAMXIntrinsics.cpp -X86 Scalarize AMX Intrinsics------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform amx intrinsics to scalar operations.; /// This pass is always enabled and it skips when it is not -O0 and has no; /// optnone attributes. With -O0 or optnone attribute, the def of shape to amx; /// intrinsics is near the amx intrinsics code. We are not able to find a; /// point which post-dominate all the shape and dominate all amx intrinsics.; /// To decouple the dependency of the shape, we transform amx intrinsics; /// to scalar operation, so that compiling doesn't fail. In long term, we; /// should improve fast register allocation to allocate amx register.; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:135,Performance,load,load,135,"// tileload.scalarize.cols.body:; // Calculate %idxmem and %idxvec; // %eltptr = getelementptr i32, i32* %base, i64 %idxmem; // %elt = load i32, i32* %ptr; // %ResVec = insertelement <256 x i32> %vec.phi, i32 %elt, i16 %idxvec",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:523,Energy Efficiency,reduce,reduce,523,"// tiledpbssd.scalarize.inner.body:; // calculate idxa, idxb; // %eltc = extractelement <256 x i32> %vec.c.inner.phi, i16 %idxc; // %elta = extractelement <256 x i32> %veca, i16 %idxa; // %eltav4i8 = bitcast i32 %elta to <4 x i8>; // %eltb = extractelement <256 x i32> %vecb, i16 %idxb; // %eltbv4i8 = bitcast i32 %eltb to <4 x i8>; // %eltav4i32 = sext <4 x i8> %eltav4i8 to <4 x i32>; // %eltbv4i32 = sext <4 x i8> %eltbv4i8 to <4 x i32>; // %mulab = mul <4 x i32> %eltbv4i32, %eltav4i32; // %acc = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %131); // %neweltc = add i32 %elt, %acc; // %NewVecC = insertelement <256 x i32> %vec.c.inner.phi, i32 %neweltc,; // i16 %idxc",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:831,Energy Efficiency,reduce,reduce,831,"// tiledpbf16ps.scalarize.inner.body:; // calculate idxa, idxb, idxc; // %eltc = extractelement <256 x i32> %vec.c.inner.phi, i16 %idxc; // %eltcf32 = bitcast i32 %eltc to float; // %elta = extractelement <256 x i32> %veca, i16 %idxa; // %eltav2i16 = bitcast i32 %elta to <2 x i16>; // %eltb = extractelement <256 x i32> %vecb, i16 %idxb; // %eltbv2i16 = bitcast i32 %eltb to <2 x i16>; // %shufflea = shufflevector <2 x i16> %elta, <2 x i16> zeroinitializer, <4; // x i32> <i32 2, i32 0, i32 3, i32 1>; // %eltav2f32 = bitcast <4 x i16> %shufflea to <2 x float>; // %shuffleb = shufflevector <2 x i16> %eltb, <2 xi16> zeroinitializer, <4 x; // i32> <i32 2, i32 0, i32 3, i32 1>; // %eltbv2f32 = bitcast <4 x i16> %shuffleb to <2 x float>; // %mulab = fmul <2 x float> %eltav2f32, %eltbv2f32; // %acc = call float; // @llvm.vector.reduce.fadd.v2f32(float %eltcf32, <2 x float> %mulab); // %neweltc = bitcast float %acc to i32; // %NewVecC = insertelement <256 x i32> %vec.c.inner.phi, i32 %neweltc,; // i16 %idxc; // %NewVecD = insertelement <256 x i32> %vec.d.inner.phi, i32 %neweltc,; // i16 %idxc",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:1211,Energy Efficiency,allocate,allocated,1211,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:420,Performance,load,load,420,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:742,Performance,load,load,742,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:784,Performance,load,load,784,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:841,Performance,load,load,841,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:885,Performance,load,load,885,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:923,Performance,load,load,923,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:523,Usability,simpl,simple,523,"//===- Target/X86/X86LowerAMXType.cpp - -------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to transform <256 x i32> load/store; /// <256 x i32> is bitcasted to x86_amx on X86, and AMX instruction set only; /// provides simple operation on x86_amx. The basic elementwise operation; /// is not supported by AMX. Since x86_amx is bitcasted from vector <256 x i32>; /// and only AMX intrinsics can operate on the type, we need transform; /// load/store <256 x i32> instruction to AMX load/store. If the bitcast can; /// not be combined with load/store, we transform the bitcast to amx load/store; /// and <256 x i32> store/load.; ///; /// If Front End not use O0 but the Mid/Back end use O0, (e.g. ""Clang -O2 -S; /// -emit-llvm t.c"" + ""llc t.ll"") we should make sure the amx data is volatile,; /// because that is necessary for AMX fast register allocation. (In Fast; /// registera allocation, register will be allocated before spill/reload, so; /// there is no additional register for amx to identify the step in spill.); /// The volatileTileData() will handle this case.; /// e.g.; /// ----------------------------------------------------------; /// | def %td = ... |; /// | ... |; /// | ""use %td"" |; /// ----------------------------------------------------------; /// will transfer to -->; /// ----------------------------------------------------------; /// | def %td = ... |; /// | call void @llvm.x86.tilestored64.internal(mem, %td) |; /// | ... |; /// | %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem)|; /// | ""use %td2"" |; /// ----------------------------------------------------------; //; //===----------------------------------------------------------------------===//; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:27,Integrability,depend,depends,27,// a * b + c; // The shape depends on which operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:196,Performance,optimiz,optimization,196,"// TODO We don't traverse all users. To make the algorithm simple, here we; // just traverse the first user. If we can find shape, then return the shape,; // otherwise just return nullptr and the optimization for undef/zero will be; // abandoned.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:59,Usability,simpl,simple,59,"// TODO We don't traverse all users. To make the algorithm simple, here we; // just traverse the first user. If we can find shape, then return the shape,; // otherwise just return nullptr and the optimization for undef/zero will be; // abandoned.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:10,Performance,load,load,10,"// %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:62,Performance,load,load,62,// Use the maximum column as stride. It must be the same with load; // stride.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:296,Performance,load,load,296,"// %13 = bitcast x86_amx %src to <256 x i32>; // store <256 x i32> %13, <256 x i32>* %addr, align 64; // %add = <256 x i32> %13, <256 x i32> %src2; // -->; // %13 = bitcast x86_amx %src to <256 x i32>; // call void @llvm.x86.tilestored64.internal(%row, %col, %addr,; // %stride64, %13); // %14 = load <256 x i32>, %addr; // %add = <256 x i32> %14, <256 x i32> %src2",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:32,Performance,load,load,32,"// transform bitcast to <store, load> instructions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:238,Performance,load,load,238,"// %2 = bitcast x86_amx %src to <256 x i32>; // -->; // %addr = alloca <256 x i32>, align 64; // %addr2 = bitcast <256 x i32>* to i8*; // call void @llvm.x86.tilestored64.internal(i16 %row, i16 %col,; // i8* %addr2, i64 %stride); // %2 = load <256 x i32>, <256 x i32>* %addr, align 64",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:6,Performance,load,load,6,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:46,Performance,load,load,46,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:63,Performance,load,load,63,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:225,Performance,load,load,225,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:433,Performance,load,load,433,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:456,Performance,load,load,456,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:504,Performance,load,load,504,"// If load has mutli-user, duplicate a vector load.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // %add = add <256 x i32> %src, <256 x i32> %src2; // -->; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64); // %add = add <256 x i32> %src, <256 x i32> %src2; // If load has one user, the load will be eliminated in DAG ISel.; // %src = load <256 x i32>, <256 x i32>* %addr, align 64; // %2 = bitcast <256 x i32> %src to x86_amx; // -->; // %2 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %addr, i64 %stride64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:713,Performance,load,load,713,"// If bitcast (%13) has one use, combine bitcast and store to amx store.; // %src = call x86_amx @llvm.x86.tileloadd64.internal(%row, %col, %addr,; // %stride);; // %13 = bitcast x86_amx %src to <256 x i32>; // store <256 x i32> %13, <256 x i32>* %addr, align 64; // -->; // call void @llvm.x86.tilestored64.internal(%row, %col, %addr,; // %stride64, %13); //; // If bitcast (%13) has multi-use, transform as below.; // %13 = bitcast x86_amx %src to <256 x i32>; // store <256 x i32> %13, <256 x i32>* %addr, align 64; // %add = <256 x i32> %13, <256 x i32> %src2; // -->; // %13 = bitcast x86_amx %src to <256 x i32>; // call void @llvm.x86.tilestored64.internal(%row, %col, %addr,; // %stride64, %13); // %14 = load <256 x i32>, %addr; // %add = <256 x i32> %14, <256 x i32> %src2; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:36,Performance,load,load,36,// All its uses (except phi) should load from stored mem.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:30,Performance,load,load,30,"// Store the defined tile and load it before use.; // All its users are not PHI.; // e.g.; // ------------------------------------------------------; // def %td = ...; // ...; // ""use %td""; // ------------------------------------------------------; // -->; // ------------------------------------------------------; // def %td = ...; // call void @llvm.x86.tilestored64.internal(mem, %td); // ...; // %td2 = call x86_amx @llvm.x86.tileloadd64.internal(mem); // ""use %td2""; // ------------------------------------------------------",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:23,Performance,load,load,23,// All its uses should load from stored mem.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:74,Modifiability,rewrite,rewrite,74,"// Check that each user of each old PHI node is something that we can; // rewrite, so that all of the old PHI nodes can be cleaned up afterwards.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:74,Modifiability,rewrite,rewrite,74,"// As long as the user is another old PHI node, then even if we don't; // rewrite it, the PHI web we're considering won't have any users; // outside itself, so it'll be dead.; // example:; // bb.0:; // %0 = amxcast ...; // bb.1:; // %1 = amxcast ...; // bb.2:; // %goodphi = phi %0, %1; // %3 = amxcast %goodphi; // bb.3:; // %goodphi2 = phi %0, %goodphi; // %4 = amxcast %goodphi2; // When optimizeAMXCastFromPhi process %3 and %goodphi, %goodphi2 is; // outside the phi-web, so the combination stop When; // optimizeAMXCastFromPhi process %4 and %goodphi2, the optimization; // will be done.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:391,Performance,optimiz,optimizeAMXCastFromPhi,391,"// As long as the user is another old PHI node, then even if we don't; // rewrite it, the PHI web we're considering won't have any users; // outside itself, so it'll be dead.; // example:; // bb.0:; // %0 = amxcast ...; // bb.1:; // %1 = amxcast ...; // bb.2:; // %goodphi = phi %0, %1; // %3 = amxcast %goodphi; // bb.3:; // %goodphi2 = phi %0, %goodphi; // %4 = amxcast %goodphi2; // When optimizeAMXCastFromPhi process %3 and %goodphi, %goodphi2 is; // outside the phi-web, so the combination stop When; // optimizeAMXCastFromPhi process %4 and %goodphi2, the optimization; // will be done.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:510,Performance,optimiz,optimizeAMXCastFromPhi,510,"// As long as the user is another old PHI node, then even if we don't; // rewrite it, the PHI web we're considering won't have any users; // outside itself, so it'll be dead.; // example:; // bb.0:; // %0 = amxcast ...; // bb.1:; // %1 = amxcast ...; // bb.2:; // %goodphi = phi %0, %1; // %3 = amxcast %goodphi; // bb.3:; // %goodphi2 = phi %0, %goodphi; // %4 = amxcast %goodphi2; // When optimizeAMXCastFromPhi process %3 and %goodphi, %goodphi2 is; // outside the phi-web, so the combination stop When; // optimizeAMXCastFromPhi process %4 and %goodphi2, the optimization; // will be done.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:563,Performance,optimiz,optimization,563,"// As long as the user is another old PHI node, then even if we don't; // rewrite it, the PHI web we're considering won't have any users; // outside itself, so it'll be dead.; // example:; // bb.0:; // %0 = amxcast ...; // bb.1:; // %1 = amxcast ...; // bb.2:; // %goodphi = phi %0, %1; // %3 = amxcast %goodphi; // bb.3:; // %goodphi2 = phi %0, %goodphi; // %4 = amxcast %goodphi2; // When optimizeAMXCastFromPhi process %3 and %goodphi, %goodphi2 is; // outside the phi-web, so the combination stop When; // optimizeAMXCastFromPhi process %4 and %goodphi2, the optimization; // will be done.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:93,Safety,safe,safely,93,// We don't need to push PHINode into DeadInst since they are operands; // of rootPN DCE can safely delete rootPN's operands if rootPN is dead.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:9,Performance,load,load,9,"// %65 = load <256 x i32>, <256 x i32>* %p, align 64; // %66 = call x86_amx @llvm.x86.cast.vector.to.tile(<256 x i32> %65); // -->; // %66 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %p, i64 64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:9,Performance,load,load,9,"// %65 = load <256 x i32>, <256 x i32>* %p, align 64; // %66 = call x86_amx @llvm.x86.cast.vector.to.tile(<256 x i32> %65); // -->; // %66 = call x86_amx @llvm.x86.tileloadd64.internal(i16 %row, i16 %col,; // i8* %p, i64 64)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:35,Performance,load,load,35,// Set the operand is null so that load instruction can be erased.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:238,Performance,load,load,238,"// %2 = amxcast x86_amx %src to <225 x i32>; // -->; // %addr = alloca <225 x i32>, align 64; // %addr2 = bitcast <225 x i32>* to i8*; // call void @llvm.x86.tilestored64.internal(i16 %row, i16 %col,; // i8* %addr2, i64 %stride); // %2 = load <225 x i32>, <225 x i32>* %addr, align 64",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:142,Performance,Optimiz,OptimizeNone,142,"// Prepare for fast register allocation at O0.; // Todo: May better check the volatile model of AMX code, not just; // by checking Attribute::OptimizeNone and CodeGenOptLevel::None.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:852,Energy Efficiency,allocate,allocate,852,"//===-- X86LowerTileCopy.cpp - Expand Tile Copy Instructions---------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass which lower AMX tile copy instructions. Since; // there is no tile copy instruction, we need store tile register to stack; // and load from stack to another tile register. We need extra GR to hold; // the stride, and we need stack slot to hold the tile data register.; // We would run this pass after copy propagation, so that we don't miss copy; // optimization. And we would run this pass before prolog/epilog insertion,; // so that we can allocate stack slot.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:540,Performance,load,load,540,"//===-- X86LowerTileCopy.cpp - Expand Tile Copy Instructions---------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass which lower AMX tile copy instructions. Since; // there is no tile copy instruction, we need store tile register to stack; // and load from stack to another tile register. We need extra GR to hold; // the stride, and we need stack slot to hold the tile data register.; // We would run this pass after copy propagation, so that we don't miss copy; // optimization. And we would run this pass before prolog/epilog insertion,; // so that we can allocate stack slot.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:760,Performance,optimiz,optimization,760,"//===-- X86LowerTileCopy.cpp - Expand Tile Copy Instructions---------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass which lower AMX tile copy instructions. Since; // there is no tile copy instruction, we need store tile register to stack; // and load from stack to another tile register. We need extra GR to hold; // the stride, and we need stack slot to hold the tile data register.; // We would run this pass after copy propagation, so that we don't miss copy; // optimization. And we would run this pass before prolog/epilog insertion,; // so that we can allocate stack slot.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate stack slot for tile register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate stack slot for stride register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp:34,Safety,avoid,avoid,34,// TODO: Pick a killed regiter to avoid save/reload. There is problem; // to get live interval in this stage.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerTileCopy.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:126,Performance,optimiz,optimization,126,/// TailCallReturnAddrDelta - The number of bytes by which return address; /// stack slot is moved as the result of tail call optimization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:51,Security,access,accesses,51,/// NumLocalDynamics - Number of local-dynamic TLS accesses.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:25,Availability,recover,recovers,25,"/// True if the function recovers from an SEH exception, and therefore needs; /// to spill and restore the frame pointer.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:25,Safety,recover,recovers,25,"/// True if the function recovers from an SEH exception, and therefore needs; /// to spill and restore the frame pointer.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:33,Modifiability,extend,extended,33,"/// Whether this function has an extended frame record [Ctx, RBP, Return; /// addr]. If so, bit 60 of the in-memory frame pointer will be 1 to enable; /// other tools to detect the extended record.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:181,Modifiability,extend,extended,181,"/// Whether this function has an extended frame record [Ctx, RBP, Return; /// addr]. If so, bit 60 of the in-memory frame pointer will be 1 to enable; /// other tools to detect the extended record.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h:170,Safety,detect,detect,170,"/// Whether this function has an extended frame record [Ctx, RBP, Return; /// addr]. If so, bit 60 of the in-memory frame pointer will be 1 to enable; /// other tools to detect the extended record.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MachineFunctionInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp:443,Energy Efficiency,schedul,scheduling,443,"//===- X86MacroFusion.cpp - X86 Macro Fusion ------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file This file contains the X86 implementation of the DAG scheduling; /// mutation to pair instructions back to back.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp:35,Testability,TEST,TEST,35,// Branch fusion can merge CMP and TEST with all conditional jumps.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.h:439,Energy Efficiency,schedul,scheduling,439,"//===- X86MacroFusion.h - X86 Macro Fusion --------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file This file contains the X86 definition of the DAG scheduling mutation; /// to pair instructions back to back.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MacroFusion.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:27,Energy Efficiency,efficient,efficient,27,"// FIXME: We would like an efficient form for this, so we don't have to do a; // lot of extra uniquing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:45,Energy Efficiency,reduce,reduce,45,"// If .set directive is supported, use it to reduce the number of; // relocations the assembler will generate for differences between; // local labels. This is only safe when the symbols are in the same; // section so we are restricting it to jumptable references.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:165,Safety,safe,safe,165,"// If .set directive is supported, use it to reduce the number of; // relocations the assembler will generate for differences between; // local labels. This is only safe when the symbols are in the same; // section so we are restricting it to jumptable references.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:271,Testability,assert,assert,271,"// CALL64r, CALL64pcrel32 - These instructions used to have; // register inputs modeled as normal uses instead of implicit uses. As such,; // they we used to truncate off all but the first operand (the callee). This; // issue seems to have been fixed at some point. This assert verifies that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:109,Performance,perform,performance,109,"// Add an REP prefix to BSF instructions so that new processors can; // recognize as TZCNT, which has better performance than BSF.; // BSF and TZCNT have different interpretations on ZF bit. So make sure; // it won't be used later.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:54,Availability,error,error,54,"// As of binutils 2.32, ld has a bogus TLS relaxation error when the GD/LD; // code sequence using R_X86_64_GOTPCREL (instead of R_X86_64_GOTPCRELX) is; // attempted to be relaxed to IE/LE (binutils PR24784). Work around the bug by; // only using GOT when GOTPCRELX is enabled.; // TODO Delete the workaround when GOTPCRELX becomes commonplace.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:42,Energy Efficiency,efficient,efficiently,42,"// Determine the longest nop which can be efficiently decoded for the given; // target cpu. 15-bytes is the longest single NOP instruction, but some; // platforms can't decode the longest forms efficiently.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:194,Energy Efficiency,efficient,efficiently,194,"// Determine the longest nop which can be efficiently decoded for the given; // target cpu. 15-bytes is the longest single NOP instruction, but some; // platforms can't decode the longest forms efficiently.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:109,Deployability,update,updated,109,"// FIXME: We can use NOOPL on 32-bit targets with FeatureNOPL, but the; // IndexReg/BaseReg below need to be updated.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:172,Performance,load,load,172,"// Currently, we only support relative addressing with statepoints.; // Otherwise, we'll need a scratch register to hold the target; // address. You'll fail asserts during load & relocation if this; // symbol is to far away. (TODO: support non-relative addressing)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:157,Testability,assert,asserts,157,"// Currently, we only support relative addressing with statepoints.; // Otherwise, we'll need a scratch register to hold the target; // address. You'll fail asserts during load & relocation if this; // symbol is to far away. (TODO: support non-relative addressing)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:174,Performance,load,load,174,"// Currently, we only support relative addressing with statepoints.; // Otherwise, we'll need a scratch register to hold the target; // immediate. You'll fail asserts during load & relocation if this; // address is to far away. (TODO: support non-relative addressing)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:159,Testability,assert,asserts,159,"// Currently, we only support relative addressing with statepoints.; // Otherwise, we'll need a scratch register to hold the target; // immediate. You'll fail asserts during load & relocation if this; // address is to far away. (TODO: support non-relative addressing)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:75,Deployability,PATCH,PATCHPOINT,75,// Record our statepoint node in the same section used by STACKMAP; // and PATCHPOINT,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:25,Deployability,patch,patchable-function-prefix,25,"// Adjust the offset for patchable-function-prefix. X86InstrInfo::getNop(); // returns a 1-byte X86::NOOP, which means the offset is the same in; // bytes. This assumes that patchable-function-prefix is the same for all; // functions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:174,Deployability,patch,patchable-function-prefix,174,"// Adjust the offset for patchable-function-prefix. X86InstrInfo::getNop(); // returns a 1-byte X86::NOOP, which means the offset is the same in; // bytes. This assumes that patchable-function-prefix is the same for all; // functions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:235,Performance,load,load,235,"// KCFI allows indirect calls to any location that's preceded by a valid; // type identifier. To avoid encoding the full constant into an instruction,; // and thus emitting potential call target gadgets at each indirect call; // site, load a negated constant to a register and compare that to the; // expected value at the call target.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:97,Safety,avoid,avoid,97,"// KCFI allows indirect calls to any location that's preceded by a valid; // type identifier. To avoid encoding the full constant into an instruction,; // and thus emitting potential call target gadgets at each indirect call; // site, load a negated constant to a register and compare that to the; // expected value at the call target.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:199,Deployability,patch,patch,199,"// For compatibility reasons, when targetting MSVC, it is important to; // generate a 'legacy' NOP in the form of a 8B FF MOV EDI, EDI. Some tools; // rely specifically on this pattern to be able to patch a function.; // This is only for 32-bit targets, when using /arch:IA32 or /arch:SSE.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:11,Deployability,patch,patchpoint,11,"// Lower a patchpoint of the form:; // [<def>], <id>, <numBytes>, <target>, <numArgs>, <cc>, ...",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:108,Integrability,depend,depending,108,"// Emit MOV to materialize the target address and the CALL to target.; // This is encoded with 12-13 bytes, depending on which register is used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:128,Deployability,patch,patched,128,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_CustomEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayCustomEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:381,Deployability,patch,patching,381,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_CustomEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayCustomEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:322,Integrability,depend,dependency,322,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_CustomEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayCustomEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:18,Integrability,depend,dependency,18,"// We emit a hard dependency on the __xray_CustomEvent symbol, which is the; // name of the trampoline to be implemented by the XRay runtime.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:128,Deployability,patch,patched,128,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_TypedEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayTypedEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:380,Deployability,patch,patching,380,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_TypedEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayTypedEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:321,Integrability,depend,dependency,321,"// We want to emit the following pattern, which follows the x86 calling; // convention to prepare for the trampoline call to be patched in.; //; // .p2align 1, ...; // .Lxray_event_sled_N:; // jmp +N // jump across the instrumentation sled; // ... // set up arguments in register; // callq __xray_TypedEvent@plt // force dependency to symbol; // ...; // <jump here>; //; // After patching, it would look something like:; //; // nopw (2-byte nop); // ...; // callq __xrayTypedEvent // already lowered; // ...; //; // ---; // First we emit the label and the jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:18,Integrability,depend,dependency,18,"// We emit a hard dependency on the __xray_TypedEvent symbol, which is the; // name of the trampoline to be implemented by the XRay runtime.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:184,Deployability,patch,patching,184,"// We want to emit the following pattern:; //; // .p2align 1, ...; // .Lxray_sled_N:; // jmp .tmpN; // # 9 bytes worth of noops; //; // We need the 9 bytes because at runtime, we'd be patching over the full 11; // bytes with the following pattern:; //; // mov %r10, <function id, 32-bit> // 6 bytes; // call <relative offset, 32-bits> // 5 bytes; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:31,Availability,mask,mask,31,"// One source operand, fix the mask to print all elements in one span.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:17,Availability,MASK,MASK,17,// Handle AVX512 MASK/MASXZ write mask comments.; // MASK: zmmX {%kY}; // MASKZ: zmmX {%kY} {z},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:34,Availability,mask,mask,34,// Handle AVX512 MASK/MASXZ write mask comments.; // MASK: zmmX {%kY}; // MASKZ: zmmX {%kY} {z},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:53,Availability,MASK,MASK,53,// Handle AVX512 MASK/MASXZ write mask comments.; // MASK: zmmX {%kY}; // MASKZ: zmmX {%kY} {z},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:74,Availability,MASK,MASKZ,74,// Handle AVX512 MASK/MASXZ write mask comments.; // MASK: zmmX {%kY}; // MASKZ: zmmX {%kY} {z},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:57,Availability,mask,mask,57,"// We didn't find a constant load, fallback to a shuffle mask decode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:29,Performance,load,load,29,"// We didn't find a constant load, fallback to a shuffle mask decode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:94,Availability,mask,mask,94,// Lower PSHUFB and VPERMILP normally but add a comment if we can find; // a constant shuffle mask. We won't be able to do this at the MC layer; // because the mask isn't an immediate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:160,Availability,mask,mask,160,// Lower PSHUFB and VPERMILP normally but add a comment if we can find; // a constant shuffle mask. We won't be able to do this at the MC layer; // because the mask isn't an immediate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:8,Availability,mask,mask,8,// Skip mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:8,Availability,mask,mask,8,// Skip mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:7,Performance,load,loads,7,"// For loads from a constant pool to a vector register, print the constant; // loaded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:79,Performance,load,loaded,79,"// For loads from a constant pool to a vector register, print the constant; // loaded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:17,Performance,load,loads,17,"// For broadcast loads from a constant pool to a vector register, repeatedly; // print the constant loaded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:100,Performance,load,loaded,100,"// For broadcast loads from a constant pool to a vector register, repeatedly; // print the constant loaded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:55,Testability,test,test,55,"// FIXME: Enable feature predicate checks once all the test pass.; // X86_MC::verifyInstructionPredicates(MI->getOpcode(),; // Subtarget->getFeatureBits());",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:27,Performance,load,loaded,27,// Add comments for values loaded from constant pool.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:27,Energy Efficiency,efficient,efficient,27,"// FIXME: We would like an efficient form for this, so we don't have to do a; // lot of extra uniquing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:29,Performance,optimiz,optimize,29,"//===- X86OptimizeLEAs.cpp - optimize usage of LEA instructions -----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass that performs some optimizations with LEA; // instructions in order to improve performance and code size.; // Currently, it does two things:; // 1) If there are two LEA instructions calculating addresses which only differ; // by displacement inside a basic block, one of them is removed.; // 2) Address calculations in load and store instructions are replaced by; // existing LEA def registers where possible.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:415,Performance,perform,performs,415,"//===- X86OptimizeLEAs.cpp - optimize usage of LEA instructions -----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass that performs some optimizations with LEA; // instructions in order to improve performance and code size.; // Currently, it does two things:; // 1) If there are two LEA instructions calculating addresses which only differ; // by displacement inside a basic block, one of them is removed.; // 2) Address calculations in load and store instructions are replaced by; // existing LEA def registers where possible.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:429,Performance,optimiz,optimizations,429,"//===- X86OptimizeLEAs.cpp - optimize usage of LEA instructions -----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass that performs some optimizations with LEA; // instructions in order to improve performance and code size.; // Currently, it does two things:; // 1) If there are two LEA instructions calculating addresses which only differ; // by displacement inside a basic block, one of them is removed.; // 2) Address calculations in load and store instructions are replaced by; // existing LEA def registers where possible.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:489,Performance,perform,performance,489,"//===- X86OptimizeLEAs.cpp - optimize usage of LEA instructions -----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass that performs some optimizations with LEA; // instructions in order to improve performance and code size.; // Currently, it does two things:; // 1) If there are two LEA instructions calculating addresses which only differ; // by displacement inside a basic block, one of them is removed.; // 2) Address calculations in load and store instructions are replaced by; // existing LEA def registers where possible.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:729,Performance,load,load,729,"//===- X86OptimizeLEAs.cpp - optimize usage of LEA instructions -----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass that performs some optimizations with LEA; // instructions in order to improve performance and code size.; // Currently, it does two things:; // 1) If there are two LEA instructions calculating addresses which only differ; // by displacement inside a basic block, one of them is removed.; // 2) Address calculations in load and store instructions are replaced by; // existing LEA def registers where possible.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:77,Security,hash,hash,77,"// If the address displacement is an immediate, it should not affect the; // hash so that memory operands which differ only be immediate displacement; // would have the same hash. If the address displacement is something else,; // we should reflect symbol/index/address in the hash.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:174,Security,hash,hash,174,"// If the address displacement is an immediate, it should not affect the; // hash so that memory operands which differ only be immediate displacement; // would have the same hash. If the address displacement is something else,; // we should reflect symbol/index/address in the hash.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:277,Security,hash,hash,277,"// If the address displacement is an immediate, it should not affect the; // hash so that memory operands which differ only be immediate displacement; // would have the same hash. If the address displacement is something else,; // we should reflect symbol/index/address in the hash.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:37,Security,hash,hash,37,// end namespace llvm; /// Returns a hash table key based on memory operands of \p MI. The; /// number of the first memory operand of \p MI is specified through \p N.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:165,Availability,redundant,redundant,165,"/// Loop over all of the basic blocks, replacing address; /// calculations in load and store instructions, if it's already; /// been calculated by LEA. Also, remove redundant LEAs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:78,Performance,load,load,78,"/// Loop over all of the basic blocks, replacing address; /// calculations in load and store instructions, if it's already; /// been calculated by LEA. Also, remove redundant LEAs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:165,Safety,redund,redundant,165,"/// Loop over all of the basic blocks, replacing address; /// calculations in load and store instructions, if it's already; /// been calculated by LEA. Also, remove redundant LEAs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:12,Availability,redundant,redundant,12,/// Removes redundant address calculations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:12,Safety,redund,redundant,12,/// Removes redundant address calculations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:324,Availability,reliab,reliable,324,"// Check that LEA def register can be used as MI address base. Some; // instructions can use a limited set of registers as address base, for; // example MOV8mr_NOREX. We could constrain the register class of the LEA; // def to suit MI, however since this case is very rare and hard to; // reproduce in a test it's just more reliable to skip the LEA.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:304,Testability,test,test,304,"// Check that LEA def register can be used as MI address base. Some; // instructions can use a limited set of registers as address base, for; // example MOV8mr_NOREX. We could constrain the register class of the LEA; // def to suit MI, however since this case is very rare and hard to; // reproduce in a test it's just more reliable to skip the LEA.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:266,Usability,simpl,simple,266,"// Choose the closest LEA instruction from the list, prior to MI if; // possible. Note that we took into account resulting address displacement; // as well. Also note that the list is sorted by the order in which the LEAs; // occur, so the break condition is pretty simple.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:10,Deployability,update,update,10,"// Do not update return LEA, if the current one provides a displacement; // which fits in 1 byte, while the new candidate does not.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:13,Testability,assert,assert,13,"// After the assert above we can be sure that both operands are of the same; // valid type and use the same symbol/index/address, thus displacement shift; // calculation is rather simple.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:180,Usability,simpl,simple,180,"// After the assert above we can be sure that both operands are of the same; // valid type and use the same symbol/index/address, thus displacement shift; // calculation is rather simple.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:113,Security,access,accesses,113,"// Loop over all uses of the Last LEA to check that its def register is; // used only as address base for memory accesses. If so, it can be; // replaced, otherwise - no.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:260,Deployability,update,updates,260,// Assign the position number to the instruction. Note that we are going to; // move some instructions during the optimization however there will never; // be a need to move two instructions before any selected instruction. So to; // avoid multiple positions' updates during moves we just increase position; // counter by two leaving a free space for instructions which will be moved.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:114,Performance,optimiz,optimization,114,// Assign the position number to the instruction. Note that we are going to; // move some instructions during the optimization however there will never; // be a need to move two instructions before any selected instruction. So to; // avoid multiple positions' updates during moves we just increase position; // counter by two leaving a free space for instructions which will be moved.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:234,Safety,avoid,avoid,234,// Assign the position number to the instruction. Note that we are going to; // move some instructions during the optimization however there will never; // be a need to move two instructions before any selected instruction. So to; // avoid multiple positions' updates during moves we just increase position; // counter by two leaving a free space for instructions which will be moved.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:15,Performance,load,load,15,// Try to find load and store instructions which recalculate addresses already; // calculated by some LEA and replace their memory operands with its def; // register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:23,Performance,load,load,23,// Instruction must be load or store.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:25,Modifiability,extend,extend,25,"// Since we can possibly extend register lifetime, clear kill flags.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:51,Usability,clear,clear,51,"// Since we can possibly extend register lifetime, clear kill flags.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:3,Deployability,Update,Update,3,"// Update the Expression, appending an offset of `AddrDispShift` to the; // Op corresponding to `OldReg`.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:42,Deployability,update,update,42,// Loop over all uses of the Last LEA and update their operands. Note; // that the correctness of this has already been checked in the; // isReplaceable function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:3,Deployability,Update,Update,3,// Update address base.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:3,Deployability,Update,Update,3,// Update address disp.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:25,Modifiability,extend,extend,25,"// Since we can possibly extend register lifetime, clear kill flags.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:51,Usability,clear,clear,51,"// Since we can possibly extend register lifetime, clear kill flags.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:10,Availability,redundant,redundant,10,// Remove redundant LEA instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:10,Safety,redund,redundant,10,// Remove redundant LEA instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:10,Availability,redundant,redundant,10,// Remove redundant address calculations. Do it only for -Os/-Oz since only; // a code size gain is expected from this part of the pass.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:10,Safety,redund,redundant,10,// Remove redundant address calculations. Do it only for -Os/-Oz since only; // a code size gain is expected from this part of the pass.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp:16,Performance,Cache,Cache,16,// VisitedBBs - Cache of previously visited BBs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp:10,Performance,cache,cached,10,// Return cached result if BB was previously visited,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:40,Safety,detect,detectExtMul,40,// This function should be aligned with detectExtMul() in X86ISelLowering.cpp.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:116,Modifiability,extend,extended,116,"// (dpbusd (zext a), (sext, b)). Since the first operand should be unsigned; // value, we need to check LHS is zero extended value. RHS should be signed; // value, so we just check the signed bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:59,Energy Efficiency,reduce,reduce,59,"// If the target support VNNI, leave it to ISel to combine reduce operation; // to VNNI instruction.; // TODO: we can support transforming reduce to VNNI intrinsic for across block; // in this pass.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:139,Energy Efficiency,reduce,reduce,139,"// If the target support VNNI, leave it to ISel to combine reduce operation; // to VNNI instruction.; // TODO: we can support transforming reduce to VNNI intrinsic for across block; // in this pass.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:209,Modifiability,extend,extend,209,"// LHS and RHS should be only used once or if they are the same then only; // used twice. Only check this when SSE4.1 is enabled and we have zext/sext; // instructions, otherwise we use punpck to emulate zero extend in stages. The; // trunc/ we need to do likely won't introduce new instructions in that case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:25,Modifiability,extend,extend,25,// Concatenate zeroes to extend back to the original type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:17,Modifiability,extend,extend,17,// Look for zero extend from i8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:43,Modifiability,extend,extends,43,// Both operands of the subtract should be extends from vXi8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:11,Availability,down,down,11,// Extract down to 2 elements.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:34,Energy Efficiency,power,power,34,// Ensure the reduction size is a power of 2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:70,Availability,mask,mask,70,// Verify the shuffle has the expected (at this stage of the pyramid) mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:186,Safety,safe,safe,186,// See if this BO is reachable from this Phi by walking forward through single; // use BinaryOperators with the same opcode. If we get back then we know we've; // found a loop and it is safe to step through this Add to find more leaves.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp:3,Usability,Simpl,Simple,3,"// Simple case. Single use, just push its operands to the worklist.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PartialReduction.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:1113,Availability,error,error,1113,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:49,Modifiability,config,configure,49,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:402,Modifiability,config,config,402,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:467,Modifiability,config,configured,467,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:644,Modifiability,config,config,644,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:697,Modifiability,variab,variable,697,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:838,Modifiability,config,configure,838,"//===-- X86PreTileConfig.cpp - Tile Register Pre-configure-----------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to pre-config the shapes of AMX registers; /// AMX register needs to be configured before use. The shapes of AMX register; /// are encoded in the 1st and 2nd machine operand of AMX pseudo instructions.; ///; /// The instruction ldtilecfg is used to config the shapes. It must be reachable; /// for all variable shapes. ldtilecfg will be inserted more than once if we; /// cannot find a dominating point for all AMX instructions.; ///; /// The configure register is caller saved according to ABI. We need to insert; /// ldtilecfg again after the call instruction if callee clobbers any AMX; /// registers.; ///; /// This pass calculates all points that ldtilecfg need to be inserted to and; /// insert them. It reports error if the reachability conditions aren't met.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:10,Usability,simpl,simply,10,// We can simply check if it is AMX instruction by its def.; // But we should exclude old API which uses physical registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:34,Security,access,access,34,// Do not hoist instructions that access memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:4,Usability,Clear,Clear,4,/// Clear MF related structures.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:4,Performance,Perform,Perform,4,/// Perform ldtilecfg instructions inserting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:58,Modifiability,config,config,58,"// If there's call before the AMX, we need to reload tile config.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:27,Modifiability,config,config,27,"// Otherwise, we need tile config to live in this BB.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:3,Deployability,Update,Update,3,// Update NeedTileCfgLiveIn for predecessors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:55,Modifiability,config,config,55,// There's no AMX instruction if we didn't find a tile config live in point.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:3,Safety,Avoid,Avoid,3,// Avoid to insert ldtilecfg before any shape defs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:99,Availability,error,error,99,// We are not able to config tile registers since the shape to config; // is not defined yet. Emit error message and continue. The function; // would not config tile registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:105,Integrability,message,message,105,// We are not able to config tile registers since the shape to config; // is not defined yet. Emit error message and continue. The function; // would not config tile registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:22,Modifiability,config,config,22,// We are not able to config tile registers since the shape to config; // is not defined yet. Emit error message and continue. The function; // would not config tile registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:63,Modifiability,config,config,63,// We are not able to config tile registers since the shape to config; // is not defined yet. Emit error message and continue. The function; // would not config tile registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:154,Modifiability,config,config,154,// We are not able to config tile registers since the shape to config; // is not defined yet. Emit error message and continue. The function; // would not config tile registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:30,Modifiability,config,config,30,// Try to insert for the tile config live in points.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:3,Safety,Avoid,Avoid,3,// Avoid the BB to be multi visited.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp:65,Safety,avoid,avoid,65,// There're chances the MBB is sunk more than once. Record it to avoid; // multi insert.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PreTileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:521,Performance,optimiz,optimization,521,"//===-- X86RegisterInfo.cpp - X86 Register Information --------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the X86 implementation of the TargetRegisterInfo class.; // This file is responsible for the frame pointer elimination optimization; // on X86.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:3,Performance,Cache,Cache,3,// Cache some information.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:20,Usability,simpl,simplified,20,// This matches the simplified 32-bit pointer code in the data layout; // computation.; // FIXME: Should use the data layout?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:119,Security,access,accesses,119,"// When the target also allows 64-bit frame pointer and we do have a; // frame, this is fine to use it for the address accesses as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:3,Availability,Avail,Available,3,// Available for tailcall (not callee-saved GPRs).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:15,Modifiability,extend,extended,15,// Reserve the extended general purpose registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:348,Deployability,release,release,348,"// Check if the EFLAGS register is marked as live-out. This shouldn't happen,; // because the calling convention defines the EFLAGS register as NOT; // preserved.; //; // Unfortunatelly the EFLAGS show up as live-out after branch folding. Adding; // an assert to track this and clear the register afterwards to avoid; // unnecessary crashes during release builds.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:311,Safety,avoid,avoid,311,"// Check if the EFLAGS register is marked as live-out. This shouldn't happen,; // because the calling convention defines the EFLAGS register as NOT; // preserved.; //; // Unfortunatelly the EFLAGS show up as live-out after branch folding. Adding; // an assert to track this and clear the register afterwards to avoid; // unnecessary crashes during release builds.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:253,Testability,assert,assert,253,"// Check if the EFLAGS register is marked as live-out. This shouldn't happen,; // because the calling convention defines the EFLAGS register as NOT; // preserved.; //; // Unfortunatelly the EFLAGS show up as live-out after branch folding. Adding; // an assert to track this and clear the register afterwards to avoid; // unnecessary crashes during release builds.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:278,Usability,clear,clear,278,"// Check if the EFLAGS register is marked as live-out. This shouldn't happen,; // because the calling convention defines the EFLAGS register as NOT; // preserved.; //; // Unfortunatelly the EFLAGS show up as live-out after branch folding. Adding; // an assert to track this and clear the register afterwards to avoid; // unnecessary crashes during release builds.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:171,Modifiability,variab,variables,171,"// When we need stack realignment, we can't address the stack from the frame; // pointer. When we have dynamic allocas or stack-adjusting inline asm, we; // can't address variables from the stack pointer. MS inline asm can; // reference locals while also adjusting the stack pointer. When we can't; // use both the SP and the FP, we need a separate base pointer register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:135,Modifiability,extend,extend,135,"// In X32 mode, ensure the base-pointer is a 32-bit operand, so the LEA will; // be replaced with a 32-bit operand MOV which will zero extend the upper; // 32-bits of the super register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:44,Deployability,patch,patchpoints,44,// The frame index format for stackmaps and patchpoints is different from the; // X86 format. It only has a FI and an offset.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:81,Usability,simpl,simple,81,"// LOCAL_ESCAPE uses a single offset, with no register. It only works in the; // simple FP case, and doesn't work with stack realignment. On 32-bit, the; // offset is from the traditional base pointer location. On 64-bit, the; // offset is from the SP at the end of the prologue, not the FP location. This; // matches the behavior of llvm.frameaddress.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:215,Safety,avoid,avoided,215,"// For LEA64_32r when BasePtr is 32-bits (X32) we can use full-size 64-bit; // register as source operand, semantic is the same and destination is; // 32-bits. It saves one byte per lea in code since 0x67 prefix is avoided.; // Don't change BasePtr since it is used later for stack adjustment.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:44,Deployability,patch,patchpoints,44,// The frame index format for stackmaps and patchpoints is different from the; // X86 format. It only has a FI and an offset.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp:7,Energy Efficiency,allocate,allocated,7,// Not allocated yet,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h:148,Modifiability,variab,variable,148,"/// BasePtr - X86 physical register used as a base ptr in complex stack; /// frames. I.e., when we need a 3rd base, not just SP and FP, due to; /// variable size stack objects.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h:118,Availability,mask,mask,118,"// Calls involved in thread-local variable lookup save more registers than; // normal calls, so they need a different mask to represent this.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h:34,Modifiability,variab,variable,34,"// Calls involved in thread-local variable lookup save more registers than; // normal calls, so they need a different mask to represent this.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86RegisterInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:46,Integrability,depend,depending,46,/// Returns the best type to use with repmovs depending on alignment.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:56,Performance,load,load,56,"/// Returns a REP MOVS instruction, possibly with a few load/stores to implement; /// a constant size memory copy. In some cases where we know REP MOVS is; /// inefficient we return an empty SDValue so the calling code can either; /// generate a load/store sequence or call the runtime memcpy function.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:246,Performance,load,load,246,"/// Returns a REP MOVS instruction, possibly with a few load/stores to implement; /// a constant size memory copy. In some cases where we know REP MOVS is; /// inefficient we return an empty SDValue so the calling code can either; /// generate a load/store sequence or call the runtime memcpy function.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:83,Energy Efficiency,efficient,efficient,83,/// TODO: Revisit next line: big copy with ERMSB on march >= haswell are very; /// efficient.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:15,Modifiability,enhance,enhanced,15,/// If we have enhanced repmovs we use it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:67,Energy Efficiency,efficient,efficient,67,/// In case we optimize for size we use repmovsb even if it's less efficient; /// so we can save the loads/stores of the leftover.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:15,Performance,optimiz,optimize,15,/// In case we optimize for size we use repmovsb even if it's less efficient; /// so we can save the loads/stores of the leftover.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:101,Performance,load,loads,101,/// In case we optimize for size we use repmovsb even if it's less efficient; /// so we can save the loads/stores of the leftover.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp:18,Availability,avail,available,18,"// If enabled and available, use fast short rep mov.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SelectionDAGInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:92,Availability,Mask,Mask,92,//===----------------------------------------------------------------------===//; // Vector Mask Decoding; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:16,Availability,error,error,16,"// It is not an error for shuffle masks to not be a vector of; // MaskEltSizeInBits because the constant pool uniques constants by their; // bit representation.; // e.g. the following take up the same space in the constant pool:; // i128 -170141183420855150465331762880109871104; //; // <2 x i64> <i64 -9223372034707292160, i64 -9223372034707292160>; //; // <4 x i32> <i32 -2147483648, i32 -2147483648,; // i32 -2147483648, i32 -2147483648>",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:34,Availability,mask,masks,34,"// It is not an error for shuffle masks to not be a vector of; // MaskEltSizeInBits because the constant pool uniques constants by their; // bit representation.; // e.g. the following take up the same space in the constant pool:; // i128 -170141183420855150465331762880109871104; //; // <2 x i64> <i64 -9223372034707292160, i64 -9223372034707292160>; //; // <4 x i32> <i32 -2147483648, i32 -2147483648,; // i32 -2147483648, i32 -2147483648>",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:66,Availability,Mask,MaskEltSizeInBits,66,"// It is not an error for shuffle masks to not be a vector of; // MaskEltSizeInBits because the constant pool uniques constants by their; // bit representation.; // e.g. the following take up the same space in the constant pool:; // i128 -170141183420855150465331762880109871104; //; // <2 x i64> <i64 -9223372034707292160, i64 -9223372034707292160>; //; // <4 x i32> <i32 -2147483648, i32 -2147483648,; // i32 -2147483648, i32 -2147483648>",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:42,Availability,mask,mask,42,// Fast path - if the constants match the mask size then copy direct.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:64,Availability,mask,masks,64,// Now extract the undef/constant bit data into the raw shuffle masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:15,Availability,mask,mask,15,// The shuffle mask requires a byte vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:15,Availability,mask,mask,15,// The shuffle mask requires elements the same size as the target.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:15,Availability,mask,mask,15,// The shuffle mask requires elements the same size as the target.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:86,Availability,Mask,Mask,86,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:130,Availability,Mask,Mask,130,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:15,Availability,mask,mask,15,// The shuffle mask requires a byte vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp:141,Testability,log,logical,141,// VPPERM Operation; // Bits[4:0] - Byte Index (0 - 31); // Bits[7:5] - Permute Operation; //; // Permute Operation:; // 0 - Source byte (no logical operation).; // 1 - Invert source byte.; // 2 - Bit reverse of source byte.; // 3 - Bit reverse of inverted source byte.; // 4 - 00h (zero - fill).; // 5 - FFh (ones - fill).; // 6 - Most significant bit of source byte replicated in all bit positions.; // 7 - Invert most significant bit of source byte and replicate in all bit; // positions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:92,Availability,Mask,Mask,92,//===----------------------------------------------------------------------===//; // Vector Mask Decoding; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:20,Availability,mask,mask,20,/// Decode a PSHUFB mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:31,Availability,mask,mask,31,/// Decode a VPERMILP variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:22,Modifiability,variab,variable,22,/// Decode a VPERMILP variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:32,Availability,mask,mask,32,/// Decode a VPERMILP2 variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:23,Modifiability,variab,variable,23,/// Decode a VPERMILP2 variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:29,Availability,mask,mask,29,/// Decode a VPPERM variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h:20,Modifiability,variab,variable,20,/// Decode a VPPERM variable mask from an IR-level vector constant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ShuffleDecodeConstantPool.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:84,Availability,redundant,redundant,84,// Keep track of whether the previous instruction was an LFENCE to avoid; // adding redundant LFENCEs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:67,Safety,avoid,avoid,67,// Keep track of whether the previous instruction was an LFENCE to avoid; // adding redundant LFENCEs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:84,Safety,redund,redundant,84,// Keep track of whether the previous instruction was an LFENCE to avoid; // adding redundant LFENCEs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:64,Performance,load,load,64,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:155,Performance,load,load,155,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:198,Performance,cache,cache,198,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:272,Performance,load,load,272,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:106,Safety,avoid,avoid,106,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:126,Safety,predict,prediction,126,// The following section will be LFENCEing before groups of terminators; // that include branches. This will close the branch prediction side; // channels since we will prevent code executing after misspeculation as; // a result of the LFENCEs placed with this logic.; // Keep track of the first terminator in a basic block since if we need; // to LFENCE the terminators in this basic block we must add the; // instruction before the first terminator in the basic block (as; // opposed to before the terminator that indicates an LFENCE is; // required). An example of why this is necessary is that the; // X86InstrInfo::analyzeBranch method assumes all terminators are grouped; // together and terminates it's analysis once the first non-termintor; // instruction is found.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:261,Testability,log,logic,261,// The following section will be LFENCEing before groups of terminators; // that include branches. This will close the branch prediction side; // channels since we will prevent code executing after misspeculation as; // a result of the LFENCEs placed with this logic.; // Keep track of the first terminator in a basic block since if we need; // to LFENCE the terminators in this basic block we must add the; // instruction before the first terminator in the basic block (as; // opposed to before the terminator that indicates an LFENCE is; // required). An example of why this is necessary is that the; // X86InstrInfo::analyzeBranch method assumes all terminators are grouped; // together and terminates it's analysis once the first non-termintor; // instruction is found.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:588,Performance,load,load,588,"//====- X86SpeculativeLoadHardening.cpp - A Spectre v1 mitigation ---------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// Provide a pass which mitigates speculative execution attacks which operate; /// by speculating incorrectly past some predicate (a type check, bounds check,; /// or other condition) to reach a load with invalid inputs and leak the data; /// accessed by that load using a side channel out of the speculative domain.; ///; /// For details on the attacks, see the first variant in both the Project Zero; /// writeup and the Spectre paper:; /// https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; /// https://spectreattack.com/spectre.pdf; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:653,Performance,load,load,653,"//====- X86SpeculativeLoadHardening.cpp - A Spectre v1 mitigation ---------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// Provide a pass which mitigates speculative execution attacks which operate; /// by speculating incorrectly past some predicate (a type check, bounds check,; /// or other condition) to reach a load with invalid inputs and leak the data; /// accessed by that load using a side channel out of the speculative domain.; ///; /// For details on the attacks, see the first variant in both the Project Zero; /// writeup and the Spectre paper:; /// https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; /// https://spectreattack.com/spectre.pdf; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:449,Security,attack,attacks,449,"//====- X86SpeculativeLoadHardening.cpp - A Spectre v1 mitigation ---------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// Provide a pass which mitigates speculative execution attacks which operate; /// by speculating incorrectly past some predicate (a type check, bounds check,; /// or other condition) to reach a load with invalid inputs and leak the data; /// accessed by that load using a side channel out of the speculative domain.; ///; /// For details on the attacks, see the first variant in both the Project Zero; /// writeup and the Spectre paper:; /// https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; /// https://spectreattack.com/spectre.pdf; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:636,Security,access,accessed,636,"//====- X86SpeculativeLoadHardening.cpp - A Spectre v1 mitigation ---------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// Provide a pass which mitigates speculative execution attacks which operate; /// by speculating incorrectly past some predicate (a type check, bounds check,; /// or other condition) to reach a load with invalid inputs and leak the data; /// accessed by that load using a side channel out of the speculative domain.; ///; /// For details on the attacks, see the first variant in both the Project Zero; /// writeup and the Spectre paper:; /// https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; /// https://spectreattack.com/spectre.pdf; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:739,Security,attack,attacks,739,"//====- X86SpeculativeLoadHardening.cpp - A Spectre v1 mitigation ---------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// Provide a pass which mitigates speculative execution attacks which operate; /// by speculating incorrectly past some predicate (a type check, bounds check,; /// or other condition) to reach a load with invalid inputs and leak the data; /// accessed by that load using a side channel out of the speculative domain.; ///; /// For details on the attacks, see the first variant in both the Project Zero; /// writeup and the Spectre paper:; /// https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; /// https://spectreattack.com/spectre.pdf; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Deployability,Update,Update,3,// Update the branch instruction if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:129,Integrability,inject,inject,129,"// If this successor was reached through a branch rather than fallthrough,; // we might have *broken* fallthrough and so need to inject a new; // unconditional branch.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:129,Security,inject,inject,129,"// If this successor was reached through a branch rather than fallthrough,; // we might have *broken* fallthrough and so need to inject a new; // unconditional branch.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Deployability,Update,Update,3,// Update the unconditional branch now that we've added one.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Modifiability,Inherit,Inherit,3,// Inherit live-ins from the successor,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:77,Safety,predict,predictable,77,"/// Removing duplicate PHI operands to leave the PHI in a canonical and; /// predictable form.; ///; /// FIXME: It's really frustrating that we have to do this, but SSA-form in MIR; /// isn't what you might expect. We may have multiple entries in PHI nodes for; /// a single predecessor. This makes CFG-updating extremely complex, so here we; /// simplify all PHI nodes to a model even simpler than the IR's model: exactly; /// one entry per predecessor, regardless of how many edges there are.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:347,Usability,simpl,simplify,347,"/// Removing duplicate PHI operands to leave the PHI in a canonical and; /// predictable form.; ///; /// FIXME: It's really frustrating that we have to do this, but SSA-form in MIR; /// isn't what you might expect. We may have multiple entries in PHI nodes for; /// a single predecessor. This makes CFG-updating extremely complex, so here we; /// simplify all PHI nodes to a model even simpler than the IR's model: exactly; /// one entry per predecessor, regardless of how many edges there are.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:386,Usability,simpl,simpler,386,"/// Removing duplicate PHI operands to leave the PHI in a canonical and; /// predictable form.; ///; /// FIXME: It's really frustrating that we have to do this, but SSA-form in MIR; /// isn't what you might expect. We may have multiple entries in PHI nodes for; /// a single predecessor. This makes CFG-updating extremely complex, so here we; /// simplify all PHI nodes to a model even simpler than the IR's model: exactly; /// one entry per predecessor, regardless of how many edges there are.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:330,Deployability,update,updates,330,"// Now walk the duplicate indices, removing both the block and value. Note; // that these are stored as a vector making this element-wise removal; // :w; // potentially quadratic.; //; // FIXME: It is really frustrating that we have to use a quadratic; // removal algorithm here. There should be a better way, but the use-def; // updates required make that impossible using the public API.; //; // Note that we have to process these backwards so that we don't; // invalidate other indices with each removal.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:34,Performance,load,loads,34,/// Helper to scan a function for loads vulnerable to misspeculation that we; /// want to harden.; ///; /// We use this to avoid making changes to functions where there is nothing we; /// need to do to harden against misspeculation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:123,Safety,avoid,avoid,123,/// Helper to scan a function for loads vulnerable to misspeculation that we; /// want to harden.; ///; /// We use this to avoid making changes to functions where there is nothing we; /// need to do to harden against misspeculation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Performance,Load,Loads,3,// Loads within this basic block after an LFENCE are not at risk of; // speculatively executing with invalid predicates from prior control; // flow. So break out of this block but continue scanning the function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:60,Safety,risk,risk,60,// Loads within this basic block after an LFENCE are not at risk of; // speculatively executing with invalid predicates from prior control; // flow. So break out of this block but continue scanning the function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:15,Performance,load,loads,15,// Looking for loads only.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:29,Performance,load,load,29,// An MFENCE is modeled as a load but isn't vulnerable to misspeculation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:14,Performance,load,load,14,// We found a load.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:6,Performance,load,loads,6,// No loads found.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:49,Safety,detect,detect,49,// Only run if this pass is forced enabled or we detect the relevant function; // attribute requesting SLH.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:51,Performance,load,loads,51,// Do a quick scan to see if we have any checkable loads.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:43,Performance,load,loads,43,"// If we have no interesting conditions or loads, nothing to do here.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:116,Integrability,inject,inject,116,"// If we have loads being hardened and we've asked for call and ret edges to; // get a full fence-based mitigation, inject that fence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:14,Performance,load,loads,14,"// If we have loads being hardened and we've asked for call and ret edges to; // get a full fence-based mitigation, inject that fence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:116,Security,inject,inject,116,"// If we have loads being hardened and we've asked for call and ret edges to; // get a full fence-based mitigation, inject that fence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:13,Deployability,update,updated,13,// Track the updated values in an SSA updater to rewrite into SSA form at the; // end.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:38,Deployability,update,updater,38,// Track the updated values in an SSA updater to rewrite into SSA form at the; // end.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:49,Modifiability,rewrite,rewrite,49,// Track the updated values in an SSA updater to rewrite into SSA form at the; // end.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:417,Availability,avail,available,417,"// We may also enter basic blocks in this function via exception handling; // control flow. Here, if we are hardening interprocedurally, we need to; // re-capture the predicate state from the throwing code. In the Itanium ABI,; // the throw will always look like a call to __cxa_throw and will have the; // predicate state in the stack pointer, so extract fresh predicate state from; // the stack pointer and make it available in SSA.; // FIXME: Handle non-itanium ABI EH models.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:40,Availability,avail,available,40,"// Now that we have the predicate state available at the start of each block; // in the CFG, trace it through each block, hardening vulnerable instructions; // as we go.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:60,Deployability,update,updater,60,// Now rewrite all the uses of the pred state using the SSA updater to insert; // PHIs connecting the state between blocks along the CFG edges.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:7,Modifiability,rewrite,rewrite,7,// Now rewrite all the uses of the pred state using the SSA updater to insert; // PHIs connecting the state between blocks along the CFG edges.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:223,Performance,perform,performance,223,/// Implements the naive hardening approach of putting an LFENCE after every; /// potentially mis-predicted control flow construct.; ///; /// We include this as an alternative mostly for the purpose of comparison. The; /// performance impact of this is expected to be extremely severe and not; /// practical for any real-world users.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:98,Safety,predict,predicted,98,/// Implements the naive hardening approach of putting an LFENCE after every; /// potentially mis-predicted control flow construct.; ///; /// We include this as an alternative mostly for the purpose of comparison. The; /// performance impact of this is expected to be extremely severe and not; /// practical for any real-world users.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:14,Availability,reliab,reliably,14,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1087,Energy Efficiency,reduce,reduce,1087,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:540,Integrability,inject,inject,540,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:665,Integrability,inject,inject,665,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:926,Performance,optimiz,optimize,926,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:980,Performance,optimiz,optimization,980,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1027,Performance,optimiz,optimized,1027,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:540,Security,inject,inject,540,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:665,Security,inject,inject,665,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1131,Usability,simpl,simply,1131,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1224,Usability,guid,guide,1224,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:55,Usability,clear,clear,55,"// If we see an unconditional branch, reset our state, clear any; // fallthrough, and set this is the ""else"" successor.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:52,Modifiability,rewrite,rewrite,52,// Collect the inserted cmov instructions so we can rewrite their uses of the; // predicate state into SSA form.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:104,Deployability,update,update,104,// Now walk all of the basic blocks looking for ones that end in conditional; // jumps where we need to update this register along each edge.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:64,Safety,safe,safe,64,"// First, we split the edge to insert the checking block into a safe; // location.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:33,Availability,avail,available,33,// And put the last one into the available values for SSA form of our; // predicate state.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:109,Safety,avoid,avoids,109,"// Since we may have split edges and changed the number of successors,; // normalize the probabilities. This avoids doing it each time we split an; // edge.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:48,Performance,load,load,48,"/// Compute the register class for the unfolded load.; ///; /// FIXME: This should probably live in X86InstrInfo, potentially by adding; /// a way to unfold into a newly created vreg rather than requiring a register; /// input.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:22,Performance,load,loading,22,// We only care about loading variants of these instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:115,Security,attack,attacks,115,"// We cannot mitigate far jumps or calls, but we also don't expect them; // to be vulnerable to Spectre v1.2 style attacks.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:26,Testability,log,logic,26,// Use the generic unfold logic now that we know we're dealing with; // expected instructions.; // FIXME: We don't have test coverage for all of these!,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:120,Testability,test,test,120,// Use the generic unfold logic now that we know we're dealing with; // expected instructions.; // FIXME: We don't have test coverage for all of these!,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:57,Availability,failure,failure,57,"// If we were able to compute an unfolded reg class, any failure here; // is just a programming error so just assert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:96,Availability,error,error,96,"// If we were able to compute an unfolded reg class, any failure here; // is just a programming error so just assert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:110,Testability,assert,assert,110,"// If we were able to compute an unfolded reg class, any failure here; // is just a programming error so just assert.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Deployability,Update,Update,3,// Update the call site info.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:279,Safety,predict,predict,279,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:982,Safety,risk,risk,982,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:227,Security,attack,attacks,227,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:446,Security,attack,attack,446,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:506,Security,attack,attacker,506,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:616,Security,attack,attack,616,"/// Trace the predicate state through indirect branches, instrumenting them to; /// poison the state if a target is reached that does not match the expected; /// target.; ///; /// This is designed to mitigate Spectre variant 1 attacks where an indirect; /// branch is trained to predict a particular target and then mispredicts that; /// target in a way that can leak data. Despite using an indirect branch, this; /// is really a variant 1 style attack: it does not steer execution to an; /// arbitrary or attacker controlled address, and it does not require any; /// special code executing next to the victim. This attack can also be mitigated; /// through retpolines, but those require either replacing indirect branches; /// with conditional direct branches or lowering them through a device that; /// blocks speculation. This mitigation can replace these retpoline-style; /// mitigations for jump tables and other indirect branches within a function; /// when variant 2 isn't a risk while allowing limited speculation. Indirect; /// calls, however, cannot be mitigated through this technique without changing; /// the ABI in a fundamental way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:211,Availability,avail,available,211,"// We use the SSAUpdater to insert PHI nodes for the target addresses of; // indirect branches. We don't actually need the full power of the SSA updater; // in this particular case as we always have immediately available values, but; // this avoids us having to re-implement the PHI construction logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:145,Deployability,update,updater,145,"// We use the SSAUpdater to insert PHI nodes for the target addresses of; // indirect branches. We don't actually need the full power of the SSA updater; // in this particular case as we always have immediately available values, but; // this avoids us having to re-implement the PHI construction logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:128,Energy Efficiency,power,power,128,"// We use the SSAUpdater to insert PHI nodes for the target addresses of; // indirect branches. We don't actually need the full power of the SSA updater; // in this particular case as we always have immediately available values, but; // this avoids us having to re-implement the PHI construction logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:242,Safety,avoid,avoids,242,"// We use the SSAUpdater to insert PHI nodes for the target addresses of; // indirect branches. We don't actually need the full power of the SSA updater; // in this particular case as we always have immediately available values, but; // this avoids us having to re-implement the PHI construction logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:296,Testability,log,logic,296,"// We use the SSAUpdater to insert PHI nodes for the target addresses of; // indirect branches. We don't actually need the full power of the SSA updater; // in this particular case as we always have immediately available values, but; // this avoids us having to re-implement the PHI construction logic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:87,Availability,avail,available,87,// Walk all the blocks which end in an indirect branch and make the; // target address available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:136,Security,attack,attacks,136,"// We cannot mitigate far jumps or calls, but we also don't expect them; // to be vulnerable to Spectre v1.2 or v2 (self trained) style attacks.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:31,Availability,avail,available,31,// Make the target register an available value for this block.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:85,Performance,load,loads,85,// We found indirect branches and targets that need to be instrumented to; // harden loads within them. Walk the blocks of the function (to get a stable; // ordering) and instrument each target of an indirect branch.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:157,Testability,assert,asserting,157,"// We don't expect EH pads to ever be reached via an indirect branch. If; // this is desired for some reason, we could simply skip them here rather; // than asserting.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:119,Usability,simpl,simply,119,"// We don't expect EH pads to ever be reached via an indirect branch. If; // this is desired for some reason, we could simply skip them here rather; // than asserting.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:295,Availability,resilien,resilient,295,"// Otherwise, we have to be the only successor. We generally expect this; // to be true as conditional branches should have had a critical edge; // split already. We don't however need to worry about EH pad successors; // as they'll happily ignore the target and their hardening strategy is; // resilient to all ways in which they could be reached speculatively.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:56,Deployability,install,install,56,// Now we need to compute the address of this block and install it as a; // synthetic target in the predecessor. We do this at the bottom of the; // predecessor.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:17,Availability,avail,available,17,// And make this available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:261,Availability,avail,available,261,"// Materialize the needed SSA value of the target. Note that we need the; // middle of the block as this block might at the bottom have an indirect; // branch back to itself. We can do this here because at this point, every; // predecessor of this block has an available value. This is basically just; // automating the construction of a PHI node for this target.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:34,Availability,avail,available,34,// And put the new value into the available values for SSA form of our; // predicate state.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:23,Availability,alive,alive,23,"// Check if EFLAGS are alive by seeing if there is a def of them or they; // live-in, and then seeing if that def is in turn used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:61,Availability,alive,alive,61,// If we didn't find anything conclusive (neither definitely alive or; // definitely dead) return whether it lives into the block.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:263,Deployability,update,updater,263,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:400,Deployability,update,updater,400,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:626,Deployability,update,updater,626,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:731,Deployability,update,update,731,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:148,Integrability,rout,routine,148,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:277,Integrability,rout,routine,277,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1194,Integrability,depend,dependencies,1194,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1272,Integrability,depend,dependent,1272,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:833,Performance,load,loads,833,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:958,Performance,load,loaded,958,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:976,Performance,load,loaded,976,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1215,Performance,load,loads,1215,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1252,Performance,load,loads,1252,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1287,Performance,load,load,1287,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1345,Performance,load,loads,1345,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1225,Safety,avoid,avoid,1225,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1702,Usability,simpl,simplify,1702,"/// Trace the predicate state through each of the blocks in the function,; /// hardening everything necessary along the way.; ///; /// We call this routine once the initial predicate state has been established; /// for each basic block in the function in the SSA updater. This routine traces; /// it through the instructions within each basic block, and for non-returning; /// blocks informs the SSA updater about the final state that lives out of the; /// block. Along the way, it hardens any vulnerable instruction using the; /// currently valid predicate state. We have to do these two things together; /// because the SSA updater only works across blocks. Within a block, we track; /// the current predicate state directly and update it as it changes.; ///; /// This operates in two passes over each block. First, we analyze the loads in; /// the block to determine which strategy will be used to harden them: hardening; /// the address or hardening the loaded value when loaded into a register; /// amenable to hardening. We have to process these first because the two; /// strategies may interact -- later hardening may change what strategy we wish; /// to use. We also will analyze data dependencies between loads and avoid; /// hardening those loads that are data dependent on a load with a hardened; /// address. We also skip hardening loads already behind an LFENCE as that is; /// sufficient to harden them against misspeculation.; ///; /// Second, we actively trace the predicate state through the block, applying; /// the hardening steps we determined necessary in the first pass as we go.; ///; /// These two passes are applied to each basic block. We operate one block at a; /// time to simplify reasoning about reachability and sequencing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:25,Integrability,depend,dependent,25,"// Track the set of load-dependent registers through the basic block. Because; // the values of these registers have an existing data dependency on a loaded; // value which we would have checked, we can omit any checks on them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:134,Integrability,depend,dependency,134,"// Track the set of load-dependent registers through the basic block. Because; // the values of these registers have an existing data dependency on a loaded; // value which we would have checked, we can omit any checks on them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:20,Performance,load,load-dependent,20,"// Track the set of load-dependent registers through the basic block. Because; // the values of these registers have an existing data dependency on a loaded; // value which we would have checked, we can omit any checks on them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:150,Performance,load,loaded,150,"// Track the set of load-dependent registers through the basic block. Because; // the values of these registers have an existing data dependency on a loaded; // value which we would have checked, we can omit any checks on them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:202,Integrability,depend,dependence,202,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:50,Performance,load,loads,50,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:81,Performance,load,loaded,81,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:115,Performance,load,loads,115,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:197,Performance,load,load,197,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:238,Performance,load,loads,238,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:353,Performance,load,loaded,353,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:704,Performance,load,loads,704,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:871,Performance,load,loads,871,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:81,Integrability,depend,dependency,81,// We naively assume that all def'ed registers of an instruction have; // a data dependency on all of their operands.; // FIXME: Do a more careful analysis of x86 to build a conservative; // model here.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:26,Usability,guid,guiding,26,"// Both Intel and AMD are guiding that they will change the semantics of; // LFENCE to be a speculation barrier, so if we see an LFENCE, there is; // no more need to guard things in this block.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:30,Performance,load,load,30,"// If this instruction cannot load, nothing to do.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:28,Performance,load,load,28,"// Some instructions which ""load"" are trivially safe or unimportant.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:48,Safety,safe,safe,48,"// Some instructions which ""load"" are trivially safe or unimportant.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:104,Integrability,depend,dependent,104,"// If we have at least one (non-frame-index, non-RIP) register operand,; // and neither operand is load-dependent, we need to check the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:99,Performance,load,load-dependent,99,"// If we have at least one (non-frame-index, non-RIP) register operand,; // and neither operand is load-dependent, we need to check the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:136,Performance,load,load,136,"// If we have at least one (non-frame-index, non-RIP) register operand,; // and neither operand is load-dependent, we need to check the load.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:30,Integrability,depend,dependent,30,"// If any register operand is dependent, this load is dependent and we; // needn't check it.; // FIXME: Is this true in the case where we are hardening loads after; // they complete? Unclear, need to investigate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:54,Integrability,depend,dependent,54,"// If any register operand is dependent, this load is dependent and we; // needn't check it.; // FIXME: Is this true in the case where we are hardening loads after; // they complete? Unclear, need to investigate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:46,Performance,load,load,46,"// If any register operand is dependent, this load is dependent and we; // needn't check it.; // FIXME: Is this true in the case where we are hardening loads after; // they complete? Unclear, need to investigate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:152,Performance,load,loads,152,"// If any register operand is dependent, this load is dependent and we; // needn't check it.; // FIXME: Is this true in the case where we are hardening loads after; // they complete? Unclear, need to investigate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:264,Integrability,depend,dependency,264,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:11,Performance,load,load,11,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:43,Performance,load,load,43,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:76,Performance,load,load,76,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:164,Performance,queue,queue,164,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:196,Performance,load,load,196,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:311,Performance,load,loads,311,"// If post-load hardening is enabled, this load is compatible with; // post-load hardening, and we aren't already going to harden one of the; // address registers, queue it up to be hardened post-load. Notably,; // even once hardened this won't introduce a useful dependency that; // could prune out subsequent loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:246,Performance,load,load,246,"// Now re-walk the instructions in the basic block, and apply whichever; // hardening strategy we have elected. Note that we do this in a second; // pass specifically so that we have the complete set of instructions for; // which we will do post-load hardening and can defer it in certain; // circumstances.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:49,Performance,load,load,49,// We cannot both require hardening the def of a load and its address.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:22,Performance,load,load,22,// Check if this is a load whose address needs to be hardened.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:47,Performance,load,load,47,// Test if this instruction is one of our post load instructions (and; // remove it from the set if so).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Testability,Test,Test,3,// Test if this instruction is one of our post load instructions (and; // remove it from the set if so).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:31,Performance,load,load,31,"// If this is a data-invariant load and there is no EFLAGS; // interference, we want to try and sink any hardening as far as; // possible.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:62,Availability,down,down,62,// Sink the instruction we'll need to harden as far as we can down; // the graph.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:43,Deployability,update,update,43,"// If we managed to sink this instruction, update everything so we; // harden that instruction when we reach it in the instruction; // sequence.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:115,Performance,load,load,115,"// Check for an indirect call or branch that may need its input hardened; // even if we couldn't find the specific load used, or were able to; // avoid hardening it for some reason. Note that here we cannot break; // out afterward as we may still need to handle any call aspect of this; // instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:146,Safety,avoid,avoid,146,"// Check for an indirect call or branch that may need its input hardened; // even if we couldn't find the specific load used, or were able to; // avoid hardening it for some reason. Note that here we cannot break; // out afterward as we may still need to handle any call aspect of this; // instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:29,Performance,load,loads,29,// After we finish hardening loads we handle interprocedural hardening if; // enabled and relevant for this instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:100,Availability,recover,recovering,100,// Otherwise we have a call. We need to handle transferring the predicate; // state into a call and recovering it after the call returns (unless this; // is a tail call).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:100,Safety,recover,recovering,100,// Otherwise we have a call. We need to handle transferring the predicate; // state into a call and recovering it after the call returns (unless this; // is a tail call).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:33,Integrability,depend,dependent,33,"// Currently, we only track data-dependent loads within a basic block.; // FIXME: We should see if this is necessary or if we could be more; // aggressive here without opening up attack avenues.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:43,Performance,load,loads,43,"// Currently, we only track data-dependent loads within a basic block.; // FIXME: We should see if this is necessary or if we could be more; // aggressive here without opening up attack avenues.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:179,Security,attack,attack,179,"// Currently, we only track data-dependent loads within a basic block.; // FIXME: We should see if this is necessary or if we could be more; // aggressive here without opening up attack avenues.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:140,Usability,simpl,simple,140,/// Save EFLAGS into the returned GPR. This can in turn be restored with; /// `restoreEFLAGS`.; ///; /// Note that LLVM can only lower very simple patterns of saved and restored; /// EFLAGS registers. The restore should always be within the same basic block; /// as the save so that no PHI nodes are inserted.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:173,Availability,reliab,reliably,173,/// Restore EFLAGS from the provided GPR. This should be produced by; /// `saveEFLAGS`.; ///; /// This must be done within the same basic block as the save in order to; /// reliably lower.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:23,Availability,alive,alive,23,"// Check if EFLAGS are alive by seeing if there is a def of them or they; // live-in, and then seeing if that def is in turn used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:53,Performance,load,load,53,"// A frame index is never a dynamically controllable load, so only; // harden it if we're covering fixed address loads as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:113,Performance,load,loads,113,"// A frame index is never a dynamically controllable load, so only; // harden it if we're covering fixed address loads as well.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:35,Performance,load,loads,35,"// For both RIP-relative addressed loads or absolute loads, we cannot; // meaningfully harden them because the address being loaded has no; // dynamic component.; //; // FIXME: When using a segment base (like TLS does) we end up with the; // dynamic address being the base plus -1 because we can't mutate the; // segment register here. This allows the signed 32-bit offset to point at; // valid segment-relative addresses and load them successfully.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:53,Performance,load,loads,53,"// For both RIP-relative addressed loads or absolute loads, we cannot; // meaningfully harden them because the address being loaded has no; // dynamic component.; //; // FIXME: When using a segment base (like TLS does) we end up with the; // dynamic address being the base plus -1 because we can't mutate the; // segment register here. This allows the signed 32-bit offset to point at; // valid segment-relative addresses and load them successfully.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:125,Performance,load,loaded,125,"// For both RIP-relative addressed loads or absolute loads, we cannot; // meaningfully harden them because the address being loaded has no; // dynamic component.; //; // FIXME: When using a segment base (like TLS does) we end up with the; // dynamic address being the base plus -1 because we can't mutate the; // segment register here. This allows the signed 32-bit offset to point at; // valid segment-relative addresses and load them successfully.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:426,Performance,load,load,426,"// For both RIP-relative addressed loads or absolute loads, we cannot; // meaningfully harden them because the address being loaded has no; // dynamic component.; //; // FIXME: When using a segment base (like TLS does) we end up with the; // dynamic address being the base plus -1 because we can't mutate the; // segment register here. This allows the signed 32-bit offset to point at; // valid segment-relative addresses and load them successfully.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:30,Deployability,update,update,30,"// Otherwise, we can directly update this operand and remove it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:68,Safety,avoid,avoid,68,// If EFLAGS are live and we don't have access to instructions that avoid; // clobbering EFLAGS we need to save and restore them. This in turn makes; // the EFLAGS no longer live.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:40,Security,access,access,40,// If EFLAGS are live and we don't have access to instructions that avoid; // clobbering EFLAGS we need to save and restore them. This in turn makes; // the EFLAGS no longer live.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:60,Testability,log,logic,60,"// If this is a vector register, we'll need somewhat custom logic to handle; // hardening it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:122,Deployability,update,update,122,// We need to avoid touching EFLAGS so shift out all but the least; // significant bit using the instruction that doesn't update flags.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:14,Safety,avoid,avoid,14,// We need to avoid touching EFLAGS so shift out all but the least; // significant bit using the instruction that doesn't update flags.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:39,Deployability,update,update,39,// Record this register as checked and update the operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:36,Performance,load,loaded,36,// See if we can sink hardening the loaded value.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:44,Performance,load,load,44,"// If we've already decided to harden a non-load, we must have sunk; // some other post-load hardened instruction to it and it must itself; // be data-invariant.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:88,Performance,load,load,88,"// If we've already decided to harden a non-load, we must have sunk; // some other post-load hardened instruction to it and it must itself; // be data-invariant.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:24,Performance,load,load,24,"// Otherwise, this is a load and the load component can't be data; // invariant so check how this register is being used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:37,Performance,load,load,37,"// Otherwise, this is a load and the load component can't be data; // invariant so check how this register is being used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:7,Performance,load,load,7,// The load uses the register as part of its address making it not; // invariant.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Deployability,Update,Update,3,// Update which MI we're checking now.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:25,Performance,load,load,25,// We don't support post-load hardening of vectors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:236,Integrability,rout,routine,236,"/// Harden a value in a register.; ///; /// This is the low-level logic to fully harden a value sitting in a register; /// against leaking during speculative execution.; ///; /// Unlike hardening an address that is used by a load, this routine is required; /// to hide *all* incoming bits in the register.; ///; /// `Reg` must be a virtual register. Currently, it is required to be a GPR no; /// larger than the predicate state register. FIXME: We should support vector; /// registers here by broadcasting the predicate state.; ///; /// The new, hardened virtual register is returned. It will have the same; /// register class as `Reg`.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:225,Performance,load,load,225,"/// Harden a value in a register.; ///; /// This is the low-level logic to fully harden a value sitting in a register; /// against leaking during speculative execution.; ///; /// Unlike hardening an address that is used by a load, this routine is required; /// to hide *all* incoming bits in the register.; ///; /// `Reg` must be a virtual register. Currently, it is required to be a GPR no; /// larger than the predicate state register. FIXME: We should support vector; /// registers here by broadcasting the predicate state.; ///; /// The new, hardened virtual register is returned. It will have the same; /// register class as `Reg`.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:66,Testability,log,logic,66,"/// Harden a value in a register.; ///; /// This is the low-level logic to fully harden a value sitting in a register; /// against leaking during speculative execution.; ///; /// Unlike hardening an address that is used by a load, this routine is required; /// to hide *all* incoming bits in the register.; ///; /// `Reg` must be a virtual register. Currently, it is required to be a GPR no; /// larger than the predicate state register. FIXME: We should support vector; /// registers here by broadcasting the predicate state.; ///; /// The new, hardened virtual register is returned. It will have the same; /// register class as `Reg`.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:13,Performance,load,load,13,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:35,Performance,load,loaded,35,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:111,Performance,load,load,111,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:192,Performance,load,loaded,192,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:352,Performance,load,loaded,352,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:374,Security,expose,exposed,374,/// Harden a load by hardening the loaded value in the defined register.; ///; /// We can harden a non-leaking load into a register without touching the; /// address by just hiding all of the loaded bits during misspeculation. We use; /// an `or` instruction to do this because we set up our poison value as all; /// ones. And the goal is just for the loaded bits to not be exposed to; /// execution and coercing them to one is sufficient.; ///; /// Returns the newly hardened register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:68,Safety,safe,safe,68,"// Now harden this register's value, getting a hardened reg that is safe to; // use. Note that we insert the instructions to compute this *after* the; // defining instruction, not before it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1305,Availability,recover,recover,1305,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:62,Performance,perform,perform,62,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:72,Performance,load,load,72,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:130,Performance,load,load,130,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:502,Performance,load,load,502,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:664,Performance,load,load,664,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1395,Performance,load,loads,1395,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1048,Safety,predict,prediction,1048,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1305,Safety,recover,recover,1305,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:139,Security,attack,attacker,139,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:241,Security,attack,attacker,241,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:915,Security,attack,attack,915,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1213,Security,attack,attacked,1213,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:971,Usability,resume,resumed,971,"/// Harden a return instruction.; ///; /// Returns implicitly perform a load which we need to harden. Without hardening; /// this load, an attacker my speculatively write over the return address to; /// steer speculation of the return to an attacker controlled address. This is; /// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in; /// this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// We can harden this by introducing an LFENCE that will delay any load of the; /// return address until prior instructions have retired (and thus are not being; /// speculated), or we can harden the address used by the implicit load: the; /// stack pointer.; ///; /// If we are not using an LFENCE, hardening the stack pointer has an additional; /// benefit: it allows us to pass the predicate state accumulated in this; /// function back to the caller. In the absence of a BCBS attack on the return,; /// the caller will typically be resumed and speculatively executed due to the; /// Return Stack Buffer (RSB) prediction which is very accurate and has a high; /// priority. It is possible that some code from the caller will be executed; /// speculatively even during a BCBS-attacked return until the steering takes; /// effect. Whenever this happens, the caller can recover the (poisoned); /// predicate state from the stack pointer and continue to harden loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:74,Modifiability,layers,layers,74,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1159,Performance,load,load,1159,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:1540,Safety,detect,detected,1540,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:650,Security,attack,attacker,650,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:835,Security,attack,attack,835,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:390,Usability,resume,resume,390,"/// Trace the predicate state through a call.; ///; /// There are several layers of this needed to handle the full complexity of; /// calls.; ///; /// First, we need to send the predicate state into the called function. We do; /// this by merging it into the high bits of the stack pointer.; ///; /// For tail calls, this is all we need to do.; ///; /// For calls where we might return and resume the control flow, we need to; /// extract the predicate state from the high bits of the stack pointer after; /// control returns from the called function.; ///; /// We also need to verify that we intended to return to this location in the; /// code. An attacker might arrange for the processor to mispredict the return; /// to this valid but incorrect return address in the program rather than the; /// correct one. See the paper on this attack, called ""ret2spec"" by the; /// researchers, here:; /// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf; ///; /// The way we verify that we returned to the correct location is by preserving; /// the expected return address across the call. One technique involves taking; /// advantage of the red-zone to load the return address from `8(%rsp)` where it; /// was left by the RET instruction when it popped `%rsp`. Alternatively, we can; /// directly save the address into a register that will be preserved across the; /// call. We compare this intended return address against the address; /// immediately following the call (the observed return address). If these; /// mismatch, we have detected misspeculation and can poison our predicate; /// state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:520,Availability,reliab,reliable,520,"// If we don't have red zones, we need to compute the expected return; // address prior to the call and store it in a register that lives across; // the call.; //; // In some ways, this is doubly satisfying as a mitigation because it will; // also successfully detect stack smashing bugs in some cases (typically,; // when a callee-saved register is used and the callee doesn't push it onto; // the stack). But that isn't our primary goal, so we only use it as; // a fallback.; //; // FIXME: It isn't clear that this is reliable in the face of; // rematerialization in the register allocator. We somehow need to force; // that to not occur for this particular instruction, and instead to spill; // or otherwise preserve the value computed *prior* to the call.; //; // FIXME: It is even less clear why MachineCSE can't just fold this when we; // end up having to use identical instructions both before and after the; // call to feed the comparison.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:261,Safety,detect,detect,261,"// If we don't have red zones, we need to compute the expected return; // address prior to the call and store it in a register that lives across; // the call.; //; // In some ways, this is doubly satisfying as a mitigation because it will; // also successfully detect stack smashing bugs in some cases (typically,; // when a callee-saved register is used and the callee doesn't push it onto; // the stack). But that isn't our primary goal, so we only use it as; // a fallback.; //; // FIXME: It isn't clear that this is reliable in the face of; // rematerialization in the register allocator. We somehow need to force; // that to not occur for this particular instruction, and instead to spill; // or otherwise preserve the value computed *prior* to the call.; //; // FIXME: It is even less clear why MachineCSE can't just fold this when we; // end up having to use identical instructions both before and after the; // call to feed the comparison.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:501,Usability,clear,clear,501,"// If we don't have red zones, we need to compute the expected return; // address prior to the call and store it in a register that lives across; // the call.; //; // In some ways, this is doubly satisfying as a mitigation because it will; // also successfully detect stack smashing bugs in some cases (typically,; // when a callee-saved register is used and the callee doesn't push it onto; // the stack). But that isn't our primary goal, so we only use it as; // a fallback.; //; // FIXME: It isn't clear that this is reliable in the face of; // rematerialization in the register allocator. We somehow need to force; // that to not occur for this particular instruction, and instead to spill; // or otherwise preserve the value computed *prior* to the call.; //; // FIXME: It is even less clear why MachineCSE can't just fold this when we; // end up having to use identical instructions both before and after the; // call to feed the comparison.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:791,Usability,clear,clear,791,"// If we don't have red zones, we need to compute the expected return; // address prior to the call and store it in a register that lives across; // the call.; //; // In some ways, this is doubly satisfying as a mitigation because it will; // also successfully detect stack smashing bugs in some cases (typically,; // when a callee-saved register is used and the callee doesn't push it onto; // the stack). But that isn't our primary goal, so we only use it as; // a fallback.; //; // FIXME: It isn't clear that this is reliable in the face of; // rematerialization in the register allocator. We somehow need to force; // that to not occur for this particular instruction, and instead to spill; // or otherwise preserve the value computed *prior* to the call.; //; // FIXME: It is even less clear why MachineCSE can't just fold this when we; // end up having to use identical instructions both before and after the; // call to feed the comparison.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:136,Availability,avail,available,136,"// If we didn't pre-compute the expected return address into a register, then; // red zones are enabled and the return address is still available on the; // stack immediately after the call. As the very first instruction, we load it; // into a register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:225,Performance,load,load,225,"// If we didn't pre-compute the expected return address into a register, then; // red zones are enabled and the return address is still available on the; // stack immediately after the call. As the very first instruction, we load it; // into a register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:3,Testability,Test,Test,3,"// Test the expected return address against our actual address. If we can; // form this basic block's address as an immediate, this is easy. Otherwise; // we compute it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:38,Performance,load,load,38,// FIXME: Could we fold this with the load? It would require careful EFLAGS; // management.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:21,Deployability,update,update,21,// Now conditionally update the predicate state we just extracted if we ended; // up at a different return address than expected.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:85,Performance,load,loaded,85,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:473,Performance,load,loads,473,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:595,Performance,load,load,595,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:836,Performance,load,loads,836,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:900,Performance,load,load,900,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:7,Security,attack,attacker,7,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:428,Security,attack,attacker,428,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:697,Security,attack,attacker,697,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:751,Security,attack,attacker,751,"/// An attacker may speculatively store over a value that is then speculatively; /// loaded and used as the target of an indirect call or jump instruction. This; /// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described; /// in this paper:; /// https://people.csail.mit.edu/vlk/spectre11.pdf; ///; /// When this happens, the speculative execution of the call or jump will end up; /// being steered to this attacker controlled address. While most such loads; /// will be adequately hardened already, we want to ensure that they are; /// definitively treated as needing post-load hardening. While address hardening; /// is sufficient to prevent secret data from leaking to the attacker, it may; /// not be sufficient to prevent an attacker from steering speculative; /// execution. We forcibly unfolded all relevant loads above and so will always; /// have an opportunity to post-load harden here, we just need to scan for cases; /// not already flagged and add them.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:73,Safety,safe,safe,73,// We don't need to harden either far calls or far jumps as they are; // safe from Spectre.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:25,Performance,load,loading,25,"// We should never see a loading instruction at this point, as those should; // have been unfolded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:99,Deployability,update,update,99,// Try to lookup a hardened version of this register. We retain a reference; // here as we want to update the map to track any newly computed hardened; // register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:22,Modifiability,variab,variable,22,/// Classify a global variable reference for the current subtarget according to; /// how we should reference it in a non-pcrel context.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:167,Availability,error,errors,167,"// Tagged globals have non-zero upper bits, which makes direct references; // require a 64-bit immediate. With the small/medium code models this causes; // relocation errors, so we go through the GOT instead.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:56,Security,access,access,56,"// Large GlobalValues use GOTOFF, otherwise use RIP-rel access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:168,Security,access,accessible,168,"// GV == nullptr is for all other non-GlobalValue global data like the; // constant pool, jump tables, labels, etc. The small and medium code; // models treat these as accessible with a RIP-rel access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:194,Security,access,access,194,"// GV == nullptr is for all other non-GlobalValue global data like the; // constant pool, jump tables, labels, etc. The small and medium code; // models treat these as accessible with a RIP-rel access.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:32,Deployability,patch,patches,32,// The COFF dynamic linker just patches the executable sections.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:150,Performance,load,load,150,"// 32 bit macho has no relocation for a-b if a is undefined, even if; // b is in the section that is being relocated.; // This means we have to use o load even for GVs that are known to be; // local to the dso.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:37,Testability,stub,stubs,37,// The static large model never uses stubs.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:89,Modifiability,extend,extend,89,"// See if we can use the 8-bit immediate form. Note that some instructions; // will sign extend the immediate operand, so to be conservative we only; // accept the range [0,128).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:168,Testability,stub,stub,168,"// Functions on COFF can be non-DSO local for three reasons:; // - They are intrinsic functions (!GV); // - They are marked dllimport; // - They are extern_weak, and a stub is needed",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:27,Testability,stub,stub,27,"// According to psABI, PLT stub clobbers XMM8-XMM15.; // In Regcall calling convention those registers are used for passing; // parameters. Thus we need to prevent lazy binding in Regcall.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:18,Safety,avoid,avoided,18,// If PLT must be avoided then the call should be via GOTPCREL.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:78,Performance,load,loads,78,"// If the function is marked as non-lazy, generate an indirect call; // which loads from the GOT directly. This avoids runtime overhead; // at the cost of eager binding (and one extra byte of encoding).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:112,Safety,avoid,avoids,112,"// If the function is marked as non-lazy, generate an indirect call; // which loads from the GOT directly. This avoids runtime overhead; // at the cost of eager binding (and one extra byte of encoding).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:44,Testability,test,tests,44,"// FIXME: ""generic"" is more modern than llc tests expect.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:61,Security,access,accesses,61,// All CPUs that implement SSE4.2 or SSE4A support unaligned accesses of; // 16-bytes and under that are reasonably fast. These features were; // introduced with Intel's Nehalem/Silvermont and AMD's Family10h; // micro-architectures respectively.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp:53,Security,access,accesses,53,"// With the large code model, None forces all memory accesses to be indirect; // rather than RIP-relative.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:31,Integrability,depend,dependencies,31,/// Initialize the full set of dependencies so we can use an initializer; /// list for X86Subtarget.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:15,Integrability,depend,depends,15,"// SSE codegen depends on cmovs, and all SSE1+ processors support them.; // All 64-bit processors support cmov.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:197,Performance,cache,cache,197,// The PREFETCHW instruction was added with 3DNow but later CPUs gave it; // its own CPUID bit as part of deprecating 3DNow. Intel eventually added; // it and KNL has another that prefetches to L2 cache. We assume the; // L1 version exists if the L2 version does.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:69,Performance,cache,cache,69,"// We implicitly enable these when we have a write prefix supporting cache; // level OR if we have prfchw, but don't already have a read prefetch from; // 3dnow.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:22,Modifiability,variab,variable,22,/// Classify a global variable reference for the current subtarget according; /// to how we should reference it in a non-pcrel context.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:56,Modifiability,extend,extended,56,"/// Return whether FrameLowering should always set the ""extended frame; /// present"" bit in FP, or set it based on a symbol in the runtime.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:83,Modifiability,extend,extended,83,"// Older OS versions (particularly system unwinders) are confused by the; // Swift extended frame, so when building code that might be run on them we; // must dynamically query the concurrency library to determine whether; // extended frames should be flagged as present.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:226,Modifiability,extend,extended,226,"// Older OS versions (particularly system unwinders) are confused by the; // Swift extended frame, so when building code that might be run on them we; // must dynamically query the concurrency library to determine whether; // extended frames should be flagged as present.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:181,Performance,concurren,concurrency,181,"// Older OS versions (particularly system unwinders) are confused by the; // Swift extended frame, so when building code that might be run on them we; // must dynamically query the concurrency library to determine whether; // extended frames should be flagged as present.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:69,Safety,avoid,avoid,69,"/// If we are using indirect thunks, we need to expand indirectbr to avoid it; /// lowering to an actual indirect jump.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:136,Performance,tune,tune-cpu,136,"// ""x86-64"" is a default target setting for many front ends. In these cases,; // they actually request for ""generic"" tuning unless the ""tune-cpu"" was; // specified.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:198,Energy Efficiency,allocate,allocate,198,// The additions here are ordered so that the definitely short strings are; // added first so we won't exceed the small size. We append the; // much longer FS string at the end so that we only heap allocate at most; // one time.; // Extract prefer-vector-width attribute.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:7,Performance,tune,tune,7,// Add tune CPU to the Key.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:86,Integrability,depend,depend,86,// This needs to be done before we create a new subtarget since any; // creation will depend on the TM and the code generation flags on the; // function that reside in TargetOptions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:90,Deployability,Pipeline,Pipeline,90,//===----------------------------------------------------------------------===//; // Pass Pipeline Configuration; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:99,Deployability,Configurat,Configuration,99,//===----------------------------------------------------------------------===//; // Pass Pipeline Configuration; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:99,Modifiability,Config,Configuration,99,//===----------------------------------------------------------------------===//; // Pass Pipeline Configuration; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:28,Deployability,Configurat,Configuration,28,/// X86 Code Generator Pass Configuration Options.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:28,Modifiability,Config,Configuration,28,/// X86 Code Generator Pass Configuration Options.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:3,Deployability,Install,Install,3,// Install an instruction selector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:42,Security,access,accesses,42,"// For ELF, cleanup any local-dynamic TLS accesses.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:191,Availability,down,downs,191,"// When -O0 is enabled, the Load Value Injection Hardening pass will fall back; // to using the Speculative Execution Side Effect Suppression pass for; // mitigation. This is to prevent slow downs due to; // analyses needed by the LVIHardening pass when compiling at -O0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:39,Integrability,Inject,Injection,39,"// When -O0 is enabled, the Load Value Injection Hardening pass will fall back; // to using the Speculative Execution Side Effect Suppression pass for; // mitigation. This is to prevent slow downs due to; // analyses needed by the LVIHardening pass when compiling at -O0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:28,Performance,Load,Load,28,"// When -O0 is enabled, the Load Value Injection Hardening pass will fall back; // to using the Speculative Execution Side Effect Suppression pass for; // mitigation. This is to prevent slow downs due to; // analyses needed by the LVIHardening pass when compiling at -O0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:39,Security,Inject,Injection,39,"// When -O0 is enabled, the Load Value Injection Hardening pass will fall back; // to using the Speculative Execution Side Effect Suppression pass for; // mitigation. This is to prevent slow downs due to; // analyses needed by the LVIHardening pass when compiling at -O0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:291,Deployability,update,updated,291,// The X86 Speculative Execution Pass must run after all control; // flow graph modifying passes. As a result it was listed to run right before; // the X86 Retpoline Thunks pass. The reason it must run after control flow; // graph modifications is that the model of LFENCE in LLVM has to be updated; // (FIXME: https://bugs.llvm.org/show_bug.cgi?id=45167). Currently the; // placement of this pass was hand checked to ensure that the subsequent; // passes don't move the code around the LFENCEs in a way that will hurt the; // correctness of this pass. This placement has been shown to work based on; // hand inspection of the codegen output.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:70,Safety,avoid,avoid,70,// Insert extra int3 instructions after trailing call instructions to avoid; // issues in the unwinder.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate tile register first.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.h:19,Deployability,pipeline,pipeline,19,// Set up the pass pipeline.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.cpp:54,Security,access,access,54,"// On Darwin/X86-64, we need to use foo@GOTPCREL+4 to access the got entry; // from a data section. In case there's an additional offset, then use; // foo@GOTPCREL+4+<offset>.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.h:19,Modifiability,variab,variable,19,/// Describe a TLS variable address within debug info.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetObjectFile.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:1973,Energy Efficiency,schedul,scheduler,1973,"n to provide; /// more precise answers to certain TTI queries, while letting the target; /// independent and default TTI implementations handle the rest.; ///; //===----------------------------------------------------------------------===//; /// About Cost Model numbers used below it's necessary to say the following:; /// the numbers correspond to some ""generic"" X86 CPU instead of usage of a; /// specific CPU model. Usually the numbers correspond to the CPU where the; /// feature first appeared. For example, if we do Subtarget.hasSSE42() in; /// the lookups below the cost is based on Nehalem as that was the first CPU; /// to support that feature level and thus has most likely the worst case cost,; /// although we may discard an outlying worst cost from one CPU (e.g. Atom).; ///; /// Some examples of other technologies/CPUs:; /// SSE 3 - Pentium4 / Athlon64; /// SSE 4.1 - Penryn; /// SSE 4.2 - Nehalem / Silvermont; /// AVX - Sandy Bridge / Jaguar / Bulldozer; /// AVX2 - Haswell / Ryzen; /// AVX-512 - Xeon Phi / Skylake; ///; /// And some examples of instruction target dependent costs (latency); /// divss sqrtss rsqrtss; /// AMD K7 11-16 19 3; /// Piledriver 9-24 13-15 5; /// Jaguar 14 16 2; /// Pentium II,III 18 30 2; /// Nehalem 7-14 7-18 3; /// Haswell 10-13 11 5; ///; /// Interpreting the 4 TargetCostKind types:; /// TCK_RecipThroughput and TCK_Latency should try to match the worst case; /// values reported by the CPU scheduler models (and llvm-mca).; /// TCK_CodeSize should match the instruction count (e.g. divss = 1), NOT the; /// actual encoding size of the instruction.; /// TCK_SizeAndLatency should match the worst case micro-op counts reported by; /// by the CPU scheduler models (and llvm-mca), to ensure that they are; /// compatible with the MicroOpBufferSize and LoopMicroOpBufferSize values which are; /// often used as the cost thresholds where TCK_SizeAndLatency is requested.; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:2227,Energy Efficiency,schedul,scheduler,2227,"n to provide; /// more precise answers to certain TTI queries, while letting the target; /// independent and default TTI implementations handle the rest.; ///; //===----------------------------------------------------------------------===//; /// About Cost Model numbers used below it's necessary to say the following:; /// the numbers correspond to some ""generic"" X86 CPU instead of usage of a; /// specific CPU model. Usually the numbers correspond to the CPU where the; /// feature first appeared. For example, if we do Subtarget.hasSSE42() in; /// the lookups below the cost is based on Nehalem as that was the first CPU; /// to support that feature level and thus has most likely the worst case cost,; /// although we may discard an outlying worst cost from one CPU (e.g. Atom).; ///; /// Some examples of other technologies/CPUs:; /// SSE 3 - Pentium4 / Athlon64; /// SSE 4.1 - Penryn; /// SSE 4.2 - Nehalem / Silvermont; /// AVX - Sandy Bridge / Jaguar / Bulldozer; /// AVX2 - Haswell / Ryzen; /// AVX-512 - Xeon Phi / Skylake; ///; /// And some examples of instruction target dependent costs (latency); /// divss sqrtss rsqrtss; /// AMD K7 11-16 19 3; /// Piledriver 9-24 13-15 5; /// Jaguar 14 16 2; /// Pentium II,III 18 30 2; /// Nehalem 7-14 7-18 3; /// Haswell 10-13 11 5; ///; /// Interpreting the 4 TargetCostKind types:; /// TCK_RecipThroughput and TCK_Latency should try to match the worst case; /// values reported by the CPU scheduler models (and llvm-mca).; /// TCK_CodeSize should match the instruction count (e.g. divss = 1), NOT the; /// actual encoding size of the instruction.; /// TCK_SizeAndLatency should match the worst case micro-op counts reported by; /// by the CPU scheduler models (and llvm-mca), to ensure that they are; /// compatible with the MicroOpBufferSize and LoopMicroOpBufferSize values which are; /// often used as the cost thresholds where TCK_SizeAndLatency is requested.; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:1473,Integrability,Bridg,Bridge,1473,"n to provide; /// more precise answers to certain TTI queries, while letting the target; /// independent and default TTI implementations handle the rest.; ///; //===----------------------------------------------------------------------===//; /// About Cost Model numbers used below it's necessary to say the following:; /// the numbers correspond to some ""generic"" X86 CPU instead of usage of a; /// specific CPU model. Usually the numbers correspond to the CPU where the; /// feature first appeared. For example, if we do Subtarget.hasSSE42() in; /// the lookups below the cost is based on Nehalem as that was the first CPU; /// to support that feature level and thus has most likely the worst case cost,; /// although we may discard an outlying worst cost from one CPU (e.g. Atom).; ///; /// Some examples of other technologies/CPUs:; /// SSE 3 - Pentium4 / Athlon64; /// SSE 4.1 - Penryn; /// SSE 4.2 - Nehalem / Silvermont; /// AVX - Sandy Bridge / Jaguar / Bulldozer; /// AVX2 - Haswell / Ryzen; /// AVX-512 - Xeon Phi / Skylake; ///; /// And some examples of instruction target dependent costs (latency); /// divss sqrtss rsqrtss; /// AMD K7 11-16 19 3; /// Piledriver 9-24 13-15 5; /// Jaguar 14 16 2; /// Pentium II,III 18 30 2; /// Nehalem 7-14 7-18 3; /// Haswell 10-13 11 5; ///; /// Interpreting the 4 TargetCostKind types:; /// TCK_RecipThroughput and TCK_Latency should try to match the worst case; /// values reported by the CPU scheduler models (and llvm-mca).; /// TCK_CodeSize should match the instruction count (e.g. divss = 1), NOT the; /// actual encoding size of the instruction.; /// TCK_SizeAndLatency should match the worst case micro-op counts reported by; /// by the CPU scheduler models (and llvm-mca), to ensure that they are; /// compatible with the MicroOpBufferSize and LoopMicroOpBufferSize values which are; /// often used as the cost thresholds where TCK_SizeAndLatency is requested.; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:1613,Integrability,depend,dependent,1613,"n to provide; /// more precise answers to certain TTI queries, while letting the target; /// independent and default TTI implementations handle the rest.; ///; //===----------------------------------------------------------------------===//; /// About Cost Model numbers used below it's necessary to say the following:; /// the numbers correspond to some ""generic"" X86 CPU instead of usage of a; /// specific CPU model. Usually the numbers correspond to the CPU where the; /// feature first appeared. For example, if we do Subtarget.hasSSE42() in; /// the lookups below the cost is based on Nehalem as that was the first CPU; /// to support that feature level and thus has most likely the worst case cost,; /// although we may discard an outlying worst cost from one CPU (e.g. Atom).; ///; /// Some examples of other technologies/CPUs:; /// SSE 3 - Pentium4 / Athlon64; /// SSE 4.1 - Penryn; /// SSE 4.2 - Nehalem / Silvermont; /// AVX - Sandy Bridge / Jaguar / Bulldozer; /// AVX2 - Haswell / Ryzen; /// AVX-512 - Xeon Phi / Skylake; ///; /// And some examples of instruction target dependent costs (latency); /// divss sqrtss rsqrtss; /// AMD K7 11-16 19 3; /// Piledriver 9-24 13-15 5; /// Jaguar 14 16 2; /// Pentium II,III 18 30 2; /// Nehalem 7-14 7-18 3; /// Haswell 10-13 11 5; ///; /// Interpreting the 4 TargetCostKind types:; /// TCK_RecipThroughput and TCK_Latency should try to match the worst case; /// values reported by the CPU scheduler models (and llvm-mca).; /// TCK_CodeSize should match the instruction count (e.g. divss = 1), NOT the; /// actual encoding size of the instruction.; /// TCK_SizeAndLatency should match the worst case micro-op counts reported by; /// by the CPU scheduler models (and llvm-mca), to ensure that they are; /// compatible with the MicroOpBufferSize and LoopMicroOpBufferSize values which are; /// often used as the cost thresholds where TCK_SizeAndLatency is requested.; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:1630,Performance,latency,latency,1630,"n to provide; /// more precise answers to certain TTI queries, while letting the target; /// independent and default TTI implementations handle the rest.; ///; //===----------------------------------------------------------------------===//; /// About Cost Model numbers used below it's necessary to say the following:; /// the numbers correspond to some ""generic"" X86 CPU instead of usage of a; /// specific CPU model. Usually the numbers correspond to the CPU where the; /// feature first appeared. For example, if we do Subtarget.hasSSE42() in; /// the lookups below the cost is based on Nehalem as that was the first CPU; /// to support that feature level and thus has most likely the worst case cost,; /// although we may discard an outlying worst cost from one CPU (e.g. Atom).; ///; /// Some examples of other technologies/CPUs:; /// SSE 3 - Pentium4 / Athlon64; /// SSE 4.1 - Penryn; /// SSE 4.2 - Nehalem / Silvermont; /// AVX - Sandy Bridge / Jaguar / Bulldozer; /// AVX2 - Haswell / Ryzen; /// AVX-512 - Xeon Phi / Skylake; ///; /// And some examples of instruction target dependent costs (latency); /// divss sqrtss rsqrtss; /// AMD K7 11-16 19 3; /// Piledriver 9-24 13-15 5; /// Jaguar 14 16 2; /// Pentium II,III 18 30 2; /// Nehalem 7-14 7-18 3; /// Haswell 10-13 11 5; ///; /// Interpreting the 4 TargetCostKind types:; /// TCK_RecipThroughput and TCK_Latency should try to match the worst case; /// values reported by the CPU scheduler models (and llvm-mca).; /// TCK_CodeSize should match the instruction count (e.g. divss = 1), NOT the; /// actual encoding size of the instruction.; /// TCK_SizeAndLatency should match the worst case micro-op counts reported by; /// by the CPU scheduler models (and llvm-mca), to ensure that they are; /// compatible with the MicroOpBufferSize and LoopMicroOpBufferSize values which are; /// often used as the cost thresholds where TCK_SizeAndLatency is requested.; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:218,Security,access,access,218,//===----------------------------------------------------------------------===//; //; // X86 cost model.; //; //===----------------------------------------------------------------------===//; // Helper struct to store/access costs for each cost kind.; // TODO: Move this to allow other targets to use it?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Integrability,Bridg,Bridge,53,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:70,Integrability,Bridg,Bridge,70,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Integrability,Bridg,Bridge,53,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:70,Integrability,Bridg,Bridge,70,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Integrability,Bridg,Bridge,53,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:70,Integrability,Bridg,Bridge,70,// - Penryn; // - Nehalem; // - Westmere; // - Sandy Bridge; // - Ivy Bridge; // - Haswell; // - Broadwell; // - Skylake; // - Kabylake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:61,Deployability,pipeline,pipelined,61,// Sandybridge and Haswell have multiple execution ports and pipelined; // vector units.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:104,Energy Efficiency,efficient,efficiently,104,// vXi8 multiplications are always promoted to vXi16.; // Sub-128-bit types can be extended/packed more efficiently.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:83,Modifiability,extend,extended,83,// vXi8 multiplications are always promoted to vXi16.; // Sub-128-bit types can be extended/packed more efficiently.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:81,Modifiability,extend,extended,81,"// If both vXi32 are representable as i15 and at least one is constant,; // zero-extended, or sign-extended from vXi16 (or less pre-SSE41) then we; // can treat this as PMADDWD which has the same costs as a vXi16 multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:99,Modifiability,extend,extended,99,"// If both vXi32 are representable as i15 and at least one is constant,; // zero-extended, or sign-extended from vXi16 (or less pre-SSE41) then we; // can treat this as PMADDWD which has the same costs as a vXi16 multiply.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:109,Energy Efficiency,reduce,reduceVMULWidth,109,// Check if the vXi32 operands can be shrunk into a smaller datatype.; // This should match the codegen from reduceVMULWidth.; // TODO: Make this generic (!ST->SSE41 || ST->isPMULLDSlow()).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:66,Performance,perform,perform,66,"// If both vXi64 are representable as (unsigned) i32, then we can perform; // the multiple with a single PMULUDQ instruction.; // TODO: Add (SSE41+) PMULDQ handling for signed extensions.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:35,Usability,simpl,simplified,35,// Vector multiply by pow2 will be simplified to shifts.; // Vector multiply by -pow2 will be simplified to shifts/negates.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:94,Usability,simpl,simplified,94,// Vector multiply by pow2 will be simplified to shifts.; // Vector multiply by -pow2 will be simplified to shifts/negates.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:47,Energy Efficiency,power,power-of-two,47,"// On X86, vector signed division by constants power-of-two are; // normally expanded to the sequence SRA + SRL + ADD + SRA.; // The OperandValue properties may not be the same as that of the previous; // operation; conservatively assume OP_None.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:67,Availability,mask,masks,67,// Vector unsigned division/remainder will be simplified to shifts/masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:46,Usability,simpl,simplified,46,// Vector unsigned division/remainder will be simplified to shifts/masks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsllvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsravw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsllvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsravw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsllvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsravw/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:5,Modifiability,extend,extend,5,// 2*extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:5,Modifiability,extend,extend,5,// 2*extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:5,Modifiability,extend,extend,5,// 2*extend/vpsravd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:90,Safety,detect,detect,90,// Shifts on vXi64/vXi32 on AVX2 is legal even though we declare to; // customize them to detect the cases where shift amount is a scalar one.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:131,Performance,throughput,throughput,131,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:156,Performance,throughput,throughput,156,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:190,Performance,throughput,throughput,190,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:215,Performance,throughput,throughput,215,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:243,Performance,throughput,throughput,243,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:17,Performance,throughput,throughput,17,// slm addq\subq throughput is 4,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsrlvd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsravd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/vpsravd/pack sequence.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend/pmullw/pack,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:135,Availability,mask,mask,135,"// Try to perform better estimation of the permutation.; // 1. Split the source/destination vectors into real registers.; // 2. Do the mask analysis to identify which real registers are; // permuted. If more than 1 source registers are used for the; // destination register building, the cost for this destination register; // is (Number_of_source_register - 1) * Cost_PermuteTwoSrc. If only one; // source register is used, build mask and calculate the cost as a cost; // of PermuteSingleSrc.; // Also, for the single register permute we try to identify if the; // destination register is just a copy of the source register or the; // copy of the previous destination register (the cost is; // TTI::TCC_Basic). If the source register is just reused, the cost for; // this operation is 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:431,Availability,mask,mask,431,"// Try to perform better estimation of the permutation.; // 1. Split the source/destination vectors into real registers.; // 2. Do the mask analysis to identify which real registers are; // permuted. If more than 1 source registers are used for the; // destination register building, the cost for this destination register; // is (Number_of_source_register - 1) * Cost_PermuteTwoSrc. If only one; // source register is used, build mask and calculate the cost as a cost; // of PermuteSingleSrc.; // Also, for the single register permute we try to identify if the; // destination register is just a copy of the source register or the; // copy of the previous destination register (the cost is; // TTI::TCC_Basic). If the source register is just reused, the cost for; // this operation is 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:10,Performance,perform,perform,10,"// Try to perform better estimation of the permutation.; // 1. Split the source/destination vectors into real registers.; // 2. Do the mask analysis to identify which real registers are; // permuted. If more than 1 source registers are used for the; // destination register building, the cost for this destination register; // is (Number_of_source_register - 1) * Cost_PermuteTwoSrc. If only one; // source register is used, build mask and calculate the cost as a cost; // of PermuteSingleSrc.; // Also, for the single register permute we try to identify if the; // destination register is just a copy of the source register or the; // copy of the previous destination register (the cost is; // TTI::TCC_Basic). If the source register is just reused, the cost for; // this operation is 0.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend to v32i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:19,Performance,throughput,throughput,19,// TODO: Allow non-throughput costs that aren't binary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:123,Testability,test,test,123,"// The cost tables include both specific, custom (non-legal) src/dst type; // conversions and generic, legalized types. We test for customs first, before; // falling back to legalization.; // FIXME: Need a better design of the cost table to handle non-simple types of; // potential massive combinations (elem_num x src_type x dst_type).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:252,Usability,simpl,simple,252,"// The cost tables include both specific, custom (non-legal) src/dst type; // conversions and generic, legalized types. We test for customs first, before; // falling back to legalization.; // FIXME: Need a better design of the cost table to handle non-simple types of; // potential massive combinations (elem_num x src_type x dst_type).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Modifiability,extend,extend,3,// extend to v16i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:8,Modifiability,extend,extend,8,// Sign extend is zmm vpternlogd+vptruncdb.; // Zero extend is zmm broadcast load+vptruncdw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Modifiability,extend,extend,53,// Sign extend is zmm vpternlogd+vptruncdb.; // Zero extend is zmm broadcast load+vptruncdw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:77,Performance,load,load,77,// Sign extend is zmm vpternlogd+vptruncdb.; // Zero extend is zmm broadcast load+vptruncdw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:8,Modifiability,extend,extend,8,// Sign extend is zmm vpternlogd+vptruncdw.; // Zero extend is zmm vpternlogd+vptruncdw+vpsrlw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Modifiability,extend,extend,53,// Sign extend is zmm vpternlogd+vptruncdw.; // Zero extend is zmm vpternlogd+vptruncdw+vpsrlw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask sign extend has an instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Availability,Mask,Mask,3,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Modifiability,extend,extend,13,// Mask zero extend is a sext + shift.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:38,Availability,mask,maskedmove,38,// vpmovwb; // sign extend is vpcmpeq+maskedmove+vpmovdw+vpacksswb; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw+vpackuswb,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:94,Availability,mask,maskedmove,94,// vpmovwb; // sign extend is vpcmpeq+maskedmove+vpmovdw+vpacksswb; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw+vpackuswb,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:20,Modifiability,extend,extend,20,// vpmovwb; // sign extend is vpcmpeq+maskedmove+vpmovdw+vpacksswb; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw+vpackuswb,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:76,Modifiability,extend,extend,76,// vpmovwb; // sign extend is vpcmpeq+maskedmove+vpmovdw+vpacksswb; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw+vpackuswb,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:26,Availability,mask,maskedmove,26,// sign extend is vpcmpeq+maskedmove+vpmovdw; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:72,Availability,mask,maskedmove,72,// sign extend is vpcmpeq+maskedmove+vpmovdw; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:8,Modifiability,extend,extend,8,// sign extend is vpcmpeq+maskedmove+vpmovdw; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:54,Modifiability,extend,extend,54,// sign extend is vpcmpeq+maskedmove+vpmovdw; // zero extend is vpcmpeq+maskedmove+vpmovdw+vpsrlw,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:112,Energy Efficiency,schedul,scheduler,112,// These are somewhat magic numbers justified by comparing the; // output of llvm-mca for our various supported scheduler models; // and basing it off the worst case scenario.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:31,Usability,simpl,simple,31,// Attempt to map directly to (simple) MVT types to let us match custom entries.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:41,Usability,simpl,simple,41,// The function getSimpleVT only handles simple value types.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:55,Modifiability,extend,extend,55,"// Fallback, for i8/i16 sitofp/uitofp cases we need to extend to i32 for; // sitofp.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:24,Modifiability,extend,extend,24,// For scalar loads the extend would be free.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:14,Performance,load,loads,14,// For scalar loads the extend would be free.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:134,Energy Efficiency,reduce,reduce,134,// Some vector comparison predicates cost extra instructions.; // TODO: Should we invert this and assume worst case cmp costs; // and reduce for particular predicates?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:21,Performance,throughput,throughput,21,// slm pcmpeq/pcmpgt throughput is 2,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,Performance,throughput,throughput,34,// slm pblendvb/blendvpd/blendvps throughput is 4,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:16,Performance,latency,latency,16,// Assume a 3cy latency for fp select ops.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:61,Testability,test,test,61,"// Costs should match the codegen from:; // BITREVERSE: llvm\test\CodeGen\X86\vector-bitreverse.ll; // BSWAP: llvm\test\CodeGen\X86\bswap-vector.ll; // CTLZ: llvm\test\CodeGen\X86\vector-lzcnt-*.ll; // CTPOP: llvm\test\CodeGen\X86\vector-popcnt-*.ll; // CTTZ: llvm\test\CodeGen\X86\vector-tzcnt-*.ll; // TODO: Overflow intrinsics (*ADDO, *SUBO, *MULO) with vector types are not; // specialized in these tables yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:115,Testability,test,test,115,"// Costs should match the codegen from:; // BITREVERSE: llvm\test\CodeGen\X86\vector-bitreverse.ll; // BSWAP: llvm\test\CodeGen\X86\bswap-vector.ll; // CTLZ: llvm\test\CodeGen\X86\vector-lzcnt-*.ll; // CTPOP: llvm\test\CodeGen\X86\vector-popcnt-*.ll; // CTTZ: llvm\test\CodeGen\X86\vector-tzcnt-*.ll; // TODO: Overflow intrinsics (*ADDO, *SUBO, *MULO) with vector types are not; // specialized in these tables yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:163,Testability,test,test,163,"// Costs should match the codegen from:; // BITREVERSE: llvm\test\CodeGen\X86\vector-bitreverse.ll; // BSWAP: llvm\test\CodeGen\X86\bswap-vector.ll; // CTLZ: llvm\test\CodeGen\X86\vector-lzcnt-*.ll; // CTPOP: llvm\test\CodeGen\X86\vector-popcnt-*.ll; // CTTZ: llvm\test\CodeGen\X86\vector-tzcnt-*.ll; // TODO: Overflow intrinsics (*ADDO, *SUBO, *MULO) with vector types are not; // specialized in these tables yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:214,Testability,test,test,214,"// Costs should match the codegen from:; // BITREVERSE: llvm\test\CodeGen\X86\vector-bitreverse.ll; // BSWAP: llvm\test\CodeGen\X86\bswap-vector.ll; // CTLZ: llvm\test\CodeGen\X86\vector-lzcnt-*.ll; // CTPOP: llvm\test\CodeGen\X86\vector-popcnt-*.ll; // CTTZ: llvm\test\CodeGen\X86\vector-tzcnt-*.ll; // TODO: Overflow intrinsics (*ADDO, *SUBO, *MULO) with vector types are not; // specialized in these tables yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:265,Testability,test,test,265,"// Costs should match the codegen from:; // BITREVERSE: llvm\test\CodeGen\X86\vector-bitreverse.ll; // BSWAP: llvm\test\CodeGen\X86\bswap-vector.ll; // CTLZ: llvm\test\CodeGen\X86\vector-lzcnt-*.ll; // CTPOP: llvm\test\CodeGen\X86\vector-popcnt-*.ll; // CTTZ: llvm\test\CodeGen\X86\vector-tzcnt-*.ll; // TODO: Overflow intrinsics (*ADDO, *SUBO, *MULO) with vector types are not; // specialized in these tables yet.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Testability,TEST,TEST,3,// TEST+BSF+CMOV/BRANCH,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Testability,TEST,TEST,3,// TEST+BSF+CMOV/BRANCH,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Testability,TEST,TEST,3,// TEST+BSF+CMOV/BRANCH,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Testability,TEST,TEST,3,// TEST+BSF+CMOV/BRANCH,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Energy Efficiency,reduce,reduced,53,"// If there are no NANs to deal with, then these are reduced to a; // single MIN** or MAX** instruction instead of the MIN/CMP/SELECT that we; // assume is used in the non-fast case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:82,Performance,load,loads,82,// Non-immediate extraction/insertion can be handled as a sequence of; // aliased loads+stores via the stack.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:36,Performance,load,load,36,"// Extract - store vector to stack, load scalar.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:49,Performance,load,load,49,"// Insert - store vector to stack, store scalar, load vector.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:39,Energy Efficiency,efficient,efficiently,39,// Extraction of vXi1 elements are now efficiently handled by MOVMSK.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:308,Energy Efficiency,reduce,reduce,308,"// For extractions we just need to shuffle the element to index 0, which; // should be very cheap (assume cost = 1). For insertions we need to shuffle; // the elements to its destination. In both cases we must handle the; // subvector move(s).; // If the vector type is already less than 128-bits then don't reduce it.; // TODO: Under what circumstances should we shuffle using the full width?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:53,Modifiability,extend,extended,53,"// Get the smaller of the legalized or original pow2-extended number of; // vector elements, which represents the number of unpacks we'll end up; // performing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:149,Performance,perform,performing,149,"// Get the smaller of the legalized or original pow2-extended number of; // vector elements, which represents the number of unpacks we'll end up; // performing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:77,Availability,mask,mask,77,// vXi1 can be efficiently extracted with MOVMSK.; // TODO: AVX512 predicate mask handling.; // NOTE: This doesn't work well for roundtrip scalarization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:15,Energy Efficiency,efficient,efficiently,15,// vXi1 can be efficiently extracted with MOVMSK.; // TODO: AVX512 predicate mask handling.; // NOTE: This doesn't work well for roundtrip scalarization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:17,Performance,perform,perform,17,"// If we have to perform the shuffle with wider elt type than our data type,; // then we will first need to anyext (we don't care about the new bits); // the source elements, and then truncate Dst elements.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:2,Availability,Mask,Mask,2,/*Mask=*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:27,Performance,load,load,27,// Add a cost for constant load to vector.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:14,Usability,simpl,simple,14,// Handle the simple case of non-vectors.; // NOTE: this assumes that legalization never creates vector from scalars!,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:8,Performance,load,load,8,// Each load/store unit costs 1.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:126,Performance,load,load,126,"// Can we use this vector size, as per the remaining element count?; // Iff the vector is naturally aligned, we can do a wide load regardless.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:25,Performance,load,load,25,"// While we can directly load/store ZMM, YMM, and 64-bit halves of XMM,; // for smaller widths (32/16/8) we have to insert/extract them separately.; // Again, it's free for the 0'th subreg (if op is 32/64 bit wide,; // but let's pretend that it is also true for 16/8 bit wide ops...)",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:119,Integrability,interface,interface,119,// This isn't exactly right. We're using slow unaligned 32-byte accesses; // as a proxy for a double-pumped AVX memory interface such as on; // Sandybridge.; // Sub-32-bit loads/stores will be slower either with PINSR*/PEXTR* or; // will be scalarized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:172,Performance,load,loads,172,// This isn't exactly right. We're using slow unaligned 32-byte accesses; // as a proxy for a double-pumped AVX memory interface such as on; // Sandybridge.; // Sub-32-bit loads/stores will be slower either with PINSR*/PEXTR* or; // will be scalarized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:64,Security,access,accesses,64,// This isn't exactly right. We're using slow unaligned 32-byte accesses; // as a proxy for a double-pumped AVX memory interface such as on; // Sandybridge.; // Sub-32-bit loads/stores will be slower either with PINSR*/PEXTR* or; // will be scalarized.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:54,Availability,mask,mask,54,"// To calculate scalar take the regular cost, without mask",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:65,Availability,mask,mask,65,// Promotion requires extend/truncate for data and a shuffle for mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:22,Modifiability,extend,extend,22,// Promotion requires extend/truncate for data and a shuffle for mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:27,Availability,mask,mask,27,// Expanding requires fill mask with zeroes,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:21,Availability,mask,maskmov,21,// Pre-AVX512 - each maskmov load costs 2 + store costs ~8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:29,Performance,load,load,29,// Pre-AVX512 - each maskmov load costs 2 + store costs ~8.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:11,Availability,mask,masked,11,// AVX-512 masked load/store is cheaper,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:18,Performance,load,load,18,// AVX-512 masked load/store is cheaper,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:275,Performance,throughput,throughput,275,// Address computations in vectorized code with non-consecutive addresses will; // likely result in more instructions compared to scalar code where the; // computation can more often be merged into the index mode. The resulting; // extra micro-ops can significantly decrease throughput.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:28,Security,Access,Access,28,"// Cost modeling of Strided Access Computation is hidden by the indexing; // modes of X86 regardless of the stride value. We dont believe that there; // is a difference between constant strided access in gerenal and constant; // strided value which is less than or equal to 64.; // Even in the case of (loop invariant) stride whose value is not known at; // compile time, the address computation will not incur more than one extra; // ADD instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:194,Security,access,access,194,"// Cost modeling of Strided Access Computation is hidden by the indexing; // modes of X86 regardless of the stride value. We dont believe that there; // is a difference between constant strided access in gerenal and constant; // strided value which is less than or equal to 64.; // Even in the case of (loop invariant) stride whose value is not known at; // compile time, the address computation will not incur more than one extra; // ADD instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:68,Performance,throughput,throughput,68,// We use the Intel Architecture Code Analyzer(IACA) to measure the throughput; // and make it as the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:41,Performance,perform,performed,41,// Special case: vXi8 mul reductions are performed as vXi16.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:16,Energy Efficiency,power,power,16,// Special case power of 2 reductions where the scalar type isn't changed; // by type legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:57,Energy Efficiency,reduce,reduce,57,// Determine the size of the remaining vector we need to reduce.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:68,Performance,throughput,throughput,68,// We use the Intel Architecture Code Analyzer(IACA) to measure the throughput; // and make it as the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:16,Energy Efficiency,power,power,16,// Special case power of 2 reductions where the scalar type isn't changed; // by type legalization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:57,Energy Efficiency,reduce,reduce,57,// Determine the size of the remaining vector we need to reduce.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:105,Testability,assert,assertions,105,"// Never hoist constants larger than 128bit, because this might lead to; // incorrect code generation or assertions in codegen.; // Fixme: Create a cost model for types larger than i128 once the codegen; // issues have been fixed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:8,Modifiability,extend,extend,8,// Sign-extend all constants to a multiple of 64-bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:159,Performance,optimiz,optimize,159,// This is an imperfect hack to prevent constant hoisting of; // compares that might be trying to check if a 64-bit value fits in; // 32-bits. The backend can optimize these cases using a right shift by 32.; // Ideally we would check the compare predicate here. There also other; // similar immediates the backend can use shifts for.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:212,Modifiability,extend,extended,212,// We support 64-bit ANDs with immediates with 32-bits of leading zeroes; // by using a 32-bit operation with implicit zero extension. Detect such; // immediates here as the normal path expects bit 31 to be sign extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:135,Safety,Detect,Detect,135,// We support 64-bit ANDs with immediates with 32-bits of leading zeroes; // by using a 32-bit operation with implicit zero extension. Detect such; // immediates here as the normal path expects bit 31 to be sign extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:30,Safety,predict,predicted,30,// Branches are assumed to be predicted.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:90,Performance,Load,Load,90,"// Some CPUs have more overhead for gather. The specified overhead is relative; // to the Load operation. ""2"" is the number provided by Intel architects. This; // parameter is used for cost estimation of Gather Op and comparison with; // other alternatives.; // TODO: Remove the explicit hasAVX512()?, That would mean we would only; // enable gather with a -march.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:10,Energy Efficiency,reduce,reduce,10,"// Try to reduce index size from 64 bit (default for GEP); // to 32. It is essential for VF 16. If the index can't be reduced to 32, the; // operation will use 16 x 64 indices which do not fit in a zmm and needs; // to split. Also check that the base pointer is the same for all lanes,; // and that there's at most one variable index.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:118,Energy Efficiency,reduce,reduced,118,"// Try to reduce index size from 64 bit (default for GEP); // to 32. It is essential for VF 16. If the index can't be reduced to 32, the; // operation will use 16 x 64 indices which do not fit in a zmm and needs; // to split. Also check that the base pointer is the same for all lanes,; // and that there's at most one variable index.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:319,Modifiability,variab,variable,319,"// Try to reduce index size from 64 bit (default for GEP); // to 32. It is essential for VF 16. If the index can't be reduced to 32, the; // operation will use 16 x 64 indices which do not fit in a zmm and needs; // to split. Also check that the base pointer is the same for all lanes,; // and that there's at most one variable index.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:13,Energy Efficiency,reduce,reduce,13,// Trying to reduce IndexSize to 32 bits for vector 16.; // By default the IndexSize is equal to pointer size.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:223,Availability,mask,mask,223,/// Return the cost of full scalarization of gather / scatter operation.; ///; /// Opcode - Load or Store instruction.; /// SrcVTy - The type of the data vector that should be gathered or scattered.; /// VariableMask - The mask is non-constant at compile time.; /// Alignment - Alignment for one element.; /// AddressSpace - pointer[s] address space.; ///; /// FIXME: Add TargetCostKind support.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:204,Modifiability,Variab,VariableMask,204,/// Return the cost of full scalarization of gather / scatter operation.; ///; /// Opcode - Load or Store instruction.; /// SrcVTy - The type of the data vector that should be gathered or scattered.; /// VariableMask - The mask is non-constant at compile time.; /// Alignment - Alignment for one element.; /// AddressSpace - pointer[s] address space.; ///; /// FIXME: Add TargetCostKind support.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:92,Performance,Load,Load,92,/// Return the cost of full scalarization of gather / scatter operation.; ///; /// Opcode - Load or Store instruction.; /// SrcVTy - The type of the data vector that should be gathered or scattered.; /// VariableMask - The mask is non-constant at compile time.; /// Alignment - Alignment for one element.; /// AddressSpace - pointer[s] address space.; ///; /// FIXME: Add TargetCostKind support.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:26,Performance,load,loads,26,// The cost of the scalar loads/stores.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:39,Performance,load,loaded,39,// The cost of forming the vector from loaded scalars/; // scalarizing the vector to perform scalar stores.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:85,Performance,perform,perform,85,// The cost of forming the vector from loaded scalars/; // scalarizing the vector to perform scalar stores.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,Performance,load,loads,34,// The only supported nontemporal loads are for aligned vectors of 16 or 32; // bytes. Note that 32-byte nontemporal vector loads are supported by AVX2; // (the equivalent stores only require AVX).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:124,Performance,load,loads,124,// The only supported nontemporal loads are for aligned vectors of 16 or 32; // bytes. Note that 32-byte nontemporal vector loads are supported by AVX2; // (the equivalent stores only require AVX).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:76,Availability,avail,available,76,"// Besides the SSE4A subtarget exception above, only aligned stores are; // available nontemporaly on any other subtarget. And only stores with a size; // of 4..32 bytes (powers of 2, only) are permitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:171,Energy Efficiency,power,powers,171,"// Besides the SSE4A subtarget exception above, only aligned stores are; // available nontemporaly on any other subtarget. And only stores with a size; // of 4..32 bytes (powers of 2, only) are permitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:78,Performance,load,loads,78,// 32-byte vector nontemporal stores are supported by AVX (the equivalent; // loads require AVX2).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:32,Performance,perform,performance,32,"// Some CPUs have better gather performance than others.; // TODO: Remove the explicit ST->hasAVX512()?, That would mean we would only; // enable gather with a -march.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:196,Availability,mask,mask,196,"// Gather / Scatter for vector 2 is not profitable on KNL / SKX; // Vector-4 of gather/scatter instruction does not exist on KNL. We can extend; // it to 8 elements, but zeroing upper bits of the mask vector will add more; // instructions. Right now we give the scalar cost of vector-4 for KNL. TODO:; // Check, maybe the gather/scatter instruction is better in the VariableMask; // case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:137,Modifiability,extend,extend,137,"// Gather / Scatter for vector 2 is not profitable on KNL / SKX; // Vector-4 of gather/scatter instruction does not exist on KNL. We can extend; // it to 8 elements, but zeroing upper bits of the mask vector will add more; // instructions. Right now we give the scalar cost of vector-4 for KNL. TODO:; // Check, maybe the gather/scatter instruction is better in the VariableMask; // case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:366,Modifiability,Variab,VariableMask,366,"// Gather / Scatter for vector 2 is not profitable on KNL / SKX; // Vector-4 of gather/scatter instruction does not exist on KNL. We can extend; // it to 8 elements, but zeroing upper bits of the mask vector will add more; // instructions. Right now we give the scalar cost of vector-4 for KNL. TODO:; // Check, maybe the gather/scatter instruction is better in the VariableMask; // case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:42,Availability,mask,mask,42,// Check the opcode pattern. We apply the mask on the opcode arguments and; // then check if it is what we expect.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:117,Performance,latency,latency,117,"// FDIV is always expensive, even if it has a very low uop count.; // TODO: Still necessary for recent CPUs with low latency/throughput fdiv?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:125,Performance,throughput,throughput,125,"// FDIV is always expensive, even if it has a very low uop count.; // TODO: Still necessary for recent CPUs with low latency/throughput fdiv?",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Usability,Simpl,Simple,3,// Simple types are always ABI compatible.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:22,Performance,load,loads,22,// All GPR and vector loads can be unaligned.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:22,Performance,load,loads,22,// Only enable vector loads for equality comparison. Right now the vector; // version is not as fast for three way compare (see #33329).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:106,Performance,perform,performance,106,"// TODO: We expect this to be beneficial regardless of arch,; // but there are currently some unexplained performance artifacts on Atom.; // As a temporary solution, disable on Atom.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:223,Energy Efficiency,reduce,reduces,223,// Get estimation for interleaved load/store operations and strided load.; // \p Indices contains indices for strided load.; // \p Factor - the factor of interleaving.; // AVX-512 provides 3-src shuffles that significantly reduces the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,Performance,load,load,34,// Get estimation for interleaved load/store operations and strided load.; // \p Indices contains indices for strided load.; // \p Factor - the factor of interleaving.; // AVX-512 provides 3-src shuffles that significantly reduces the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:68,Performance,load,load,68,// Get estimation for interleaved load/store operations and strided load.; // \p Indices contains indices for strided load.; // \p Factor - the factor of interleaving.; // AVX-512 provides 3-src shuffles that significantly reduces the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:118,Performance,load,load,118,// Get estimation for interleaved load/store operations and strided load.; // \p Indices contains indices for strided load.; // \p Factor - the factor of interleaving.; // AVX-512 provides 3-src shuffles that significantly reduces the cost.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:222,Performance,load,load,222,"// VecTy for interleave memop is <VF*Factor x Elt>.; // So, for VF=4, Interleave Factor = 3, Element type = i32 we have; // VecTy = <12 x i32>.; // Calculate the number of memory operations (NumOfMemOps), required; // for load/store the VecTy.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:12,Availability,mask,mask,12,"// The Gaps mask is invariant and created outside the loop, therefore the; // cost of creating it is not accounted for here. However if we have both; // a MaskForGaps and some other mask that guards the execution of the; // memory access, we need to account for the cost of And-ing the two masks; // inside the loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:155,Availability,Mask,MaskForGaps,155,"// The Gaps mask is invariant and created outside the loop, therefore the; // cost of creating it is not accounted for here. However if we have both; // a MaskForGaps and some other mask that guards the execution of the; // memory access, we need to account for the cost of And-ing the two masks; // inside the loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:182,Availability,mask,mask,182,"// The Gaps mask is invariant and created outside the loop, therefore the; // cost of creating it is not accounted for here. However if we have both; // a MaskForGaps and some other mask that guards the execution of the; // memory access, we need to account for the cost of And-ing the two masks; // inside the loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:290,Availability,mask,masks,290,"// The Gaps mask is invariant and created outside the loop, therefore the; // cost of creating it is not accounted for here. However if we have both; // a MaskForGaps and some other mask that guards the execution of the; // memory access, we need to account for the cost of And-ing the two masks; // inside the loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:231,Security,access,access,231,"// The Gaps mask is invariant and created outside the loop, therefore the; // cost of creating it is not accounted for here. However if we have both; // a MaskForGaps and some other mask that guards the execution of the; // memory access, we need to account for the cost of And-ing the two masks; // inside the loop.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:99,Performance,optimiz,optimized,99,// The tables (AVX512InterleavedLoadTbl and AVX512InterleavedStoreTbl); // contain the cost of the optimized shuffle sequence that the; // X86InterleavedAccess pass will generate.; // The cost of loads and stores are computed separately from the table.; // X86InterleavedAccess support only the following interleaved-access group.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:196,Performance,load,loads,196,// The tables (AVX512InterleavedLoadTbl and AVX512InterleavedStoreTbl); // contain the cost of the optimized shuffle sequence that the; // X86InterleavedAccess pass will generate.; // The cost of loads and stores are computed separately from the table.; // X86InterleavedAccess support only the following interleaved-access group.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:317,Security,access,access,317,// The tables (AVX512InterleavedLoadTbl and AVX512InterleavedStoreTbl); // contain the cost of the optimized shuffle sequence that the; // X86InterleavedAccess pass will generate.; // The cost of loads and stores are computed separately from the table.; // X86InterleavedAccess support only the following interleaved-access group.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Performance,load,load,3,//(load 48i8 and) deinterleave into 3 x 16i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Performance,load,load,3,//(load 96i8 and) deinterleave into 3 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:3,Performance,load,load,3,//(load 96i8 and) deinterleave into 3 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:90,Integrability,depend,depends,90,"//If an entry does not exist, fallback to the default implementation.; // Kind of shuffle depends on number of loaded values.; // If we load the entire data in one register, we can use a 1-src shuffle.; // Otherwise, we'll merge 2 sources in each operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:111,Performance,load,loaded,111,"//If an entry does not exist, fallback to the default implementation.; // Kind of shuffle depends on number of loaded values.; // If we load the entire data in one register, we can use a 1-src shuffle.; // Otherwise, we'll merge 2 sources in each operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:136,Performance,load,load,136,"//If an entry does not exist, fallback to the default implementation.; // Kind of shuffle depends on number of loaded values.; // If we load the entire data in one register, we can use a 1-src shuffle.; // Otherwise, we'll merge 2 sources in each operation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:139,Availability,mask,masked,139,"// About a half of the loads may be folded in shuffles when we have only; // one result. If we have more than one result, or the loads are masked,; // we do not fold loads at all.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:23,Performance,load,loads,23,"// About a half of the loads may be folded in shuffles when we have only; // one result. If we have more than one result, or the loads are masked,; // we do not fold loads at all.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:129,Performance,load,loads,129,"// About a half of the loads may be folded in shuffles when we have only; // one result. If we have more than one result, or the loads are masked,; // we do not fold loads at all.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:166,Performance,load,loads,166,"// About a half of the loads may be folded in shuffles when we have only; // one result. If we have more than one result, or the loads are masked,; // we do not fold loads at all.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:63,Security,access,access,63,// X86InterleavedAccess support only the following interleaved-access group.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,Performance,load,load,34,"// Get estimation for interleaved load/store operations for SSE-AVX2.; // As opposed to AVX-512, SSE-AVX2 do not have generic shuffles that allow; // computing the cost using a generic formula as a function of generic; // shuffles. We therefore use a lookup table instead, filled according to; // the instruction sequences that codegen currently generates.; // VecTy for interleave memop is <VF*Factor x Elt>.; // So, for VF=4, Interleave Factor = 3, Element type = i32 we have; // VecTy = <12 x i32>.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:71,Performance,load,loads,71,// Get the cost of all the memory operations.; // FIXME: discount dead loads.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:306,Performance,load,loads,306,"// TODO: Complete for other data-types and strides.; // Each combination of Stride, element bit width and VF results in a different; // sequence; The cost tables are therefore accessed with:; // Factor (stride) and VectorType=VFxiN.; // The Cost accounts only for the shuffle sequence;; // The cost of the loads/stores is accounted for separately.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:176,Security,access,accessed,176,"// TODO: Complete for other data-types and strides.; // Each combination of Stride, element bit width and VF results in a different; // sequence; The cost tables are therefore accessed with:; // Factor (stride) and VectorType=VFxiN.; // The Cost accounts only for the shuffle sequence;; // The cost of the loads/stores is accounted for separately.; //",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 4i8 and) deinterleave into 2 x 2i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i8 and) deinterleave into 2 x 4i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i8 and) deinterleave into 2 x 8i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i8 and) deinterleave into 2 x 16i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i8 and) deinterleave into 2 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i16 and) deinterleave into 2 x 8i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i16 and) deinterleave into 2 x 16i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i16 and) deinterleave into 2 x 32i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i32 and) deinterleave into 2 x 8i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i32 and) deinterleave into 2 x 16i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i32 and) deinterleave into 2 x 32i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i64 and) deinterleave into 2 x 4i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i64 and) deinterleave into 2 x 8i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i64 and) deinterleave into 2 x 16i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i64 and) deinterleave into 2 x 32i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 6i8 and) deinterleave into 3 x 2i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i8 and) deinterleave into 3 x 4i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i8 and) deinterleave into 3 x 8i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i8 and) deinterleave into 3 x 16i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i8 and) deinterleave into 3 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 6i16 and) deinterleave into 3 x 2i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i16 and) deinterleave into 3 x 4i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i16 and) deinterleave into 3 x 8i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i16 and) deinterleave into 3 x 16i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i16 and) deinterleave into 3 x 32i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 6i32 and) deinterleave into 3 x 2i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i32 and) deinterleave into 3 x 4i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i32 and) deinterleave into 3 x 8i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i32 and) deinterleave into 3 x 16i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i32 and) deinterleave into 3 x 32i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 6i64 and) deinterleave into 3 x 2i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i64 and) deinterleave into 3 x 4i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i64 and) deinterleave into 3 x 8i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i64 and) deinterleave into 3 x 16i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i8 and) deinterleave into 4 x 2i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i8 and) deinterleave into 4 x 4i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i8 and) deinterleave into 4 x 8i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i8 and) deinterleave into 4 x 16i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 128i8 and) deinterleave into 4 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i16 and) deinterleave into 4 x 2i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i16 and) deinterleave into 4 x 4i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i16 and) deinterleave into 4 x 8i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i16 and) deinterleave into 4 x 16i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 128i16 and) deinterleave into 4 x 32i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i32 and) deinterleave into 4 x 2i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i32 and) deinterleave into 4 x 4i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i32 and) deinterleave into 4 x 8i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i32 and) deinterleave into 4 x 16i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 128i32 and) deinterleave into 4 x 32i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i64 and) deinterleave into 4 x 2i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 16i64 and) deinterleave into 4 x 4i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 32i64 and) deinterleave into 4 x 8i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i64 and) deinterleave into 4 x 16i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i8 and) deinterleave into 6 x 2i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i8 and) deinterleave into 6 x 4i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i8 and) deinterleave into 6 x 8i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i8 and) deinterleave into 6 x 16i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 192i8 and) deinterleave into 6 x 32i8,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i16 and) deinterleave into 6 x 2i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i16 and) deinterleave into 6 x 4i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i16 and) deinterleave into 6 x 8i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i16 and) deinterleave into 6 x 16i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 192i16 and) deinterleave into 6 x 32i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i32 and) deinterleave into 6 x 2i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i32 and) deinterleave into 6 x 4i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i32 and) deinterleave into 6 x 8i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 96i32 and) deinterleave into 6 x 16i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 12i64 and) deinterleave into 6 x 2i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 24i64 and) deinterleave into 6 x 4i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 48i64 and) deinterleave into 6 x 8i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 64i32 and) deinterleave into 8 x 8i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i16 and) deinterleave into 2 x 4i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 4i16 and) deinterleave into 2 x 2i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i16 and) deinterleave into 2 x 4i16,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 4i32 and) deinterleave into 2 x 2i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 8i32 and) deinterleave into 2 x 4i32,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:4,Performance,load,load,4,// (load 4i64 and) deinterleave into 2 x 2i64,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:313,Performance,load,load,313,"// Scaling factors are not free at all.; // An indexed folded instruction, i.e., inst (reg1, reg2, scale),; // will take 2 allocations in the out of order engine instead of 1; // for plain addressing mode, i.e. inst (reg1).; // E.g.,; // vaddps (%rsi,%rdx), %ymm0, %ymm1; // Requires two allocations (one for the load, one for the computation); // whereas:; // vaddps (%rsi), %ymm0, %ymm1; // Requires just 1 allocation, i.e., freeing allocations for other operations; // and having less micro operations to execute.; //; // For some X86 architectures, this is even worse because for instance for; // stores, the complex addressing mode forces the instruction to use the; // ""load"" ports instead of the dedicated ""store"" port.; // E.g., on Haswell:; // vmovaps %ymm1, (%r8, %rdi) can use port 2 or 3.; // vmovaps %ymm1, (%r8) can use port 2, 3, or 7.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:676,Performance,load,load,676,"// Scaling factors are not free at all.; // An indexed folded instruction, i.e., inst (reg1, reg2, scale),; // will take 2 allocations in the out of order engine instead of 1; // for plain addressing mode, i.e. inst (reg1).; // E.g.,; // vaddps (%rsi,%rdx), %ymm0, %ymm1; // Requires two allocations (one for the load, one for the computation); // whereas:; // vaddps (%rsi), %ymm0, %ymm1; // Requires just 1 allocation, i.e., freeing allocations for other operations; // and having less micro operations to execute.; //; // For some X86 architectures, this is even worse because for instance for; // stores, the complex addressing mode forces the instruction to use the; // ""load"" ports instead of the dedicated ""store"" port.; // E.g., on Haswell:; // vmovaps %ymm1, (%r8, %rdi) can use port 2 or 3.; // vmovaps %ymm1, (%r8) can use port 2, 3, or 7.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h:53,Performance,load,loads,53,// Some older targets can be setup to fold unaligned loads.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h:18,Performance,Cache,Cache,18,/// @}; /// \name Cache TTI Implementation; /// @{,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h:116,Performance,load,load,116,"/// Return the cost of the scaling factor used in the addressing; /// mode represented by AM for this target, for a load/store; /// of the specified type.; /// If the AM is supported, the return value must be >= 0.; /// If the AM is not supported, it returns a negative value.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:865,Energy Efficiency,allocate,allocated,865,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:42,Modifiability,Config,Configure,42,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:396,Modifiability,config,config,396,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:468,Modifiability,config,configured,468,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:884,Modifiability,config,config,884,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:904,Modifiability,config,config,904,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:879,Performance,load,load,879,"//===-- X86TileConfig.cpp - Tile Register Configure----------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Pass to config the shape of AMX physical registers; /// AMX register need to be configured before use. In X86PreTileConfig pass; /// the pldtilecfg instruction is inserted, however at that time we don't; /// know the shape of each physical tile registers, because the register; /// allocation is not done yet. This pass runs after egister allocation; /// pass. It collects the shape information of each physical tile register; /// and store the shape in the stack slot that is allocated for load config; /// to tile config register.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:4,Performance,Perform,Perform,4,/// Perform register allocation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp:40,Modifiability,config,config,40,"// Here is the data format for the tile config.; // 0 palette; // 1 start_row; // 2-15 reserved, must be zero; // 16-17 tile0.colsb Tile 0 bytes per row.; // 18-19 tile1.colsb Tile 1 bytes per row.; // 20-21 tile2.colsb Tile 2 bytes per row.; // ... (sequence continues); // 30-31 tile7.colsb Tile 7 bytes per row.; // 32-47 reserved, must be zero; // 48 tile0.rows Tile 0 rows.; // 49 tile1.rows Tile 1 rows.; // 50 tile2.rows Tile 2 rows.; // ... (sequence continues); // 55 tile7.rows Tile 7 rows.; // 56-63 reserved, must be zero",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TileConfig.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp:522,Performance,latency,latency,522,"//===- X86VZeroUpper.cpp - AVX vzeroupper instruction inserter ------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass which inserts x86 AVX vzeroupper instructions; // before calls to SSE encoded functions. This avoids transition latency; // penalty when transferring control between AVX encoded instructions and old; // SSE encoding mode.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp:504,Safety,avoid,avoids,504,"//===- X86VZeroUpper.cpp - AVX vzeroupper instruction inserter ------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the pass which inserts x86 AVX vzeroupper instructions; // before calls to SSE encoded functions. This avoids transition latency; // penalty when transferring control between AVX encoded instructions and old; // SSE encoding mode.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp:420,Usability,clear,clears,420,// Core algorithm state:; // BlockState - Each block is either:; // - PASS_THROUGH: There are neither YMM/ZMM dirtying instructions nor; // vzeroupper instructions in this block.; // - EXITS_CLEAN: There is (or will be) a vzeroupper instruction in this; // block that will ensure that YMM/ZMM is clean on exit.; // - EXITS_DIRTY: An instruction in the block dirties YMM/ZMM and no; // subsequent vzeroupper in the block clears it.; //; // AddedToDirtySuccessors - This flag is raised when a block is added to the; // DirtySuccessors list to ensure that it's not; // added multiple times.; //; // FirstUnguardedCall - Records the location of the first unguarded call in; // each basic block that may need to be guarded by a; // vzeroupper. We won't know whether it actually needs; // to be guarded until we discover a predecessor that; // is DIRTY_OUT.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp:121,Integrability,depend,depends,121,"// If this block is currently in pass-through state and we encounter a; // call then whether we need a vzeroupper or not depends on whether this; // block has successors that exit dirty. Record the location of the call,; // and set the state to EXITS_CLEAN, but do not insert the vzeroupper yet.; // It will be inserted later if necessary.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86VZeroUpper.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:40,Deployability,update,updates,40,"//===-- X86WinEHState - Insert EH state updates for win32 exceptions ------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // All functions using an MSVC EH personality use an explicitly updated state; // number stored in an exception registration stack object. The registration; // object is linked into a thread-local chain of registrations stored at fs:00.; // This pass adds the registration object and EH state updates.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:444,Deployability,update,updated,444,"//===-- X86WinEHState - Insert EH state updates for win32 exceptions ------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // All functions using an MSVC EH personality use an explicitly updated state; // number stored in an exception registration stack object. The registration; // object is linked into a thread-local chain of registrations stored at fs:00.; // This pass adds the registration object and EH state updates.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:673,Deployability,update,updates,673,"//===-- X86WinEHState - Insert EH state updates for win32 exceptions ------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // All functions using an MSVC EH personality use an explicitly updated state; // number stored in an exception registration stack object. The registration; // object is linked into a thread-local chain of registrations stored at fs:00.; // This pass adds the registration object and EH state updates.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:36,Security,secur,security,36,// The allocation containing the EH security guard.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:59,Security,access,accesses,59,"// This pass should only insert a stack allocation, memory accesses, and; // localrecovers.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate local structures.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:13,Safety,safe,safeseh,13,// Emit the .safeseh directive for this function.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:9,Modifiability,rewrite,rewrite,9,// Don't rewrite calls with a weird number of arguments.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:95,Availability,recover,recover,95,// Mark the registration node. The backend needs to know which alloca it is so; // that it can recover the original frame pointer.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:95,Safety,recover,recover,95,// Mark the registration node. The backend needs to know which alloca it is so; // that it can recover the original frame pointer.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp:3,Deployability,Update,Update,3,// Update our FinalState to reflect the common InitialState of our; // successors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86WinEHState.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:33,Modifiability,extend,extended,33,// Does this instruction use apx extended register?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:50,Deployability,update,update,50,// Is this instruction explicitly required not to update flags?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:14,Integrability,Inject,Injection,14,// Load Value Injection (LVI) Mitigations for machine code,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:3,Performance,Load,Load,3,// Load Value Injection (LVI) Mitigations for machine code,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:14,Security,Inject,Injection,14,// Load Value Injection (LVI) Mitigations for machine code,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:4,Integrability,Wrap,Wrapper,4,/// Wrapper around MCStreamer::emitInstruction(). Possibly adds; /// instrumentation around Inst.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:47,Availability,mask,masked,47,"/// Parses AVX512 specific operand primitives: masked registers ({%k<NUM>}, {z}); /// and memory broadcasting ({1to<NUM>}) primitives, updating Operands vector if required.; /// return false if no parsing errors occurred, true otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:205,Availability,error,errors,205,"/// Parses AVX512 specific operand primitives: masked registers ({%k<NUM>}, {z}); /// and memory broadcasting ({1to<NUM>}) primitives, updating Operands vector if required.; /// return false if no parsing errors occurred, true otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:25,Availability,avail,available,25,// Initialize the set of available features.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:56,Modifiability,variab,variable,56,"// It is widely common for MS InlineAsm to use a global variable and one/two; // registers in a mmory expression, and though unaccessible via rip/eip.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:61,Modifiability,rewrite,rewrite,61,"// If we have only a symbol than there's no need for complex rewrite,; // simply skip everything after it",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:74,Usability,simpl,simply,74,"// If we have only a symbol than there's no need for complex rewrite,; // simply skip everything after it",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:29,Modifiability,rewrite,rewrite,29,// Build an Intel Expression rewrite,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:27,Modifiability,variab,variable,27,// Inline assembly may use variable names with namespace alias qualifiers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:10,Modifiability,rewrite,rewrite,10,"// Push a rewrite for replacing the identifier name with the internal name,; // unless we are parsing the operand of an offset operator",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:29,Deployability,update,update,29,// Eat the DotExpression and update End,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:164,Modifiability,variab,variables,164,"/// Parse the 'LENGTH', 'TYPE' and 'SIZE' operators. The LENGTH operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZE operator returns the size of a C or C++; /// variable. A variable's size is the product of its LENGTH and TYPE. The; /// TYPE operator returns the size of a C or C++ type or variable. If the; /// variable is an array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:229,Modifiability,variab,variable,229,"/// Parse the 'LENGTH', 'TYPE' and 'SIZE' operators. The LENGTH operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZE operator returns the size of a C or C++; /// variable. A variable's size is the product of its LENGTH and TYPE. The; /// TYPE operator returns the size of a C or C++ type or variable. If the; /// variable is an array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:241,Modifiability,variab,variable,241,"/// Parse the 'LENGTH', 'TYPE' and 'SIZE' operators. The LENGTH operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZE operator returns the size of a C or C++; /// variable. A variable's size is the product of its LENGTH and TYPE. The; /// TYPE operator returns the size of a C or C++ type or variable. If the; /// variable is an array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:358,Modifiability,variab,variable,358,"/// Parse the 'LENGTH', 'TYPE' and 'SIZE' operators. The LENGTH operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZE operator returns the size of a C or C++; /// variable. A variable's size is the product of its LENGTH and TYPE. The; /// TYPE operator returns the size of a C or C++ type or variable. If the; /// variable is an array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:380,Modifiability,variab,variable,380,"/// Parse the 'LENGTH', 'TYPE' and 'SIZE' operators. The LENGTH operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZE operator returns the size of a C or C++; /// variable. A variable's size is the product of its LENGTH and TYPE. The; /// TYPE operator returns the size of a C or C++ type or variable. If the; /// variable is an array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:171,Modifiability,variab,variables,171,"/// Parse the 'LENGTHOF', 'SIZEOF', and 'TYPE' operators. The LENGTHOF operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZEOF operator returns the size of a type or; /// variable in bytes. A variable's size is the product of its LENGTH and TYPE.; /// The TYPE operator returns the size of a variable. If the variable is an; /// array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:237,Modifiability,variab,variable,237,"/// Parse the 'LENGTHOF', 'SIZEOF', and 'TYPE' operators. The LENGTHOF operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZEOF operator returns the size of a type or; /// variable in bytes. A variable's size is the product of its LENGTH and TYPE.; /// The TYPE operator returns the size of a variable. If the variable is an; /// array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:258,Modifiability,variab,variable,258,"/// Parse the 'LENGTHOF', 'SIZEOF', and 'TYPE' operators. The LENGTHOF operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZEOF operator returns the size of a type or; /// variable in bytes. A variable's size is the product of its LENGTH and TYPE.; /// The TYPE operator returns the size of a variable. If the variable is an; /// array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:358,Modifiability,variab,variable,358,"/// Parse the 'LENGTHOF', 'SIZEOF', and 'TYPE' operators. The LENGTHOF operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZEOF operator returns the size of a type or; /// variable in bytes. A variable's size is the product of its LENGTH and TYPE.; /// The TYPE operator returns the size of a variable. If the variable is an; /// array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:375,Modifiability,variab,variable,375,"/// Parse the 'LENGTHOF', 'SIZEOF', and 'TYPE' operators. The LENGTHOF operator; /// returns the number of elements in an array. It returns the value 1 for; /// non-array variables. The SIZEOF operator returns the size of a type or; /// variable in bytes. A variable's size is the product of its LENGTH and TYPE.; /// The TYPE operator returns the size of a variable. If the variable is an; /// array, TYPE returns the size of a single element.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:15,Deployability,update,update,15,// Eat ':' and update Start location,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:34,Modifiability,variab,variable,34,// Disp includes the address of a variable; make sure this is recorded; // for later handling.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:126,Availability,error,error,126,"// If BaseReg is a vector register and IndexReg is not, swap them unless; // Scale was specified in which case it would be an error.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:82,Modifiability,variab,variable,82,"// When parsing x64 MS-style assembly, all non-absolute references to a named; // variable default to RIP-relative.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:56,Availability,error,error,56,// Treat `call [offset fn_ref]` (or `jmp`) syntax as an error.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:120,Availability,error,errors,120,"// This is an immediate, so we should not parse a register. Do a precheck; // for '%' to supercede intra-register parse errors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:217,Modifiability,variab,variable,217,// This a memory operand or a register. We have some parsing complications; // as a '(' may be part of an immediate expression or the addressing mode; // block. This is complicated by the fact that an assembler-level variable; // may refer either to a register or an immediate expression.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:11,Availability,failure,failure,11,"// true on failure, false otherwise; // If no {z} mark was found - Parser doesn't advance",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:136,Availability,error,error,136,"// Assuming we are just pass the '{' mark, quering the next token; // Searched for {z}, but none was found. Return false, as no parsing error was; // encountered",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:11,Availability,failure,failure,11,"// true on failure, false otherwise",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:79,Availability,error,errors,79,// Reaching here means that parsing of the allegadly '{z}' mark yielded; // no errors.; // Query for the need of further parsing for a {%k<NUM>} mark,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:15,Availability,mask,mask,15,"// Parse an op-mask register mark ({%k<NUM>}), which is now to be; // expected",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:30,Availability,error,error,30,"// Have we've found a parsing error, or found no (expected) {z} mark; // - report an error",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:85,Availability,error,error,85,"// Have we've found a parsing error, or found no (expected) {z} mark; // - report an error",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:3,Security,Validat,Validate,3,// Validate the scale amount.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:130,Availability,error,error,130,"// If the displacement is a constant, check overflows. For 64-bit addressing,; // gas requires isInt<32> and otherwise reports an error. For others, gas; // reports a warning and allows a wider range. E.g. gas allows; // [-0xffffffff,0xffffffff] for 32-bit addressing (e.g. Linux kernel uses; // `leal -__PAGE_OFFSET(%ecx),%esp` where __PAGE_OFFSET is 0xc0000000).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:94,Availability,robust,robustness,94,"// Determine whether this is an instruction prefix.; // FIXME:; // Enhance prefixes integrity robustness. for example, following forms; // are currently tolerated:; // repz repnz <insn> ; GAS errors for the use of two similar prefixes; // lock addq %rax, %rbx ; Destination operand must be of memory type; // xacquire <insn> ; xacquire must be accompanied by 'lock'",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:153,Availability,toler,tolerated,153,"// Determine whether this is an instruction prefix.; // FIXME:; // Enhance prefixes integrity robustness. for example, following forms; // are currently tolerated:; // repz repnz <insn> ; GAS errors for the use of two similar prefixes; // lock addq %rax, %rbx ; Destination operand must be of memory type; // xacquire <insn> ; xacquire must be accompanied by 'lock'",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:192,Availability,error,errors,192,"// Determine whether this is an instruction prefix.; // FIXME:; // Enhance prefixes integrity robustness. for example, following forms; // are currently tolerated:; // repz repnz <insn> ; GAS errors for the use of two similar prefixes; // lock addq %rax, %rbx ; Destination operand must be of memory type; // xacquire <insn> ; xacquire must be accompanied by 'lock'",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:67,Modifiability,Enhance,Enhance,67,"// Determine whether this is an instruction prefix.; // FIXME:; // Enhance prefixes integrity robustness. for example, following forms; // are currently tolerated:; // repz repnz <insn> ; GAS errors for the use of two similar prefixes; // lock addq %rax, %rbx ; Destination operand must be of memory type; // xacquire <insn> ; xacquire must be accompanied by 'lock'",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:84,Security,integrity,integrity,84,"// Determine whether this is an instruction prefix.; // FIXME:; // Enhance prefixes integrity robustness. for example, following forms; // are currently tolerated:; // repz repnz <insn> ; GAS errors for the use of two similar prefixes; // lock addq %rax, %rbx ; Destination operand must be of memory type; // xacquire <insn> ; xacquire must be accompanied by 'lock'",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:30,Availability,error,error,30,// Check if we encountered an error for one the string insturctions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:45,Performance,optimiz,optimization,45,"// Transforms ""int $3"" into ""int3"" as a size optimization.; // We can't write this as an InstAlias.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:7,Availability,mask,mask,7,"// The mask variants have different operand list. Scan from the third; // operand to avoid emitting incorrect warning.; // VFMULCPHZrr Dest, Src1, Src2; // VFMULCPHZrrk Dest, Dest, Mask, Src1, Src2; // VFMULCPHZrrkz Dest, Mask, Src1, Src2",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:181,Availability,Mask,Mask,181,"// The mask variants have different operand list. Scan from the third; // operand to avoid emitting incorrect warning.; // VFMULCPHZrr Dest, Src1, Src2; // VFMULCPHZrrk Dest, Dest, Mask, Src1, Src2; // VFMULCPHZrrkz Dest, Mask, Src1, Src2",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:222,Availability,Mask,Mask,222,"// The mask variants have different operand list. Scan from the third; // operand to avoid emitting incorrect warning.; // VFMULCPHZrr Dest, Src1, Src2; // VFMULCPHZrrk Dest, Dest, Mask, Src1, Src2; // VFMULCPHZrrkz Dest, Mask, Src1, Src2",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:85,Safety,avoid,avoid,85,"// The mask variants have different operand list. Scan from the third; // operand to avoid emitting incorrect warning.; // VFMULCPHZrr Dest, Src1, Src2; // VFMULCPHZrrk Dest, Dest, Mask, Src1, Src2; // VFMULCPHZrrkz Dest, Mask, Src1, Src2",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:498,Integrability,inject,injection,498,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:96,Performance,load,load,96,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:230,Performance,load,load,230,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:487,Performance,load,load-value-injection,487,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:441,Security,secur,security-software-guidance,441,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:498,Security,inject,injection,498,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:459,Usability,guid,guidance,459,"/// RET instructions and also instructions that indirect calls/jumps from memory; /// combine a load and a branch within a single instruction. To mitigate these; /// instructions against LVI, they must be decomposed into separate load and; /// branch instructions, with an LFENCE in between. For more details, see:; /// - X86LoadValueInjectionRetHardening.cpp; /// - X86LoadValueInjectionIndirectThunks.cpp; /// - https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:186,Integrability,inject,injection,186,// Information on control-flow instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:175,Performance,load,load-value-injection,175,// Information on control-flow instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:129,Security,secur,security-software-guidance,129,// Information on control-flow instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:186,Security,inject,injection,186,// Information on control-flow instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:147,Usability,guid,guidance,147,// Information on control-flow instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:371,Integrability,inject,injection,371,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:44,Performance,perform,performs,44,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:55,Performance,load,load,55,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:360,Performance,load,load-value-injection,360,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:314,Security,secur,security-software-guidance,314,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:371,Security,inject,injection,371,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:332,Usability,guid,guidance,332,"/// To mitigate LVI, every instruction that performs a load can be followed by; /// an LFENCE instruction to squash any potential mis-speculation. There are; /// some instructions that require additional considerations, and may requre; /// manual mitigation. For more details, see:; /// https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection; ///; /// Returns `true` if a mitigation was applied or warning was emitted.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:184,Integrability,inject,injection,184,// Information on REP string instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:173,Performance,load,load-value-injection,173,// Information on REP string instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:127,Security,secur,security-software-guidance,127,// Information on REP string instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:184,Security,inject,injection,184,// Information on REP string instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:145,Usability,guid,guidance,145,// Information on REP string instructions that require manual mitigation can; // be found here:; // https://software.intel.com/security-software-guidance/insights/deep-dive-load-value-injection#specialinstructions,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:41,Availability,failure,failure,41,"// If this returned as a missing feature failure, remember that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:56,Availability,error,error,56,"// Otherwise, the match failed, try to produce a decent error message.; // If we had multiple suffix matches, then identify this as an ambiguous; // match.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:62,Integrability,message,message,62,"// Otherwise, the match failed, try to produce a decent error message.; // If we had multiple suffix matches, then identify this as an ambiguous; // match.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:3,Availability,Recover,Recover,3,// Recover location info for the operand if we know which was the problem.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:3,Safety,Recover,Recover,3,// Recover location info for the operand if we know which was the problem.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:85,Availability,failure,failure,85,"// If one instruction matched with an invalid operand, report this as an; // operand failure.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:36,Availability,failure,failure,36,"// If all of these were an outright failure, report it in a useless way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:41,Availability,failure,failure,41,"// If this returned as a missing feature failure, remember that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:41,Availability,failure,failure,41,"// If this returned as a missing feature failure, remember that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:9,Modifiability,rewrite,rewrite,9,// Add a rewrite that encodes the size information we used from the; // frontend.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:85,Availability,failure,failure,85,"// If one instruction matched with an invalid operand, report this as an; // operand failure.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:36,Availability,failure,failure,36,"// If all of these were an outright failure, report it in a useless way.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:1416,Integrability,Depend,Depending,1416,"roduced by the decoder into; // MCInsts.; //; //; // The X86 disassembler is a table-driven disassembler for the 16-, 32-, and; // 64-bit X86 instruction sets. The main decode sequence for an assembly; // instruction in this disassembler is:; //; // 1. Read the prefix bytes and determine the attributes of the instruction.; // These attributes, recorded in enum attributeBits; // (X86DisassemblerDecoderCommon.h), form a bitmask. The table CONTEXTS_SYM; // provides a mapping from bitmasks to contexts, which are represented by; // enum InstructionContext (ibid.).; //; // 2. Read the opcode, and determine what kind of opcode it is. The; // disassembler distinguishes four kinds of opcodes, which are enumerated in; // OpcodeType (X86DisassemblerDecoderCommon.h): one-byte (0xnn), two-byte; // (0x0f 0xnn), three-byte-38 (0x0f 0x38 0xnn), or three-byte-3a; // (0x0f 0x3a 0xnn). Mandatory prefixes are treated as part of the context.; //; // 3. Depending on the opcode type, look in one of four ClassDecision structures; // (X86DisassemblerDecoderCommon.h). Use the opcode class to determine which; // OpcodeDecision (ibid.) to look the opcode in. Look up the opcode, to get; // a ModRMDecision (ibid.).; //; // 4. Some instructions, such as escape opcodes or extended opcodes, or even; // instructions that have ModRM*Reg / ModRM*Mem forms in LLVM, need the; // ModR/M byte to complete decode. The ModRMDecision's type is an entry from; // ModRMDecisionType (X86DisassemblerDecoderCommon.h) that indicates if the; // ModR/M byte is required and how to interpret it.; //; // 5. After resolving the ModRMDecision, the disassembler has a unique ID; // of type InstrUID (X86DisassemblerDecoderCommon.h). Looking this ID up in; // INSTRUCTIONS_SYM yields the name of the instruction and the encodings and; // meanings of its operands.; //; // 6. For each operand, its encoding is an entry from OperandEncoding; // (X86DisassemblerDecoderCommon.h) and its type is an entry from; // OperandType (ibid.). T",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:3708,Integrability,interface,interface,3708,"ModR/M byte is required and how to interpret it.; //; // 5. After resolving the ModRMDecision, the disassembler has a unique ID; // of type InstrUID (X86DisassemblerDecoderCommon.h). Looking this ID up in; // INSTRUCTIONS_SYM yields the name of the instruction and the encodings and; // meanings of its operands.; //; // 6. For each operand, its encoding is an entry from OperandEncoding; // (X86DisassemblerDecoderCommon.h) and its type is an entry from; // OperandType (ibid.). The encoding indicates how to read it from the; // instruction; the type indicates how to interpret the value once it has; // been read. For example, a register operand could be stored in the R/M; // field of the ModR/M byte, the REG field of the ModR/M byte, or added to; // the main opcode. This is orthogonal from its meaning (an GPR or an XMM; // register, for instance). Given this information, the operands can be; // extracted and interpreted.; //; // 7. As the last step, the disassembler translates the instruction information; // and operands into a format understandable by the client - in this case, an; // MCInst for use by the MC infrastructure.; //; // The disassembler is broken broadly into two parts: the table emitter that; // emits the instruction decode tables discussed above during compilation, and; // the disassembler itself. The table emitter is documented in more detail in; // utils/TableGen/X86DisassemblerEmitter.h.; //; // X86Disassembler.cpp contains the code responsible for step 7, and for; // invoking the decoder to execute steps 1-6.; // X86DisassemblerDecoderCommon.h contains the definitions needed by both the; // table emitter and the disassembler.; // X86DisassemblerDecoder.h contains the public interface of the decoder,; // factored out into C for possible use by other projects.; // X86DisassemblerDecoder.c contains the source code of the decoder, which is; // responsible for steps 1-6.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:1731,Modifiability,extend,extended,1731,"f the instruction.; // These attributes, recorded in enum attributeBits; // (X86DisassemblerDecoderCommon.h), form a bitmask. The table CONTEXTS_SYM; // provides a mapping from bitmasks to contexts, which are represented by; // enum InstructionContext (ibid.).; //; // 2. Read the opcode, and determine what kind of opcode it is. The; // disassembler distinguishes four kinds of opcodes, which are enumerated in; // OpcodeType (X86DisassemblerDecoderCommon.h): one-byte (0xnn), two-byte; // (0x0f 0xnn), three-byte-38 (0x0f 0x38 0xnn), or three-byte-3a; // (0x0f 0x3a 0xnn). Mandatory prefixes are treated as part of the context.; //; // 3. Depending on the opcode type, look in one of four ClassDecision structures; // (X86DisassemblerDecoderCommon.h). Use the opcode class to determine which; // OpcodeDecision (ibid.) to look the opcode in. Look up the opcode, to get; // a ModRMDecision (ibid.).; //; // 4. Some instructions, such as escape opcodes or extended opcodes, or even; // instructions that have ModRM*Reg / ModRM*Mem forms in LLVM, need the; // ModR/M byte to complete decode. The ModRMDecision's type is an entry from; // ModRMDecisionType (X86DisassemblerDecoderCommon.h) that indicates if the; // ModR/M byte is required and how to interpret it.; //; // 5. After resolving the ModRMDecision, the disassembler has a unique ID; // of type InstrUID (X86DisassemblerDecoderCommon.h). Looking this ID up in; // INSTRUCTIONS_SYM yields the name of the instruction and the encodings and; // meanings of its operands.; //; // 6. For each operand, its encoding is an entry from OperandEncoding; // (X86DisassemblerDecoderCommon.h) and its type is an entry from; // OperandType (ibid.). The encoding indicates how to read it from the; // instruction; the type indicates how to interpret the value once it has; // been read. For example, a register operand could be stored in the R/M; // field of the ModR/M byte, the REG field of the ModR/M byte, or added to; // the main opcode. This is ortho",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:187,Availability,down,down,187,"// Specifies whether a ModR/M byte is needed and (if so) which; // instruction each possible value of the ModR/M byte corresponds to. Once; // this information is known, we have narrowed down to a single instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:3,Usability,PAUSE,PAUSE,3,// PAUSE instruction support,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:34,Usability,simpl,simplicity,34,// We simulate the REX prefix for simplicity's sake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:35,Usability,simpl,simplicity,35,// We simulate the REX2 prefix for simplicity's sake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:34,Usability,simpl,simplicity,34,// We simulate the REX prefix for simplicity's sake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:34,Usability,simpl,simplicity,34,// We simulate the REX prefix for simplicity's sake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:34,Usability,simpl,simplicity,34,// We simulate the REX prefix for simplicity's sake,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:148,Availability,avail,available,148,// EVEX_X can extend the register id to 32 for a non-GPR register that is; // encoded in RM.; // mode : MODE_64_BIT; // Only 8 vector registers are available in 32 bit mode; // mod : 3; // RM encodes a register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:14,Modifiability,extend,extend,14,// EVEX_X can extend the register id to 32 for a non-GPR register that is; // encoded in RM.; // mode : MODE_64_BIT; // Only 8 vector registers are available in 32 bit mode; // mod : 3; // RM encodes a register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:58,Modifiability,extend,extended,58,// Read the opcode (except the ModR/M byte in the case of extended or escape; // opcodes).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:148,Availability,mask,mask,148,"// Determine the ID of an instruction, consuming the ModR/M byte as appropriate; // for extended and escape opcodes, and using a supplied attribute mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:88,Modifiability,extend,extended,88,"// Determine the ID of an instruction, consuming the ModR/M byte as appropriate; // for extended and escape opcodes, and using a supplied attribute mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:88,Modifiability,extend,extended,88,"// Determine the ID of an instruction, consuming the ModR/M byte as appropriate; // for extended and escape opcodes. Determines the attributes and context for; // the instruction before doing so.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:23,Usability,PAUSE,PAUSE,23,// Special support for PAUSE,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:12,Usability,clear,clear,12,// Can only clear bit 4. Bit 3 must be cleared later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:39,Usability,clear,cleared,39,// Can only clear bit 4. Bit 3 must be cleared later.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:11,Availability,mask,mask,11,// Read an mask register from the opcode field of an instruction.; //; // @param insn - The instruction whose opcode field is to be read.; // @return - 0 on success; nonzero otherwise.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:21,Usability,pause,pause,21,// It should not be 'pause' f3 90,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:8,Modifiability,extend,extend,8,// Sign-extend the immediate if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:19,Modifiability,extend,extend,19,// By default sign-extend all X86 immediates based on their encoding.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:211,Safety,avoid,avoid,211,"// Use EIZ/RIZ for a few ambiguous cases where the SIB byte is present,; // but no index is used and modrm alone should have been enough.; // -No base register in 32-bit mode. In 64-bit mode this is used to; // avoid rip-relative addressing.; // -Any base register used other than ESP/RSP/R12D/R12. Using these as a; // base always requires a SIB byte.; // -A scale other than 1 is used.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:47,Availability,mask,mask,47,"/// translateMaskRegister - Translates a 3-bit mask register number to; /// LLVM form, and appends it to an MCInst.; ///; /// @param mcInst - The MCInst to append to.; /// @param maskRegNum - Number of mask register from 0 to 7.; /// @return - false on success; true otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:179,Availability,mask,maskRegNum,179,"/// translateMaskRegister - Translates a 3-bit mask register number to; /// LLVM form, and appends it to an MCInst.; ///; /// @param mcInst - The MCInst to append to.; /// @param maskRegNum - Number of mask register from 0 to 7.; /// @return - false on success; true otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp:202,Availability,mask,mask,202,"/// translateMaskRegister - Translates a 3-bit mask register number to; /// LLVM form, and appends it to an MCInst.; ///; /// @param mcInst - The MCInst to append to.; /// @param maskRegNum - Number of mask register from 0 to 7.; /// @return - false on success; true otherwise.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86Disassembler.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h:453,Integrability,interface,interface,453,"//===-- X86DisassemblerDecoderInternal.h - Disassembler decoder -*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file is part of the X86 Disassembler.; // It contains the public interface of the instruction decoder.; // Documentation for the disassembler can be found in X86Disassembler.h.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h:33,Usability,usab,usable,33,"// The start of the instruction, usable with the reader",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h:112,Integrability,depend,depend,112,"// Portions of the ModR/M byte; // These fields determine the allowable values for the ModR/M fields, which; // depend on operand and address widths.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/Disassembler/X86DisassemblerDecoder.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp:20,Usability,simpl,simple,20,// TODO: handle not simple cases.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp:20,Usability,simpl,simple,20,// TODO: handle not simple cases.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86CallLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:97,Usability,simpl,simple,97,// FIXME: We need some sort of API in RBI/TRI to allow generic code to; // constrain operands of simple instructions given a TargetRegisterClass; // and LLT,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:47,Performance,perform,performe,47,"// This case can be generated by ABI lowering, performe anyext",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:35,Performance,perform,performe,35,// Change the physical register to performe truncate.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:228,Performance,load,loading,228,"// Note: for unordered operations, we rely on the fact the appropriate MMO; // is already on the instruction we're mutating, and thus we don't need to; // make any changes. So long as we select an opcode which is capable of; // loading or storing the appropriate size atomically, the rest of the; // backend is required to respect the MMO state.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:35,Performance,load,load,35,// TODO: The ABI requires an extra load. not supported yet.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:14,Performance,load,load,14,// Create the load from the constant pool.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:18,Energy Efficiency,allocate,allocated,18,// PICBase can be allocated by TII.getGlobalBaseReg(&MF).; // In DAGISEL the code that initialize it generated by the CGBR pass.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:42,Energy Efficiency,adapt,adapted,42,// The implementation of this function is adapted from X86FastISel.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:42,Modifiability,adapt,adapted,42,// The implementation of this function is adapted from X86FastISel.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:306,Modifiability,extend,extended,306,"// For the X86 IDIV instruction, in most cases the dividend; // (numerator) must be in a specific register pair highreg:lowreg,; // producing the quotient in lowreg and the remainder in highreg.; // For most data types, to set up the instruction, the dividend is; // copied into lowreg, and lowreg is sign-extended into highreg. The; // exception is i8, where the dividend is defined as a single register rather; // than a register pair, and we therefore directly sign-extend the dividend; // into lowreg, instead of copying, and ignore the highreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:469,Modifiability,extend,extend,469,"// For the X86 IDIV instruction, in most cases the dividend; // (numerator) must be in a specific register pair highreg:lowreg,; // producing the quotient in lowreg and the remainder in highreg.; // For most data types, to set up the instruction, the dividend is; // copied into lowreg, and lowreg is sign-extended into highreg. The; // exception is i8, where the dividend is defined as a single register rather; // than a register pair, and we therefore directly sign-extend the dividend; // into lowreg, instead of copying, and ignore the highreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:25,Integrability,depend,depends,25,// The following portion depends only on the data type.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:60,Integrability,depend,depends,60,// high part of the register pair; // The following portion depends on both the data type and the operation.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:19,Modifiability,extend,extending,19,"// Opcode for sign-extending lowreg into; // highreg, or copying a zero into highreg.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:61,Modifiability,extend,extending,61,"// Opcode for copying dividend into lowreg, or; // zero/sign-extending into lowreg for i8.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:8,Modifiability,extend,extend,8,// Zero-extend or sign-extend into high-order input register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:23,Modifiability,extend,extend,23,// Zero-extend or sign-extend into high-order input register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:391,Availability,robust,robust,391,"// For i8 remainder, we can't reference ah directly, as we'll end; // up with bogus copies like %r9b = COPY %ah. Reference ax; // instead to prevent ah references in a rex instruction.; //; // The current assumption of the fast register allocator is that isel; // won't generate explicit references to the GR8_NOREX registers. If; // the allocator and/or the backend get enhanced to be more robust in; // that regard, this can be, and should be, removed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:371,Modifiability,enhance,enhanced,371,"// For i8 remainder, we can't reference ah directly, as we'll end; // up with bogus copies like %r9b = COPY %ah. Reference ax; // instead to prevent ah references in a rex instruction.; //; // The current assumption of the fast register allocator is that isel; // won't generate explicit references to the GR8_NOREX registers. If; // the allocator and/or the backend get enhanced to be more robust in; // that regard, this can be, and should be, removed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp:68,Modifiability,EXTEND,EXTEND,68,// 32/64-bits needs support for s64/s128 to handle cases:; // s64 = EXTEND (G_IMPLICIT_DEF s32) -> s64 = G_IMPLICIT_DEF; // s128 = EXTEND (G_IMPLICIT_DEF s32/s64) -> s128 = G_IMPLICIT_DEF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp:131,Modifiability,EXTEND,EXTEND,131,// 32/64-bits needs support for s64/s128 to handle cases:; // s64 = EXTEND (G_IMPLICIT_DEF s32) -> s64 = G_IMPLICIT_DEF; // s128 = EXTEND (G_IMPLICIT_DEF s32/s64) -> s128 = G_IMPLICIT_DEF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp:11,Testability,log,logic,11,// integer logic,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp:3,Performance,load,load,3,// load/store: add more corner cases,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp:3,Security,validat,validate,3,// validate RegBank initialization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp:19,Testability,log,logic,19,// Try the default logic for non-generic instructions that are either copies; // or already have some operands assigned to banks.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp:84,Performance,tune,tune,84,// Some of the floating-point instructions have mixed GPR and FP operands:; // fine-tune the computed mapping.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.h:86,Energy Efficiency,allocate,allocated,86,/// Get an instruction mapping.; /// \return An InstructionMappings with a statically allocated; /// OperandsMapping.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86RegisterBankInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h:613,Energy Efficiency,schedul,scheduling,613,"//===-------------------- X86CustomBehaviour.h ------------------*-C++ -* -===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// This file defines the X86CustomBehaviour class which inherits from; /// CustomBehaviour. This class is used by the tool llvm-mca to enforce; /// target specific behaviour that is not expressed well enough in the; /// scheduling model for mca to enforce it automatically.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h:449,Modifiability,inherit,inherits,449,"//===-------------------- X86CustomBehaviour.h ------------------*-C++ -* -===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; /// \file; ///; /// This file defines the X86CustomBehaviour class which inherits from; /// CustomBehaviour. This class is used by the tool llvm-mca to enforce; /// target specific behaviour that is not expressed well enough in the; /// scheduling model for mca to enforce it automatically.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h:78,Performance,load,load,78,/// Called within X86InstrPostProcess to specify certain instructions; /// as load and store barriers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCA/X86CustomBehaviour.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:28,Availability,mask,mask,28,/// A wrapper for holding a mask of the values from X86::AlignBranchBoundaryKind,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:6,Integrability,wrap,wrapper,6,/// A wrapper for holding a mask of the values from X86::AlignBranchBoundaryKind,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:12,Energy Efficiency,reduce,reduce,12,"/// X86 can reduce the bytes of NOP by padding instructions with prefixes to; /// get a better peformance in some cases. Here, we determine which prefix is; /// the most suitable.; ///; /// If the instruction has a segment override prefix, use the existing one.; /// If the target is 64-bit, use the CS.; /// If the target is 32-bit,; /// - If the instruction has a ESP/EBP base register, use SS.; /// - Otherwise use DS.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:79,Usability,simpl,simple,79,"// Since data is always emitted into a DataFragment, our check strategy is; // simple here.; // - If the fragment is a DataFragment; // - If it's not the fragment where the previous instruction is,; // returns true.; // - If it's the fragment holding the previous instruction but its; // size changed since the previous instruction was emitted into; // it, returns true.; // - Otherwise returns false.; // - If the fragment is not a DataFragment, returns false.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:14,Modifiability,rewrite,rewrite,14,// Linker may rewrite the instruction with variant symbol operand(e.g.; // TLSCALL).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:53,Usability,clear,clear,53,"// If this instruction follows any data, there is no clear; // instruction boundary, inserting a nop/prefix would change semantic.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:39,Usability,clear,clear,39,"// Macro fusion doesn't happen indeed, clear the pending.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:3,Deployability,Update,Update,3,// Update the maximum alignment on the current section if necessary.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:127,Safety,safe,safe,127,"// TODO: It turns out we need a decent amount of plumbing for the target; // specific bits to determine number of prefixes its safe to add. Various; // targets (older chips mostly, but also Atom family) encounter decoder; // stalls with too many prefixes. For testing purposes, we set the value; // externally for the moment.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:260,Testability,test,testing,260,"// TODO: It turns out we need a decent amount of plumbing for the target; // specific bits to determine number of prefixes its safe to add. Various; // targets (older chips mostly, but also Atom family) encounter decoder; // stalls with too many prefixes. For testing purposes, we set the value; // externally for the moment.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:106,Performance,perform,performance,106,// TODO: There are lots of other tricks we could apply for increasing; // encoding size without impacting performance.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:56,Availability,down,down,56,"// See if we can further relax some instructions to cut down on the number of; // nop bytes required for code alignment. The actual win is in reducing; // instruction count, not number of bytes. Modern X86-64 can easily end up; // decode limited. It is often better to reduce the number of instructions; // (i.e. eliminate nops) even at the cost of increasing the size and; // complexity of others.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:269,Energy Efficiency,reduce,reduce,269,"// See if we can further relax some instructions to cut down on the number of; // nop bytes required for code alignment. The actual win is in reducing; // instruction count, not number of bytes. Modern X86-64 can easily end up; // decode limited. It is often better to reduce the number of instructions; // (i.e. eliminate nops) even at the cost of increasing the size and; // complexity of others.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:73,Deployability,update,updated,73,"// Make sure the offsets for any fragments in the effected range get; // updated. Note that this (conservatively) invalidates the offsets of; // those following, but this is not required.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:134,Energy Efficiency,efficient,efficiently,134,"// FIXME: handle 32-bit mode; // 15-bytes is the longest single NOP instruction, but 10-bytes is; // commonly the longest that can be efficiently decoded.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:123,Availability,failure,failure,123,"/// Write a sequence of optimal nops to the output, covering \p Count; /// bytes.; /// \return - true on success, false on failure",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:34,Availability,avail,available,34,/// No compact unwind encoding is available.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:4,Availability,Mask,Mask,4,/// Mask for encoding the frame registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp:4,Availability,Mask,Mask,4,/// Mask for encoding the frameless registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86AsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp:23,Performance,Load,Load,23,// Broadcast form.; // Load size is word for TA map. Otherwise it is based on W-bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp:9,Availability,mask,mask,9,// Print mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp:23,Performance,Load,Load,23,// Broadcast form.; // Load size is based on W-bit as only D and Q are supported.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp:9,Availability,mask,mask,9,// Print mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ATTInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:3,Testability,TEST,TEST,3,// TEST,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:3,Testability,TEST,TEST,3,// TEST,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:65,Availability,mask,mask,65,/// Defines the possible values of the branch boundary alignment mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:129,Deployability,integrat,integrated,129,/// MO_GOTPCREL_NORELAX - Same as MO_GOTPCREL except that R_X86_64_GOTPCREL; /// relocations are guaranteed to be emitted by the integrated assembler; /// instead of the relaxable R_X86_64[_REX]_GOTPCRELX relocations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:129,Integrability,integrat,integrated,129,/// MO_GOTPCREL_NORELAX - Same as MO_GOTPCREL except that R_X86_64_GOTPCREL; /// relocations are guaranteed to be emitted by the integrated assembler; /// instead of the relaxable R_X86_64[_REX]_GOTPCRELX relocations.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:175,Modifiability,variab,variable,175,/// MO_TLSGD - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the TLS index structure that contains; /// the module number and variable offset for the symbol. Used in the; /// general dynamic TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @TLSGD,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:244,Security,access,access,244,/// MO_TLSGD - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the TLS index structure that contains; /// the module number and variable offset for the symbol. Used in the; /// general dynamic TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @TLSGD,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:347,Security,access,access,347,"/// MO_TLSLD - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the TLS index for the module that; /// contains the symbol. When this index is passed to a call to; /// __tls_get_addr, the function will return the base address of the TLS; /// block for the symbol. Used in the x86-64 local dynamic TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @TLSLD",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:347,Security,access,access,347,"/// MO_TLSLDM - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the TLS index for the module that; /// contains the symbol. When this index is passed to a call to; /// ___tls_get_addr, the function will return the base address of the TLS; /// block for the symbol. Used in the IA32 local dynamic TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @TLSLDM",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:196,Security,access,access,196,/// MO_GOTTPOFF - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the thread-pointer offset for the; /// symbol. Used in the x86-64 initial exec TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @GOTTPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:222,Security,access,access,222,/// MO_INDNTPOFF - On a symbol operand this indicates that the immediate is; /// the absolute address of the GOT entry with the negative thread-pointer; /// offset for the symbol. Used in the non-PIC IA32 initial exec TLS access; /// model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @INDNTPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:158,Security,access,access,158,/// MO_TPOFF - On a symbol operand this indicates that the immediate is; /// the thread-pointer offset for the symbol. Used in the x86-64 local; /// exec TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @TPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:176,Security,access,access,176,/// MO_DTPOFF - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the TLS offset of the symbol. Used; /// in the local dynamic TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @DTPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:166,Security,access,access,166,/// MO_NTPOFF - On a symbol operand this indicates that the immediate is; /// the negative thread-pointer offset for the symbol. Used in the IA32; /// local exec TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @NTPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:208,Security,access,access,208,/// MO_GOTNTPOFF - On a symbol operand this indicates that the immediate is; /// the offset of the GOT entry with the negative thread-pointer offset for; /// the symbol. Used in the PIC IA32 initial exec TLS access model.; /// See 'ELF Handling for Thread-Local Storage' for more details.; /// SYMBOL_LABEL @GOTNTPOFF,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:218,Testability,stub,stub,218,"/// MO_DARWIN_NONLAZY - On a symbol operand ""FOO"", this indicates that the; /// reference is actually to the ""FOO$non_lazy_ptr"" symbol, which is a; /// non-PIC-base-relative reference to a non-hidden dyld lazy pointer stub.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:222,Testability,stub,stub,222,"/// MO_DARWIN_NONLAZY_PIC_BASE - On a symbol operand ""FOO"", this indicates; /// that the reference is actually to ""FOO$non_lazy_ptr - PICBASE"", which is; /// a PIC-base-relative reference to a non-hidden dyld lazy pointer stub.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:147,Testability,stub,stub,147,"/// MO_COFFSTUB - On a symbol operand ""FOO"", this indicates that the; /// reference is actually to the "".refptr.FOO"" symbol. This is used for; /// stub symbols on windows.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:343,Availability,toler,tolerated,343,"//===------------------------------------------------------------------===//; // Instruction encodings. These are the standard/most common forms for X86; // instructions.; //; /// PseudoFrm - This represents an instruction that is a pseudo instruction; /// or one that has not been implemented yet. It is illegal to code generate; /// it, but tolerated for intermediate implementation stages.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:101,Performance,load,load,101,/// MRMSrcMem4VOp3 - This form is used for instructions that encode; /// operand 3 with VEX.VVVV and load from memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:99,Modifiability,extend,extended,99,"/// MRM0m-MRM7m - Instructions that operate on a memory r/m operand and use; /// reg field to hold extended opcode, which is represented as /0, /1, ...",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:108,Performance,load,load,108,/// MRMSrcReg4VOp3 - This form is used for instructions that encode; /// operand 3 with VEX.VVVV and do not load from memory.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:101,Modifiability,extend,extended,101,"/// MRM0r-MRM7r - Instructions that operate on a register r/m operand and use; /// reg field to hold extended opcode, which is represented as /0, /1, ...",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:87,Performance,perform,performed,87,/// PD - Prefix code for packed double precision vector floating point; /// operations performed in the SSE registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:106,Performance,perform,performed,106,"/// XS, XD - These prefix codes are for single and double precision scalar; /// floating point operations performed in the SSE registers.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:258,Usability,simpl,simplify,258,"/// ThreeDNow - This indicates that the instruction uses the; /// wacky 0x0F 0x0F prefix for 3DNow! instructions. The manual documents; /// this as having a 0x0F prefix with a 0x0F opcode, and each instruction; /// storing a classifier in the imm8 field. To simplify our implementation,; /// we handle this by storeing the classifier in the opcode field and using; /// this flag to indicate that the encoder should do the wacky 3DNow! thing.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:161,Availability,Mask,Mask,161,//===------------------------------------------------------------------===//; /// FP Instruction Classification... Zero is non-fp instruction.; /// FPTypeMask - Mask for all of the FP types...,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:151,Availability,mask,mask,151,"/// EVEX - Specifies that this instruction use EVEX form which provides; /// syntax support up to 32 512-bit register operands and up to 7 16-bit; /// mask operands as well as source operand data swizzling/memory operand; /// conversion, eviction hint, and rounding mode.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:141,Safety,detect,detected,141,"/// VEX_L - Stands for a bit in the VEX opcode prefix meaning the current; /// instruction uses 256-bit wide registers. This is usually auto detected; /// if a VR256 register is used, but some AVX instructions also have this; /// field marked when using a f256 memory references.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:46,Availability,mask,masking,46,/// EVEX_K - Set if this instruction requires masking,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:75,Availability,mask,mask,75,"// Start from 1, skip any registers encoded in VEX_VVVV or I8IMM, or a; // mask register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:75,Availability,mask,mask,75,"// Start from 1, skip any registers encoded in VEX_VVVV or I8IMM, or a; // mask register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:57,Availability,mask,mask,57,"// Start from 0, skip registers encoded in VEX_VVVV or a mask register.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:40,Modifiability,extend,extended,40,/// \returns true if \p RegNo is an apx extended register.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:52,Modifiability,extend,extended,52,"/// \returns true if the MachineOperand is a x86-64 extended (r8 or; /// higher) register, e.g. r8, xmm8, xmm13, etc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:47,Modifiability,extend,extended,47,"/// \returns true if the MemoryOperand is a 32 extended (zmm16 or higher); /// registers, e.g. zmm21, etc.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:31,Availability,mask,masked,31,/// \returns true if this is a masked instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h:37,Availability,mask,masked,37,/// \returns true if this is a merge masked instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86BaseInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:51,Performance,optimiz,optimization,51,"//===-- X86EncodingOptimization.cpp - X86 Encoding optimization -*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the implementation of the X86 encoding optimization; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:441,Performance,optimiz,optimization,441,"//===-- X86EncodingOptimization.cpp - X86 Encoding optimization -*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the implementation of the X86 encoding optimization; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:109,Modifiability,extend,extended,109,"// Commute operands to get a smaller encoding by using VEX.R instead of; // VEX.B if one of the registers is extended, but other isn't.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:83,Security,validat,validateTargetOperandClass,83,// NOTE: We may write this as an InstAlias if it's only used by AsmParser. See; // validateTargetOperandClass.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:4,Usability,Simpl,Simplify,4,/// Simplify things like MOV32rm to MOV32o32a.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:79,Performance,perform,perform,79,// Don't make these simplifications in 64-bit mode; other assemblers don't; // perform them because they make the code larger.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:20,Usability,simpl,simplifications,20,// Don't make these simplifications in 64-bit mode; other assemblers don't; // perform them because they make the code larger.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:10,Modifiability,rewrite,rewrite,10,"// If so, rewrite the instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:4,Usability,Simpl,Simplify,4,"/// Simplify FOO $imm, %{al,ax,eax,rax} to FOO $imm, for instruction with; /// a short fixed-register form.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:10,Modifiability,rewrite,rewrite,10,"// If so, rewrite the instruction.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:10,Performance,optimiz,optimize,10,// We may optimize twice here.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h:49,Performance,optimiz,optimization,49,"//===-- X86EncodingOptimization.h - X86 Encoding optimization ---*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the declarations of the X86 encoding optimization; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h:439,Performance,optimiz,optimization,439,"//===-- X86EncodingOptimization.h - X86 Encoding optimization ---*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the declarations of the X86 encoding optimization; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86FixupKinds.h:57,Modifiability,extend,extended,57,// 32-bit signed. Unlike FK_Data_4; // this will be sign extended at; // runtime.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86FixupKinds.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86FixupKinds.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:52,Availability,mask,mask,52,/// Wraps the destination register name with AVX512 mask/maskz filtering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:57,Availability,mask,maskz,57,/// Wraps the destination register name with AVX512 mask/maskz filtering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:4,Integrability,Wrap,Wraps,4,/// Wraps the destination register name with AVX512 mask/maskz filtering.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:3,Availability,MASK,MASK,3,// MASK: zmmX {%kY},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:3,Availability,MASK,MASKZ,3,// MASKZ: zmmX {%kY} {z},MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:119,Availability,mask,mask,119,"// The operands for FMA3 instructions without rounding fall into two forms:; // dest, src1, src2, src3; // dest, src1, mask, src2, src3; // Where src3 is either a register or 5 memory address operands. So to find; // dest and src1 we can index from the front. To find src2 and src3 we can; // index from the end by taking into account memory vs register form when; // finding src2.; // The operands for FMA4 instructions:; // dest, src1, src2, src3; // Where src2 OR src3 are either a register or 5 memory address operands. So; // to find dest and src1 we can index from the front, src2 (reg/mem) follows; // and then src3 (reg) will be at the end.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:98,Availability,mask,mask,98,"// The only comments we decode are shuffles, so give up if we were unable to; // decode a shuffle mask.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:15,Availability,mask,mask,15,// From second mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp:15,Availability,mask,mask,15,"// The shuffle mask specifies which elements of the src1/src2 fill in the; // destination, with a few sentinel values. Loop through and print them; // out.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86InstComments.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp:9,Availability,mask,mask,9,// Print mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp:23,Performance,Load,Load,23,// Broadcast form.; // Load size is word for TA map. Otherwise it is based on W-bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp:9,Availability,mask,mask,9,// Print mask operand.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp:23,Performance,Load,Load,23,// Broadcast form.; // Load size is based on W-bit as only D and Q are supported.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp:6,Security,access,accesses,6,// DI accesses are always ES-based.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86IntelInstPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp:69,Modifiability,rewrite,rewrite,69,// x86_64 distinguishes movq foo@GOTPCREL so that the linker can; // rewrite the movq to an leaq at link time if the symbol ends up in; // the same linkage unit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp:254,Performance,load,loading,254,"// If the offset is more than 24-bits, it won't fit in a scattered; // relocation offset field, so we fall back to using a non-scattered; // relocation. This is a bit risky, as if the offset reaches out of; // the block and the linker is doing scattered loading on this; // symbol, things can go badly.; //; // Required for 'as' compatibility.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp:167,Safety,risk,risky,167,"// If the offset is more than 24-bits, it won't fit in a scattered; // relocation offset field, so we fall back to using a non-scattered; // relocation. This is a bit risky, as if the offset reaches out of; // the block and the linker is doing scattered loading on this; // symbol, things can go badly.; //; // Required for 'as' compatibility.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp:20,Modifiability,variab,variables,20,// Resolve constant variables.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MachObjectWriter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp:156,Availability,error,error,156,"// we can't emit a 64-bit unit; // Use ## as a comment string so that .s files generated by llvm can go; // through the GCC preprocessor without causing an error. This is needed; // because ""clang foo.s"" runs the C preprocessor, which is usually reserved; // for .S files on other systems. Perhaps this is because the file system; // wasn't always case preserving or something.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp:32,Integrability,depend,depends,32,"// For ELF, x86-64 pointer size depends on the ABI.; // For x86-64 without the x32 ABI, pointer size is 8. For x86 and for x86-64; // with the x32 ABI, pointer size remains the default 4.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCAsmInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:1226,Integrability,depend,depending,1226,"-+ +-------------------+; // | C4h | | RXB | m-mmmm | | W | vvvv | L | pp |; // +-----+ +--------------+ +-------------------+; // VEX_R: opcode externsion equivalent to REX.R in; // 1's complement (inverted) form; //; // 1: Same as REX_R=0 (must be 1 in 32-bit mode); // 0: Same as REX_R=1 (64 bit mode only); // VEX_X: equivalent to REX.X, only used when a; // register is used for index in SIB Byte.; //; // 1: Same as REX.X=0 (must be 1 in 32-bit mode); // 0: Same as REX.X=1 (64-bit mode only); // VEX_B:; // 1: Same as REX_B=0 (ignored in 32-bit mode); // 0: Same as REX_B=1 (64 bit mode only); // VEX_W: opcode specific (use like REX.W, or used for; // opcode extension, or ignored, depending on the opcode byte); // VEX_5M (VEX m-mmmmm field):; //; // 0b00000: Reserved for future use; // 0b00001: implied 0F leading opcode; // 0b00010: implied 0F 38 leading opcode bytes; // 0b00011: implied 0F 3A leading opcode bytes; // 0b00100: Reserved for future use; // 0b00101: VEX MAP5; // 0b00110: VEX MAP6; // 0b00111: VEX MAP7; // 0b00111-0b11111: Reserved for future use; // 0b01000: XOP map select - 08h instructions with imm byte; // 0b01001: XOP map select - 09h instructions with no imm byte; // 0b01010: XOP map select - 0Ah instructions with imm dword; // VEX_4V (VEX vvvv field): a register specifier; // (in 1's complement form) or 1111 if unused.; // VEX_PP: opcode extension providing equivalent; // functionality of a SIMD prefix; // 0b00: None; // 0b01: 66; // 0b10: F3; // 0b11: F2; // EVEX (4 bytes); // +-----+ +---------------+ +--------------------+ +------------------------+; // | 62h | | RXBR' | B'mmm | | W | vvvv | X' | pp | | z | L'L | b | v' | aaa |; // +-----+ +---------------+ +--------------------+ +------------------------+; // EVEX_L2/VEX_L (Vector Length):; // L2 L; // 0 0: scalar or 128-bit vector; // 0 1: 256-bit vector; // 1 0: 512-bit vector; // 32-Register Support in 64-bit Mode Using EVEX with Embedded REX/REX2 Bits:; //; // +----------+---------+-------",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:16,Modifiability,extend,extend,16,// X is used to extend vector register only when shift is not 3.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:54,Modifiability,extend,extend,54,// Index can be a vector register while X2 is used to extend GPR only.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:53,Modifiability,extend,extend,53,// Base can be a vector register while B2 is used to extend GPR only,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:221,Usability,simpl,simple,221,/// Check if this expression starts with _GLOBAL_OFFSET_TABLE_ and if it is; /// of the form _GLOBAL_OFFSET_TABLE_-symbol. This is needed to support PIC on; /// ELF i386 as _GLOBAL_OFFSET_TABLE_ is magical. We check only simple case that; /// are know to be used: _GLOBAL_OFFSET_TABLE_ by itself or at the start of a; /// binary expression.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:16,Usability,simpl,simple,16,"// If this is a simple integer displacement that doesn't require a; // relocation, emit it now.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:28,Performance,load,load,28,"// If this is a pc-relative load off _GLOBAL_OFFSET_TABLE_:; // leaq _GLOBAL_OFFSET_TABLE_(%rip), %r15; // this needs to be a GOTPC32 relocation.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:11,Performance,load,loads,11,// Certain loads for GOT references can be relocated against the symbol; // directly if the symbol ends up in the same linkage unit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:137,Modifiability,flexible,flexible,137,// movq loads is a subset of reloc_riprel_4byte_relax_rex. It is a; // special case because COFF and Mach-O don't support ELF's more; // flexible R_X86_64_REX_GOTPCRELX relaxation.; // TODO: Support new relocation for REX2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:8,Performance,load,loads,8,// movq loads is a subset of reloc_riprel_4byte_relax_rex. It is a; // special case because COFF and Mach-O don't support ELF's more; // flexible R_X86_64_REX_GOTPCRELX relaxation.; // TODO: Support new relocation for REX2.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:92,Usability,simpl,simple,92,"// If the base is not EBP/ESP/R12/R13/R20/R21/R28/R29 and there is no; // displacement, use simple indirect register encoding, this handles; // addresses like [EAX]. The encoding for [EBP], [R13], [R20], [R21], [R28]; // or [R29] with no displacement means [disp32] so we handle it by emitting; // a displacement of 0 later.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:125,Modifiability,extend,extended,125,"/// Emit REX prefix which specifies; /// 1) 64-bit instructions,; /// 2) non-default operand size, and; /// 3) use of X86-64 extended registers.; ///; /// \returns the used prefix (REX or None).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:9,Security,access,accesses,9,"// If it accesses SPL, BPL, SIL, or DIL, then it requires a REX prefix.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:77,Performance,optimiz,optimizations,77,"// GOTTPOFF and TLSDESC relocations require a REX prefix to allow; // linker optimizations: even if the instructions we see may not require; // any prefix, they may be replaced by instructions that do. This is; // handled as a special case here so that it also works for hand-written; // assembly without the user needing to write REX, as with GNU as.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h:445,Modifiability,extend,extended,445,"//=--- X86MCExpr.h - X86 specific MC expression classes ---*- C++ -*-=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file describes X86-specific MCExprs, i.e, registers used for; // extended variable assignments.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h:454,Modifiability,variab,variable,454,"//=--- X86MCExpr.h - X86 specific MC expression classes ---*- C++ -*-=//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file describes X86-specific MCExprs, i.e, registers used for; // extended variable assignments.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h:18,Security,Access,Accessors,18,/// @}; /// @name Accessors; /// @{; /// getSubExpr - Get the child of this expression.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCExpr.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp:2,Performance,Tune,TuneCPU,2,/*TuneCPU*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp:118,Deployability,update,update,118,"// On X86-64, a general purpose integer register is viewed as a 64-bit; // register internal to the processor.; // An update to the lower 32 bits of a 64 bit integer register is; // architecturally defined to zero extend the upper 32 bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp:214,Modifiability,extend,extend,214,"// On X86-64, a general purpose integer register is viewed as a 64-bit; // register internal to the processor.; // An update to the lower 32 bits of a 64 bit integer register is; // architecturally defined to zero extend the upper 32 bits.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp:13,Usability,simpl,simple,13,// Must be a simple rip-relative address.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.h:51,Security,expose,exposed,51,"/// Create a X86 MCSubtargetInfo instance. This is exposed so Asm parser, etc.; /// do not need to go through TargetRegistry.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCTargetDesc.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:475,Availability,mask,mask,475,"//===-- X86ShuffleDecode.cpp - X86 shuffle decode logic -------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Define several functions to decode x86 specific shuffle semantics into a; // generic vector mask.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:50,Testability,log,logic,50,"//===-- X86ShuffleDecode.cpp - X86 shuffle decode logic -------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Define several functions to decode x86 specific shuffle semantics into a; // generic vector mask.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:92,Availability,Mask,Mask,92,//===----------------------------------------------------------------------===//; // Vector Mask Decoding; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:52,Deployability,update,update,52,// CountD specifies which element of destination to update.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:45,Availability,mask,mask,45,// Not all bits of the immediate are used so mask it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:81,Availability,mask,mask,81,"// If there are more than 8 elements in the vector, then any immediate blend; // mask wraps around.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:86,Integrability,wrap,wraps,86,"// If there are more than 8 elements in the vector, then any immediate blend; // mask wraps around.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:141,Testability,log,logical,141,// VPPERM Operation; // Bits[4:0] - Byte Index (0 - 31); // Bits[7:5] - Permute Operation; //; // Permute Operation:; // 0 - Source byte (no logical operation).; // 1 - Invert source byte.; // 2 - Bit reverse of source byte.; // 3 - Bit reverse of inverted source byte.; // 4 - 00h (zero - fill).; // 5 - FFh (ones - fill).; // 6 - Most significant bit of source byte replicated in all bit positions.; // 7 - Invert most significant bit of source byte and replicate in all bit positions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:98,Modifiability,extend,extends,98,// First element comes from the first element of second source.; // Remaining elements: Load zero extends / Move copies from first source.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:88,Performance,Load,Load,88,// First element comes from the first element of second source.; // Remaining elements: Load zero extends / Move copies from first source.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:86,Availability,Mask,Mask,86,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp:130,Availability,Mask,Mask,130,// VPERMIL2 Operation.; // Bits[3] - Match Bit.; // Bits[2:1] - (Per Lane) PD Shuffle Mask.; // Bits[2:0] - (Per Lane) PS Shuffle Mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:475,Availability,mask,mask,475,"//===-- X86ShuffleDecode.h - X86 shuffle decode logic -----------*-C++-*---===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Define several functions to decode x86 specific shuffle semantics into a; // generic vector mask.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:48,Testability,log,logic,48,"//===-- X86ShuffleDecode.h - X86 shuffle decode logic -----------*-C++-*---===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Define several functions to decode x86 specific shuffle semantics into a; // generic vector mask.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:92,Availability,Mask,Mask,92,//===----------------------------------------------------------------------===//; // Vector Mask Decoding; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:61,Availability,mask,mask,61,/// Decode a 128-bit INSERTPS instruction as a v4f32 shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:58,Availability,mask,mask,58,"/// Decode a MOVHLPS instruction as a v2f64/v4f32 shuffle mask.; /// i.e. <3,1> or <6,7,2,3>",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:58,Availability,mask,mask,58,"/// Decode a MOVLHPS instruction as a v2f64/v4f32 shuffle mask.; /// i.e. <0,2> or <0,1,4,5>",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for pshufd/pshufw/vpermilpd/vpermilps.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for pshufhw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for pshuflw.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for shufp*.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for unpckhps/unpckhpd and punpckh*.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for unpcklps/unpcklpd and punpckl*.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:20,Availability,mask,mask,20,/// Decode a PSHUFB mask from a raw array of constants such as from; /// BUILD_VECTOR.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:29,Availability,mask,mask,29,/// Decode a BLEND immediate mask into a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:49,Availability,mask,mask,49,/// Decode a BLEND immediate mask into a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:120,Availability,mask,mask,120,/// Decode a shuffle packed values at 128-bit granularity; /// (SHUFF32x4/SHUFF64x2/SHUFI32x4/SHUFI64x2); /// immediate mask into a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:140,Availability,mask,mask,140,/// Decode a shuffle packed values at 128-bit granularity; /// (SHUFF32x4/SHUFF64x2/SHUFI32x4/SHUFI64x2); /// immediate mask into a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:24,Availability,mask,masks,24,/// Decodes the shuffle masks for VPERMQ/VPERMPD.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:20,Availability,mask,mask,20,"/// Decode a VPPERM mask from a raw array of constants such as from; /// BUILD_VECTOR.; /// This can only basic masks (permutes + zeros), not any of the other; /// operations that VPPERM can perform.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:112,Availability,mask,masks,112,"/// Decode a VPPERM mask from a raw array of constants such as from; /// BUILD_VECTOR.; /// This can only basic masks (permutes + zeros), not any of the other; /// operations that VPPERM can perform.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:191,Performance,perform,perform,191,"/// Decode a VPPERM mask from a raw array of constants such as from; /// BUILD_VECTOR.; /// This can only basic masks (permutes + zeros), not any of the other; /// operations that VPPERM can perform.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:53,Availability,mask,mask,53,/// Decode a zero extension instruction as a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:64,Availability,mask,mask,64,/// Decode a move lower and zero upper instruction as a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:56,Availability,mask,mask,56,/// Decode a scalar float move instruction as a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:50,Availability,mask,mask,50,/// Decode a SSE4A EXTRQ instruction as a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:52,Availability,mask,mask,52,/// Decode a SSE4A INSERTQ instruction as a shuffle mask.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:42,Availability,mask,mask,42,/// Decode a VPERMILPD/VPERMILPS variable mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:33,Modifiability,variab,variable,33,/// Decode a VPERMILPD/VPERMILPS variable mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:44,Availability,mask,mask,44,/// Decode a VPERMIL2PD/VPERMIL2PS variable mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:35,Modifiability,variab,variable,35,/// Decode a VPERMIL2PD/VPERMIL2PS variable mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:31,Availability,mask,mask,31,/// Decode a VPERM W/D/Q/PS/PD mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h:33,Availability,mask,mask,33,/// Decode a VPERMT2 W/D/Q/PS/PD mask from a raw array of constants.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86ShuffleDecode.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp:17,Availability,error,error,17,/// Diagnoses an error at L if we are not in an FPO prologue. Return true on; /// error.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp:82,Availability,error,error,82,/// Diagnoses an error at L if we are not in an FPO prologue. Return true on; /// error.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp:286,Modifiability,variab,variables,286,"// Assign $T0, the VFRAME register, the value of ESP after it is aligned.; // Starting from the CFA, we subtract the size of all pushed registers, and; // align the result. While we don't store any CSRs in this area, $T0 is used; // by S_DEFRANGE_FRAMEPOINTER_REL records to find local variables.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86WinCOFFTargetStreamer.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCore.h:28,Integrability,interface,interface,28,"//===-- XCore.h - Top-level interface for XCore representation --*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains the entry points for global functions defined in the LLVM; // XCore back-end.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCore.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCore.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreAsmPrinter.cpp:474,Integrability,depend,dependent,474,"//===-- XCoreAsmPrinter.cpp - XCore LLVM assembly writer ------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file contains a printer that converts from our internal representation; // of machine-dependent LLVM code to the XAS-format XCore assembly language.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreAsmPrinter.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreAsmPrinter.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:134,Performance,load,load,134,"/// The SP register is moved in steps of 'MaxImmU16' towards the top of the; /// frame. During these steps, it may be necessary to re-load registers.; /// IfNeededLDAWSP emits the necessary LDAWSP instructions to move the SP only; /// as far as to make 'OffsetFromTop' reachable using an LDAWSP_lru6.; /// \param OffsetFromTop the spill offset from the top of the frame.; /// \param [in,out] RemainingAdj the current SP offset from the top of the; /// frame.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:3,Energy Efficiency,Allocate,Allocate,3,// Allocate space on the stack at the same time as saving LR.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:28,Performance,load,loadRegFromStackSlot,28,// Insert in reverse order. loadRegFromStackSlot can insert multiple; // instructions.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:45,Energy Efficiency,efficient,efficient,45,// If we need to extend the stack it is more efficient to use entsp / retsp.; // We force the LR to be saved so these instructions are used.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:17,Modifiability,extend,extend,17,// If we need to extend the stack it is more efficient to use entsp / retsp.; // We force the LR to be saved so these instructions are used.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp:58,Energy Efficiency,allocate,allocate,58,// We will handle the LR in the prologue/epilogue; // and allocate space on the stack ourselves.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreFrameLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp:80,Performance,load,load,80,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp:208,Performance,load,loaded,208,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp:335,Performance,load,loading,335,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp:205,Performance,load,loaded,205,"/// isStoreToStackSlot - If the specified machine instruction is a direct; /// store to a stack slot, return the virtual or physical register number of; /// the source reg along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than storing to the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h:80,Performance,load,load,80,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h:208,Performance,load,loaded,208,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h:335,Performance,load,loading,335,"/// isLoadFromStackSlot - If the specified machine instruction is a direct; /// load from a stack slot, return the virtual or physical register number of; /// the destination along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than loading from the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h:205,Performance,load,loaded,205,"/// isStoreToStackSlot - If the specified machine instruction is a direct; /// store to a stack slot, return the virtual or physical register number of; /// the source reg along with the FrameIndex of the loaded stack slot. If; /// not, return 0. This predicate must return 0 if the instruction has; /// any side effects other than storing to the stack slot.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h:28,Performance,load,load,28,// Emit code before MBBI to load immediate value into physical register Reg.; // Returns an iterator to the new instruction.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreInstrInfo.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp:114,Energy Efficiency,schedul,scheduling,114,"/// createXCoreISelDag - This pass converts a legalized DAG into a; /// XCore-specific DAG, ready for instruction scheduling.; ///",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp:46,Availability,mask,mask,46,// Transformation function: get the size of a mask; // Look for the first non-zero bit,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelDAGToDAG.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:3,Performance,Load,Loads,3,// Loads,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:28,Performance,load,loads,28,// Custom expand misaligned loads / stores.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:45,Performance,load,loads,45,// Lower to pair of consecutive word aligned loads plus some bit shifting.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:28,Modifiability,extend,extended,28,// The inputs are both zero-extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:28,Modifiability,extend,extended,28,// The inputs are both sign-extended.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:3,Performance,Load,Load,3,// Load the actual argument out of the pointer VAList,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:47,Performance,optimiz,optimization,47,// XCore target does not yet support tail call optimization.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:17,Performance,load,loads,17,// Transform all loads nodes into one single node because; // all load nodes are independent of each other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:66,Performance,load,load,66,// Transform all loads nodes into one single node because; // all load nodes are independent of each other.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:51,Availability,avail,available,51,// The ABI dictates there should be one stack slot available to the callee; // on function entry (for saving lr).,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:58,Performance,load,loads,58,"// Walk the register/memloc assignments, inserting copies/loads.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:94,Performance,load,load,94,/// LowerCCCArguments - transform physical registers into; /// virtual registers and generate load operations for; /// arguments places on the stack.; /// TODO: sret,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:73,Energy Efficiency,schedul,scheduler,73,// All getCopyFromReg ops must precede any getMemcpys to prevent the; // scheduler clobbering a register before it has been copied.; // The stages are:; // 1. CopyFromReg (and load) arg & vararg registers.; // 2. Chain CopyFromReg nodes into a TokenFactor.; // 3. Memcpy 'byVal' args & push final InVals.; // 4. Chain mem ops nodes into a TokenFactor.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:176,Performance,load,load,176,// All getCopyFromReg ops must precede any getMemcpys to prevent the; // scheduler clobbering a register before it has been copied.; // The stages are:; // 1. CopyFromReg (and load) arg & vararg registers.; // 2. Chain CopyFromReg nodes into a TokenFactor.; // 3. Memcpy 'byVal' args & push final InVals.; // 4. Chain mem ops nodes into a TokenFactor.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:24,Performance,load,load,24,// 1a. CopyFromReg (and load) arg registers.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:3,Performance,Load,Load,3,// Load the argument to a virtual register,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:52,Performance,load,load,52,// Create the SelectionDAG nodes corresponding to a load; //from this parameter,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:61,Safety,avoid,avoiding,61,"// guarantee that all emitted copies are; // stuck together, avoiding something bad",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:3,Deployability,Update,Update,3,// Update chain.; // Add the glue if we have it.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:3,Deployability,Update,Update,3,// Update machine-CFG edges,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:92,Performance,Optimiz,Optimization,92,//===----------------------------------------------------------------------===//; // Target Optimization Hooks; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:106,Modifiability,extend,extended,106,"// Fold 64 bit expression such as add(add(mul(x,y),a),b) ->; // lmul(x, y, a, b) if all operands are zero-extended. We do this; // before type legalization as it is messy to match the operands after; // that.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:40,Performance,load,load,40,// Replace unaligned store of unaligned load with memmove.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:34,Usability,clear,clear,34,// Top bits of carry / borrow are clear.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:118,Performance,load,load,118,"/// isLegalAddressingMode - Return true if the addressing mode represented; /// by AM is legal for this target, for a load/store of the specified type.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h:49,Integrability,Interface,Interface,49,"//===-- XCoreISelLowering.h - XCore DAG Lowering Interface ------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the interfaces that XCore uses to lower LLVM code into a; // selection DAG.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h:405,Integrability,interface,interfaces,405,"//===-- XCoreISelLowering.h - XCore DAG Lowering Interface ------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file defines the interfaces that XCore uses to lower LLVM code into a; // selection DAG.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h:3,Performance,Load,Load,3,// Load word from stack,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:51,Modifiability,variab,variables,51,"//===-- XCoreLowerThreadLocal - Lower thread local variables --------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// This file contains a pass that lowers thread local variables on the; /// XCore.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:447,Modifiability,variab,variables,447,"//===-- XCoreLowerThreadLocal - Lower thread local variables --------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// This file contains a pass that lowers thread local variables on the; /// XCore.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:24,Modifiability,variab,variables,24,/// Lowers thread local variables on the XCore. Each thread local variable is; /// expanded to an array of n elements indexed by the thread ID where n is the; /// fixed number hardware threads supported by the device.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:66,Modifiability,variab,variable,66,/// Lowers thread local variables on the XCore. Each thread local variable is; /// expanded to an array of n elements indexed by the thread ID where n is the; /// fixed number hardware threads supported by the device.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:68,Availability,error,error,68,// Skip globals that we can't lower and leave it for the backend to error.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp:3,Deployability,Update,Update,3,// Update uses.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreLowerThreadLocal.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreSubtarget.cpp:2,Performance,Tune,TuneCPU,2,/*TuneCPU*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreSubtarget.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreSubtarget.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp:30,Deployability,Configurat,Configuration,30,/// XCore Code Generator Pass Configuration Options.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp:30,Modifiability,Config,Configuration,30,/// XCore Code Generator Pass Configuration Options.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h:8,Deployability,Pipeline,Pipeline,8,// Pass Pipeline Configuration,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h:17,Deployability,Configurat,Configuration,17,// Pass Pipeline Configuration,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h:17,Modifiability,Config,Configuration,17,// Pass Pipeline Configuration,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreTargetMachine.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/MCTargetDesc/XCoreMCTargetDesc.cpp:2,Performance,Tune,TuneCPU,2,/*TuneCPU*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/XCore/MCTargetDesc/XCoreMCTargetDesc.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/MCTargetDesc/XCoreMCTargetDesc.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Xtensa/AsmParser/XtensaAsmParser.cpp:107,Availability,error,error,107,"// If there wasn't a custom match, try the generic matcher below. Otherwise,; // there was a match, but an error occurred, in which case, just return that; // the operand parsing failed.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/Xtensa/AsmParser/XtensaAsmParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Xtensa/AsmParser/XtensaAsmParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Xtensa/MCTargetDesc/XtensaAsmBackend.cpp:37,Availability,error,error,37,// TODO maybe function should return error if (Count > 0),MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Target/Xtensa/MCTargetDesc/XtensaAsmBackend.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Xtensa/MCTargetDesc/XtensaAsmBackend.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:49,Integrability,depend,depends,49,"// Recursively enable all features that this one depends on. This handles all; // of the simple cases, where the behaviour doesn't depend on the base; // architecture version.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:131,Integrability,depend,depend,131,"// Recursively enable all features that this one depends on. This handles all; // of the simple cases, where the behaviour doesn't depend on the base; // architecture version.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:89,Usability,simpl,simple,89,"// Recursively enable all features that this one depends on. This handles all; // of the simple cases, where the behaviour doesn't depend on the base; // architecture version.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:21,Integrability,depend,dependencies,21,// Special cases for dependencies which vary depending on the base; // architecture version.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:45,Integrability,depend,depending,45,// Special cases for dependencies which vary depending on the base; // architecture version.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp:41,Integrability,depend,depends,41,// Recursively disable all features that depends on this one.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/AArch64TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/ARMTargetParserCommon.cpp:233,Availability,error,error,233,"// Parse a branch protection specification, which has the form; // standard | none | [bti,pac-ret[+b-key,+leaf,+pc]*]; // Returns true on success, with individual elements of the specification; // returned in `PBP`. Returns false in error, with `Err` containing; // an erroneous part of the spec.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/ARMTargetParserCommon.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/ARMTargetParserCommon.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:37,Safety,Detect,Detection,37,"//===-- Host.cpp - Implement OS Host Detection ------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file implements the operating system Host detection.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:430,Safety,detect,detection,430,"//===-- Host.cpp - Implement OS Host Detection ------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // This file implements the operating system Host detection.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:126,Integrability,rout,routines,126,//===----------------------------------------------------------------------===//; //; // Implementations of the CPU detection routines; //; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:116,Safety,detect,detection,116,//===----------------------------------------------------------------------===//; //; // Implementations of the CPU detection routines; //; //===----------------------------------------------------------------------===//,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:53,Energy Efficiency,Power,PowerPC,53,"// Access to the Processor Version Register (PVR) on PowerPC is privileged,; // and so we must use an operating-system interface to determine the current; // processor type. On Linux, this is exposed through the /proc/cpuinfo file.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:119,Integrability,interface,interface,119,"// Access to the Processor Version Register (PVR) on PowerPC is privileged,; // and so we must use an operating-system interface to determine the current; // processor type. On Linux, this is exposed through the /proc/cpuinfo file.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:3,Security,Access,Access,3,"// Access to the Processor Version Register (PVR) on PowerPC is privileged,; // and so we must use an operating-system interface to determine the current; // processor type. On Linux, this is exposed through the /proc/cpuinfo file.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:192,Security,expose,exposed,192,"// Access to the Processor Version Register (PVR) on PowerPC is privileged,; // and so we must use an operating-system interface to determine the current; // processor type. On Linux, this is exposed through the /proc/cpuinfo file.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:36,Security,access,accessible,36,"// The cpuid register on arm is not accessible from user space. On Linux,; // it is exposed through the /proc/cpuinfo file.; // Read 32 lines from /proc/cpuinfo, which should contain the CPU part line; // in all cases.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:84,Security,expose,exposed,84,"// The cpuid register on arm is not accessible from user space. On Linux,; // it is exposed through the /proc/cpuinfo file.; // Read 32 lines from /proc/cpuinfo, which should contain the CPU part line; // in all cases.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:118,Safety,predict,predictive,118,"// Samsung Electronics Co., Ltd.; // The Exynos chips have a convoluted ID scheme that doesn't seem to follow; // any predictive pattern across variants and parts.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:158,Performance,cache,cache,158,"// STIDP is a privileged operation, so use /proc/cpuinfo instead.; // The ""processor 0:"" line comes after a fair amount of other information,; // including a cache breakdown, but this should be plenty.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:3,Usability,Clear,Clear,3,/* Clear the whole attr in case its content changed by syscall. */,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:411,Testability,test,test-suite,411,"// The check below for i386 was copied from clang's cpuid.h (__get_cpuid_max).; // Check motivated by bug reports for OpenSSL crashing on CPUs without CPUID; // support. Consequently, for i386, the presence of CPUID is checked first; // via the corresponding eflags bit.; // Removal of cpuid.h header motivated by PR30384; // Header cpuid.h and method __get_cpuid_max are not used in llvm, clang, openmp; // or test-suite, but are used in external projects e.g. libstdcxx",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:25,Modifiability,portab,portable,25,// The MSVC intrinsic is portable across x86 and x64.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:43,Safety,detect,detect,43,// Read control register 0 (XCR0). Used to detect features such as AVX.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:11,Modifiability,extend,extended,11,// Examine extended family ID if family ID is F.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:28,Modifiability,extend,extended,28,// Bits 20 - 27; // Examine extended model ID if family ID is 6 or F.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:7,Integrability,Bridg,Bridge,7,// Ivy Bridge EP,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:49,Performance,optimiz,optimization,49,// Atom Silvermont codes from the Intel software optimization guide.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:62,Usability,guid,guide,62,// Atom Silvermont codes from the Intel software optimization guide.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:3,Usability,Clear,Clearwaterforest,3,// Clearwaterforest:,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:185,Safety,detect,detect,185,"// Unknown family 6 CPU, try to guess.; // Don't both with Type/Subtype here, they aren't used by the caller.; // They're used above to keep the code in sync with compiler-rt.; // TODO detect tigerlake host from model",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:178,Modifiability,extend,extended,178,// Get pointer to Communications Vector Table (CVT).; // The pointer is located at offset 16 of the Prefixed Save Area (PSA).; // It is stored as 31 bit pointer and will be zero-extended to 64 bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:14,Usability,clear,clear,14,// Explicitly clear the high order bit.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:41,Availability,avail,available,41,// TODO: simplify this once the macro is available in all OS levels.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:9,Usability,simpl,simplify,9,// TODO: simplify this once the macro is available in all OS levels.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:23,Safety,detect,detect,23,// Use processor id to detect cpu name.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:42,Safety,detect,detected,42,"// Miscellaneous memory related features, detected by; // using the 0x80000008 leaf of the CPUID instruction",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:127,Availability,avail,availability,127,"// There are two CPUID leafs which information associated with the pconfig; // instruction:; // EAX=0x7, ECX=0x0 indicates the availability of the instruction (via the 18th; // bit of EDX), while the EAX=0x1b leaf returns information on the; // availability of specific pconfig leafs.; // The target feature here only refers to the the first of these two.; // Users might need to check for the availability of specific pconfig; // leaves using cpuid, since that information is ignored while; // detecting features using the ""-march=native"" flag.; // For more info, see X86 ISA docs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:245,Availability,avail,availability,245,"// There are two CPUID leafs which information associated with the pconfig; // instruction:; // EAX=0x7, ECX=0x0 indicates the availability of the instruction (via the 18th; // bit of EDX), while the EAX=0x1b leaf returns information on the; // availability of specific pconfig leafs.; // The target feature here only refers to the the first of these two.; // Users might need to check for the availability of specific pconfig; // leaves using cpuid, since that information is ignored while; // detecting features using the ""-march=native"" flag.; // For more info, see X86 ISA docs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:394,Availability,avail,availability,394,"// There are two CPUID leafs which information associated with the pconfig; // instruction:; // EAX=0x7, ECX=0x0 indicates the availability of the instruction (via the 18th; // bit of EDX), while the EAX=0x1b leaf returns information on the; // availability of specific pconfig leafs.; // The target feature here only refers to the the first of these two.; // Users might need to check for the availability of specific pconfig; // leaves using cpuid, since that information is ignored while; // detecting features using the ""-march=native"" flag.; // For more info, see X86 ISA docs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp:495,Safety,detect,detecting,495,"// There are two CPUID leafs which information associated with the pconfig; // instruction:; // EAX=0x7, ECX=0x0 indicates the availability of the instruction (via the 18th; // bit of EDX), while the EAX=0x1b leaf returns information on the; // availability of specific pconfig leafs.; // The target feature here only refers to the the first of these two.; // Users might need to check for the availability of specific pconfig; // leaves using cpuid, since that information is ignored while; // detecting features using the ""-march=native"" flag.; // For more info, see X86 ISA docs.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Host.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp:422,Integrability,interface,interface,422,"//===- SubtargetFeature.cpp - CPU characteristics Implementation ----------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; /// \file Implements the SubtargetFeature interface.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp:3,Energy Efficiency,power,powerpc-apple,3,// powerpc-apple-*,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/SubtargetFeature.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/TargetParser.cpp:24,Availability,avail,available,24,"// Default to wave32 if available, or wave64 if not",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp:46,Testability,log,logic,46,// Some architectures require special parsing logic just to compute the; // ArchType result.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp:56,Integrability,depend,dependendent,56,"// ""xcoff"" must come before ""coff"" because of the order-dependendent; // pattern matching.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp:218,Safety,avoid,avoids,218,"// If the first component corresponds to a known architecture, preferentially; // use it for the architecture. If the second component corresponds to a; // known vendor, preferentially use it for the vendor, etc. This avoids silly; // component movement when a component parses as (eg) both a valid arch and a; // valid os.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp:16,Testability,log,logic,16,"// Special case logic goes here. At this point Arch, Vendor and OS have the; // correct values for the computed components.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/Triple.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:17,Modifiability,inherit,inherits,17,// SkylakeServer inherits all SkylakeClient features except SGX.; // FIXME: That doesn't match gcc.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:9,Integrability,Bridg,Bridge,9,// Sandy Bridge microarchitecture based processors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:7,Integrability,Bridg,Bridge,7,// Ivy Bridge microarchitecture based processors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:3,Usability,Clear,Clearwaterforest,3,// Clearwaterforest microarchitecture based processors.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:17,Safety,avoid,avoid,17,// FIXME: Can we avoid a linear search here? The table might be sorted by; // CPUKind so we could binary search?,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:20,Integrability,depend,dependencies,20,// Features with no dependencies.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:22,Integrability,depend,dependent,22,// XSAVE features are dependent on basic XSAVE.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:127,Integrability,depend,dependencies,127,// FIXME: These two aren't really implemented and just exist in the feature; // list for __builtin_cpu_supports. So omit their dependencies.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:50,Security,validat,validate,50,// Remove the 64-bit feature which we only use to validate if a CPU can; // be used with 64-bit mode.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:38,Integrability,depend,dependent,38,"// Check all features looking for any dependent on this feature. If we find; // one, mark it and recursively find any feature that depend on it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:131,Integrability,depend,depend,131,"// Check all features looking for any dependent on this feature. If we find; // one, mark it and recursively find any feature that depend on it.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp:3,Deployability,Update,Update,3,// Update the map entry for all implied features.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TargetParser/X86TargetParser.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:58,Testability,test,tests,58,"//===--- Annotations.cpp - Annotated source code for unit tests --*- C++-*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:85,Availability,error,error,85,"// Crash if the assertion fails, printing the message and testcase.; // More elegant error handling isn't needed for unit tests.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:46,Integrability,message,message,46,"// Crash if the assertion fails, printing the message and testcase.; // More elegant error handling isn't needed for unit tests.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:16,Testability,assert,assertion,16,"// Crash if the assertion fails, printing the message and testcase.; // More elegant error handling isn't needed for unit tests.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:58,Testability,test,testcase,58,"// Crash if the assertion fails, printing the message and testcase.; // More elegant error handling isn't needed for unit tests.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp:122,Testability,test,tests,122,"// Crash if the assertion fails, printing the message and testcase.; // More elegant error handling isn't needed for unit tests.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Annotations/Annotations.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp:28,Availability,Error,Error,28,"//===- llvm/Testing/Support/Error.cpp -------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp:12,Testability,Test,Testing,12,"//===- llvm/Testing/Support/Error.cpp -------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/Error.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp:7,Integrability,Interface,InterfaceFile,7,"//===- InterfaceFile.cpp --------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Implements the Interface File.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp:398,Integrability,Interface,Interface,398,"//===- InterfaceFile.cpp --------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Implements the Interface File.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/InterfaceFile.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/Platform.cpp:13,Integrability,bridg,bridgeOS,13,// TODO: add bridgeOS & driverKit once in llvm::Triple,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/Platform.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/Platform.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp:31,Availability,Error,Error,31,"//===- TextAPIError.cpp - Tapi Error ----------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// \brief Implements TAPI Error.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp:419,Availability,Error,Error,419,"//===- TextAPIError.cpp - Tapi Error ----------------------------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// \brief Implements TAPI Error.; ///; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextAPIError.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:403,Testability,stub,stub,403,"//===- TextStub.cpp -------------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Implements the text stub file reader/writer.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:417,Deployability,install,install-name,417,"// clang-format off; /*. YAML Format specification. The TBD v1 format only support two level address libraries and is per; definition application extension safe. --- # the tag !tapi-tbd-v1 is optional and; # shouldn't be emitted to support older linker.; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; platform: ios # Specifies the platform (macosx, ios, etc); install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: none # Optional: defaults to none; exports: # List of export sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; */; /*. YAML Format specification. --- !tapi-tbd-v2; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-c",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:1515,Deployability,install,install-name,1515," defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: none # Optional: defaults to none; exports: # List of export sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; */; /*. YAML Format specification. --- !tapi-tbd-v2; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of a",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:3050,Deployability,install,install-name,3050," Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd-v3; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undef",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:4763,Deployability,install,install-name,4763,"tional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd; tbd-version: 4 # The tbd version for format; targets: [ armv7-ios, x86_64-maccatalyst ] # The list of applicable tapi supported target triples; uuids: # Optional: List of target and UUID pairs.; - target: armv7-ios; value: ...; - target: x86_64-maccatalyst; value: ...; flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; parent-umbrella: # Optional:; allowable-clients:; - targets: [ armv7-ios ] # Optional:; clients: [ clientA ]; exports: # List of export sections; ...; re-exports: # List of reexport sections; ...; undefineds: # List of undefineds sections; ... Each export and reexport section is defined as following:. - targets: [ arm64-macos ] # The list of target triples associated with symbols; symbols: [ _symA ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; - targets: [ arm64-macos, x86_64-maccatalyst ] # Optio",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:1065,Modifiability,Variab,Variables,1065,"// clang-format off; /*. YAML Format specification. The TBD v1 format only support two level address libraries and is per; definition application extension safe. --- # the tag !tapi-tbd-v1 is optional and; # shouldn't be emitted to support older linker.; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; platform: ios # Specifies the platform (macosx, ios, etc); install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: none # Optional: defaults to none; exports: # List of export sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; */; /*. YAML Format specification. --- !tapi-tbd-v2; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-c",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:2261,Modifiability,Variab,Variables,2261,"ional: List of thread local symbols; */; /*. YAML Format specification. --- !tapi-tbd-v2; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd-v3; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Opt",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:2667,Modifiability,Variab,Variables,2667," Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd-v3; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:3870,Modifiability,Variab,Variables,3870,"; /*. YAML Format specification. --- !tapi-tbd-v3; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd; tbd-version: 4 # The tbd version for format; targets: [ armv7-ios, x86_64-maccatalyst ] # The list of applicable tapi supported target triples; uuids: # Optional: List of target and UUID pairs.; - target: armv7-ios; value: ...; - target: x86_64-maccatalyst; value: ...; fla",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:4346,Modifiability,Variab,Variables,4346,"tional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols. Each undefineds section is defined as following:; - archs: [ arm64 ] # the list of architecture slices; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd; tbd-version: 4 # The tbd version for format; targets: [ armv7-ios, x86_64-maccatalyst ] # The list of applicable tapi supported target triples; uuids: # Optional: List of target and UUID pairs.; - target: armv7-ios; value: ...; - target: x86_64-maccatalyst; value: ...; flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; parent-umbrella: # Optional:; allowable-clients:; - targets: [ armv7-ios ] # Optional:; clients: [ clientA ]; exports: # List of export sections; ...; re-exports: # List of reexport sections; ...; undefineds: # List of undefineds sections; ... Each export and reexp",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:5573,Modifiability,Variab,Variables,5573,": List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd; tbd-version: 4 # The tbd version for format; targets: [ armv7-ios, x86_64-maccatalyst ] # The list of applicable tapi supported target triples; uuids: # Optional: List of target and UUID pairs.; - target: armv7-ios; value: ...; - target: x86_64-maccatalyst; value: ...; flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; parent-umbrella: # Optional:; allowable-clients:; - targets: [ armv7-ios ] # Optional:; clients: [ clientA ]; exports: # List of export sections; ...; re-exports: # List of reexport sections; ...; undefineds: # List of undefineds sections; ... Each export and reexport section is defined as following:. - targets: [ arm64-macos ] # The list of target triples associated with symbols; symbols: [ _symA ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; - targets: [ arm64-macos, x86_64-maccatalyst ] # Optional: Targets for applicable additional symbols; symbols: [ _symB ] # Optional: List of symbols. Each undefineds section is defined as following:; - targets: [ arm64-macos ] # The list of target triples associated with symbols; symbols: [ _symC ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-symbols: [] # Optional: List of weak defined symbols; */; // clang-format on",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:6223,Modifiability,Variab,Variables,6223,": List of Objective C Instance Variables; weak-ref-symbols: [] # Optional: List of weak defined symbols; */; /*. YAML Format specification. --- !tapi-tbd; tbd-version: 4 # The tbd version for format; targets: [ armv7-ios, x86_64-maccatalyst ] # The list of applicable tapi supported target triples; uuids: # Optional: List of target and UUID pairs.; - target: armv7-ios; value: ...; - target: x86_64-maccatalyst; value: ...; flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-abi-version: 0 # Optional: defaults to 0; parent-umbrella: # Optional:; allowable-clients:; - targets: [ armv7-ios ] # Optional:; clients: [ clientA ]; exports: # List of export sections; ...; re-exports: # List of reexport sections; ...; undefineds: # List of undefineds sections; ... Each export and reexport section is defined as following:. - targets: [ arm64-macos ] # The list of target triples associated with symbols; symbols: [ _symA ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; - targets: [ arm64-macos, x86_64-maccatalyst ] # Optional: Targets for applicable additional symbols; symbols: [ _symB ] # Optional: List of symbols. Each undefineds section is defined as following:; - targets: [ arm64-macos ] # The list of target triples associated with symbols; symbols: [ _symC ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-eh-types: [] # Optional: List of Objective-C classes; # with EH; objc-ivars: [] # Optional: List of Objective C Instance Variables; weak-symbols: [] # Optional: List of weak defined symbols; */; // clang-format on",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:156,Safety,safe,safe,156,"// clang-format off; /*. YAML Format specification. The TBD v1 format only support two level address libraries and is per; definition application extension safe. --- # the tag !tapi-tbd-v1 is optional and; # shouldn't be emitted to support older linker.; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; platform: ios # Specifies the platform (macosx, ios, etc); install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: none # Optional: defaults to none; exports: # List of export sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-clients: [ client ] # Optional: List of clients; re-exports: [ ] # Optional: List of re-exports; symbols: [ _sym ] # Optional: List of symbols; objc-classes: [] # Optional: List of Objective-C classes; objc-ivars: [] # Optional: List of Objective C Instance; # Variables; weak-def-symbols: [] # Optional: List of weak defined symbols; thread-local-symbols: [] # Optional: List of thread local symbols; */; /*. YAML Format specification. --- !tapi-tbd-v2; archs: [ armv7, armv7s, arm64 ] # the list of architecture slices that are; # supported by this file.; uuids: [ armv7:... ] # Optional: List of architecture and UUID pairs.; platform: ios # Specifies the platform (macosx, ios, etc); flags: [] # Optional:; install-name: /u/l/libfoo.dylib #; current-version: 1.2.3 # Optional: defaults to 1.0; compatibility-version: 1.0 # Optional: defaults to 1.0; swift-version: 0 # Optional: defaults to 0; objc-constraint: retain_release # Optional: defaults to retain_release; parent-umbrella: # Optional:; exports: # List of export sections; ...; undefineds: # List of undefineds sections; ... Each export section is defined as following:. - archs: [ arm64 ] # the list of architecture slices; allowed-c",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:20,Integrability,interface,interface,20,// Fill vector with interface file objects created by parsing the YAML file.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:66,Availability,error,error,66,"// YAMLIn dynamically allocates for Interface file and in case of error,; // memory leak will occur unless wrapped around unique_ptr",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:22,Energy Efficiency,allocate,allocates,22,"// YAMLIn dynamically allocates for Interface file and in case of error,; // memory leak will occur unless wrapped around unique_ptr",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:36,Integrability,Interface,Interface,36,"// YAMLIn dynamically allocates for Interface file and in case of error,; // memory leak will occur unless wrapped around unique_ptr",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:107,Integrability,wrap,wrapped,107,"// YAMLIn dynamically allocates for Interface file and in case of error,; // memory leak will occur unless wrapped around unique_ptr",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp:2,Integrability,Wrap,WrapColumn,2,/*WrapColumn=*/,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStub.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.cpp:406,Testability,Stub,Stub,406,"//===- TextStubCommon.cpp -------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Implements common Text Stub YAML mappings.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.h:403,Testability,Stub,Stub,403,"//===- TextStubCommon.h ---------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Defines common Text Stub YAML mappings.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.h,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubCommon.h
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp:399,Testability,Stub,Stub,399,"//===- TextStubV5.cpp -----------------------------------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Implements Text Stub JSON mappings.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp:658,Deployability,install,install,658,"// clang-format off; /*. JSON Format specification. All library level keys, accept target values and are defaulted if not specified. . {; ""tapi_tbd_version"": 5, # Required: TBD version for all documents in file; ""main_library"": { # Required: top level library; ""target_info"": [ # Required: target information ; {; ""target"": ""x86_64-macos"",; ""min_deployment"": ""10.14"" # Optional: minOS defaults to 0; },; {; ""target"": ""arm64-macos"",; ""min_deployment"": ""10.14""; },; {; ""target"": ""arm64-maccatalyst"",; ""min_deployment"": ""12.1""; }],; ""flags"":[{""attributes"": [""flat_namespace""]}], # Optional:; ""install_names"":[{""name"":""/S/L/F/Foo.fwk/Foo""}], # Required: library install name ; ""current_versions"":[{""version"": ""1.2""}], # Optional: defaults to 1; ""compatibility_versions"":[{ ""version"": ""1.1""}], # Optional: defaults to 1; ""rpaths"": [ # Optional: ; {; ""targets"": [""x86_64-macos""], # Optional: defaults to targets in `target-info`; ""paths"": [""@executable_path/.../Frameworks""]; }],; ""parent_umbrellas"": [{""umbrella"": ""System""}],; ""allowable_clients"": [{""clients"": [""ClientA""]}],; ""reexported_libraries"": [{""names"": [""/u/l/l/foo.dylib""]}],; ""exported_symbols"": [{ # List of export symbols section; ""targets"": [""x86_64-macos"", ""arm64-macos""], # Optional: defaults to targets in `target-info`; ""text"": { # List of Text segment symbols ; ""global"": [ ""_func"" ],; ""weak"": [],; ""thread_local"": []; },; ""data"": { ... }, # List of Data segment symbols; }],; ""reexported_symbols"": [{ ... }], # List of reexported symbols section; ""undefined_symbols"": [{ ... }] # List of undefined symbols section; },; ""libraries"": [ # Optional: Array of inlined libraries; {...}, {...}, {...}; ]; }; */; // clang-format on",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp:13,Testability,Stub,StubParser,13,// namespace StubParser,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/TextStubV5.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp:78,Performance,load,load,78,// Record unknown platform for older binaries that don't enforce platform; // load commands.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp:36,Availability,error,error,36,// Skip the archive and consume the error.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TextAPI/BinaryReader/DylibReader.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp:394,Integrability,interface,interface,394,"//===- DlltoolDriver.cpp - dlltool.exe-compatible driver ------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Defines an interface to a dlltool.exe-compatible driver.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp:211,Safety,avoid,avoids,211,"// If ExtName is set (if the ""ExtName = Name"" syntax was used), overwrite; // Name with ExtName and clear ExtName. When only creating an import; // library and not linking, the internal name is irrelevant. This avoids; // cases where writeImportLibrary tries to transplant decoration from; // symbol decoration onto ExtName.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp:100,Usability,clear,clear,100,"// If ExtName is set (if the ""ExtName = Name"" syntax was used), overwrite; // Name with ExtName and clear ExtName. When only creating an import; // library and not linking, the internal name is irrelevant. This avoids; // cases where writeImportLibrary tries to transplant decoration from; // symbol decoration onto ExtName.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-dlltool/DlltoolDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp:394,Integrability,interface,interface,394,"//===- LibDriver.cpp - lib.exe-compatible driver --------------------------===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; //; // Defines an interface to a lib.exe-compatible driver that also understands; // bitcode files. Used by llvm-lib and lld-link /lib.; //; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp:28,Availability,error,error,28,// lib.exe doesn't print an error if no .lib files are passed.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp:440,Availability,error,errors,440,"// Check that all input files have the same machine type.; // Mixing normal objects and LTO bitcode files is fine as long as they; // have the same machine type.; // Doing this here duplicates the header parsing work that writeArchive(); // below does, but it's not a lot of work and it's a bit awkward to do; // in writeArchive() which needs to support many tools, can't assume the; // input is COFF, and doesn't have a good way to report errors.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ToolDrivers/llvm-lib/LibDriver.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:102,Safety,avoid,avoid,102,"// As with the one-use checks below, this is not strictly necessary, but we; // are being cautious to avoid potential perf regressions on targets that; // do not actually have a funnel/rotate instruction (where the funnel shift; // would be expanded back into math/shift/logic ops).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:271,Testability,log,logic,271,"// As with the one-use checks below, this is not strictly necessary, but we; // are being cautious to avoid potential perf regressions on targets that; // do not actually have a funnel/rotate instruction (where the funnel shift; // would be expanded back into math/shift/logic ops).",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:111,Safety,avoid,avoid,111,"// The incoming block with our source operand must be the ""guard"" block.; // That must contain a cmp+branch to avoid the funnel/rotate when the shift; // amount is equal to 0. The other incoming block is the block with the; // funnel/rotate.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:101,Availability,Mask,Mask,101,"/// This is used by foldAnyOrAllBitsSet() to capture a source value (Root) and; /// the bit indexes (Mask) needed by a masked compare. If we're matching a chain; /// of 'and' ops, then we also need to capture the fact that we saw an; /// ""and X, 1"", so that's an extra return value for that case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:119,Availability,mask,masked,119,"/// This is used by foldAnyOrAllBitsSet() to capture a source value (Root) and; /// the bit indexes (Mask) needed by a masked compare. If we're matching a chain; /// of 'and' ops, then we also need to capture the fact that we saw an; /// ""and X, 1"", so that's an extra return value for that case.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:205,Usability,clear,cleared,205,"// Recurse through a chain of 'and' operands. This requires an extra check; // vs. the 'or' matcher: we must find an ""and X, 1"" instruction somewhere; // in the chain to know that all of the high bits are cleared.",MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:61,Usability,simpl,simplified,61,// The shift constant is out-of-range? This code hasn't been simplified.,MatchSource.CODE_COMMENT,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp
