id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://root.cern/root/html530/TMap.html:12182,Integrability,depend,depending,12182,"(Bool_t dir = kIterForward) const; Create an iterator for TMap. void PrintCollectionEntry(TObject* entry, Option_t* option, Int_t recurse) const; Print the collection entry. void Rehash(Int_t newCapacity, Bool_t checkObjValidity = kTRUE); Rehash the underlaying THashTable (see THashTable::Rehash()). TObject * Remove(TObject* key); Remove the (key,value) pair with key from the map. Returns the; key object or 0 in case key was not found. If map is the owner; of values, the value is deleted. TPair * RemoveEntry(TObject* key); Remove (key,value) pair with key from the map. Returns the; pair object or 0 in case the key was not found.; It is caller's responsibility to delete the pair and, eventually,; the key and value objects. void SetOwnerValue(Bool_t enable = kTRUE); Set whether this map is the owner (enable==true); of its values. If it is the owner of its contents,; these objects will be deleted whenever the collection itself; is deleted. The objects might also be deleted or destructed when Clear; is called (depending on the collection). void SetOwnerKeyValue(Bool_t ownkeys = kTRUE, Bool_t ownvals = kTRUE); Set ownership for keys and values. void Streamer(TBuffer& b); Stream all key/value pairs in the map to or from the I/O buffer. TMap(const TMap& map). TMap& operator=(const TMap& map). void DeleteKeys(); { Delete(); }. TObject ** GetObjectRef(const TObject* obj) const; { return fTable->GetObjectRef(obj); }. const THashTable * GetTable() const; { return fTable; }. Bool_t IsOwnerValue() const; { return TestBit(kIsOwnerValue); }. TObject * operator()(const char* keyname) const; { return GetValue(keyname); }. TObject * operator()(const TObject* key) const; { return GetValue(key); }. » Author: Fons Rademakers 12/11/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/cont:$Id: TMap.h 34744 2010-08-07 06:16:36Z brun $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the doc",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMap.html:615,Modifiability,inherit,inherit,615,". TMap. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » CONT; » TMap. class TMap: public TCollection. TMap. TMap implements an associative array of (key,value) pairs using a; THashTable for efficient retrieval (therefore TMap does not conserve; the order of the entries). The hash value is calculated; using the value returned by the keys Hash() function and the; key comparison is done via the IsEqual() function.; Both key and value must inherit from TObject. /*. */. Function Members (Methods); public:. TMap(Int_t capacity = TCollection::kInitHashTableCapacity, Int_t rehash = 0); virtual~TMap(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(TObject* obj); voidAdd(TObject* key, TObject* value); virtual voidTCollection::AddAll(const TCollection* col); voidTCollection::AddVector(TObject* obj1); virtual voidTObject::AppendPad(Option_t* option = """"); Bool_tTCollection::AssertClass(TClass* cl) const; Float_tAverageCollisions() const; virtual voidTCollection::Browse(TBrowser* b); Int_tCapacity() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TCollection::Clone(const char* newname = """") const; Int_tCollisions(const char* keyname) const; Int_tCollisions(TObject* key) const; virtual Int_tTCollection::Compare(const TObject* obj) const; Bool_tTCollection::Contains(const char* name) const; Bool_tTCollection::Contains(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidDelete(Option_t* option = """"); voidDeleteAll(); Bool_tDeleteEntry(TObject* key); voidDeleteKeys(); voidDeleteValues(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTCollection::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TOb",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMap.html:451,Security,hash,hash,451,". TMap. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » CONT; » TMap. class TMap: public TCollection. TMap. TMap implements an associative array of (key,value) pairs using a; THashTable for efficient retrieval (therefore TMap does not conserve; the order of the entries). The hash value is calculated; using the value returned by the keys Hash() function and the; key comparison is done via the IsEqual() function.; Both key and value must inherit from TObject. /*. */. Function Members (Methods); public:. TMap(Int_t capacity = TCollection::kInitHashTableCapacity, Int_t rehash = 0); virtual~TMap(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(TObject* obj); voidAdd(TObject* key, TObject* value); virtual voidTCollection::AddAll(const TCollection* col); voidTCollection::AddVector(TObject* obj1); virtual voidTObject::AppendPad(Option_t* option = """"); Bool_tTCollection::AssertClass(TClass* cl) const; Float_tAverageCollisions() const; virtual voidTCollection::Browse(TBrowser* b); Int_tCapacity() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TCollection::Clone(const char* newname = """") const; Int_tCollisions(const char* keyname) const; Int_tCollisions(TObject* key) const; virtual Int_tTCollection::Compare(const TObject* obj) const; Bool_tTCollection::Contains(const char* name) const; Bool_tTCollection::Contains(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidDelete(Option_t* option = """"); voidDeleteAll(); Bool_tDeleteEntry(TObject* key); voidDeleteKeys(); voidDeleteValues(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTCollection::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TOb",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMap.html:8941,Security,hash,hashtable,8941,"ick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTCollection::fNamename of the collection; Int_tTCollection::fSizenumber of elements in collection. private:. THashTable*fTableHash table used to store TPair's. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMap(Int_t capacity = TCollection::kInitHashTableCapacity, Int_t rehash = 0); TMap ctor. See THashTable for a description of the arguments. ~TMap(); TMap dtor. Objects are not deleted unless the TMap is the; owner (set via SetOwner()). void Add(TObject* obj); This function may not be used (but we need to provide it since it is; a pure virtual in TCollection). Use Add(key,value) instead. void Add(TObject* key, TObject* value); Add a (key,value) pair to the map. Float_t AverageCollisions() const; Return the ratio of entries vs occupied slots. Int_t Capacity() const; Return number of slots in the hashtable. Use GetSize() to get the; number of objects stored in the TMap. void Clear(Option_t* option = """"); Remove all (key,value) pairs from the map. The keys/values are; deleted depending on the state of key-ownership (SetOwner()) and; value-ownership (SetOwnerValue()). To delete these objects regardless of the ownership state use:; - Delete() to delete only keys;; - DeleteValues() to delete only values;; - DeleteAll() to delete both keys and values. Int_t Collisions(const char* keyname) const; Returns the number of collisions for a key with a certain name; (i.e. number of objects in same slot in the hash table, i.e. length; of linked list). Int_t Collisions(TObject* key) const; Returns the number of collisions for a key (i.e. number of objects; in same slot in the hash table, i.e. length of linked list). void Delete(Option_t* option = """"); Remove all (key,value) pairs from the map AND delete the keys; when they are allocated on the heap. void DeleteValues(); ",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMap.html:9553,Security,hash,hash,9553,"is the; owner (set via SetOwner()). void Add(TObject* obj); This function may not be used (but we need to provide it since it is; a pure virtual in TCollection). Use Add(key,value) instead. void Add(TObject* key, TObject* value); Add a (key,value) pair to the map. Float_t AverageCollisions() const; Return the ratio of entries vs occupied slots. Int_t Capacity() const; Return number of slots in the hashtable. Use GetSize() to get the; number of objects stored in the TMap. void Clear(Option_t* option = """"); Remove all (key,value) pairs from the map. The keys/values are; deleted depending on the state of key-ownership (SetOwner()) and; value-ownership (SetOwnerValue()). To delete these objects regardless of the ownership state use:; - Delete() to delete only keys;; - DeleteValues() to delete only values;; - DeleteAll() to delete both keys and values. Int_t Collisions(const char* keyname) const; Returns the number of collisions for a key with a certain name; (i.e. number of objects in same slot in the hash table, i.e. length; of linked list). Int_t Collisions(TObject* key) const; Returns the number of collisions for a key (i.e. number of objects; in same slot in the hash table, i.e. length of linked list). void Delete(Option_t* option = """"); Remove all (key,value) pairs from the map AND delete the keys; when they are allocated on the heap. void DeleteValues(); Remove all (key,value) pairs from the map AND delete the values; when they are allocated on the heap. void DeleteAll(); Remove all (key,value) pairs from the map AND delete the keys AND; values when they are allocated on the heap. Bool_t DeleteEntry(TObject* key); Remove (key,value) pair with key from the map. Returns true; if the key was found and removed, false otherwise.; The key and value objects are deleted if map is the owner; of keys and values respectively. TObject * FindObject(const char* keyname) const; Check if a (key,value) pair exists with keyname as name of the key.; Returns a TPair* (need to downcast",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMap.html:9721,Security,hash,hash,9721,"d(key,value) instead. void Add(TObject* key, TObject* value); Add a (key,value) pair to the map. Float_t AverageCollisions() const; Return the ratio of entries vs occupied slots. Int_t Capacity() const; Return number of slots in the hashtable. Use GetSize() to get the; number of objects stored in the TMap. void Clear(Option_t* option = """"); Remove all (key,value) pairs from the map. The keys/values are; deleted depending on the state of key-ownership (SetOwner()) and; value-ownership (SetOwnerValue()). To delete these objects regardless of the ownership state use:; - Delete() to delete only keys;; - DeleteValues() to delete only values;; - DeleteAll() to delete both keys and values. Int_t Collisions(const char* keyname) const; Returns the number of collisions for a key with a certain name; (i.e. number of objects in same slot in the hash table, i.e. length; of linked list). Int_t Collisions(TObject* key) const; Returns the number of collisions for a key (i.e. number of objects; in same slot in the hash table, i.e. length of linked list). void Delete(Option_t* option = """"); Remove all (key,value) pairs from the map AND delete the keys; when they are allocated on the heap. void DeleteValues(); Remove all (key,value) pairs from the map AND delete the values; when they are allocated on the heap. void DeleteAll(); Remove all (key,value) pairs from the map AND delete the keys AND; values when they are allocated on the heap. Bool_t DeleteEntry(TObject* key); Remove (key,value) pair with key from the map. Returns true; if the key was found and removed, false otherwise.; The key and value objects are deleted if map is the owner; of keys and values respectively. TObject * FindObject(const char* keyname) const; Check if a (key,value) pair exists with keyname as name of the key.; Returns a TPair* (need to downcast from TObject). Use Key() and; Value() to get the pointers to the key and value, respectively.; Returns 0 if not found. TObject * FindObject(const TObject* key) const;",MatchSource.WIKI,root/html530/TMap.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMap.html
https://root.cern/root/html530/TMapFile.html:2414,Availability,robust,robust,2414,"directly in shared memory in the; producer, but the consumer still has to copy the object from; shared memory into a local object which has the correct vtbl; pointer for that process (copy ctor's can be used for creating; the local copy).; 2) Another possibility is to only allow objects without virtual; functions in shared memory (like simple C structs), or to; forbid (how?) the consumer from calling any virtual functions; of the objects in shared memory.; 3) A last option is to copy the object internals to shared memory; and copy them again from there. This is what is done in the; TMapFile (using the object Streamer() to make a deep copy).; Option 1) saves one copy, but requires solid copy ctor's (along the; full inheritance chain) to rebuild the object in the consumer. Most; classes don't provide these copy ctor's, especially not when objects; contain collections, etc. 2) is too limiting or dangerous (calling; accidentally a virtual function will segv). So since we have a; robust Streamer mechanism I opted for 3). Function Members (Methods); public:. virtual~TMapFile(); voidTObject::AbstractMethod(const char* method) const; voidAdd(const TObject* obj, const char* name = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); Bool_tcd(const char* path = 0); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidClose(Option_t* option = """"); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; static TMapFile*Create(const char* name, Option_t* option = ""READ"", Int_t size = kDefaultMapSize, const char* title = """"); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::Dr",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:3657,Availability,error,error,3657," option = """"); virtual voidBrowse(TBrowser* b); Bool_tcd(const char* path = 0); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidClose(Option_t* option = """"); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; static TMapFile*Create(const char* name, Option_t* option = ""READ"", Int_t size = kDefaultMapSize, const char* title = """"); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TObject*Get(const char* name, TObject* retObj = 0); void*GetBaseAddr() const; void*GetBreakval() const; TDirectory*GetDirectory() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetFd() const; TMapRec*GetFirst() const; virtual const char*TObject::GetIconName() const; TMapRec*GetLast() const; void*GetMmallocDesc() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual const char*GetOption() const; Int_tGetSize() const; virtual const char*GetTitle() const; virtual UInt_tTObject::GetUniqueID",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:3741,Availability,error,error,3741,"ic TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidClose(Option_t* option = """"); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; static TMapFile*Create(const char* name, Option_t* option = ""READ"", Int_t size = kDefaultMapSize, const char* title = """"); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TObject*Get(const char* name, TObject* retObj = 0); void*GetBaseAddr() const; void*GetBreakval() const; TDirectory*GetDirectory() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetFd() const; TMapRec*GetFirst() const; virtual const char*TObject::GetIconName() const; TMapRec*GetLast() const; void*GetMmallocDesc() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual const char*GetOption() const; Int_tGetSize() const; virtual const char*GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject:",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:11893,Availability,error,error,11893,"ce the object actually into shared memory call Update(). void Update(TObject* obj = 0); Update an object (or all objects, if obj == 0) in shared memory. TObject * Remove(TObject* obj, Bool_t lock); Remove object from shared memory. Returns pointer to removed; object if successful, 0 otherwise. TObject * Remove(const char* name, Bool_t lock); Remove object by name from shared memory. Returns pointer to removed; object if successful, 0 otherwise. void RemoveAll(); Remove all objects from shared memory. TObject * Get(const char* name, TObject* retObj = 0); Return pointer to object retrieved from shared memory. The object must; be deleted after use. If delObj is a pointer to a previously allocated; object it will be deleted. Returns 0 in case object with the given; name does not exist. void CreateSemaphore(Int_t pid = 0); Create semaphore used for synchronizing access to shared memory. void DeleteSemaphore(); Delete the semaphore. Int_t AcquireSemaphore(); Acquire semaphore. Returns 0 if OK, -1 on error. Int_t ReleaseSemaphore(); Release semaphore. Returns 0 if OK, -1 on error. void Close(Option_t* option = """"); Close a mapped file. First detach mapped memory then close file.; No member functions of a TMapFile that was opened in write mode; may be called after Close() (this includes, of course, ""delete"" which; would call the dtors). The option=""dtor"" is only used when called; via the ~TMapFile. TMapFile * FindShadowMapFile(); Returns shadow map file. void Print(Option_t* option = """") const; Print some info about the mapped file. Bool_t IsFolder() const; Returns kTRUE in case object is a folder (i.e. contains browsable lists). void Browse(TBrowser* b); Browse contents of TMapFile. Bool_t cd(const char* path = 0); Cd to associated directory,. void ls(Option_t* option = """") const; List contents of TMapFile. void SumBuffer(Int_t bufsize); Increment statistics for buffer sizes of objects in this file. Int_t GetBestBuffer(); Return the best buffer size for objects in this fil",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:11968,Availability,error,error,11968,"t* obj = 0); Update an object (or all objects, if obj == 0) in shared memory. TObject * Remove(TObject* obj, Bool_t lock); Remove object from shared memory. Returns pointer to removed; object if successful, 0 otherwise. TObject * Remove(const char* name, Bool_t lock); Remove object by name from shared memory. Returns pointer to removed; object if successful, 0 otherwise. void RemoveAll(); Remove all objects from shared memory. TObject * Get(const char* name, TObject* retObj = 0); Return pointer to object retrieved from shared memory. The object must; be deleted after use. If delObj is a pointer to a previously allocated; object it will be deleted. Returns 0 in case object with the given; name does not exist. void CreateSemaphore(Int_t pid = 0); Create semaphore used for synchronizing access to shared memory. void DeleteSemaphore(); Delete the semaphore. Int_t AcquireSemaphore(); Acquire semaphore. Returns 0 if OK, -1 on error. Int_t ReleaseSemaphore(); Release semaphore. Returns 0 if OK, -1 on error. void Close(Option_t* option = """"); Close a mapped file. First detach mapped memory then close file.; No member functions of a TMapFile that was opened in write mode; may be called after Close() (this includes, of course, ""delete"" which; would call the dtors). The option=""dtor"" is only used when called; via the ~TMapFile. TMapFile * FindShadowMapFile(); Returns shadow map file. void Print(Option_t* option = """") const; Print some info about the mapped file. Bool_t IsFolder() const; Returns kTRUE in case object is a folder (i.e. contains browsable lists). void Browse(TBrowser* b); Browse contents of TMapFile. Bool_t cd(const char* path = 0); Cd to associated directory,. void ls(Option_t* option = """") const; List contents of TMapFile. void SumBuffer(Int_t bufsize); Increment statistics for buffer sizes of objects in this file. Int_t GetBestBuffer(); Return the best buffer size for objects in this file. The best buffer size is estimated based on the current mean value; and s",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:8613,Deployability,update,update,8613,"t*Remove(const char* name, Bool_t lock); voidSumBuffer(Int_t bufsize). Data Members; public:. enum { kDefaultMapSize; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. ULong_tfBaseAddrBase address of mapped memory region; TList*fBrowseListList of KeyMapFile objects; TDirectory*fDirectoryPointer to directory associated to this mapfile; Int_tfFdDescriptor of mapped file; TMapRec*fFirstList of streamed objects is shared memory; TObject*fGettingDon't deadlock in update mode, when from Get() Add() is called; TMapRec*fLastLast object in list of shared objects; void*fMmallocDescPointer to mmalloc descriptor; char*fNameName of mapped file; Long_tfOffsetOffset in bytes for region mapped by reader; char*fOptionDirectory creation options; Int_tfSemaphoreModification semaphore (or getpid() for WIN32); Int_tfSizeOriginal start size of memory mapped region; Double_tfSum2BufferSum of squares of buffer sizes of objects written so far; Double_tfSumBufferSum of buffer sizes of objects written sofar; char*fTitleTitle of mapped file; Int_tfVersionROOT version (or -1 for shadow map file); Bool_tfWritableTRUE if mapped file opened in RDWR mode; Int_tfWrittenNumber of objects written sofar; static Long_tfgMapAddressMap to this address, set address via SetMapAddress(); static void*fgMmallocDescUsed in Close() and operator delete(); ULong_tfhSemaphoreHANDLE of WIN32 Mutex object to implement semaphore. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMapFile(); Default ctor. Does not much except setting some basic values. TMapFile(const char* name, const char* title, Option_t* option, Int_t size, TMapFile*& newMapFile); Create a memory mapped file. This opens a file (to which the; memory will be mapped) and attaches a memory region to i",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:1405,Energy Efficiency,allocate,allocate,1405,") also whenever the mapped object(s) change(s); call Update() to put a fresh copy in the shared memory. This extra; step is necessary since it is not possible to share objects with; virtual pointers between processes (the vtbl ptr points to the; originators unique address space and can not be used by the; consumer process(es)). Consumer processes can map the memory region; from this file and access the objects stored in it via the Get(); method (which returns a copy of the object stored in the shared; memory with correct vtbl ptr set). Only objects of classes with a; Streamer() member function defined can be shared. I know the current implementation is not ideal (you need to copy to; and from the shared memory file) but the main problem is with the; class' virtual_table pointer. This pointer points to a table unique; for every process. Therefore, different options are:; 1) One could allocate an object directly in shared memory in the; producer, but the consumer still has to copy the object from; shared memory into a local object which has the correct vtbl; pointer for that process (copy ctor's can be used for creating; the local copy).; 2) Another possibility is to only allow objects without virtual; functions in shared memory (like simple C structs), or to; forbid (how?) the consumer from calling any virtual functions; of the objects in shared memory.; 3) A last option is to copy the object internals to shared memory; and copy them again from there. This is what is done in the; TMapFile (using the object Streamer() to make a deep copy).; Option 1) saves one copy, but requires solid copy ctor's (along the; full inheritance chain) to rebuild the object in the consumer. Most; classes don't provide these copy ctor's, especially not when objects; contain collections, etc. 2) is too limiting or dangerous (calling; accidentally a virtual function will segv). So since we have a; robust Streamer mechanism I opted for 3). Function Members (Methods); public:. virtual~TMapFile",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:11577,Energy Efficiency,allocate,allocated,11577,"operator has been made private. Use Close() to properly; terminate a TMapFile (also done via the TROOT dtor). void InitDirectory(); Create the directory associated to this mapfile. void Add(const TObject* obj, const char* name = """"); Add an object to the list of objects to be stored in shared memory.; To place the object actually into shared memory call Update(). void Update(TObject* obj = 0); Update an object (or all objects, if obj == 0) in shared memory. TObject * Remove(TObject* obj, Bool_t lock); Remove object from shared memory. Returns pointer to removed; object if successful, 0 otherwise. TObject * Remove(const char* name, Bool_t lock); Remove object by name from shared memory. Returns pointer to removed; object if successful, 0 otherwise. void RemoveAll(); Remove all objects from shared memory. TObject * Get(const char* name, TObject* retObj = 0); Return pointer to object retrieved from shared memory. The object must; be deleted after use. If delObj is a pointer to a previously allocated; object it will be deleted. Returns 0 in case object with the given; name does not exist. void CreateSemaphore(Int_t pid = 0); Create semaphore used for synchronizing access to shared memory. void DeleteSemaphore(); Delete the semaphore. Int_t AcquireSemaphore(); Acquire semaphore. Returns 0 if OK, -1 on error. Int_t ReleaseSemaphore(); Release semaphore. Returns 0 if OK, -1 on error. void Close(Option_t* option = """"); Close a mapped file. First detach mapped memory then close file.; No member functions of a TMapFile that was opened in write mode; may be called after Close() (this includes, of course, ""delete"" which; would call the dtors). The option=""dtor"" is only used when called; via the ~TMapFile. TMapFile * FindShadowMapFile(); Returns shadow map file. void Print(Option_t* option = """") const; Print some info about the mapped file. Bool_t IsFolder() const; Returns kTRUE in case object is a folder (i.e. contains browsable lists). void Browse(TBrowser* b); Browse contents ",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:11740,Integrability,synchroniz,synchronizing,11740," associated to this mapfile. void Add(const TObject* obj, const char* name = """"); Add an object to the list of objects to be stored in shared memory.; To place the object actually into shared memory call Update(). void Update(TObject* obj = 0); Update an object (or all objects, if obj == 0) in shared memory. TObject * Remove(TObject* obj, Bool_t lock); Remove object from shared memory. Returns pointer to removed; object if successful, 0 otherwise. TObject * Remove(const char* name, Bool_t lock); Remove object by name from shared memory. Returns pointer to removed; object if successful, 0 otherwise. void RemoveAll(); Remove all objects from shared memory. TObject * Get(const char* name, TObject* retObj = 0); Return pointer to object retrieved from shared memory. The object must; be deleted after use. If delObj is a pointer to a previously allocated; object it will be deleted. Returns 0 in case object with the given; name does not exist. void CreateSemaphore(Int_t pid = 0); Create semaphore used for synchronizing access to shared memory. void DeleteSemaphore(); Delete the semaphore. Int_t AcquireSemaphore(); Acquire semaphore. Returns 0 if OK, -1 on error. Int_t ReleaseSemaphore(); Release semaphore. Returns 0 if OK, -1 on error. void Close(Option_t* option = """"); Close a mapped file. First detach mapped memory then close file.; No member functions of a TMapFile that was opened in write mode; may be called after Close() (this includes, of course, ""delete"" which; would call the dtors). The option=""dtor"" is only used when called; via the ~TMapFile. TMapFile * FindShadowMapFile(); Returns shadow map file. void Print(Option_t* option = """") const; Print some info about the mapped file. Bool_t IsFolder() const; Returns kTRUE in case object is a folder (i.e. contains browsable lists). void Browse(TBrowser* b); Browse contents of TMapFile. Bool_t cd(const char* path = 0); Cd to associated directory,. void ls(Option_t* option = """") const; List contents of TMapFile. void SumBuf",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:2148,Modifiability,inherit,inheritance,2148,"w the current implementation is not ideal (you need to copy to; and from the shared memory file) but the main problem is with the; class' virtual_table pointer. This pointer points to a table unique; for every process. Therefore, different options are:; 1) One could allocate an object directly in shared memory in the; producer, but the consumer still has to copy the object from; shared memory into a local object which has the correct vtbl; pointer for that process (copy ctor's can be used for creating; the local copy).; 2) Another possibility is to only allow objects without virtual; functions in shared memory (like simple C structs), or to; forbid (how?) the consumer from calling any virtual functions; of the objects in shared memory.; 3) A last option is to copy the object internals to shared memory; and copy them again from there. This is what is done in the; TMapFile (using the object Streamer() to make a deep copy).; Option 1) saves one copy, but requires solid copy ctor's (along the; full inheritance chain) to rebuild the object in the consumer. Most; classes don't provide these copy ctor's, especially not when objects; contain collections, etc. 2) is too limiting or dangerous (calling; accidentally a virtual function will segv). So since we have a; robust Streamer mechanism I opted for 3). Function Members (Methods); public:. virtual~TMapFile(); voidTObject::AbstractMethod(const char* method) const; voidAdd(const TObject* obj, const char* name = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); Bool_tcd(const char* path = 0); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidClose(Option_t* option = """"); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; static TMapFile*Create(const char* name, Option_t* option = ""READ"", Int_t size =",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:904,Security,access,access,904,". TMapFile. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » IO; » IO; » TMapFile. class TMapFile: public TObject. TMapFile. This class implements a shared memory region mapped to a file.; Objects can be placed into this shared memory area using the Add(); member function. To actually place a copy of the object is shared; memory call Update() also whenever the mapped object(s) change(s); call Update() to put a fresh copy in the shared memory. This extra; step is necessary since it is not possible to share objects with; virtual pointers between processes (the vtbl ptr points to the; originators unique address space and can not be used by the; consumer process(es)). Consumer processes can map the memory region; from this file and access the objects stored in it via the Get(); method (which returns a copy of the object stored in the shared; memory with correct vtbl ptr set). Only objects of classes with a; Streamer() member function defined can be shared. I know the current implementation is not ideal (you need to copy to; and from the shared memory file) but the main problem is with the; class' virtual_table pointer. This pointer points to a table unique; for every process. Therefore, different options are:; 1) One could allocate an object directly in shared memory in the; producer, but the consumer still has to copy the object from; shared memory into a local object which has the correct vtbl; pointer for that process (copy ctor's can be used for creating; the local copy).; 2) Another possibility is to only allow objects without virtual; functions in shared memory (like simple C structs), or to; forbid (how?) the consumer from calling any virtual functions; of the objects in shared memory.; 3) A last option is to copy the object internals to shared memory; and copy them again from there. This is what is d",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:11754,Security,access,access,11754," associated to this mapfile. void Add(const TObject* obj, const char* name = """"); Add an object to the list of objects to be stored in shared memory.; To place the object actually into shared memory call Update(). void Update(TObject* obj = 0); Update an object (or all objects, if obj == 0) in shared memory. TObject * Remove(TObject* obj, Bool_t lock); Remove object from shared memory. Returns pointer to removed; object if successful, 0 otherwise. TObject * Remove(const char* name, Bool_t lock); Remove object by name from shared memory. Returns pointer to removed; object if successful, 0 otherwise. void RemoveAll(); Remove all objects from shared memory. TObject * Get(const char* name, TObject* retObj = 0); Return pointer to object retrieved from shared memory. The object must; be deleted after use. If delObj is a pointer to a previously allocated; object it will be deleted. Returns 0 in case object with the given; name does not exist. void CreateSemaphore(Int_t pid = 0); Create semaphore used for synchronizing access to shared memory. void DeleteSemaphore(); Delete the semaphore. Int_t AcquireSemaphore(); Acquire semaphore. Returns 0 if OK, -1 on error. Int_t ReleaseSemaphore(); Release semaphore. Returns 0 if OK, -1 on error. void Close(Option_t* option = """"); Close a mapped file. First detach mapped memory then close file.; No member functions of a TMapFile that was opened in write mode; may be called after Close() (this includes, of course, ""delete"" which; would call the dtors). The option=""dtor"" is only used when called; via the ~TMapFile. TMapFile * FindShadowMapFile(); Returns shadow map file. void Print(Option_t* option = """") const; Print some info about the mapped file. Bool_t IsFolder() const; Returns kTRUE in case object is a folder (i.e. contains browsable lists). void Browse(TBrowser* b); Browse contents of TMapFile. Bool_t cd(const char* path = 0); Cd to associated directory,. void ls(Option_t* option = """") const; List contents of TMapFile. void SumBuf",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapFile.html:1762,Usability,simpl,simple,1762,"e address space and can not be used by the; consumer process(es)). Consumer processes can map the memory region; from this file and access the objects stored in it via the Get(); method (which returns a copy of the object stored in the shared; memory with correct vtbl ptr set). Only objects of classes with a; Streamer() member function defined can be shared. I know the current implementation is not ideal (you need to copy to; and from the shared memory file) but the main problem is with the; class' virtual_table pointer. This pointer points to a table unique; for every process. Therefore, different options are:; 1) One could allocate an object directly in shared memory in the; producer, but the consumer still has to copy the object from; shared memory into a local object which has the correct vtbl; pointer for that process (copy ctor's can be used for creating; the local copy).; 2) Another possibility is to only allow objects without virtual; functions in shared memory (like simple C structs), or to; forbid (how?) the consumer from calling any virtual functions; of the objects in shared memory.; 3) A last option is to copy the object internals to shared memory; and copy them again from there. This is what is done in the; TMapFile (using the object Streamer() to make a deep copy).; Option 1) saves one copy, but requires solid copy ctor's (along the; full inheritance chain) to rebuild the object in the consumer. Most; classes don't provide these copy ctor's, especially not when objects; contain collections, etc. 2) is too limiting or dangerous (calling; accidentally a virtual function will segv). So since we have a; robust Streamer mechanism I opted for 3). Function Members (Methods); public:. virtual~TMapFile(); voidTObject::AbstractMethod(const char* method) const; voidAdd(const TObject* obj, const char* name = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); Bool_tcd(const char* path = 0); static TClass*Class(); virtual co",MatchSource.WIKI,root/html530/TMapFile.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapFile.html
https://root.cern/root/html530/TMapRec.html:785,Security,access,access,785,". TMapRec. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » IO; » IO; » TMapRec. class TMapRec. TMapFile. This class implements a shared memory region mapped to a file.; Objects can be placed into this shared memory area using the Add(); member function. Whenever the mapped object(s) change(s) call; Update() to put a fresh copy in the shared memory. This extra; step is necessary since it is not possible to share objects with; virtual pointers between processes (the vtbl ptr points to the; originators unique address space and can not be used by the; consumer process(es)). Consumer processes can map the memory region; from this file and access the objects stored in it via the Get(); method (which returns a copy of the object stored in the shared; memory with correct vtbl ptr set). Only objects of classes with a; Streamer() member function defined can be shared. Function Members (Methods); public:. TMapRec(const TMapRec&); TMapRec(const char* name, const TObject* obj, Int_t size, void* buf); ~TMapRec(); void*GetBuffer(Long_t offset = 0) const; Int_tGetBufSize() const; const char*GetClassName(Long_t offset = 0) const; const char*GetName(Long_t offset = 0) const; TMapRec*GetNext(Long_t offset = 0) const; TObject*GetObject() const; TMapRec&operator=(const TMapRec&). Data Members; private:. Int_tfBufSizebuffer size; void*fBufferbuffer containing object of class name; char*fClassNameclass name; char*fNameobject name; TMapRec*fNextnext MapRec in list; TObject*fObjectpointer to original object. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void operator=(const TMapRec& ). const char * GetName(); { return fName; }. TMapRec(const char* name, const TObject* obj, Int_t size, void* buf). ~TMapRec(). const char * GetClassName(Long_t offset = 0) const; { return (char *)((Long_t) fClassName + offset);",MatchSource.WIKI,root/html530/TMapRec.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMapRec.html
https://root.cern/root/html530/TMarker.html:1546,Availability,error,error,1546,"_t marker); virtual~TMarker(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidCopy(TObject& marker) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; static voidDisplayMarkerTypes(); virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidDrawMarker(Double_t x, Double_t y); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual Color_tTAttMarker::GetMarkerColor() const; virtual Size_tTAttMarker::GetMarkerSize() const; virtual Style_tTAttMarker::GetMarkerStyle() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; Double_tGetX() const; Double_tGetY() const; virtual Bool_tTObject::HandleTimer(TTi",MatchSource.WIKI,root/html530/TMarker.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMarker.html
https://root.cern/root/html530/TMarker.html:1630,Availability,error,error,1630,"; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidCopy(TObject& marker) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; static voidDisplayMarkerTypes(); virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidDrawMarker(Double_t x, Double_t y); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual Color_tTAttMarker::GetMarkerColor() const; virtual Size_tTAttMarker::GetMarkerSize() const; virtual Style_tTAttMarker::GetMarkerStyle() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; Double_tGetX() const; Double_tGetY() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const c",MatchSource.WIKI,root/html530/TMarker.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMarker.html
https://root.cern/root/html530/TMarker.html:7466,Deployability,release,released,7466,"ted Members; Includes; Libraries. Function documentation; TMarker(); Marker default constructor. TMarker(Double_t x, Double_t y, Int_t marker); Marker normal constructor. ~TMarker(); Marker default destructor. TMarker(const TMarker& marker); Marker copy constructor. void Copy(TObject& marker) const; Copy this marker to marker. void DisplayMarkerTypes(); Display the table of markers with their numbers. Int_t DistancetoPrimitive(Int_t px, Int_t py); Compute distance from point px,py to a marker. Compute the closest distance of approach from point px,py to this marker.; The distance is computed in pixels units. void Draw(Option_t* option = """"); Draw this marker with its current attributes. void DrawMarker(Double_t x, Double_t y); Draw this marker with new coordinates. void ExecuteEvent(Int_t event, Int_t px, Int_t py); Execute action corresponding to one event. This member function is called when a marker is clicked with the locator. If Left button is clicked on a marker, the marker is moved to; a new position when the mouse button is released. void ls(Option_t* option = """") const; List this marker with its attributes. void Paint(Option_t* option = """"); Paint this marker with its current attributes. void PaintMarker(Double_t x, Double_t y); Draw this marker with new coordinates. void PaintMarkerNDC(Double_t u, Double_t v); Draw this marker with new coordinates in NDC. void Print(Option_t* option = """") const; Dump this marker with its attributes. void SavePrimitive(ostream& out, Option_t* option = """"); Save primitive as a C++ statement(s) on output stream out. void SetNDC(Bool_t isNDC = kTRUE); Set NDC mode on if isNDC = kTRUE, off otherwise. void Streamer(TBuffer& b); Stream an object of class TMarker. Double_t GetX() const; {return fX;}. Double_t GetY() const; {return fY;}. void SetX(Double_t x); { fX = x;}. void SetY(Double_t y); { fY = y;}. » Author: Rene Brun 12/05/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/graf:$Id: TMarker",MatchSource.WIKI,root/html530/TMarker.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMarker.html
https://root.cern/root/html530/TMarker3DBox.html:1993,Availability,error,error,1993,"AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; Int_tTAttLine::DistancetoLine(Int_t px, Int_t py, Double_t xp1, Double_t yp1, Double_t xp2, Double_t yp2); virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidGetDirection(Float_t& theta, Float_t& phi) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Color_tTAttLine::GetLineColor() const; virtual Style_tTAttLine::GetLineStyle() const; virtual Width_tTAttLine::GetLineWidth() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual voidGetPosition(Fl",MatchSource.WIKI,root/html530/TMarker3DBox.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMarker3DBox.html
https://root.cern/root/html530/TMarker3DBox.html:2077,Availability,error,error,2077,"ption = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; Int_tTAttLine::DistancetoLine(Int_t px, Int_t py, Double_t xp1, Double_t yp1, Double_t xp2, Double_t yp2); virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidGetDirection(Float_t& theta, Float_t& phi) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Color_tTAttLine::GetLineColor() const; virtual Style_tTAttLine::GetLineStyle() const; virtual Width_tTAttLine::GetLineWidth() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual voidGetPosition(Float_t& x, Float_t& y, Float_t& z) const; TObject*GetRefObject() const; virtual voidG",MatchSource.WIKI,root/html530/TMarker3DBox.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMarker3DBox.html
https://root.cern/root/html530/TMaterial.html:1572,Availability,error,error,1572," a, Float_t z, Float_t density, Float_t radl, Float_t inter); virtual~TMaterial(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tGetA() const; virtual Float_tGetDensity() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Float_tGetInterLength() const; virtual const char*TNamed::GetName() const; virtual Int_tGetNumber() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual Float_tGetRadLength() const; vi",MatchSource.WIKI,root/html530/TMaterial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMaterial.html
https://root.cern/root/html530/TMaterial.html:1656,Availability,error,error,1656,"oidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tGetA() const; virtual Float_tGetDensity() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Float_tGetInterLength() const; virtual const char*TNamed::GetName() const; virtual Int_tGetNumber() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual Float_tGetRadLength() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() cons",MatchSource.WIKI,root/html530/TMaterial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMaterial.html
https://root.cern/root/html530/TMaterial.html:315,Safety,detect,detector,315,". TMaterial. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » GRAF3D; » G3D; » TMaterial. class TMaterial: public TNamed, public TAttFill. Manages a detector material. See class TGeometry. Function Members (Methods); public:. TMaterial(); TMaterial(const TMaterial&); TMaterial(const char* name, const char* title, Float_t a, Float_t z, Float_t density); TMaterial(const char* name, const char* title, Float_t a, Float_t z, Float_t density, Float_t radl, Float_t inter); virtual~TMaterial(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tGetA(",MatchSource.WIKI,root/html530/TMaterial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMaterial.html
https://root.cern/root/html530/TMath.html:10366,Availability,down,down,10366,"); Short_tRange(Short_t lb, Short_t ub, Short_t x); Int_tRange(Int_t lb, Int_t ub, Int_t x); Long_tRange(Long_t lb, Long_t ub, Long_t x); ULong_tRange(ULong_t lb, ULong_t ub, ULong_t x); Double_tRange(Double_t lb, Double_t ub, Double_t x); Double_tRgair(); Double_tRMS(Long64_t n, const short* a); Double_tRMS(Long64_t n, const int* a); Double_tRMS(Long64_t n, const float* a); Double_tRMS(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10442,Availability,down,down,10442,"_t ub, Int_t x); Long_tRange(Long_t lb, Long_t ub, Long_t x); ULong_tRange(ULong_t lb, ULong_t ub, ULong_t x); Double_tRange(Double_t lb, Double_t ub, Double_t x); Double_tRgair(); Double_tRMS(Long64_t n, const short* a); Double_tRMS(Long64_t n, const int* a); Double_tRMS(Long64_t n, const float* a); Double_tRMS(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10520,Availability,down,down,10520,"ng_t lb, ULong_t ub, ULong_t x); Double_tRange(Double_t lb, Double_t ub, Double_t x); Double_tRgair(); Double_tRMS(Long64_t n, const short* a); Double_tRMS(Long64_t n, const int* a); Double_tRMS(Long64_t n, const float* a); Double_tRMS(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x);",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10599,Availability,down,down,10599,"_t x); Double_tRgair(); Double_tRMS(Long64_t n, const short* a); Double_tRMS(Long64_t n, const int* a); Double_tRMS(Long64_t n, const float* a); Double_tRMS(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10676,Availability,down,down,10676,"Long64_t n, const int* a); Double_tRMS(Long64_t n, const float* a); Double_tRMS(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10758,Availability,down,down,10758,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10824,Availability,down,down,10824,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10888,Availability,down,down,10888,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:10954,Availability,down,down,10954,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:11021,Availability,down,down,11021,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:11086,Availability,down,down,11086,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:11156,Availability,down,down,11156,"(Long64_t n, const double* a); Double_tRMS(Long64_t n, const long* a); Double_tRMS(Long64_t n, const long long* a); Bool_tRootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Double_tRUncertainty(); Double_tSigma(); Double_tSigmaUncertainty(); Short_tSign(Short_t a, Short_t b); Int_tSign(Int_t a, Int_t b); Long_tSign(Long_t a, Long_t b); Long64_tSign(Long64_t a, Long64_t b); Float_tSign(Float_t a, Float_t b); Double_tSign(Double_t a, Double_t b); Double_tSignalingNaN(); Double_tSin(Double_t x); Double_tSinH(Double_t x); voidSort(long long n, const short* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const int* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const float* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const double* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long* a, long long* index, Bool_t down = kTRUE); voidSort(long long n, const long long* a, long long* index, Bool_t down = kTRUE); voidSort(int n, const short* a, int* index, Bool_t down = kTRUE); voidSort(int n, const int* a, int* index, Bool_t down = kTRUE); voidSort(int n, const float* a, int* index, Bool_t down = kTRUE); voidSort(int n, const double* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long* a, int* index, Bool_t down = kTRUE); voidSort(int n, const long long* a, int* index, Bool_t down = kTRUE); Double_tSqrt(Double_t x); Double_tSqrt2(); Double_tStruveH0(Double_t x); Double_tStruveH1(Double_t x); Double_tStruveL0(Double_t x); Double_tStruveL1(Double_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4).",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:12339,Availability,error,error,12339,"_t x); Double_tStudent(Double_t T, Double_t ndf); Double_tStudentI(Double_t T, Double_t ndf); Double_tStudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4). Class Charts; Function documentation; Long_t Hypot(Long_t x, Long_t y). Double_t Hypot(Double_t x, Double_t y). Double_t ASinH(Double_t ). Double_t ACosH(Double_t ). Double_t ATanH(Double_t ). Double_t Log2(Double_t x). Int_t Nint(Float_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Int_t Nint(Double_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Double_t DiLog(Double_t x); The DiLogarithm function; Code translated by R.Brun from CERNLIB DILOG function C332. Double_t Erf(Double_t x); Computation of the error function erf(x).; Erf(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between 0 and x. Double_t Erfc(Double_t x); Compute the complementary error function erfc(x).; Erfc(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between x and infinity. Double_t ErfInverse(Double_t x); returns the inverse error function; x must be <-1<x<1. Double_t ErfcInverse(Double_t x); returns the inverse of the complementary error function; x must be 0<x<2; implement using the quantile of the normal distribution; instead of ErfInverse for better numerical precision for large x. Double_t Factorial(Int_t i); Compute factorial(n). Double_t Freq(Double_t x); Computation of the normal frequency function freq(x).; Freq(x) = (1/sqrt(2pi)) Integral(exp(-t^2/2))dt between -infinity and x. Translated from CERNLIB C300 by Rene Brun. Double_t Gamma(Double_t z); Computation of gamma(z) for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. Double_t Gamma(Double_t a, Double_t x); Computation of the norma",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:12477,Availability,error,error,12477,"le_t ndf, Bool_t lower_tail = kTRUE); Double_tTan(Double_t x); Double_tTanH(Double_t x); Double_tTwoPi(); Double_tVavilov(Double_t x, Double_t kappa, Double_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4). Class Charts; Function documentation; Long_t Hypot(Long_t x, Long_t y). Double_t Hypot(Double_t x, Double_t y). Double_t ASinH(Double_t ). Double_t ACosH(Double_t ). Double_t ATanH(Double_t ). Double_t Log2(Double_t x). Int_t Nint(Float_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Int_t Nint(Double_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Double_t DiLog(Double_t x); The DiLogarithm function; Code translated by R.Brun from CERNLIB DILOG function C332. Double_t Erf(Double_t x); Computation of the error function erf(x).; Erf(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between 0 and x. Double_t Erfc(Double_t x); Compute the complementary error function erfc(x).; Erfc(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between x and infinity. Double_t ErfInverse(Double_t x); returns the inverse error function; x must be <-1<x<1. Double_t ErfcInverse(Double_t x); returns the inverse of the complementary error function; x must be 0<x<2; implement using the quantile of the normal distribution; instead of ErfInverse for better numerical precision for large x. Double_t Factorial(Int_t i); Compute factorial(n). Double_t Freq(Double_t x); Computation of the normal frequency function freq(x).; Freq(x) = (1/sqrt(2pi)) Integral(exp(-t^2/2))dt between -infinity and x. Translated from CERNLIB C300 by Rene Brun. Double_t Gamma(Double_t z); Computation of gamma(z) for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. Double_t Gamma(Double_t a, Double_t x); Computation of the normalized lower incomplete gamma function P(a,x) as defined in the; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:12624,Availability,error,error,12624,"ble_t beta2); Double_tVavilovI(Double_t x, Double_t kappa, Double_t beta2); Double_tVoigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4). Class Charts; Function documentation; Long_t Hypot(Long_t x, Long_t y). Double_t Hypot(Double_t x, Double_t y). Double_t ASinH(Double_t ). Double_t ACosH(Double_t ). Double_t ATanH(Double_t ). Double_t Log2(Double_t x). Int_t Nint(Float_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Int_t Nint(Double_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Double_t DiLog(Double_t x); The DiLogarithm function; Code translated by R.Brun from CERNLIB DILOG function C332. Double_t Erf(Double_t x); Computation of the error function erf(x).; Erf(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between 0 and x. Double_t Erfc(Double_t x); Compute the complementary error function erfc(x).; Erfc(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between x and infinity. Double_t ErfInverse(Double_t x); returns the inverse error function; x must be <-1<x<1. Double_t ErfcInverse(Double_t x); returns the inverse of the complementary error function; x must be 0<x<2; implement using the quantile of the normal distribution; instead of ErfInverse for better numerical precision for large x. Double_t Factorial(Int_t i); Compute factorial(n). Double_t Freq(Double_t x); Computation of the normal frequency function freq(x).; Freq(x) = (1/sqrt(2pi)) Integral(exp(-t^2/2))dt between -infinity and x. Translated from CERNLIB C300 by Rene Brun. Double_t Gamma(Double_t z); Computation of gamma(z) for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. Double_t Gamma(Double_t a, Double_t x); Computation of the normalized lower incomplete gamma function P(a,x) as defined in the; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.5.1 on page 260 .; Its normalization is such that TMath::Gamma(a,+infinity) = 1 . --- Nve 14-nov-1998 UU-SAP Utrecht. Double_t BreitWigner(Double_t x, D",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:12734,Availability,error,error,12734,"Function documentation; Long_t Hypot(Long_t x, Long_t y). Double_t Hypot(Double_t x, Double_t y). Double_t ASinH(Double_t ). Double_t ACosH(Double_t ). Double_t ATanH(Double_t ). Double_t Log2(Double_t x). Int_t Nint(Float_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Int_t Nint(Double_t x); Round to nearest integer. Rounds half integers to the nearest; even integer. Double_t DiLog(Double_t x); The DiLogarithm function; Code translated by R.Brun from CERNLIB DILOG function C332. Double_t Erf(Double_t x); Computation of the error function erf(x).; Erf(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between 0 and x. Double_t Erfc(Double_t x); Compute the complementary error function erfc(x).; Erfc(x) = (2/sqrt(pi)) Integral(exp(-t^2))dt between x and infinity. Double_t ErfInverse(Double_t x); returns the inverse error function; x must be <-1<x<1. Double_t ErfcInverse(Double_t x); returns the inverse of the complementary error function; x must be 0<x<2; implement using the quantile of the normal distribution; instead of ErfInverse for better numerical precision for large x. Double_t Factorial(Int_t i); Compute factorial(n). Double_t Freq(Double_t x); Computation of the normal frequency function freq(x).; Freq(x) = (1/sqrt(2pi)) Integral(exp(-t^2/2))dt between -infinity and x. Translated from CERNLIB C300 by Rene Brun. Double_t Gamma(Double_t z); Computation of gamma(z) for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. Double_t Gamma(Double_t a, Double_t x); Computation of the normalized lower incomplete gamma function P(a,x) as defined in the; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.5.1 on page 260 .; Its normalization is such that TMath::Gamma(a,+infinity) = 1 . --- Nve 14-nov-1998 UU-SAP Utrecht. Double_t BreitWigner(Double_t x, Double_t mean = 0, Double_t gamma = 1); Calculate a Breit Wigner function with mean and gamma. Double_t Gaus(Double_t x, Double_t mean = 0, Double_t sigma = 1, B",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18250,Availability,error,error,18250,"nst Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:20935,Availability,error,error,20935,"convince yourself that the; old CERNLIB method is wrong is that it implies that the function defined as the; difference between a and b is multi-valued at x -- besides being ugly, this; would invalidate Kolmogorov's theorem). The solution is to just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than 10^(-r).; r can be set by the the user subject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roo",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:21157,Availability,error,error,21157,"just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than 10^(-r).; r can be set by the the user subject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t type = 7); Computes sample quantiles, corresponding to the ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:42229,Availability,down,down,42229,"lement value); Binary search in an array defined by its iterators. The values in the iterators range are supposed to be sorted; prior to this call. If match is found, function returns; position of element. If no match found, function gives nearest; element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T *array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T **array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename Element, typename Index> void Sort(Index n, const Element* a, Index* index, Bool_t down); Sort the n elements of the array a of generic templated type Element.; In output the array index of type Index contains the indices of the sorted array.; If down is false sort in increasing order (default is decreasing order). template <typename T> T * Cross(const T v1[3],const T v2[3], T out[3]); Calculate the Cross Product of two vectors:; out = [v1 x v2]. template <typename T> T * Normal2Plane(const T p1[3],const T p2[3],const T p3[3], T normal[3]); Calculate a normal vector of a plane. Input:; Float_t *p1,*p2,*p3 - 3 3D points belonged the plane to define it. Return:; Pointer to 3D normal vector (normalized). template <typename T> Bool_t IsInside(T xp, T yp, Int_t np, T *x, T *y); Function which returns kTRUE if point xp,yp lies inside the; polygon defined by the np points in arrays x and y, kFALSE otherwise.; Note that the polygon may be open or closed. template <typename T> Double_t Median(Long64_t n, const T *a, const Double_t *w, Long64_t *work); Return the ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:42393,Availability,down,down,42393,"o match found, function gives nearest; element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T *array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T **array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename Element, typename Index> void Sort(Index n, const Element* a, Index* index, Bool_t down); Sort the n elements of the array a of generic templated type Element.; In output the array index of type Index contains the indices of the sorted array.; If down is false sort in increasing order (default is decreasing order). template <typename T> T * Cross(const T v1[3],const T v2[3], T out[3]); Calculate the Cross Product of two vectors:; out = [v1 x v2]. template <typename T> T * Normal2Plane(const T p1[3],const T p2[3],const T p3[3], T normal[3]); Calculate a normal vector of a plane. Input:; Float_t *p1,*p2,*p3 - 3 3D points belonged the plane to define it. Return:; Pointer to 3D normal vector (normalized). template <typename T> Bool_t IsInside(T xp, T yp, Int_t np, T *x, T *y); Function which returns kTRUE if point xp,yp lies inside the; polygon defined by the np points in arrays x and y, kFALSE otherwise.; Note that the polygon may be open or closed. template <typename T> Double_t Median(Long64_t n, const T *a, const Double_t *w, Long64_t *work); Return the median of the array a where each entry i has weight w[i] .; Both arrays have a length of at least n . The median is a number obtained; from the sorted array a through. median = (a[jl]+a[jh])/2. where (using al",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:48696,Availability,down,down,48696,"is less than epsilon. Bool_t AreEqualRel(Double_t af, Double_t bf, Double_t relPrec); return kTRUE if relative difference between af and bf is less than relPrec. return Abs(af-bf). template <typename T> T MinElement(Long64_t n, const T *a). Array Algorithms. Min, Max of an array. template <typename T> T MaxElement(Long64_t n, const T *a). template <typename T> Long64_t LocMin(Long64_t n, const T *a); Locate Min, Max element number in an array. template <typename Iterator> Iterator LocMin(Iterator first, Iterator last). template <typename T> Long64_t LocMax(Long64_t n, const T *a). template <typename Iterator> Iterator LocMax(Iterator first, Iterator last). template <typename T> Long64_t BinarySearch(Long64_t n, const T *array, T value); Binary search. template <typename T> Long64_t BinarySearch(Long64_t n, const T **array, T value). template <typename Iterator, typename Element> Iterator BinarySearch(Iterator first, Iterator last, Element value). void Sort(Index n, const Element* a, Index* index, Bool_t down=kTRUE); Sorting. template <typename T> Bool_t IsInside(T xp, T yp, Int_t np, T *x, T *y); IsInside. template <typename T> T * Cross(const T v1[3],const T v2[3], T out[3]); Calculate the Cross Product of two vectors. template <typename T> inline T NormCross(const T v1[3],const T v2[3],T out[3]); Calculate the Normalized Cross Product of two vectors. template <typename T> T * Normal2Plane(const T v1[3],const T v2[3],const T v3[3], T normal[3]); Calculate a normal vector of a plane. template <typename T> Double_t Mean(Long64_t n, const T *a, const Double_t *w=0). Statistics over arrays. Mean, Geometric Mean, Median, RMS(sigma). template <typename Iterator> Double_t Mean(Iterator first, Iterator last). template <typename Iterator, typename WeightIterator> Double_t Mean(Iterator first, Iterator last, WeightIterator w). template <typename T> Double_t GeomMean(Long64_t n, const T *a). template <typename Iterator> Double_t GeomMean(Iterator first, Iterator last). templa",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:52717,Availability,down,down,52717,"lement value); Binary search in an array defined by its iterators. The values in the iterators range are supposed to be sorted; prior to this call. If match is found, function returns; position of element. If no match found, function gives nearest; element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T *array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T **array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename Element, typename Index> void Sort(Index n, const Element* a, Index* index, Bool_t down); Sort the n elements of the array a of generic templated type Element.; In output the array index of type Index contains the indices of the sorted array.; If down is false sort in increasing order (default is decreasing order). template <typename T> Double_t Median(Long64_t n, const T *a, const Double_t *w, Long64_t *work); Return the median of the array a where each entry i has weight w[i] .; Both arrays have a length of at least n . The median is a number obtained; from the sorted array a through. median = (a[jl]+a[jh])/2. where (using also the sorted index on the array w). sum_i=0,jl w[i] <= sumTot/2; sum_i=0,jh w[i] >= sumTot/2; sumTot = sum_i=0,n w[i]. If w=0, the algorithm defaults to the median definition where it is; a number that divides the sorted sequence into 2 halves.; When n is odd or n > 1000, the median is kth element k = (n + 1) / 2.; when n is even and n < 1000the median is a mean of the elements k = n/2 and k = n/2 + 1. If the weights are supplied ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:52881,Availability,down,down,52881,"o match found, function gives nearest; element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T *array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename T> Long64_t BinarySearch(Long64_t n, const T **array, T value); Binary search in an array of n values to locate value. Array is supposed to be sorted prior to this call.; If match is found, function returns position of element.; If no match found, function gives nearest element smaller than value. template <typename Element, typename Index> void Sort(Index n, const Element* a, Index* index, Bool_t down); Sort the n elements of the array a of generic templated type Element.; In output the array index of type Index contains the indices of the sorted array.; If down is false sort in increasing order (default is decreasing order). template <typename T> Double_t Median(Long64_t n, const T *a, const Double_t *w, Long64_t *work); Return the median of the array a where each entry i has weight w[i] .; Both arrays have a length of at least n . The median is a number obtained; from the sorted array a through. median = (a[jl]+a[jh])/2. where (using also the sorted index on the array w). sum_i=0,jl w[i] <= sumTot/2; sum_i=0,jh w[i] >= sumTot/2; sumTot = sum_i=0,n w[i]. If w=0, the algorithm defaults to the median definition where it is; a number that divides the sorted sequence into 2 halves.; When n is odd or n > 1000, the median is kth element k = (n + 1) / 2.; when n is even and n < 1000the median is a mean of the elements k = n/2 and k = n/2 + 1. If the weights are supplied (w not 0) all weights must be >= 0. If work is supplied, it is used to store the sorting index and assumed to be; >= n . If work=0, local storage is used, either on the stack if n < kWorkMax; or on the heap fo",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18466,Deployability,integrat,integrated,18466,"on, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case,",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:22867,Deployability,continuous,continuous,22867,"urned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t type = 7); Computes sample quantiles, corresponding to the given probabilities; Parameters:; x -the data sample; n - its size; quantiles - computed quantiles are returned in there; prob - probabilities where to compute quantiles; nprob - size of prob array; isSorted - is the input array x sorted?; NOTE, that when the input is not sorted, an array of integers of size n needs; to be allocated. It can be passed by the user in parameter index,; or, if not passed, it will be allocated inside the function. type - method to compute (from 1 to 9). Following types are provided:; Discontinuous:; type=1 - inverse of the empirical distribution function; type=2 - like type 1, but with averaging at discontinuities; type=3 - SAS definition: nearest even order statistic; Piecwise linear continuous:; In this case, sample quantiles can be obtained by linear interpolation; between the k-th order statistic and p(k).; type=4 - linear interpolation of empirical cdf, p(k)=k/n;; type=5 - a very popular definition, p(k) = (k-0.5)/n;; type=6 - used by Minitab and SPSS, p(k) = k/(n+1);; type=7 - used by S-Plus and R, p(k) = (k-1)/(n-1);; type=8 - resulting sample quantiles are approximately median unbiased; regardless of the distribution of x. p(k) = (k-1/3)/(n+1/3);; type=9 - resulting sample quantiles are approximately unbiased, when; the sample comes from Normal distribution. p(k)=(k-3/8)/(n+1/4);. default type = 7. References:; 1) Hyndman, R.J and Fan, Y, (1996) ""Sample quantiles in statistical packages""; American Statistician, 50, 361-365; 2) R Project documentation for the function quantile of package {stats}. void BubbleHigh(Int_t Narr, Double_t* arr1, Int_t* arr2); Bubble sort variant to obtain the order of an array'",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:29180,Deployability,continuous,continuous,29180,"atural lower and upper limits. Double_t BetaIncomplete(Double_t x, Double_t a, Double_t b); Calculates the incomplete Beta-function. Double_t Binomial(Int_t n, Int_t k); Calculate the binomial coefficient n over k. Double_t BinomialI(Double_t p, Int_t n, Int_t k); Suppose an event occurs with probability _p_ per trial; Then the probability P of its occuring _k_ or more times; in _n_ trials is termed a cumulative binomial probability; the formula is P = sum_from_j=k_to_n(TMath::Binomial(n, j)*; *TMath::Power(p, j)*TMath::Power(1-p, n-j); For _n_ larger than 12 BetaIncomplete is a much better way; to evaluate the sum than would be the straightforward sum calculation; for _n_ smaller than 12 either method is acceptable; (""Numerical Recipes""); --implementation by Anna Kreshuk. Double_t CauchyDist(Double_t x, Double_t t = 0, Double_t s = 1); Computes the density of Cauchy distribution at point x; by default, standard Cauchy distribution is used (t=0, s=1); t is the location parameter; s is the scale parameter; The Cauchy distribution, also called Lorentzian distribution,; is a continuous distribution describing resonance behavior; The mean and standard deviation of the Cauchy distribution are undefined.; The practical meaning of this is that collecting 1,000 data points gives; no more accurate an estimate of the mean and standard deviation than; does a single point.; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm; Implementation by Anna Kreshuk.; Example:; TF1* fc = new TF1(""fc"", ""TMath::CauchyDist(x, [0], [1])"", -5, 5);; fc->SetParameters(0, 1);; fc->Draw();. Double_t ChisquareQuantile(Double_t p, Double_t ndf); Evaluate the quantiles of the chi-squared probability distribution function.; Algorithm AS 91 Appl. Statist. (1975) Vol.24, P.35; implemented by Anna Kreshuk.; Incorporates the suggested changes in AS R85 (vol.40(1), pp.233-5, 1991); Parameters:; p - the probability value, at",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:14382,Energy Efficiency,adapt,adapted,14382,"; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.5.1 on page 260 .; Its normalization is such that TMath::Gamma(a,+infinity) = 1 . --- Nve 14-nov-1998 UU-SAP Utrecht. Double_t BreitWigner(Double_t x, Double_t mean = 0, Double_t gamma = 1); Calculate a Breit Wigner function with mean and gamma. Double_t Gaus(Double_t x, Double_t mean = 0, Double_t sigma = 1, Bool_t norm = kFALSE); Calculate a gaussian function with mean and sigma.; If norm=kTRUE (default is kFALSE) the result is divided; by sqrt(2*Pi)*sigma. Double_t Landau(Double_t x, Double_t mpv = 0, Double_t sigma = 1, Bool_t norm = kFALSE); The LANDAU function.; mpv is a location parameter and correspond approximatly to the most probable value; and sigma is a scale parameter (not the sigma of the full distribution which is not defined); Note that for mpv=0 and sigma=1 (default values) the exact location of the maximum of the distribution (most proble value) is at; x = -0.22278; This function has been adapted from the CERNLIB routine G110 denlan.; If norm=kTRUE (default is kFALSE) the result is divided by sigma. Double_t LnGamma(Double_t z); Computation of ln[gamma(z)] for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. The accuracy of the result is better than 2e-10. --- Nve 14-nov-1998 UU-SAP Utrecht. Float_t Normalize(Float_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector. Double_t Normalize(Double_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector.; This implementation (thanks Kevin Lynch <krlynch@bu.edu>) is protected; against possible overflows. Double_t Poisson(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); The Poisson PDF is implemented by means of Euler's Gamma-function; (for the factorial), so for all integer arguments it is correct.; BUT for non-integer values it IS NOT equal to the Poisson distribution.; see TMath::PoissonI to get a non-smooth function.; Note that",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:16476,Energy Efficiency,power,powerful,16476,"I(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); This is a non-smooth function.; This function is equivalent to ROOT::Math::poisson_pdf. /*. */. Double_t Prob(Double_t chi2, Int_t ndf); Computation of the probability for a certain Chi-squared (chi2); and number of degrees of freedom (ndf). Calculations are based on the incomplete gamma function P(a,x),; where a=ndf/2 and x=chi2/2. P(a,x) represents the probability that the observed Chi-squared; for a correct model should be less than the value chi2. The returned probability corresponds to 1-P(a,x),; which denotes the probability that an observed Chi-squared exceeds; the value chi2 by chance, even for a correct model. --- NvE 14-nov-1998 UU-SAP Utrecht. Double_t KolmogorovProb(Double_t z); Calculates the Kolmogorov distribution function,. /*; ; */. which gives the probability that Kolmogorov's test statistic will exceed; the value z assuming the null hypothesis. This gives a very powerful; test for comparing two one-dimensional distributions.; see, for example, Eadie et al, ""statistocal Methods in Experimental; Physics', pp 269-270). This function returns the confidence level for the null hypothesis, where:; z = dn*sqrt(n), and; dn is the maximum deviation between a hypothetical distribution; function and an experimental distribution with; n events. NOTE: To compare two experimental distributions with m and n events,; use z = sqrt(m*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18572,Energy Efficiency,adapt,adapted,18572,":; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case, a=b, the algorithm advances each array by one index in an; attempt to move through the equality. However, this is in",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:21084,Energy Efficiency,adapt,adapted,21084," would invalidate Kolmogorov's theorem). The solution is to just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than 10^(-r).; r can be set by the the user subject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:22469,Energy Efficiency,allocate,allocated,22469,"ubject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t type = 7); Computes sample quantiles, corresponding to the given probabilities; Parameters:; x -the data sample; n - its size; quantiles - computed quantiles are returned in there; prob - probabilities where to compute quantiles; nprob - size of prob array; isSorted - is the input array x sorted?; NOTE, that when the input is not sorted, an array of integers of size n needs; to be allocated. It can be passed by the user in parameter index,; or, if not passed, it will be allocated inside the function. type - method to compute (from 1 to 9). Following types are provided:; Discontinuous:; type=1 - inverse of the empirical distribution function; type=2 - like type 1, but with averaging at discontinuities; type=3 - SAS definition: nearest even order statistic; Piecwise linear continuous:; In this case, sample quantiles can be obtained by linear interpolation; between the k-th order statistic and p(k).; type=4 - linear interpolation of empirical cdf, p(k)=k/n;; type=5 - a very popular definition, p(k) = (k-0.5)/n;; type=6 - used by Minitab and SPSS, p(k) = k/(n+1);; type=7 - used by S-Plus and R, p(k) = (k-1)/(n-1);; ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:22560,Energy Efficiency,allocate,allocated,22560,"ble_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t type = 7); Computes sample quantiles, corresponding to the given probabilities; Parameters:; x -the data sample; n - its size; quantiles - computed quantiles are returned in there; prob - probabilities where to compute quantiles; nprob - size of prob array; isSorted - is the input array x sorted?; NOTE, that when the input is not sorted, an array of integers of size n needs; to be allocated. It can be passed by the user in parameter index,; or, if not passed, it will be allocated inside the function. type - method to compute (from 1 to 9). Following types are provided:; Discontinuous:; type=1 - inverse of the empirical distribution function; type=2 - like type 1, but with averaging at discontinuities; type=3 - SAS definition: nearest even order statistic; Piecwise linear continuous:; In this case, sample quantiles can be obtained by linear interpolation; between the k-th order statistic and p(k).; type=4 - linear interpolation of empirical cdf, p(k)=k/n;; type=5 - a very popular definition, p(k) = (k-0.5)/n;; type=6 - used by Minitab and SPSS, p(k) = k/(n+1);; type=7 - used by S-Plus and R, p(k) = (k-1)/(n-1);; type=8 - resulting sample quantiles are approximately median unbiased; regardless of the distribution of x. p(k) = (k-1/3)/(n+1/3);; type=9 - resulting sample quantiles are approximately unbiased, when; the sample comes from Normal distribution. p(k)=(k-3/8)/(n+1/4);. default type = 7. References:; 1) Hyndman, R.J and F",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:33681,Energy Efficiency,adapt,adapted,33681,"meter beta.; By default, alpha=0, beta=1; This distribution is known under different names, most common is; double exponential distribution, but it also appears as; the two-tailed exponential or the bilateral exponential distribution. Double_t LogNormal(Double_t x, Double_t sigma, Double_t theta = 0, Double_t m = 1); Computes the density of LogNormal distribution at point x.; Variable X has lognormal distribution if Y=Ln(X) has normal distribution; sigma is the shape parameter; theta is the location parameter; m is the scale parameter; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm; Implementation using ROOT::Math::lognormal_pdf. /*; ; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then th",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:47403,Energy Efficiency,charge,charge,47403," 1.0e7 * K(); }. Double_t KUncertainty(); { return 0.0000024e-23; }. Double_t Sigma(); Stefan-Boltzmann constant. { return 5.6704e-8; }. Double_t SigmaUncertainty(); { return 0.000040e-8; }. Double_t Na(); Avogadro constant (Avogadro's Number). { return 6.02214199e+23; }. Double_t NaUncertainty(); { return 0.00000047e+23; }. Double_t R(); universal gas constant (Na * K); http://scienceworld.wolfram.com/physics/UniversalGasConstant.html. { return K() * Na(); }. Double_t RUncertainty(); { return R()*((KUncertainty()/K()) + (NaUncertainty()/Na())); }. Double_t MWair(); Molecular weight of dry air; 1976 US Standard Atmosphere,; also see http://atmos.nmsu.edu/jsdap/encyclopediawork.html. { return 28.9644; }. Double_t Rgair(); Dry Air Gas Constant (R / MWair); http://atmos.nmsu.edu/education_and_outreach/encyclopedia/gas_constant.htm. { return (1000.0 * R()) / MWair(); }. Double_t EulerGamma(); Euler-Mascheroni Constant. { return 0.577215664901532860606512090082402431042; }. Double_t Qe(); Elementary charge. { return 1.602176462e-19; }. Double_t QeUncertainty(); { return 0.000000063e-19; }. T Min(). T Max(). Bool_t AreEqualAbs(Double_t af, Double_t bf, Double_t epsilon); Comparing floating points. return Abs(af-bf); return kTRUE if absolute difference between af and bf is less than epsilon. Bool_t AreEqualRel(Double_t af, Double_t bf, Double_t relPrec); return kTRUE if relative difference between af and bf is less than relPrec. return Abs(af-bf). template <typename T> T MinElement(Long64_t n, const T *a). Array Algorithms. Min, Max of an array. template <typename T> T MaxElement(Long64_t n, const T *a). template <typename T> Long64_t LocMin(Long64_t n, const T *a); Locate Min, Max element number in an array. template <typename Iterator> Iterator LocMin(Iterator first, Iterator last). template <typename T> Long64_t LocMax(Long64_t n, const T *a). template <typename Iterator> Iterator LocMax(Iterator first, Iterator last). template <typename T> Long64_t BinarySearch(Long64_",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:296,Integrability,rout,routines,296,". TMath. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATHCORE; » TMath. namespace TMath. TMath. Encapsulate math routines. Function Members (Methods); public:. Short_tAbs(Short_t d); Int_tAbs(Int_t d); Long_tAbs(Long_t d); Long64_tAbs(Long64_t d); Float_tAbs(Float_t d); Double_tAbs(Double_t d); Double_tACos(Double_t x); Double_tACosH(Double_t); Bool_tAreEqualAbs(Double_t af, Double_t bf, Double_t epsilon); Bool_tAreEqualRel(Double_t af, Double_t bf, Double_t relPrec); Double_tASin(Double_t x); Double_tASinH(Double_t); Double_tATan(Double_t x); Double_tATan2(Double_t y, Double_t x); Double_tATanH(Double_t); Double_tBesselI(Int_t n, Double_t x); Double_tBesselI0(Double_t x); Double_tBesselI1(Double_t x); Double_tBesselJ0(Double_t x); Double_tBesselJ1(Double_t x); Double_tBesselK(Int_t n, Double_t x); Double_tBesselK0(Double_t x); Double_tBesselK1(Double_t x); Double_tBesselY0(Double_t x); Double_tBesselY1(Double_t x); Double_tBeta(Double_t p, Double_t q); Double_tBetaCf(Double_t x, Double_t a, Double_t b); Double_tBetaDist(Double_t x, Double_t p, Double_t q); Double_tBetaDistI(Double_t x, Double_t p, Double_t q); Double_tBetaIncomplete(Double_t x, Double_t a, Double_t b); Long64_tBinarySearch(Long64_t n, const short* array, short value); Long64_tBinarySearch(Long64_t n, const short** array, short value); Long64_tBinarySearch(Long64_t n, const int* array, int value); Long64_tBinarySearch(Long64_t n, const int** array, int value); Long64_tBinarySearch(Long64_t n, const float* array, float value); Long64_tBinarySearch(Long64_t n, const float** array, float value); Long64_tBinarySearch(Long64_t n, const double* array, double value); Long64_tBinarySearch(Long64_t n, const double** array, double value); Long64_tBinarySearch(Long64_t n, const long* array, long value); Long64_tBinarySearch(Long64_",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:14407,Integrability,rout,routine,14407,"; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.5.1 on page 260 .; Its normalization is such that TMath::Gamma(a,+infinity) = 1 . --- Nve 14-nov-1998 UU-SAP Utrecht. Double_t BreitWigner(Double_t x, Double_t mean = 0, Double_t gamma = 1); Calculate a Breit Wigner function with mean and gamma. Double_t Gaus(Double_t x, Double_t mean = 0, Double_t sigma = 1, Bool_t norm = kFALSE); Calculate a gaussian function with mean and sigma.; If norm=kTRUE (default is kFALSE) the result is divided; by sqrt(2*Pi)*sigma. Double_t Landau(Double_t x, Double_t mpv = 0, Double_t sigma = 1, Bool_t norm = kFALSE); The LANDAU function.; mpv is a location parameter and correspond approximatly to the most probable value; and sigma is a scale parameter (not the sigma of the full distribution which is not defined); Note that for mpv=0 and sigma=1 (default values) the exact location of the maximum of the distribution (most proble value) is at; x = -0.22278; This function has been adapted from the CERNLIB routine G110 denlan.; If norm=kTRUE (default is kFALSE) the result is divided by sigma. Double_t LnGamma(Double_t z); Computation of ln[gamma(z)] for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. The accuracy of the result is better than 2e-10. --- Nve 14-nov-1998 UU-SAP Utrecht. Float_t Normalize(Float_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector. Double_t Normalize(Double_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector.; This implementation (thanks Kevin Lynch <krlynch@bu.edu>) is protected; against possible overflows. Double_t Poisson(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); The Poisson PDF is implemented by means of Euler's Gamma-function; (for the factorial), so for all integer arguments it is correct.; BUT for non-integer values it IS NOT equal to the Poisson distribution.; see TMath::PoissonI to get a non-smooth function.; Note that",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18466,Integrability,integrat,integrated,18466,"on, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case,",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18606,Integrability,rout,routine,18606,":; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case, a=b, the algorithm advances each array by one index in an; attempt to move through the equality. However, this is in",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:33702,Integrability,rout,routine,33702,"meter beta.; By default, alpha=0, beta=1; This distribution is known under different names, most common is; double exponential distribution, but it also appears as; the two-tailed exponential or the bilateral exponential distribution. Double_t LogNormal(Double_t x, Double_t sigma, Double_t theta = 0, Double_t m = 1); Computes the density of LogNormal distribution at point x.; Variable X has lognormal distribution if Y=Ln(X) has normal distribution; sigma is the shape parameter; theta is the location parameter; m is the scale parameter; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm; Implementation using ROOT::Math::lognormal_pdf. /*; ; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then th",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:38949,Integrability,wrap,wrapper,38949,"Double_t x); { return tan(x); }. Double_t SinH(Double_t x); { return sinh(x); }. Double_t CosH(Double_t x); { return cosh(x); }. Double_t TanH(Double_t x); { return tanh(x); }. Double_t ASin(Double_t x). Double_t ACos(Double_t x). Double_t ATan(Double_t x); { return atan(x); }. Double_t ATan2(Double_t y, Double_t x). Double_t Sqrt(Double_t x); { return sqrt(x); }. Double_t Ceil(Double_t x); { return ceil(x); }. Int_t CeilNint(Double_t x); { return TMath::Nint(ceil(x)); }. Double_t Floor(Double_t x); { return floor(x); }. Int_t FloorNint(Double_t x); { return TMath::Nint(floor(x)); }. Double_t Exp(Double_t x); { return exp(x); }. Double_t Ldexp(Double_t x, Int_t exp); { return ldexp(x, exp); }. Double_t Power(Double_t x, Double_t y); { return pow(x, y); }. Double_t Log(Double_t x); { return log(x); }. Double_t Log10(Double_t x); { return log10(x); }. Int_t Finite(Double_t x); { return isfinite(x); }. Int_t IsNaN(Double_t x); from math.h. { return isnan(x); }. Double_t QuietNaN(); --------wrapper to numeric_limits. Double_t SignalingNaN(). Double_t Infinity(); returns an infinity as defined by the IEEE standard. template <typename T> inline T NormCross(const T v1[3],const T v2[3],T out[3]); Calculate the Normalized Cross Product of two vectors. T MinElement(Long64_t n, const T *a); Return minimum of array a of length n. T MaxElement(Long64_t n, const T *a); Return maximum of array a of length n. Long64_t LocMin(Long64_t n, const T *a); Return index of array with the minimum element.; If more than one element is minimum returns first found. Iterator LocMin(Iterator first, Iterator last); Return index of array with the minimum element.; If more than one element is minimum returns first found. Long64_t LocMax(Long64_t n, const T *a); Return index of array with the maximum element.; If more than one element is maximum returns first found. Iterator LocMax(Iterator first, Iterator last); Return index of array with the maximum element.; If more than one element is maximum re",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:14382,Modifiability,adapt,adapted,14382,"; Handbook of Mathematical Functions by Abramowitz and Stegun, formula 6.5.1 on page 260 .; Its normalization is such that TMath::Gamma(a,+infinity) = 1 . --- Nve 14-nov-1998 UU-SAP Utrecht. Double_t BreitWigner(Double_t x, Double_t mean = 0, Double_t gamma = 1); Calculate a Breit Wigner function with mean and gamma. Double_t Gaus(Double_t x, Double_t mean = 0, Double_t sigma = 1, Bool_t norm = kFALSE); Calculate a gaussian function with mean and sigma.; If norm=kTRUE (default is kFALSE) the result is divided; by sqrt(2*Pi)*sigma. Double_t Landau(Double_t x, Double_t mpv = 0, Double_t sigma = 1, Bool_t norm = kFALSE); The LANDAU function.; mpv is a location parameter and correspond approximatly to the most probable value; and sigma is a scale parameter (not the sigma of the full distribution which is not defined); Note that for mpv=0 and sigma=1 (default values) the exact location of the maximum of the distribution (most proble value) is at; x = -0.22278; This function has been adapted from the CERNLIB routine G110 denlan.; If norm=kTRUE (default is kFALSE) the result is divided by sigma. Double_t LnGamma(Double_t z); Computation of ln[gamma(z)] for all z. C.Lanczos, SIAM Journal of Numerical Analysis B1 (1964), 86. The accuracy of the result is better than 2e-10. --- Nve 14-nov-1998 UU-SAP Utrecht. Float_t Normalize(Float_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector. Double_t Normalize(Double_t v[3]); Normalize a vector v in place.; Returns the norm of the original vector.; This implementation (thanks Kevin Lynch <krlynch@bu.edu>) is protected; against possible overflows. Double_t Poisson(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); The Poisson PDF is implemented by means of Euler's Gamma-function; (for the factorial), so for all integer arguments it is correct.; BUT for non-integer values it IS NOT equal to the Poisson distribution.; see TMath::PoissonI to get a non-smooth function.; Note that",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18572,Modifiability,adapt,adapted,18572,":; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case, a=b, the algorithm advances each array by one index in an; attempt to move through the equality. However, this is in",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:21084,Modifiability,adapt,adapted,21084," would invalidate Kolmogorov's theorem). The solution is to just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than 10^(-r).; r can be set by the the user subject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubic(const Double_t* coef, Double_t& a, Double_t& b, Double_t& c); Calculates roots of polynomial of 3rd order a*x^3 + b*x^2 + c*x + d, where; a == coef[3], b == coef[2], c == coef[1], d == coef[0]; coef[3] must be different from 0; If the boolean returned by the method is false:; ==> there are 3 real roots a,b,c; If the boolean returned by the method is true:; ==> there is one real root a and 2 complex conjugates roots (b+i*c,b-i*c); Author: Francois-Xavier Gentit. void Quantiles(Int_t n, Int_t nprob, Double_t* x, Double_t* quantiles, Double_t* prob, Bool_t isSorted = kTRUE, Int_t* index = 0, Int_t ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:30435,Modifiability,variab,variable,30435,"andard deviation than; does a single point.; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm; Implementation by Anna Kreshuk.; Example:; TF1* fc = new TF1(""fc"", ""TMath::CauchyDist(x, [0], [1])"", -5, 5);; fc->SetParameters(0, 1);; fc->Draw();. Double_t ChisquareQuantile(Double_t p, Double_t ndf); Evaluate the quantiles of the chi-squared probability distribution function.; Algorithm AS 91 Appl. Statist. (1975) Vol.24, P.35; implemented by Anna Kreshuk.; Incorporates the suggested changes in AS R85 (vol.40(1), pp.233-5, 1991); Parameters:; p - the probability value, at which the quantile is computed; ndf - number of degrees of freedom. Double_t FDist(Double_t F, Double_t N, Double_t M); Computes the density function of F-distribution; (probability function, integral of density, is computed in FDistI). Parameters N and M stand for degrees of freedom of chi-squares; mentioned above parameter F is the actual variable x of the; density function p(x) and the point at which the density function; is calculated. About F distribution:; F-distribution arises in testing whether two random samples; have the same variance. It is the ratio of two chi-square; distributions, with N and M degrees of freedom respectively,; where each chi-square is first divided by it's number of degrees; of freedom.; Implementation by Anna Kreshuk. Double_t FDistI(Double_t F, Double_t N, Double_t M); Calculates the cumulative distribution function of F-distribution,; this function occurs in the statistical test of whether two observed; samples have the same variance. For this test a certain statistic F,; the ratio of observed dispersion of the first sample to that of the; second sample, is calculated. N and M stand for numbers of degrees; of freedom in the samples 1-FDistI() is the significance level at; which the hypothesis ""1 has smaller variance than 2"" can be rejected.; A small numerical value of 1 - FDistI() impl",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:33681,Modifiability,adapt,adapted,33681,"meter beta.; By default, alpha=0, beta=1; This distribution is known under different names, most common is; double exponential distribution, but it also appears as; the two-tailed exponential or the bilateral exponential distribution. Double_t LogNormal(Double_t x, Double_t sigma, Double_t theta = 0, Double_t m = 1); Computes the density of LogNormal distribution at point x.; Variable X has lognormal distribution if Y=Ln(X) has normal distribution; sigma is the shape parameter; theta is the location parameter; m is the scale parameter; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm; Implementation using ROOT::Math::lognormal_pdf. /*; ; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then th",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:34070,Modifiability,variab,variable,34070,"e shape parameter; theta is the location parameter; m is the scale parameter; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm; Implementation using ROOT::Math::lognormal_pdf. /*; ; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then the variable. t = (sample_mean - Mu)/(sample_deviation / sqrt(n)). has Student's t-distribution with n-1 degrees of freedom. NOTE that this function's second argument is number of degrees of freedom,; not the sample size. As the number of degrees of freedom grows, t-distribution approaches; Normal(0,1) distribution.; Implementation by Anna Kreshuk. Double_t StudentI(Double_t T, Double_t ndf); Calculates the cumulative distribution function of Student's; t-distrib",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:34630,Modifiability,variab,variable,34630,"f; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then the variable. t = (sample_mean - Mu)/(sample_deviation / sqrt(n)). has Student's t-distribution with n-1 degrees of freedom. NOTE that this function's second argument is number of degrees of freedom,; not the sample size. As the number of degrees of freedom grows, t-distribution approaches; Normal(0,1) distribution.; Implementation by Anna Kreshuk. Double_t StudentI(Double_t T, Double_t ndf); Calculates the cumulative distribution function of Student's; t-distribution second parameter stands for number of degrees of freedom,; not for the number of samples; if x has Student's t-distribution, the function returns the probability of; x being less than T.; Implementation by Anna Kreshuk. Double_t StudentQuantile(Double_t p, Double_t ndf, Bool_t lower_tail = kTRUE); Computes quantiles of the Student's t-distribution; 1st argument is the probability, at which the quantile is computed; 2nd argument - the number of degrees of freedom of the; Student distribution; When the 3rd argument lower_tail i",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:20201,Performance,perform,perform,20201,"a++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case, a=b, the algorithm advances each array by one index in an; attempt to move through the equality. However, this is incorrect when one or; the other of a or b (or both) have a repeated value, call it x. For the KS; statistic to be computed properly, rdiff needs to be calculated after all of; the a and b at x have been tallied (this is due to the definition of the; empirical distribution function; another way to convince yourself that the; old CERNLIB method is wrong is that it implies that the function defined as the; difference between a and b is multi-valued at x -- besides being ugly, this; would invalidate Kolmogorov's theorem). The solution is to just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:24361,Security,hash,hash,24361,"pe=9 - resulting sample quantiles are approximately unbiased, when; the sample comes from Normal distribution. p(k)=(k-3/8)/(n+1/4);. default type = 7. References:; 1) Hyndman, R.J and Fan, Y, (1996) ""Sample quantiles in statistical packages""; American Statistician, 50, 361-365; 2) R Project documentation for the function quantile of package {stats}. void BubbleHigh(Int_t Narr, Double_t* arr1, Int_t* arr2); Bubble sort variant to obtain the order of an array's elements into; an index in order to do more useful things than the standard built; in functions.; *arr1 is unchanged;; *arr2 is the array of indicies corresponding to the decending value; of arr1 with arr2[0] corresponding to the largest arr1 value and; arr2[Narr] the smallest. Author: Adrian Bevan (bevan@slac.stanford.edu). void BubbleLow(Int_t Narr, Double_t* arr1, Int_t* arr2); Opposite ordering of the array arr2[] to that of BubbleHigh. Author: Adrian Bevan (bevan@slac.stanford.edu). ULong_t Hash(const void* txt, Int_t ntxt); Calculates hash index from any char string.; Based on precalculated table of 256 specially selected numbers.; These numbers are selected in such a way, that for string; length == 4 (integer number) the hash is unambigous, i.e.; from hash value we can recalculate input (no degeneration). The quality of hash method is good enough, that; ""random"" numbers made as R = Hash(1), Hash(2), ...Hash(N); tested by <R>, <R*R>, <Ri*Ri+1> gives the same result; as for libc rand(). For string: i = TMath::Hash(string,nstring);; For int: i = TMath::Hash(&intword,sizeof(int));; For pointer: i = TMath::Hash(&pointer,sizeof(void*));. V.Perev; This function is kept for back compatibility. The code previously in this function; has been moved to the static function TString::Hash. ULong_t Hash(const char* str). Double_t BesselI0(Double_t x); Compute the modified Bessel function I_0(x) for any real x. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselK0(Double_t x); Compute the modified Bessel function K_0(x) ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:24552,Security,hash,hash,24552," Hyndman, R.J and Fan, Y, (1996) ""Sample quantiles in statistical packages""; American Statistician, 50, 361-365; 2) R Project documentation for the function quantile of package {stats}. void BubbleHigh(Int_t Narr, Double_t* arr1, Int_t* arr2); Bubble sort variant to obtain the order of an array's elements into; an index in order to do more useful things than the standard built; in functions.; *arr1 is unchanged;; *arr2 is the array of indicies corresponding to the decending value; of arr1 with arr2[0] corresponding to the largest arr1 value and; arr2[Narr] the smallest. Author: Adrian Bevan (bevan@slac.stanford.edu). void BubbleLow(Int_t Narr, Double_t* arr1, Int_t* arr2); Opposite ordering of the array arr2[] to that of BubbleHigh. Author: Adrian Bevan (bevan@slac.stanford.edu). ULong_t Hash(const void* txt, Int_t ntxt); Calculates hash index from any char string.; Based on precalculated table of 256 specially selected numbers.; These numbers are selected in such a way, that for string; length == 4 (integer number) the hash is unambigous, i.e.; from hash value we can recalculate input (no degeneration). The quality of hash method is good enough, that; ""random"" numbers made as R = Hash(1), Hash(2), ...Hash(N); tested by <R>, <R*R>, <Ri*Ri+1> gives the same result; as for libc rand(). For string: i = TMath::Hash(string,nstring);; For int: i = TMath::Hash(&intword,sizeof(int));; For pointer: i = TMath::Hash(&pointer,sizeof(void*));. V.Perev; This function is kept for back compatibility. The code previously in this function; has been moved to the static function TString::Hash. ULong_t Hash(const char* str). Double_t BesselI0(Double_t x); Compute the modified Bessel function I_0(x) for any real x. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselK0(Double_t x); Compute the modified Bessel function K_0(x) for positive real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; Applied Mathematics Series vol. 55 (1964), Washington. --- NvE 12-mar-2000 UU-S",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:24583,Security,hash,hash,24583,"istician, 50, 361-365; 2) R Project documentation for the function quantile of package {stats}. void BubbleHigh(Int_t Narr, Double_t* arr1, Int_t* arr2); Bubble sort variant to obtain the order of an array's elements into; an index in order to do more useful things than the standard built; in functions.; *arr1 is unchanged;; *arr2 is the array of indicies corresponding to the decending value; of arr1 with arr2[0] corresponding to the largest arr1 value and; arr2[Narr] the smallest. Author: Adrian Bevan (bevan@slac.stanford.edu). void BubbleLow(Int_t Narr, Double_t* arr1, Int_t* arr2); Opposite ordering of the array arr2[] to that of BubbleHigh. Author: Adrian Bevan (bevan@slac.stanford.edu). ULong_t Hash(const void* txt, Int_t ntxt); Calculates hash index from any char string.; Based on precalculated table of 256 specially selected numbers.; These numbers are selected in such a way, that for string; length == 4 (integer number) the hash is unambigous, i.e.; from hash value we can recalculate input (no degeneration). The quality of hash method is good enough, that; ""random"" numbers made as R = Hash(1), Hash(2), ...Hash(N); tested by <R>, <R*R>, <Ri*Ri+1> gives the same result; as for libc rand(). For string: i = TMath::Hash(string,nstring);; For int: i = TMath::Hash(&intword,sizeof(int));; For pointer: i = TMath::Hash(&pointer,sizeof(void*));. V.Perev; This function is kept for back compatibility. The code previously in this function; has been moved to the static function TString::Hash. ULong_t Hash(const char* str). Double_t BesselI0(Double_t x); Compute the modified Bessel function I_0(x) for any real x. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselK0(Double_t x); Compute the modified Bessel function K_0(x) for positive real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; Applied Mathematics Series vol. 55 (1964), Washington. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselI1(Double_t x); Compute the modified Bessel function I_1(x) for ",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:24653,Security,hash,hash,24653,"ackage {stats}. void BubbleHigh(Int_t Narr, Double_t* arr1, Int_t* arr2); Bubble sort variant to obtain the order of an array's elements into; an index in order to do more useful things than the standard built; in functions.; *arr1 is unchanged;; *arr2 is the array of indicies corresponding to the decending value; of arr1 with arr2[0] corresponding to the largest arr1 value and; arr2[Narr] the smallest. Author: Adrian Bevan (bevan@slac.stanford.edu). void BubbleLow(Int_t Narr, Double_t* arr1, Int_t* arr2); Opposite ordering of the array arr2[] to that of BubbleHigh. Author: Adrian Bevan (bevan@slac.stanford.edu). ULong_t Hash(const void* txt, Int_t ntxt); Calculates hash index from any char string.; Based on precalculated table of 256 specially selected numbers.; These numbers are selected in such a way, that for string; length == 4 (integer number) the hash is unambigous, i.e.; from hash value we can recalculate input (no degeneration). The quality of hash method is good enough, that; ""random"" numbers made as R = Hash(1), Hash(2), ...Hash(N); tested by <R>, <R*R>, <Ri*Ri+1> gives the same result; as for libc rand(). For string: i = TMath::Hash(string,nstring);; For int: i = TMath::Hash(&intword,sizeof(int));; For pointer: i = TMath::Hash(&pointer,sizeof(void*));. V.Perev; This function is kept for back compatibility. The code previously in this function; has been moved to the static function TString::Hash. ULong_t Hash(const char* str). Double_t BesselI0(Double_t x); Compute the modified Bessel function I_0(x) for any real x. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselK0(Double_t x); Compute the modified Bessel function K_0(x) for positive real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; Applied Mathematics Series vol. 55 (1964), Washington. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselI1(Double_t x); Compute the modified Bessel function I_1(x) for any real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; A",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:16388,Testability,test,test,16388,"e values of par, it is better to call; TMath::Gaus(x,par,sqrt(par),kTRUE). /*. */. Double_t PoissonI(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); This is a non-smooth function.; This function is equivalent to ROOT::Math::poisson_pdf. /*. */. Double_t Prob(Double_t chi2, Int_t ndf); Computation of the probability for a certain Chi-squared (chi2); and number of degrees of freedom (ndf). Calculations are based on the incomplete gamma function P(a,x),; where a=ndf/2 and x=chi2/2. P(a,x) represents the probability that the observed Chi-squared; for a correct model should be less than the value chi2. The returned probability corresponds to 1-P(a,x),; which denotes the probability that an observed Chi-squared exceeds; the value chi2 by chance, even for a correct model. --- NvE 14-nov-1998 UU-SAP Utrecht. Double_t KolmogorovProb(Double_t z); Calculates the Kolmogorov distribution function,. /*; ; */. which gives the probability that Kolmogorov's test statistic will exceed; the value z assuming the null hypothesis. This gives a very powerful; test for comparing two one-dimensional distributions.; see, for example, Eadie et al, ""statistocal Methods in Experimental; Physics', pp 269-270). This function returns the confidence level for the null hypothesis, where:; z = dn*sqrt(n), and; dn is the maximum deviation between a hypothetical distribution; function and an experimental distribution with; n events. NOTE: To compare two experimental distributions with m and n events,; use z = sqrt(m*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:16486,Testability,test,test,16486,"I(Double_t x, Double_t par); compute the Poisson distribution function for (x,par); This is a non-smooth function.; This function is equivalent to ROOT::Math::poisson_pdf. /*. */. Double_t Prob(Double_t chi2, Int_t ndf); Computation of the probability for a certain Chi-squared (chi2); and number of degrees of freedom (ndf). Calculations are based on the incomplete gamma function P(a,x),; where a=ndf/2 and x=chi2/2. P(a,x) represents the probability that the observed Chi-squared; for a correct model should be less than the value chi2. The returned probability corresponds to 1-P(a,x),; which denotes the probability that an observed Chi-squared exceeds; the value chi2 by chance, even for a correct model. --- NvE 14-nov-1998 UU-SAP Utrecht. Double_t KolmogorovProb(Double_t z); Calculates the Kolmogorov distribution function,. /*; ; */. which gives the probability that Kolmogorov's test statistic will exceed; the value z assuming the null hypothesis. This gives a very powerful; test for comparing two one-dimensional distributions.; see, for example, Eadie et al, ""statistocal Methods in Experimental; Physics', pp 269-270). This function returns the confidence level for the null hypothesis, where:; z = dn*sqrt(n), and; dn is the maximum deviation between a hypothetical distribution; function and an experimental distribution with; n events. NOTE: To compare two experimental distributions with m and n events,; use z = sqrt(m*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:17378,Testability,test,test,17378,"est statistic will exceed; the value z assuming the null hypothesis. This gives a very powerful; test for comparing two one-dimensional distributions.; see, for example, Eadie et al, ""statistocal Methods in Experimental; Physics', pp 269-270). This function returns the confidence level for the null hypothesis, where:; z = dn*sqrt(n), and; dn is the maximum deviation between a hypothetical distribution; function and an experimental distribution with; n events. NOTE: To compare two experimental distributions with m and n events,; use z = sqrt(m*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:17510,Testability,test,test,17510,"est statistic will exceed; the value z assuming the null hypothesis. This gives a very powerful; test for comparing two one-dimensional distributions.; see, for example, Eadie et al, ""statistocal Methods in Experimental; Physics', pp 269-270). This function returns the confidence level for the null hypothesis, where:; z = dn*sqrt(n), and; dn is the maximum deviation between a hypothetical distribution; function and an experimental distribution with; n events. NOTE: To compare two experimental distributions with m and n events,; use z = sqrt(m*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:17967,Testability,test,test,17967,"*n/(m+n))*dn. Accuracy: The function is far too accurate for any imaginable application.; Probabilities less than 10^-15 are returned as zero.; However, remember that the formula is only valid for ""large"" n.; Theta function inversion formula is used for z <= 1. This function was translated by Rene Brun from PROBKL in CERNLIB. Double_t KolmogorovTest(Int_t na, const Double_t* a, Int_t nb, const Double_t* b, Option_t* option); Statistical test whether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two so",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18391,Testability,test,test,18391,"ether two one-dimensional sets of points are compatible; with coming from the same parent distribution, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (i",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:18409,Testability,test,test,18409,"on, using the Kolmogorov test.; That is, it is used to compare two experimental distributions of unbinned data. Input:; a,b: One-dimensional arrays of length na, nb, respectively.; The elements of a and b must be given in ascending order.; option is a character string to specify options; ""D"" Put out a line of ""Debug"" printout; ""M"" Return the Maximum Kolmogorov distance instead of prob. Output:; The returned value prob is a calculated confidence level which gives a; statistical test for compatibility of a and b.; Values of prob close to zero are taken as indicating a small probability; of compatibility. For two point sets drawn randomly from the same parent; distribution, the value of prob should be uniformly distributed between; zero and one.; in case of error the function return -1; If the 2 sets have a different number of points, the minimum of; the two sets is used. Method:; The Kolmogorov test is used. The test statistic is the maximum deviation; between the two integrated distribution functions, multiplied by the; normalizing factor (rdmax*sqrt(na*nb/(na+nb)). Code adapted by Rene Brun from CERNLIB routine TKOLMO (Fred James); (W.T. Eadie, D. Drijard, F.E. James, M. Roos and B. Sadoulet,; Statistical Methods in Experimental Physics, (North-Holland,; Amsterdam 1971) 269-271). Method Improvement by Jason A Detwiler (JADetwiler@lbl.gov). The nuts-and-bolts of the TMath::KolmogorovTest() algorithm is a for-loop; over the two sorted arrays a and b representing empirical distribution; functions. The for-loop handles 3 cases: when the next points to be; evaluated satisfy a>b, a<b, or a=b:. for (Int_t i=0;i<na+nb;i++) {; if (a[ia-1] < b[ib-1]) {; rdiff -= sa;; ia++;; if (ia > na) {ok = kTRUE; break;}; } else if (a[ia-1] > b[ib-1]) {; rdiff += sb;; ib++;; if (ib > nb) {ok = kTRUE; break;}; } else {; rdiff += sb - sa;; ia++;; ib++;; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }; rdmax = TMath::Max(rdmax,TMath::Abs(rdiff));; }. For the last case,",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:20487,Testability,test,test,20487,"ase, a=b, the algorithm advances each array by one index in an; attempt to move through the equality. However, this is incorrect when one or; the other of a or b (or both) have a repeated value, call it x. For the KS; statistic to be computed properly, rdiff needs to be calculated after all of; the a and b at x have been tallied (this is due to the definition of the; empirical distribution function; another way to convince yourself that the; old CERNLIB method is wrong is that it implies that the function defined as the; difference between a and b is multi-valued at x -- besides being ugly, this; would invalidate Kolmogorov's theorem). The solution is to just add while-loops into the equality-case handling to; perform the tally:. } else {; double x = a[ia-1];; while(a[ia-1] == x && ia <= na) {; rdiff -= sa;; ia++;; }; while(b[ib-1] == x && ib <= nb) {; rdiff += sb;; ib++;; }; if (ia > na) {ok = kTRUE; break;}; if (ib > nb) {ok = kTRUE; break;}; }. NOTE1; A good description of the Kolmogorov test can be seen at:; http://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm. Double_t Voigt(Double_t x, Double_t sigma, Double_t lg, Int_t R = 4); Computation of Voigt function (normalised).; Voigt is a convolution of; gauss(xx) = 1/(sqrt(2*pi)*sigma) * exp(xx*xx/(2*sigma*sigma); and; lorentz(xx) = (1/pi) * (lg/2) / (xx*xx + lg*lg/4); functions. The Voigt function is known to be the real part of Faddeeva function also; called complex error function [2]. The algoritm was developed by J. Humlicek [1].; This code is based on fortran code presented by R. J. Wells [2].; Translated and adapted by Miha D. Puc. To calculate the Faddeeva function with relative error less than 10^(-r).; r can be set by the the user subject to the constraints 2 <= r <= 5. [1] J. Humlicek, JQSRT, 21, 437 (1982).; [2] R.J. Wells ""Rapid Approximation to the Voigt/Faddeeva Function and its; Derivatives"" JQSRT 62 (1999), pp 29-48.; http://www-atm.physics.ox.ac.uk/user/wells/voigt.html. Bool_t RootsCubi",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:24746,Testability,test,tested,24746,"t to obtain the order of an array's elements into; an index in order to do more useful things than the standard built; in functions.; *arr1 is unchanged;; *arr2 is the array of indicies corresponding to the decending value; of arr1 with arr2[0] corresponding to the largest arr1 value and; arr2[Narr] the smallest. Author: Adrian Bevan (bevan@slac.stanford.edu). void BubbleLow(Int_t Narr, Double_t* arr1, Int_t* arr2); Opposite ordering of the array arr2[] to that of BubbleHigh. Author: Adrian Bevan (bevan@slac.stanford.edu). ULong_t Hash(const void* txt, Int_t ntxt); Calculates hash index from any char string.; Based on precalculated table of 256 specially selected numbers.; These numbers are selected in such a way, that for string; length == 4 (integer number) the hash is unambigous, i.e.; from hash value we can recalculate input (no degeneration). The quality of hash method is good enough, that; ""random"" numbers made as R = Hash(1), Hash(2), ...Hash(N); tested by <R>, <R*R>, <Ri*Ri+1> gives the same result; as for libc rand(). For string: i = TMath::Hash(string,nstring);; For int: i = TMath::Hash(&intword,sizeof(int));; For pointer: i = TMath::Hash(&pointer,sizeof(void*));. V.Perev; This function is kept for back compatibility. The code previously in this function; has been moved to the static function TString::Hash. ULong_t Hash(const char* str). Double_t BesselI0(Double_t x); Compute the modified Bessel function I_0(x) for any real x. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselK0(Double_t x); Compute the modified Bessel function K_0(x) for positive real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; Applied Mathematics Series vol. 55 (1964), Washington. --- NvE 12-mar-2000 UU-SAP Utrecht. Double_t BesselI1(Double_t x); Compute the modified Bessel function I_1(x) for any real x. M.Abramowitz and I.A.Stegun, Handbook of Mathematical Functions,; Applied Mathematics Series vol. 55 (1964), Washington. --- NvE 12-mar-2000 UU-SAP Utrecht. Dou",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:30584,Testability,test,testing,30584,"/section3/eda3663.htm; Implementation by Anna Kreshuk.; Example:; TF1* fc = new TF1(""fc"", ""TMath::CauchyDist(x, [0], [1])"", -5, 5);; fc->SetParameters(0, 1);; fc->Draw();. Double_t ChisquareQuantile(Double_t p, Double_t ndf); Evaluate the quantiles of the chi-squared probability distribution function.; Algorithm AS 91 Appl. Statist. (1975) Vol.24, P.35; implemented by Anna Kreshuk.; Incorporates the suggested changes in AS R85 (vol.40(1), pp.233-5, 1991); Parameters:; p - the probability value, at which the quantile is computed; ndf - number of degrees of freedom. Double_t FDist(Double_t F, Double_t N, Double_t M); Computes the density function of F-distribution; (probability function, integral of density, is computed in FDistI). Parameters N and M stand for degrees of freedom of chi-squares; mentioned above parameter F is the actual variable x of the; density function p(x) and the point at which the density function; is calculated. About F distribution:; F-distribution arises in testing whether two random samples; have the same variance. It is the ratio of two chi-square; distributions, with N and M degrees of freedom respectively,; where each chi-square is first divided by it's number of degrees; of freedom.; Implementation by Anna Kreshuk. Double_t FDistI(Double_t F, Double_t N, Double_t M); Calculates the cumulative distribution function of F-distribution,; this function occurs in the statistical test of whether two observed; samples have the same variance. For this test a certain statistic F,; the ratio of observed dispersion of the first sample to that of the; second sample, is calculated. N and M stand for numbers of degrees; of freedom in the samples 1-FDistI() is the significance level at; which the hypothesis ""1 has smaller variance than 2"" can be rejected.; A small numerical value of 1 - FDistI() implies a very significant; rejection, in turn implying high confidence in the hypothesis; ""1 has variance greater than 2"".; Implementation by Anna Kreshuk. Doub",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:31013,Testability,test,test,31013,"na Kreshuk.; Incorporates the suggested changes in AS R85 (vol.40(1), pp.233-5, 1991); Parameters:; p - the probability value, at which the quantile is computed; ndf - number of degrees of freedom. Double_t FDist(Double_t F, Double_t N, Double_t M); Computes the density function of F-distribution; (probability function, integral of density, is computed in FDistI). Parameters N and M stand for degrees of freedom of chi-squares; mentioned above parameter F is the actual variable x of the; density function p(x) and the point at which the density function; is calculated. About F distribution:; F-distribution arises in testing whether two random samples; have the same variance. It is the ratio of two chi-square; distributions, with N and M degrees of freedom respectively,; where each chi-square is first divided by it's number of degrees; of freedom.; Implementation by Anna Kreshuk. Double_t FDistI(Double_t F, Double_t N, Double_t M); Calculates the cumulative distribution function of F-distribution,; this function occurs in the statistical test of whether two observed; samples have the same variance. For this test a certain statistic F,; the ratio of observed dispersion of the first sample to that of the; second sample, is calculated. N and M stand for numbers of degrees; of freedom in the samples 1-FDistI() is the significance level at; which the hypothesis ""1 has smaller variance than 2"" can be rejected.; A small numerical value of 1 - FDistI() implies a very significant; rejection, in turn implying high confidence in the hypothesis; ""1 has variance greater than 2"".; Implementation by Anna Kreshuk. Double_t GammaDist(Double_t x, Double_t gamma, Double_t mu = 0, Double_t beta = 1); Computes the density function of Gamma distribution at point x.; gamma - shape parameter; mu - location parameter; beta - scale parameter. The definition can be found in ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda366b.htm; use now impleme",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:31084,Testability,test,test,31084,"grees of freedom. Double_t FDist(Double_t F, Double_t N, Double_t M); Computes the density function of F-distribution; (probability function, integral of density, is computed in FDistI). Parameters N and M stand for degrees of freedom of chi-squares; mentioned above parameter F is the actual variable x of the; density function p(x) and the point at which the density function; is calculated. About F distribution:; F-distribution arises in testing whether two random samples; have the same variance. It is the ratio of two chi-square; distributions, with N and M degrees of freedom respectively,; where each chi-square is first divided by it's number of degrees; of freedom.; Implementation by Anna Kreshuk. Double_t FDistI(Double_t F, Double_t N, Double_t M); Calculates the cumulative distribution function of F-distribution,; this function occurs in the statistical test of whether two observed; samples have the same variance. For this test a certain statistic F,; the ratio of observed dispersion of the first sample to that of the; second sample, is calculated. N and M stand for numbers of degrees; of freedom in the samples 1-FDistI() is the significance level at; which the hypothesis ""1 has smaller variance than 2"" can be rejected.; A small numerical value of 1 - FDistI() implies a very significant; rejection, in turn implying high confidence in the hypothesis; ""1 has variance greater than 2"".; Implementation by Anna Kreshuk. Double_t GammaDist(Double_t x, Double_t gamma, Double_t mu = 0, Double_t beta = 1); Computes the density function of Gamma distribution at point x.; gamma - shape parameter; mu - location parameter; beta - scale parameter. The definition can be found in ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda366b.htm; use now implementation in ROOT::Math::gamma_pdf. /*; ; */. Double_t LaplaceDist(Double_t x, Double_t alpha = 0, Double_t beta = 1); Computes the probability density function of Laplace distributi",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:33022,Testability,log,lognormal,33022,"lace distribution; at point x, with location parameter alpha and shape parameter beta.; By default, alpha=0, beta=1; This distribution is known under different names, most common is; double exponential distribution, but it also appears as; the two-tailed exponential or the bilateral exponential distribution. Double_t LaplaceDistI(Double_t x, Double_t alpha = 0, Double_t beta = 1); Computes the distribution function of Laplace distribution; at point x, with location parameter alpha and shape parameter beta.; By default, alpha=0, beta=1; This distribution is known under different names, most common is; double exponential distribution, but it also appears as; the two-tailed exponential or the bilateral exponential distribution. Double_t LogNormal(Double_t x, Double_t sigma, Double_t theta = 0, Double_t m = 1); Computes the density of LogNormal distribution at point x.; Variable X has lognormal distribution if Y=Ln(X) has normal distribution; sigma is the shape parameter; theta is the location parameter; m is the scale parameter; The formula was taken from ""Engineering Statistics Handbook"" on site; http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm; Implementation using ROOT::Math::lognormal_pdf. /*; ; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at wh",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:34302,Testability,test,tests,34302,"; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then the variable. t = (sample_mean - Mu)/(sample_deviation / sqrt(n)). has Student's t-distribution with n-1 degrees of freedom. NOTE that this function's second argument is number of degrees of freedom,; not the sample size. As the number of degrees of freedom grows, t-distribution approaches; Normal(0,1) distribution.; Implementation by Anna Kreshuk. Double_t StudentI(Double_t T, Double_t ndf); Calculates the cumulative distribution function of Student's; t-distribution second parameter stands for number of degrees of freedom,; not for the number of samples; if x has Student's t-distribution, the function returns the probability of; x being less than T.; Implementation by Anna Kreshuk. Double_t StudentQuantile(Double_t p, Dou",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:34343,Testability,test,tests,34343,"; */. Double_t NormQuantile(Double_t p); Computes quantiles for standard normal distribution N(0, 1); at probability p; ALGORITHM AS241 APPL. STATIST. (1988) VOL. 37, NO. 3, 477-484. Bool_t Permute(Int_t n, Int_t* a); Simple recursive algorithm to find the permutations of; n natural numbers, not necessarily all distinct; adapted from CERNLIB routine PERMU.; The input array has to be initialised with a non descending; sequence. The method returns kFALSE when; all combinations are exhausted. Double_t Student(Double_t T, Double_t ndf); Computes density function for Student's t- distribution; (the probability function (integral of density) is computed in StudentI). First parameter stands for x - the actual variable of the; density function p(x) and the point at which the density is calculated.; Second parameter stands for number of degrees of freedom. About Student distribution:; Student's t-distribution is used for many significance tests, for example,; for the Student's t-tests for the statistical significance of difference; between two sample means and for confidence intervals for the difference; between two population means. Example: suppose we have a random sample of size n drawn from normal; distribution with mean Mu and st.deviation Sigma. Then the variable. t = (sample_mean - Mu)/(sample_deviation / sqrt(n)). has Student's t-distribution with n-1 degrees of freedom. NOTE that this function's second argument is number of degrees of freedom,; not the sample size. As the number of degrees of freedom grows, t-distribution approaches; Normal(0,1) distribution.; Implementation by Anna Kreshuk. Double_t StudentI(Double_t T, Double_t ndf); Calculates the cumulative distribution function of Student's; t-distribution second parameter stands for number of degrees of freedom,; not for the number of samples; if x has Student's t-distribution, the function returns the probability of; x being less than T.; Implementation by Anna Kreshuk. Double_t StudentQuantile(Double_t p, Dou",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:38748,Testability,log,log,38748,"big and B.Schorr, ""A program package for the Landau; distribution"", Computer Phys.Comm., 31(1984), 97-111. Double_t Sin(Double_t x); { return sin(x); }. Double_t Cos(Double_t x); { return cos(x); }. Double_t Tan(Double_t x); { return tan(x); }. Double_t SinH(Double_t x); { return sinh(x); }. Double_t CosH(Double_t x); { return cosh(x); }. Double_t TanH(Double_t x); { return tanh(x); }. Double_t ASin(Double_t x). Double_t ACos(Double_t x). Double_t ATan(Double_t x); { return atan(x); }. Double_t ATan2(Double_t y, Double_t x). Double_t Sqrt(Double_t x); { return sqrt(x); }. Double_t Ceil(Double_t x); { return ceil(x); }. Int_t CeilNint(Double_t x); { return TMath::Nint(ceil(x)); }. Double_t Floor(Double_t x); { return floor(x); }. Int_t FloorNint(Double_t x); { return TMath::Nint(floor(x)); }. Double_t Exp(Double_t x); { return exp(x); }. Double_t Ldexp(Double_t x, Int_t exp); { return ldexp(x, exp); }. Double_t Power(Double_t x, Double_t y); { return pow(x, y); }. Double_t Log(Double_t x); { return log(x); }. Double_t Log10(Double_t x); { return log10(x); }. Int_t Finite(Double_t x); { return isfinite(x); }. Int_t IsNaN(Double_t x); from math.h. { return isnan(x); }. Double_t QuietNaN(); --------wrapper to numeric_limits. Double_t SignalingNaN(). Double_t Infinity(); returns an infinity as defined by the IEEE standard. template <typename T> inline T NormCross(const T v1[3],const T v2[3],T out[3]); Calculate the Normalized Cross Product of two vectors. T MinElement(Long64_t n, const T *a); Return minimum of array a of length n. T MaxElement(Long64_t n, const T *a); Return maximum of array a of length n. Long64_t LocMin(Long64_t n, const T *a); Return index of array with the minimum element.; If more than one element is minimum returns first found. Iterator LocMin(Iterator first, Iterator last); Return index of array with the minimum element.; If more than one element is minimum returns first found. Long64_t LocMax(Long64_t n, const T *a); Return index of array with th",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:45130,Testability,log,log,45130,"st Element *a, Size k, Size *work); Returns k_th order statistic of the array a of size n; (k_th smallest element out of n elements). C-convention is used for array indexing, so if you want; the second smallest element, call KOrdStat(n, a, 1). If work is supplied, it is used to store the sorting index and; assumed to be >= n. If work=0, local storage is used, either on; the stack if n < kWorkMax or on the heap for n >= kWorkMax. Taken from ""Numerical Recipes in C++"" without the index array; implemented by Anna Khreshuk. See also the declarations at the top of this file. Double_t Pi(). Fundamental constants. { return 3.14159265358979323846; }. Double_t TwoPi(); { return 2.0 * Pi(); }. Double_t PiOver2(); { return Pi() / 2.0; }. Double_t PiOver4(); { return Pi() / 4.0; }. Double_t InvPi(); { return 1.0 / Pi(); }. Double_t RadToDeg(); { return 180.0 / Pi(); }. Double_t DegToRad(); { return Pi() / 180.0; }. Double_t Sqrt2(); { return 1.4142135623730950488016887242097; }. Double_t E(); e (base of natural log). { return 2.71828182845904523536; }. Double_t Ln10(); natural log of 10 (to convert log to ln). { return 2.30258509299404568402; }. Double_t LogE(); base-10 log of e (to convert ln to log). { return 0.43429448190325182765; }. Double_t C(); velocity of light. { return 2.99792458e8; }. Double_t Ccgs(); { return 100.0 * C(); }. Double_t CUncertainty(); { return 0.0; }. Double_t G(); gravitational constant. { return 6.673e-11; }. Double_t Gcgs(); { return G() / 1000.0; }. Double_t GUncertainty(); { return 0.010e-11; }. Double_t GhbarC(); G over h-bar C. { return 6.707e-39; }. Double_t GhbarCUncertainty(); { return 0.010e-39; }. Double_t Gn(); standard acceleration of gravity. { return 9.80665; }. Double_t GnUncertainty(); { return 0.0; }. Double_t H(); Planck's constant. { return 6.62606876e-34; }. Double_t Hcgs(); { return 1.0e7 * H(); }. Double_t HUncertainty(); { return 0.00000052e-34; }. Double_t Hbar(); h-bar (h over 2 pi). { return 1.054571596e-34; }. Double_t Hbar",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:45197,Testability,log,log,45197,"ze n; (k_th smallest element out of n elements). C-convention is used for array indexing, so if you want; the second smallest element, call KOrdStat(n, a, 1). If work is supplied, it is used to store the sorting index and; assumed to be >= n. If work=0, local storage is used, either on; the stack if n < kWorkMax or on the heap for n >= kWorkMax. Taken from ""Numerical Recipes in C++"" without the index array; implemented by Anna Khreshuk. See also the declarations at the top of this file. Double_t Pi(). Fundamental constants. { return 3.14159265358979323846; }. Double_t TwoPi(); { return 2.0 * Pi(); }. Double_t PiOver2(); { return Pi() / 2.0; }. Double_t PiOver4(); { return Pi() / 4.0; }. Double_t InvPi(); { return 1.0 / Pi(); }. Double_t RadToDeg(); { return 180.0 / Pi(); }. Double_t DegToRad(); { return Pi() / 180.0; }. Double_t Sqrt2(); { return 1.4142135623730950488016887242097; }. Double_t E(); e (base of natural log). { return 2.71828182845904523536; }. Double_t Ln10(); natural log of 10 (to convert log to ln). { return 2.30258509299404568402; }. Double_t LogE(); base-10 log of e (to convert ln to log). { return 0.43429448190325182765; }. Double_t C(); velocity of light. { return 2.99792458e8; }. Double_t Ccgs(); { return 100.0 * C(); }. Double_t CUncertainty(); { return 0.0; }. Double_t G(); gravitational constant. { return 6.673e-11; }. Double_t Gcgs(); { return G() / 1000.0; }. Double_t GUncertainty(); { return 0.010e-11; }. Double_t GhbarC(); G over h-bar C. { return 6.707e-39; }. Double_t GhbarCUncertainty(); { return 0.010e-39; }. Double_t Gn(); standard acceleration of gravity. { return 9.80665; }. Double_t GnUncertainty(); { return 0.0; }. Double_t H(); Planck's constant. { return 6.62606876e-34; }. Double_t Hcgs(); { return 1.0e7 * H(); }. Double_t HUncertainty(); { return 0.00000052e-34; }. Double_t Hbar(); h-bar (h over 2 pi). { return 1.054571596e-34; }. Double_t Hbarcgs(); { return 1.0e7 * Hbar(); }. Double_t HbarUncertainty(); { return 0.000000082e-",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:45219,Testability,log,log,45219,"ze n; (k_th smallest element out of n elements). C-convention is used for array indexing, so if you want; the second smallest element, call KOrdStat(n, a, 1). If work is supplied, it is used to store the sorting index and; assumed to be >= n. If work=0, local storage is used, either on; the stack if n < kWorkMax or on the heap for n >= kWorkMax. Taken from ""Numerical Recipes in C++"" without the index array; implemented by Anna Khreshuk. See also the declarations at the top of this file. Double_t Pi(). Fundamental constants. { return 3.14159265358979323846; }. Double_t TwoPi(); { return 2.0 * Pi(); }. Double_t PiOver2(); { return Pi() / 2.0; }. Double_t PiOver4(); { return Pi() / 4.0; }. Double_t InvPi(); { return 1.0 / Pi(); }. Double_t RadToDeg(); { return 180.0 / Pi(); }. Double_t DegToRad(); { return Pi() / 180.0; }. Double_t Sqrt2(); { return 1.4142135623730950488016887242097; }. Double_t E(); e (base of natural log). { return 2.71828182845904523536; }. Double_t Ln10(); natural log of 10 (to convert log to ln). { return 2.30258509299404568402; }. Double_t LogE(); base-10 log of e (to convert ln to log). { return 0.43429448190325182765; }. Double_t C(); velocity of light. { return 2.99792458e8; }. Double_t Ccgs(); { return 100.0 * C(); }. Double_t CUncertainty(); { return 0.0; }. Double_t G(); gravitational constant. { return 6.673e-11; }. Double_t Gcgs(); { return G() / 1000.0; }. Double_t GUncertainty(); { return 0.010e-11; }. Double_t GhbarC(); G over h-bar C. { return 6.707e-39; }. Double_t GhbarCUncertainty(); { return 0.010e-39; }. Double_t Gn(); standard acceleration of gravity. { return 9.80665; }. Double_t GnUncertainty(); { return 0.0; }. Double_t H(); Planck's constant. { return 6.62606876e-34; }. Double_t Hcgs(); { return 1.0e7 * H(); }. Double_t HUncertainty(); { return 0.00000052e-34; }. Double_t Hbar(); h-bar (h over 2 pi). { return 1.054571596e-34; }. Double_t Hbarcgs(); { return 1.0e7 * Hbar(); }. Double_t HbarUncertainty(); { return 0.000000082e-",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:45292,Testability,log,log,45292," you want; the second smallest element, call KOrdStat(n, a, 1). If work is supplied, it is used to store the sorting index and; assumed to be >= n. If work=0, local storage is used, either on; the stack if n < kWorkMax or on the heap for n >= kWorkMax. Taken from ""Numerical Recipes in C++"" without the index array; implemented by Anna Khreshuk. See also the declarations at the top of this file. Double_t Pi(). Fundamental constants. { return 3.14159265358979323846; }. Double_t TwoPi(); { return 2.0 * Pi(); }. Double_t PiOver2(); { return Pi() / 2.0; }. Double_t PiOver4(); { return Pi() / 4.0; }. Double_t InvPi(); { return 1.0 / Pi(); }. Double_t RadToDeg(); { return 180.0 / Pi(); }. Double_t DegToRad(); { return Pi() / 180.0; }. Double_t Sqrt2(); { return 1.4142135623730950488016887242097; }. Double_t E(); e (base of natural log). { return 2.71828182845904523536; }. Double_t Ln10(); natural log of 10 (to convert log to ln). { return 2.30258509299404568402; }. Double_t LogE(); base-10 log of e (to convert ln to log). { return 0.43429448190325182765; }. Double_t C(); velocity of light. { return 2.99792458e8; }. Double_t Ccgs(); { return 100.0 * C(); }. Double_t CUncertainty(); { return 0.0; }. Double_t G(); gravitational constant. { return 6.673e-11; }. Double_t Gcgs(); { return G() / 1000.0; }. Double_t GUncertainty(); { return 0.010e-11; }. Double_t GhbarC(); G over h-bar C. { return 6.707e-39; }. Double_t GhbarCUncertainty(); { return 0.010e-39; }. Double_t Gn(); standard acceleration of gravity. { return 9.80665; }. Double_t GnUncertainty(); { return 0.0; }. Double_t H(); Planck's constant. { return 6.62606876e-34; }. Double_t Hcgs(); { return 1.0e7 * H(); }. Double_t HUncertainty(); { return 0.00000052e-34; }. Double_t Hbar(); h-bar (h over 2 pi). { return 1.054571596e-34; }. Double_t Hbarcgs(); { return 1.0e7 * Hbar(); }. Double_t HbarUncertainty(); { return 0.000000082e-34; }. Double_t HC(); hc (h * c). { return H() * C(); }. Double_t HCcgs(); { return Hcgs() * C",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMath.html:45319,Testability,log,log,45319," you want; the second smallest element, call KOrdStat(n, a, 1). If work is supplied, it is used to store the sorting index and; assumed to be >= n. If work=0, local storage is used, either on; the stack if n < kWorkMax or on the heap for n >= kWorkMax. Taken from ""Numerical Recipes in C++"" without the index array; implemented by Anna Khreshuk. See also the declarations at the top of this file. Double_t Pi(). Fundamental constants. { return 3.14159265358979323846; }. Double_t TwoPi(); { return 2.0 * Pi(); }. Double_t PiOver2(); { return Pi() / 2.0; }. Double_t PiOver4(); { return Pi() / 4.0; }. Double_t InvPi(); { return 1.0 / Pi(); }. Double_t RadToDeg(); { return 180.0 / Pi(); }. Double_t DegToRad(); { return Pi() / 180.0; }. Double_t Sqrt2(); { return 1.4142135623730950488016887242097; }. Double_t E(); e (base of natural log). { return 2.71828182845904523536; }. Double_t Ln10(); natural log of 10 (to convert log to ln). { return 2.30258509299404568402; }. Double_t LogE(); base-10 log of e (to convert ln to log). { return 0.43429448190325182765; }. Double_t C(); velocity of light. { return 2.99792458e8; }. Double_t Ccgs(); { return 100.0 * C(); }. Double_t CUncertainty(); { return 0.0; }. Double_t G(); gravitational constant. { return 6.673e-11; }. Double_t Gcgs(); { return G() / 1000.0; }. Double_t GUncertainty(); { return 0.010e-11; }. Double_t GhbarC(); G over h-bar C. { return 6.707e-39; }. Double_t GhbarCUncertainty(); { return 0.010e-39; }. Double_t Gn(); standard acceleration of gravity. { return 9.80665; }. Double_t GnUncertainty(); { return 0.0; }. Double_t H(); Planck's constant. { return 6.62606876e-34; }. Double_t Hcgs(); { return 1.0e7 * H(); }. Double_t HUncertainty(); { return 0.00000052e-34; }. Double_t Hbar(); h-bar (h over 2 pi). { return 1.054571596e-34; }. Double_t Hbarcgs(); { return 1.0e7 * Hbar(); }. Double_t HbarUncertainty(); { return 0.000000082e-34; }. Double_t HC(); hc (h * c). { return H() * C(); }. Double_t HCcgs(); { return Hcgs() * C",MatchSource.WIKI,root/html530/TMath.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMath.html
https://root.cern/root/html530/TMatrixTBase_double_.html:822,Availability,avail,available,822,". TMatrixTBase<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTBase<double>. class TMatrixTBase<double>: public TObject. Linear Algebra Package. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Si",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3983,Availability,down,down,3983,"ken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:7544,Availability,avail,available,7544,"Function(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixDBase, TMatrixTBase<Double_t>. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<double>(); virtual TMatrixTBase<double>&Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<double>&Apply(const TElementActionT<double>& action); virtual TMatrixTBase<double>&Apply(const TElementPosActionT<double>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual vo",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:8862,Availability,error,error,8862,"(const TElementPosActionT<double>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleE2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tGetNcols() const; Int_tGetNoElements() const; Int_tGetNrows() const; virtual char*TObject::GetObjectI",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:8946,Availability,error,error,8946,"; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleE2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tGetNcols() const; Int_tGetNoElements() const; Int_tGetNrows() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2031,Deployability,integrat,integrated,2031,"kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2545,Deployability,install,installation,2545,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2583,Deployability,install,installation,2583,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:1988,Energy Efficiency,efficient,efficient,1988,"ch matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack ",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2454,Energy Efficiency,adapt,adapted,2454,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3259,Energy Efficiency,adapt,adapted,3259,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3315,Energy Efficiency,efficient,efficiently,3315,"; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices,",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:4342,Energy Efficiency,efficient,efficient,4342,"or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);. 4. Accessing row/col/diagonal of a matrix without much fuss; (and without moving a lot of stuff around):. TMatrixD m(n,n); TVectorD v(n); TMatrixDDiag(m) += 4;; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2031,Integrability,integrat,integrated,2031,"kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3101,Integrability,rout,routines,3101,"age examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) ca",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3298,Integrability,rout,routines,3298,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2454,Modifiability,adapt,adapted,2454,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3259,Modifiability,adapt,adapted,3259,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:3955,Performance,optimiz,optimized,3955,"ken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:851,Safety,avoid,avoiding,851,". TMatrixTBase<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTBase<double>. class TMatrixTBase<double>: public TObject. Linear Algebra Package. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Si",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:2133,Testability,test,test,2133," additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-ve",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:4688,Testability,test,test,4688,"; from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);. 4. Accessing row/col/diagonal of a matrix without much fuss; (and without moving a lot of stuff around):. TMatrixD m(n,n); TVectorD v(n); TMatrixDDiag(m) += 4;; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. void foo(const TMatrixD &m); {; TMatrixD m1(TMatrixD::kZero,m);; st",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:6650,Testability,test,test,6650,"xD m1(TMatrixD::kZero,m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixDBase, TMatrixTBase<Double_t>. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<double>(); virtual TMatrixTBase<double>&Abs()",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:6277,Usability,simpl,simple,6277,"; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. void foo(const TMatrixD &m); {; TMatrixD m1(TMatrixD::kZero,m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_double_.html:6950,Usability,simpl,simple,6950,"imal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixDBase, TMatrixTBase<Double_t>. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<double>(); virtual TMatrixTBase<double>&Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<double>&Apply(const TElementActionT<double>& action); virtual TMatrixTBase<double>&Apply(const TElementPosActio",MatchSource.WIKI,root/html530/TMatrixTBase_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_double_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:819,Availability,avail,available,819,". TMatrixTBase<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTBase<float>. class TMatrixTBase<float>: public TObject. Linear Algebra Package. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3980,Availability,down,down,3980,"ken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:7540,Availability,avail,available,7540,"yFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixTBase<Float_t>, TMatrixFBase. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<float>(); virtual TMatrixTBase<float>&Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<float>&Apply(const TElementActionT<float>& action); virtual TMatrixTBase<float>&Apply(const TElementPosActionT<float>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual voidTObje",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:8850,Availability,error,error,8850,"ply(const TElementPosActionT<float>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatE2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tGetNcols() const; Int_tGetNoElements() const; Int_tGetNrows() const; virtual char*TObject::GetObjectInfo(",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:8934,Availability,error,error,8934,"b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatE2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tGetNcols() const; Int_tGetNoElements() const; Int_tGetNrows() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*T",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2028,Deployability,integrat,integrated,2028,"kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2542,Deployability,install,installation,2542,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2580,Deployability,install,installation,2580,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:1985,Energy Efficiency,efficient,efficient,1985,"ch matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack ",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2451,Energy Efficiency,adapt,adapted,2451,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3256,Energy Efficiency,adapt,adapted,3256,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3312,Energy Efficiency,efficient,efficiently,3312,"; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices,",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:4339,Energy Efficiency,efficient,efficient,4339,"or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);. 4. Accessing row/col/diagonal of a matrix without much fuss; (and without moving a lot of stuff around):. TMatrixD m(n,n); TVectorD v(n); TMatrixDDiag(m) += 4;; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2028,Integrability,integrat,integrated,2028,"kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3098,Integrability,rout,routines,3098,"age examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) ca",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3295,Integrability,rout,routines,3295,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2451,Modifiability,adapt,adapted,2451,"es; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom,",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3256,Modifiability,adapt,adapted,3256,"bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:3952,Performance,optimiz,optimized,3952,"ken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines. How to efficiently use this package. 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:848,Safety,avoid,avoiding,848,". TMatrixTBase<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTBase<float>. class TMatrixTBase<float>: public TObject. Linear Algebra Package. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:2130,Testability,test,test,2130," additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify aribtrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in ROOT, they of course; can be stored in a ROOT database. For usage examples see $ROOTSYS/test/stressLinear.cxx. Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-ve",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:4685,Testability,test,test,4685,"; from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. 2. Use ""two-address instructions""; ""void TMatrixD::operator += (const TMatrixD &B);""; as much as possible.; That is, to add two matrices, it's much more efficient to write; A += B;; than; TMatrixD C = A + B;; (if both operand should be preserved,; TMatrixD C = A; C += B;; is still better). 3. Use glorified constructors when returning of an object seems; inevitable:; ""TMatrixD A(TMatrixD::kTransposed,B);""; ""TMatrixD C(A,TMatrixD::kTransposeMult,B);"". like in the following snippet (from $ROOTSYS/test/vmatrix.cxx); that verifies that for an orthogonal matrix T, T'T = TT' = E. TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);. 4. Accessing row/col/diagonal of a matrix without much fuss; (and without moving a lot of stuff around):. TMatrixD m(n,n); TVectorD v(n); TMatrixDDiag(m) += 4;; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. void foo(const TMatrixD &m); {; TMatrixD m1(TMatrixD::kZero,m);; st",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:6647,Testability,test,test,6647,"xD m1(TMatrixD::kZero,m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixTBase<Float_t>, TMatrixFBase. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<float>(); virtual TMatrixTBase<float>&Abs(); v",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:6274,Usability,simpl,simple,6274,"; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. void foo(const TMatrixD &m); {; TMatrixD m1(TMatrixD::kZero,m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTBase_float_.html:6947,Usability,simpl,simple,6947,"imal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix; element:. void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }. Validation code $ROOTSYS/test/vmatrix.cxx and vvector.cxx contain; a few more examples of that kind. 6. Lazy matrices: instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:; TMatrixD haar = THaarMatrixD(5);; THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. This class is also known as (typedefs to this class)TMatrixTBase<Float_t>, TMatrixFBase. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTBase<float>(); virtual TMatrixTBase<float>&Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<float>&Apply(const TElementActionT<float>& action); virtual TMatrixTBase<float>&Apply(const TElementPosActionT<flo",MatchSource.WIKI,root/html530/TMatrixTBase_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTBase_float_.html
https://root.cern/root/html530/TMatrixTCramerInv.html:402,Energy Efficiency,adapt,adapted,402,". TMatrixTCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTCramerInv. namespace TMatrixTCramerInv. TMatrixTCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixT<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixT<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv5x5(TMatrixT<",MatchSource.WIKI,root/html530/TMatrixTCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTCramerInv.html
https://root.cern/root/html530/TMatrixTCramerInv.html:367,Integrability,rout,routines,367,". TMatrixTCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTCramerInv. namespace TMatrixTCramerInv. TMatrixTCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixT<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixT<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv5x5(TMatrixT<",MatchSource.WIKI,root/html530/TMatrixTCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTCramerInv.html
https://root.cern/root/html530/TMatrixTCramerInv.html:415,Integrability,rout,routines,415,". TMatrixTCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTCramerInv. namespace TMatrixTCramerInv. TMatrixTCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixT<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixT<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv5x5(TMatrixT<",MatchSource.WIKI,root/html530/TMatrixTCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTCramerInv.html
https://root.cern/root/html530/TMatrixTCramerInv.html:402,Modifiability,adapt,adapted,402,". TMatrixTCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTCramerInv. namespace TMatrixTCramerInv. TMatrixTCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixT<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixT<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixT<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixT<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixT<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixT<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixT<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixT<Element> &m,Double_t *determ). template<class Element> Bool_t Inv5x5(TMatrixT<",MatchSource.WIKI,root/html530/TMatrixTCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTCramerInv.html
https://root.cern/root/html530/TMatrixTLazy_double_.html:663,Availability,avail,available,663,". TMatrixTLazy<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTLazy<double>. class TMatrixTLazy<double>: public TObject. Templates of Lazy Matrix classes. TMatrixTLazy; TMatrixTSymLazy; THaarMatrixT; THilbertMatrixT; THilbertMatrixTSym. This class is also known as (typedefs to this class)TMatrixTLazy<Double_t>, TMatrixDLazy. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTLazy<double>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const",MatchSource.WIKI,root/html530/TMatrixTLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_double_.html
https://root.cern/root/html530/TMatrixTLazy_double_.html:1641,Availability,error,error,1641," virtual~TMatrixTLazy<double>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const",MatchSource.WIKI,root/html530/TMatrixTLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_double_.html
https://root.cern/root/html530/TMatrixTLazy_double_.html:1725,Availability,error,error,1725," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetRowLwb() const; Int_tGetRowUpb() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* cl",MatchSource.WIKI,root/html530/TMatrixTLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_double_.html
https://root.cern/root/html530/TMatrixTLazy_float_.html:659,Availability,avail,available,659,". TMatrixTLazy<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTLazy<float>. class TMatrixTLazy<float>: public TObject. Templates of Lazy Matrix classes. TMatrixTLazy; TMatrixTSymLazy; THaarMatrixT; THilbertMatrixT; THilbertMatrixTSym. This class is also known as (typedefs to this class)TMatrixTLazy<Float_t>, TMatrixFLazy. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTLazy<float>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int",MatchSource.WIKI,root/html530/TMatrixTLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_float_.html
https://root.cern/root/html530/TMatrixTLazy_float_.html:1636,Availability,error,error,1636," virtual~TMatrixTLazy<float>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int",MatchSource.WIKI,root/html530/TMatrixTLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_float_.html
https://root.cern/root/html530/TMatrixTLazy_float_.html:1720,Availability,error,error,1720," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetColLwb() const; Int_tGetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetRowLwb() const; Int_tGetRowUpb() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* cl",MatchSource.WIKI,root/html530/TMatrixTLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTLazy_float_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:5249,Availability,error,error,5249," b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tTMatrixTBase<double>::Determinant() const; virtual voidTMatrixTBase<double>::Determinant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(double* data, Option_t* = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<double>::GetNcols() const; Int_tTMatrixTBase<double",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:5333,Availability,error,error,5333,"oidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tTMatrixTBase<double>::Determinant() const; virtual voidTMatrixTBase<double>::Determinant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(double* data, Option_t* = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<double>::GetNcols() const; Int_tTMatrixTBase<double>::GetNoElements() const; Int_tTMatrixTBase<double>::GetNrows() const; virtual char*",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:17938,Energy Efficiency,allocate,allocated,17938,"lon > 1. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void TMatrixTSparse<Element> Allocate(Int_t nrows, Int_t ncols, Int_t row_lwb = 0, Int_t col_lwb = 0, Int_t init = 0, Int_t nr_nonzeros = 0); Allocate new matrix. Arguments are number of rows, columns, row lowerbound (0 default); and column lowerbound (0 default), 0 initialization flag and number of non-zero; elements (only relevant for sparse format). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const double* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:18164,Energy Efficiency,allocate,allocated,18164,"_nonzeros = 0); Allocate new matrix. Arguments are number of rows, columns, row lowerbound (0 default); and column lowerbound (0 default), 0 initialization flag and number of non-zero; elements (only relevant for sparse format). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const double* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatri",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:18390,Energy Efficiency,allocate,allocated,18390,"). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const double* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<E",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:18614,Energy Efficiency,allocate,allocated,18614,"nt_t col, double* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy m",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:18832,Energy Efficiency,allocate,allocated,18832,"Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:19060,Energy Efficiency,allocate,allocated,19060,"t_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:19282,Energy Efficiency,allocate,allocated,19282,"b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<double>& another); Use non-zero data of matrix source t",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:19504,Energy Efficiency,allocate,allocated,19504,"lement> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<double>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b;",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:20548,Energy Efficiency,allocate,allocated,20548,"ubtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(double* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<double>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t nr_nonzeros = -1); Set size of the matrix to nrows x ncols with nr_nonzeros non-zero entries; if nr_nonzeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are cre",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:20789,Energy Efficiency,allocate,allocated,20789,"Nelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, double* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<double>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t nr_nonzeros = -1); Set size of the matrix to nrows x ncols with nr_nonzeros non-zero entries; if nr_nonzeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTSparse<Element> &TMatrixTSparse<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros,",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:2198,Integrability,rout,routine,2198,"+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is smart to first; set the index table through a call to SetSparseIndex(..); 5. SetSub(Int_t row_lwb,Int_t col_lwb,const TMatrixTBase &source); the matrix to be inserted at position (row_lwb,col_lwb) can be; both dense or sparse . This class is also known as (typedefs to this class)TMatrixTSparse<Double_t>, TMatrixDSparse. Function Members (Methods); public:. TMatrixTSparse<double>(); TMatrixTSparse<double>(const TMatrixTSparse<double>& another); TMatrixTSparse<double>(const TMatrixT<double>& another); TMatrixTSparse<double>(Int_t nrows, Int_t ncols); TMatrixTSparse<double>(TMatrixTSparse<double>::EMatrixCreatorsOp1 op, const TMatrixTSparse<double>& prototype); TM",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:22002,Integrability,depend,depends,22002,"zeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTSparse<Element> &TMatrixTSparse<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros, Int_t* pRowIndex, Int_t* pColIndex, double* pData). TMatrixTBase<Element> &TMatrixTSparse<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTBase<Element> &TMatrixTSparse<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<double>& source); Insert matrix source starting at [row_lwb][col_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source-1][col_lwb..col_lwb+ncols_source-1];. TMatrixTSparse<Element> &TMatrixTSparse<Element> Transpose(const TMatrixTSparse<double>& source); Transpose a matrix. TMatrixTBase<Element> &TMatrixTSparse<Element> Zero(). TMatrixTBase<Element> &TMatrixTSparse<Element> UnitMatrix(); Make a unit matrix (matrix need not be a square one). Element TMatrixTSparse<Element> RowNorm() const; Row matrix norm, MAX{ SUM{ |M(i,j)|, over j}, over i}.; The norm is induced by the infinity vector norm. Element TMatrixTSparse<Element> ColNorm() const; Column matrix norm, MAX{ SUM{ |M(i,j)|, over i}, over j}.; The",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:2320,Modifiability,flexible,flexible,2320,"e matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is smart to first; set the index table through a call to SetSparseIndex(..); 5. SetSub(Int_t row_lwb,Int_t col_lwb,const TMatrixTBase &source); the matrix to be inserted at position (row_lwb,col_lwb) can be; both dense or sparse . This class is also known as (typedefs to this class)TMatrixTSparse<Double_t>, TMatrixDSparse. Function Members (Methods); public:. TMatrixTSparse<double>(); TMatrixTSparse<double>(const TMatrixTSparse<double>& another); TMatrixTSparse<double>(const TMatrixT<double>& another); TMatrixTSparse<double>(Int_t nrows, Int_t ncols); TMatrixTSparse<double>(TMatrixTSparse<double>::EMatrixCreatorsOp1 op, const TMatrixTSparse<double>& prototype); TMatrixTSparse<double>(const TMatrixTSparse<double>& a, TMatrixTSparse<double>::EMatrixCreatorsOp2 op, const TMatrixTSparse<double>& b); TMatrixTSparse<double>(const TMatrixTSparse<double>& a, TMatrixTSparse<double>::EMatrixCreatorsOp2 op, const TMatrixT<do",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:1566,Performance,perform,performance,1566,"e also store a row index, fRowIndex and; column index, fColIndex only for those elements unequal zero:. fRowIndex[0,..,fNrows]: Stores for each row the index range of; the elements in the data and column array; fColIndex[0,..,fNelems-1]: Stores the column number for each data; element != 0. As an example how to access all sparse data elements:. for (Int_t irow = 0; irow < this->fNrows; irow++) {; const Int_t sIndex = fRowIndex[irow];; const Int_t eIndex = fRowIndex[irow+1];; for (Int_t index = sIndex; index < eIndex; index++) {; const Int_t icol = fColIndex[index];; const Element data = fElements[index];; printf(""data(%d,%d) = %.4e\n"",irow+this->fRowLwb,icol+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is sm",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_double_.html:840,Security,access,access,840,". TMatrixTSparse<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSparse<double>. class TMatrixTSparse<double>: public TMatrixTBase<double>. TMatrixTSparse. Template class of a general sparse matrix in the Harwell-Boeing; format. Besides the usual shape/size decsriptors of a matrix like fNrows,; fRowLwb,fNcols and fColLwb, we also store a row index, fRowIndex and; column index, fColIndex only for those elements unequal zero:. fRowIndex[0,..,fNrows]: Stores for each row the index range of; the elements in the data and column array; fColIndex[0,..,fNelems-1]: Stores the column number for each data; element != 0. As an example how to access all sparse data elements:. for (Int_t irow = 0; irow < this->fNrows; irow++) {; const Int_t sIndex = fRowIndex[irow];; const Int_t eIndex = fRowIndex[irow+1];; for (Int_t index = sIndex; index < eIndex; index++) {; const Int_t icol = fColIndex[index];; const Element data = fElements[index];; printf(""data(%d,%d) = %.4e\n"",irow+this->fRowLwb,icol+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); wher",MatchSource.WIKI,root/html530/TMatrixTSparse_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_double_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:5205,Availability,error,error,5205,"owser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tTMatrixTBase<float>::Determinant() const; virtual voidTMatrixTBase<float>::Determinant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(float* data, Option_t* = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::GetNcols() const; Int_tTMatrixTBase<float>::GetNo",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:5289,Availability,error,error,5289,"tual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tTMatrixTBase<float>::Determinant() const; virtual voidTMatrixTBase<float>::Determinant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidGetMatrix2Array(float* data, Option_t* = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::GetNcols() const; Int_tTMatrixTBase<float>::GetNoElements() const; Int_tTMatrixTBase<float>::GetNrows() const; virtual char*TObject::",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:17721,Energy Efficiency,allocate,allocated,17721,"silon > 1. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void TMatrixTSparse<Element> Allocate(Int_t nrows, Int_t ncols, Int_t row_lwb = 0, Int_t col_lwb = 0, Int_t init = 0, Int_t nr_nonzeros = 0); Allocate new matrix. Arguments are number of rows, columns, row lowerbound (0 default); and column lowerbound (0 default), 0 initialization flag and number of non-zero; elements (only relevant for sparse format). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const float* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:17947,Energy Efficiency,allocate,allocated,17947,"nr_nonzeros = 0); Allocate new matrix. Arguments are number of rows, columns, row lowerbound (0 default); and column lowerbound (0 default), 0 initialization flag and number of non-zero; elements (only relevant for sparse format). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const float* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatri",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:18173,Energy Efficiency,allocate,allocated,18173,"at). TMatrixTBase<Element> &TMatrixTSparse<Element> InsertRow(Int_t row, Int_t col, const float* v, Int_t n = -1); Insert in row rown, n elements of array v at column coln. void TMatrixTSparse<Element> ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<E",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:18397,Energy Efficiency,allocate,allocated,18397,"Int_t col, float* v, Int_t n = -1) const; Store in array v, n matrix elements of row rown starting at column coln. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy ma",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:18615,Energy Efficiency,allocate,allocated,18615,"Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/co",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:18843,Energy Efficiency,allocate,allocated,18843,"t_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMultBt(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(I",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:19065,Energy Efficiency,allocate,allocated,19065,"b,Int_t constr); General matrix multiplication. Create a matrix C such that C = A * B'.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<float>& another); Use non-zero data of matrix source to s",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:19287,Energy Efficiency,allocate,allocated,19287,"lement> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> APlusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix addition. Create a matrix C such that C = A + B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixTSparse<Element> &a,const TMatrixT<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> AMinusB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b,Int_t constr); General matrix subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<float>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:20328,Energy Efficiency,allocate,allocated,20328,"x subtraction. Create a matrix C such that C = A - B.; Note, matrix C is allocated for constr=1. void TMatrixTSparse<Element> GetMatrix2Array(float* data, Option_t* = """") const; Copy matrix data to array . It is assumed that array is of size >= fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<float>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t nr_nonzeros = -1); Set size of the matrix to nrows x ncols with nr_nonzeros non-zero entries; if nr_nonzeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are cre",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:20569,Energy Efficiency,allocate,allocated,20569," fNelems. TMatrixTBase<Element> &TMatrixTSparse<Element> SetMatrixArray(Int_t nr_nonzeros, Int_t* irow, Int_t* icol, float* data); Copy nr elements from row/col index and data array to matrix . It is assumed; that arrays are of size >= nr; Note that the input arrays are not passed as const since they will be modified !. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(Int_t nelem_new); Increase/decrease the number of non-zero elements to nelems_new. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndex(const TMatrixTBase<float>& another); Use non-zero data of matrix source to set the sparse structure. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixTSparse<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTSparse<Element> &TMatrixTSparse<Element> SetSparseIndexAB(const TMatrixT<Element> &a,const TMatrixTSparse<Element> &b); Set the row/column indices to the ""sum"" of matrices a and b; It is checked that enough space has been allocated. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t nr_nonzeros = -1); Set size of the matrix to nrows x ncols with nr_nonzeros non-zero entries; if nr_nonzeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTSparse<Element> &TMatrixTSparse<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros,",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:2194,Integrability,rout,routine,2194,"+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is smart to first; set the index table through a call to SetSparseIndex(..); 5. SetSub(Int_t row_lwb,Int_t col_lwb,const TMatrixTBase &source); the matrix to be inserted at position (row_lwb,col_lwb) can be; both dense or sparse . This class is also known as (typedefs to this class)TMatrixTSparse<Float_t>, TMatrixFSparse. Function Members (Methods); public:. TMatrixTSparse<float>(); TMatrixTSparse<float>(const TMatrixTSparse<float>& another); TMatrixTSparse<float>(const TMatrixT<float>& another); TMatrixTSparse<float>(Int_t nrows, Int_t ncols); TMatrixTSparse<float>(TMatrixTSparse<float>::EMatrixCreatorsOp1 op, const TMatrixTSparse<float>& prototype); TMatrixTSpar",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:21780,Integrability,depend,depends,21780,"onzeros > 0 .; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSparse<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb] with nr_nonzeros; non-zero entries if nr_nonzeros > 0 .; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTSparse<Element> &TMatrixTSparse<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t nr_nonzeros, Int_t* pRowIndex, Int_t* pColIndex, float* pData). TMatrixTBase<Element> &TMatrixTSparse<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTBase<Element> &TMatrixTSparse<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<float>& source); Insert matrix source starting at [row_lwb][col_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source-1][col_lwb..col_lwb+ncols_source-1];. TMatrixTSparse<Element> &TMatrixTSparse<Element> Transpose(const TMatrixTSparse<float>& source); Transpose a matrix. TMatrixTBase<Element> &TMatrixTSparse<Element> Zero(). TMatrixTBase<Element> &TMatrixTSparse<Element> UnitMatrix(); Make a unit matrix (matrix need not be a square one). Element TMatrixTSparse<Element> RowNorm() const; Row matrix norm, MAX{ SUM{ |M(i,j)|, over j}, over i}.; The norm is induced by the infinity vector norm. Element TMatrixTSparse<Element> ColNorm() const; Column matrix norm, MAX{ SUM{ |M(i,j)|, over i}, over j}.; The n",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:2316,Modifiability,flexible,flexible,2316,"e matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is smart to first; set the index table through a call to SetSparseIndex(..); 5. SetSub(Int_t row_lwb,Int_t col_lwb,const TMatrixTBase &source); the matrix to be inserted at position (row_lwb,col_lwb) can be; both dense or sparse . This class is also known as (typedefs to this class)TMatrixTSparse<Float_t>, TMatrixFSparse. Function Members (Methods); public:. TMatrixTSparse<float>(); TMatrixTSparse<float>(const TMatrixTSparse<float>& another); TMatrixTSparse<float>(const TMatrixT<float>& another); TMatrixTSparse<float>(Int_t nrows, Int_t ncols); TMatrixTSparse<float>(TMatrixTSparse<float>::EMatrixCreatorsOp1 op, const TMatrixTSparse<float>& prototype); TMatrixTSparse<float>(const TMatrixTSparse<float>& a, TMatrixTSparse<float>::EMatrixCreatorsOp2 op, const TMatrixTSparse<float>& b); TMatrixTSparse<float>(const TMatrixTSparse<float>& a, TMatrixTSparse<float>::EMatrixCreatorsOp2 op, const TMatrixT<float>& b); TMatrix",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:1562,Performance,perform,performance,1562,"e also store a row index, fRowIndex and; column index, fColIndex only for those elements unequal zero:. fRowIndex[0,..,fNrows]: Stores for each row the index range of; the elements in the data and column array; fColIndex[0,..,fNelems-1]: Stores the column number for each data; element != 0. As an example how to access all sparse data elements:. for (Int_t irow = 0; irow < this->fNrows; irow++) {; const Int_t sIndex = fRowIndex[irow];; const Int_t eIndex = fRowIndex[irow+1];; for (Int_t index = sIndex; index < eIndex; index++) {; const Int_t icol = fColIndex[index];; const Element data = fElements[index];; printf(""data(%d,%d) = %.4e\n"",irow+this->fRowLwb,icol+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it is expected that the irow,icol and data array contain; nr entries . Only the entries with non-zero data[i] value are; inserted. Be aware that the input data array will be modified; inside the routine for doing the necessary sorting of indices !; 4. TMatrixTSparse a(n,m); for(....) { a(i,j) = ....; This is a very flexible method but expensive :; - if no entry for slot (i,j) is found in the sparse index table; it will be entered, which involves some memory management !; - before invoking this method in a loop it is sm",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSparse_float_.html:836,Security,access,access,836,". TMatrixTSparse<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSparse<float>. class TMatrixTSparse<float>: public TMatrixTBase<float>. TMatrixTSparse. Template class of a general sparse matrix in the Harwell-Boeing; format. Besides the usual shape/size decsriptors of a matrix like fNrows,; fRowLwb,fNcols and fColLwb, we also store a row index, fRowIndex and; column index, fColIndex only for those elements unequal zero:. fRowIndex[0,..,fNrows]: Stores for each row the index range of; the elements in the data and column array; fColIndex[0,..,fNelems-1]: Stores the column number for each data; element != 0. As an example how to access all sparse data elements:. for (Int_t irow = 0; irow < this->fNrows; irow++) {; const Int_t sIndex = fRowIndex[irow];; const Int_t eIndex = fRowIndex[irow+1];; for (Int_t index = sIndex; index < eIndex; index++) {; const Int_t icol = fColIndex[index];; const Element data = fElements[index];; printf(""data(%d,%d) = %.4e\n"",irow+this->fRowLwb,icol+; this->fColLwb,data);; }; }. When checking whether sparse matrices are compatible (like in an; assigment !), not only the shape parameters are compared but also; the sparse structure through fRowIndex and fColIndex . Several methods exist to fill a sparse matrix with data entries.; Most are the same like for dense matrices but some care has to be; taken with regard to performance. In the constructor, always the; shape of the matrix has to be specified in some form . Data can be; entered through the following methods :; 1. constructor; TMatrixTSparse(Int_t row_lwb,Int_t row_upb,Int_t dol_lwb,; Int_t col_upb,Int_t nr_nonzeros,; Int_t *row, Int_t *col,Element *data);; It uses SetMatrixArray(..), see below; 2. copy constructors; 3. SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Element *data); where it",MatchSource.WIKI,root/html530/TMatrixTSparse_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSparse_float_.html
https://root.cern/root/html530/TMatrixTSymCramerInv.html:414,Energy Efficiency,adapt,adapted,414,". TMatrixTSymCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymCramerInv. namespace TMatrixTSymCramerInv. TMatrixTSymCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixTSym<Element> &m,",MatchSource.WIKI,root/html530/TMatrixTSymCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymCramerInv.html
https://root.cern/root/html530/TMatrixTSymCramerInv.html:379,Integrability,rout,routines,379,". TMatrixTSymCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymCramerInv. namespace TMatrixTSymCramerInv. TMatrixTSymCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixTSym<Element> &m,",MatchSource.WIKI,root/html530/TMatrixTSymCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymCramerInv.html
https://root.cern/root/html530/TMatrixTSymCramerInv.html:427,Integrability,rout,routines,427,". TMatrixTSymCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymCramerInv. namespace TMatrixTSymCramerInv. TMatrixTSymCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixTSym<Element> &m,",MatchSource.WIKI,root/html530/TMatrixTSymCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymCramerInv.html
https://root.cern/root/html530/TMatrixTSymCramerInv.html:414,Modifiability,adapt,adapted,414,". TMatrixTSymCramerInv. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; namespace description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymCramerInv. namespace TMatrixTSymCramerInv. TMatrixTSymCramerInv. Encapsulate templates of Cramer Inversion routines. The 4x4, 5x5 and 6x6 are adapted from routines written by; Mark Fischler and Steven Haywood as part of the CLHEP package. Although for sizes <= 6x6 the Cramer Inversion has a gain in speed; compared to factorization schemes (like LU) , one pays a price in; accuracy . For Example:; H * H^-1 = U, where H is a 5x5 Hilbert matrix; U is a 5x5 Unity matrix. LU : |U_jk| < 10e-13 for j!=k; Cramer: |U_jk| < 10e-7 for j!=k. however Cramer algorithm is about 10 (!) times faster. Function Members (Methods); public:. Bool_tInv2x2(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv2x2(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv3x3(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv4x4(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv5x5(TMatrixTSym<double>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<float>& m, Double_t* determ); Bool_tInv6x6(TMatrixTSym<double>& m, Double_t* determ). Class Charts; Function documentation; Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv4x4(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv5x5(TMatrixTSym<Element> &m,Double_t *determ). Bool_t Inv6x6(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv2x2(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv3x3(TMatrixTSym<Element> &m,Double_t *determ). template<class Element> Bool_t Inv4x4(TMatrixTSym<Element> &m,",MatchSource.WIKI,root/html530/TMatrixTSymCramerInv.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymCramerInv.html
https://root.cern/root/html530/TMatrixTSymLazy_double_.html:678,Availability,avail,available,678,". TMatrixTSymLazy<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymLazy<double>. class TMatrixTSymLazy<double>: public TObject. Templates of Lazy Matrix classes. TMatrixTLazy; TMatrixTSymLazy; THaarMatrixT; THilbertMatrixT; THilbertMatrixTSym. This class is also known as (typedefs to this class)TMatrixTSymLazy<Double_t>, TMatrixDSymLazy. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTSymLazy<double>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const T",MatchSource.WIKI,root/html530/TMatrixTSymLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_double_.html
https://root.cern/root/html530/TMatrixTSymLazy_double_.html:1659,Availability,error,error,1659," virtual~TMatrixTSymLazy<double>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const T",MatchSource.WIKI,root/html530/TMatrixTSymLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_double_.html
https://root.cern/root/html530/TMatrixTSymLazy_double_.html:1743,Availability,error,error,1743," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetRowLwb() const; Int_tGetRowUpb() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsF",MatchSource.WIKI,root/html530/TMatrixTSymLazy_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_double_.html
https://root.cern/root/html530/TMatrixTSymLazy_float_.html:674,Availability,avail,available,674,". TMatrixTSymLazy<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSymLazy<float>. class TMatrixTSymLazy<float>: public TObject. Templates of Lazy Matrix classes. TMatrixTLazy; TMatrixTSymLazy; THaarMatrixT; THilbertMatrixT; THilbertMatrixTSym. This class is also known as (typedefs to this class)TMatrixTSymLazy<Float_t>, TMatrixFSymLazy. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMatrixTSymLazy<float>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObjec",MatchSource.WIKI,root/html530/TMatrixTSymLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_float_.html
https://root.cern/root/html530/TMatrixTSymLazy_float_.html:1654,Availability,error,error,1654," virtual~TMatrixTSymLazy<float>(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObjec",MatchSource.WIKI,root/html530/TMatrixTSymLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_float_.html
https://root.cern/root/html530/TMatrixTSymLazy_float_.html:1738,Availability,error,error,1738," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetRowLwb() const; Int_tGetRowUpb() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsF",MatchSource.WIKI,root/html530/TMatrixTSymLazy_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSymLazy_float_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:2905,Availability,error,error,2905,"ect::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleTMatrixTBase<double>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; const TMatrixT<double>EigenVectors(TVectorT<double>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<double>::ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<double>::GetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:2989,Availability,error,error,2989,"Clone(const char* newname = """") const; virtual doubleTMatrixTBase<double>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; const TMatrixT<double>EigenVectors(TVectorT<double>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<double>::ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<double>::GetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<double>::GetNcols() const; Int_tTMatrixTBase<double>::GetNoElements() const; Int_tTM",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:492,Deployability,update,updated,492,". TMatrixTSym<double>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSym<double>. class TMatrixTSym<double>: public TMatrixTBase<double>. TMatrixTSym. Template class of a symmetric matrix in the linear algebra package. Note that in this implementation both matrix element m[i][j] and; m[j][i] are updated and stored in memory . However, when making the; object persistent only the upper right triangle is stored . This class is also known as (typedefs to this class)TMatrixTSym<Double_t>, TMatrixDSym. Function Members (Methods); public:. TMatrixTSym<double>(); TMatrixTSym<double>(Int_t nrows); TMatrixTSym<double>(const TMatrixTSym<double>& another); TMatrixTSym<double>(const TMatrixTSymLazy<double>& lazy_constructor); TMatrixTSym<double>(Int_t row_lwb, Int_t row_upb); TMatrixTSym<double>(TMatrixTSym<double>::EMatrixCreatorsOp1 op, const TMatrixTSym<double>& prototype); TMatrixTSym<double>(TMatrixTSym<double>::EMatrixCreatorsOp1 op, const TMatrixT<double>& prototype); TMatrixTSym<double>(Int_t nrows, const double* data, Option_t* option = """"); TMatrixTSym<double>(const TMatrixTSym<double>& a, TMatrixTSym<double>::EMatrixCreatorsOp2 op, const TMatrixTSym<double>& b); TMatrixTSym<double>(Int_t row_lwb, Int_t row_upb, const double* data, Option_t* option = """"); virtual~TMatrixTSym<double>(); virtual TMatrixTBase<double>&TMatrixTBase<double>::Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<double>&Apply(const TElementActionT<double>& action); virtual TMatrixTBase<double>&Apply(const TElementPosActionT<double>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(con",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18142,Energy Efficiency,efficient,efficient,18142," TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<double>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<double>& v, double alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixT",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18482,Energy Efficiency,efficient,efficient,18482,"<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<double>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<double>& v, double alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Ele",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18874,Energy Efficiency,efficient,efficient,18874,"= 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator*=(double val); Multiply every element of the matrix with val. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(const TMatrixTSym<Element> &source); Add the source matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(const TMatrixTSym<Element> &source); Subtract the",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:15143,Integrability,depend,depends,15143,"ound (0 default) and column lowerbound (0 default). void TMatrixTSym<Element> Plus(const TMatrixTSym<double>& a, const TMatrixTSym<double>& b); Symmetric matrix summation. Create a matrix C such that C = A + B. void TMatrixTSym<Element> Minus(const TMatrixTSym<double>& a, const TMatrixTSym<double>& b); Symmetric matrix summation. Create a matrix C such that C = A + B. void TMatrixTSym<Element> TMult(const TMatrixT<Element> &a); Create a matrix C such that C = A' * A. In other words,; c[i,j] = SUM{ a[k,i] * a[k,j] }. void TMatrixTSym<Element> TMult(const TMatrixTSym<Element> &a); Matrix multiplication, with A symmetric; Create a matrix C such that C = A' * A = A * A = A * A'. TMatrixTSym<Element> &TMatrixTSym<Element> Use(Int_t row_lwb, Int_t row_upb, double* data). TMatrixTSym<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, TMatrixTSym<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][row_lwb..row_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..row_upb-row_lwb+1] (default); else : return [row_lwb..row_upb][row_lwb..row_upb]. TMatrixTBase<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTSym<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, const TMatrixTBase<double>& source); Insert matrix source starting at [row_lwb][row_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<double>& source); Insert matrix source starti",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:15574,Integrability,depend,depends,15574," Create a matrix C such that C = A' * A. In other words,; c[i,j] = SUM{ a[k,i] * a[k,j] }. void TMatrixTSym<Element> TMult(const TMatrixTSym<Element> &a); Matrix multiplication, with A symmetric; Create a matrix C such that C = A' * A = A * A = A * A'. TMatrixTSym<Element> &TMatrixTSym<Element> Use(Int_t row_lwb, Int_t row_upb, double* data). TMatrixTSym<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, TMatrixTSym<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][row_lwb..row_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..row_upb-row_lwb+1] (default); else : return [row_lwb..row_upb][row_lwb..row_upb]. TMatrixTBase<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTSym<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, const TMatrixTBase<double>& source); Insert matrix source starting at [row_lwb][row_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<double>& source); Insert matrix source starting at [row_lwb][col_lwb] in a symmetric fashion, thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetMatrixArray(const double* data, Option_t* option = """"). TMatrixTBase<Element> &TMatrixTSym<Element> Shift(Int_t row_shift, Int_t col_shift). TMatrixTBase<Element> &TMatrixTSym<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set siz",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18206,Integrability,rout,routine,18206," TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<double>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<double>& v, double alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixT",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18546,Integrability,rout,routine,18546,"<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<double>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<double>& v, double alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Ele",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:18938,Integrability,rout,routine,18938,"= 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<double>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<double>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator*=(double val); Multiply every element of the matrix with val. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(const TMatrixTSym<Element> &source); Add the source matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(const TMatrixTSym<Element> &source); Subtract the",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_double_.html:17472,Security,access,access,17472,"MatrixTSym<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set size of the matrix to nrows x ncols; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSym<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb]; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. Double_t TMatrixTSym<Element> Determinant() const. void TMatrixTSym<Element> Determinant(Double_t& d1, Double_t& d2) const. TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<double>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<double>& v, double alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficien",MatchSource.WIKI,root/html530/TMatrixTSym_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_double_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:2921,Availability,error,error,2921,"ar*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatTMatrixTBase<float>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; const TMatrixT<float>EigenVectors(TVectorT<float>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<float>::ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<float>::GetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:3005,Availability,error,error,3005,"bject::Clone(const char* newname = """") const; virtual floatTMatrixTBase<float>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; const TMatrixT<float>EigenVectors(TVectorT<float>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<float>::ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<float>::GetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::GetNcols() const; Int_tTMatrixTBase<float>::GetNoElements() const; Int_tTMatrixTBase",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:488,Deployability,update,updated,488,". TMatrixTSym<float>. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MATRIX; » TMatrixTSym<float>. class TMatrixTSym<float>: public TMatrixTBase<float>. TMatrixTSym. Template class of a symmetric matrix in the linear algebra package. Note that in this implementation both matrix element m[i][j] and; m[j][i] are updated and stored in memory . However, when making the; object persistent only the upper right triangle is stored . This class is also known as (typedefs to this class)TMatrixFSym, TMatrixTSym<Float_t>. Function Members (Methods); public:. TMatrixTSym<float>(); TMatrixTSym<float>(Int_t nrows); TMatrixTSym<float>(const TMatrixTSym<float>& another); TMatrixTSym<float>(const TMatrixTSymLazy<float>& lazy_constructor); TMatrixTSym<float>(const TMatrixTSym<double>& another); TMatrixTSym<float>(Int_t row_lwb, Int_t row_upb); TMatrixTSym<float>(TMatrixTSym<float>::EMatrixCreatorsOp1 op, const TMatrixTSym<float>& prototype); TMatrixTSym<float>(TMatrixTSym<float>::EMatrixCreatorsOp1 op, const TMatrixT<float>& prototype); TMatrixTSym<float>(Int_t nrows, const float* data, Option_t* option = """"); TMatrixTSym<float>(const TMatrixTSym<float>& a, TMatrixTSym<float>::EMatrixCreatorsOp2 op, const TMatrixTSym<float>& b); TMatrixTSym<float>(Int_t row_lwb, Int_t row_upb, const float* data, Option_t* option = """"); virtual~TMatrixTSym<float>(); virtual TMatrixTBase<float>&TMatrixTBase<float>::Abs(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual TMatrixTBase<float>&Apply(const TElementActionT<float>& action); virtual TMatrixTBase<float>&Apply(const TElementPosActionT<float>& action); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TOb",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:17983,Energy Efficiency,efficient,efficient,17983,"st. TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<float>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<float>& v, float alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSy",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:18323,Energy Efficiency,efficient,efficient,18323,"Sym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<float>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<float>& v, float alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Eleme",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:18713,Energy Efficiency,efficient,efficient,18713,"a = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator*=(float val); Multiply every element of the matrix with val. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(const TMatrixTSym<Element> &source); Add the source matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(const TMatrixTSym<Element> &source); Subtract the s",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:14991,Integrability,depend,depends,14991,"lowerbound (0 default) and column lowerbound (0 default). void TMatrixTSym<Element> Plus(const TMatrixTSym<float>& a, const TMatrixTSym<float>& b); Symmetric matrix summation. Create a matrix C such that C = A + B. void TMatrixTSym<Element> Minus(const TMatrixTSym<float>& a, const TMatrixTSym<float>& b); Symmetric matrix summation. Create a matrix C such that C = A + B. void TMatrixTSym<Element> TMult(const TMatrixT<Element> &a); Create a matrix C such that C = A' * A. In other words,; c[i,j] = SUM{ a[k,i] * a[k,j] }. void TMatrixTSym<Element> TMult(const TMatrixTSym<Element> &a); Matrix multiplication, with A symmetric; Create a matrix C such that C = A' * A = A * A = A * A'. TMatrixTSym<Element> &TMatrixTSym<Element> Use(Int_t row_lwb, Int_t row_upb, float* data). TMatrixTSym<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, TMatrixTSym<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][row_lwb..row_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..row_upb-row_lwb+1] (default); else : return [row_lwb..row_upb][row_lwb..row_upb]. TMatrixTBase<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTSym<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, const TMatrixTBase<float>& source); Insert matrix source starting at [row_lwb][row_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<float>& source); Insert matrix source starting ",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:15421,Integrability,depend,depends,15421,"a); Create a matrix C such that C = A' * A. In other words,; c[i,j] = SUM{ a[k,i] * a[k,j] }. void TMatrixTSym<Element> TMult(const TMatrixTSym<Element> &a); Matrix multiplication, with A symmetric; Create a matrix C such that C = A' * A = A * A = A * A'. TMatrixTSym<Element> &TMatrixTSym<Element> Use(Int_t row_lwb, Int_t row_upb, float* data). TMatrixTSym<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, TMatrixTSym<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][row_lwb..row_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..row_upb-row_lwb+1] (default); else : return [row_lwb..row_upb][row_lwb..row_upb]. TMatrixTBase<Element> &TMatrixTSym<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb][col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb+1][0..col_upb-col_lwb+1] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTSym<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, const TMatrixTBase<float>& source); Insert matrix source starting at [row_lwb][row_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<float>& source); Insert matrix source starting at [row_lwb][col_lwb] in a symmetric fashion, thereby overwriting the part; [row_lwb..row_lwb+nrows_source][row_lwb..row_lwb+nrows_source];. TMatrixTBase<Element> &TMatrixTSym<Element> SetMatrixArray(const float* data, Option_t* option = """"). TMatrixTBase<Element> &TMatrixTSym<Element> Shift(Int_t row_shift, Int_t col_shift). TMatrixTBase<Element> &TMatrixTSym<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set size o",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:18047,Integrability,rout,routine,18047,"st. TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<float>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<float>& v, float alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSy",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:18387,Integrability,rout,routine,18387,"Sym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<float>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<float>& v, float alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Eleme",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:18777,Integrability,rout,routine,18777,"a = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . Element TMatrixTSym<Element> Similarity(const TVectorT<float>& v) const; Calculate scalar v * (*this) * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> SimilarityT(const TMatrixT<float>& n); Calculate B^T * (*this) * B , final matrix will be (ncolsb x ncolsb); It is more efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSym<Element> &source). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(const TMatrixTSymLazy<Element> &lazy_constructor). TMatrixTSym<Element> &TMatrixTSym<Element> operator=(Element val); Assign val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(Element val); Add val to every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(Element val); Subtract val from every element of the matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator*=(float val); Multiply every element of the matrix with val. TMatrixTSym<Element> &TMatrixTSym<Element> operator+=(const TMatrixTSym<Element> &source); Add the source matrix. TMatrixTSym<Element> &TMatrixTSym<Element> operator-=(const TMatrixTSym<Element> &source); Subtract the s",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixTSym_float_.html:17316,Security,access,access,17316,"MatrixTSym<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set size of the matrix to nrows x ncols; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixTSym<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb]; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. Double_t TMatrixTSym<Element> Determinant() const. void TMatrixTSym<Element> Determinant(Double_t& d1, Double_t& d2) const. TMatrixTSym<Element> &TMatrixTSym<Element> Invert(Double_t* det = 0); Invert the matrix and calculate its determinant; Notice that the LU decomposition is used instead of Bunch-Kaufman; Bunch-Kaufman guarantees a symmetric inverted matrix but is slower than LU .; The user can access Bunch-Kaufman through the TDecompBK class . TMatrixTSym<Element> &TMatrixTSym<Element> InvertFast(Double_t* det = 0); Invert the matrix and calculate its determinant. TMatrixTSym<Element> &TMatrixTSym<Element> Transpose(const TMatrixTSym<float>& source); Transpose a matrix. TMatrixTSym<Element> &TMatrixTSym<Element> Rank1Update(const TVectorT<float>& v, float alpha = 1.0); Perform a rank 1 operation on the matrix:; A += alpha * v * v^T. TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixT<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient than applying the actual multiplication because this; routine realizes that the final matrix is symmetric . TMatrixTSym<Element> &TMatrixTSym<Element> Similarity(const TMatrixTSym<Element> &b); Calculate B * (*this) * B^T , final matrix will be (nrowsb x nrowsb); This is a similarity transform when B is orthogonal . It is more; efficient t",MatchSource.WIKI,root/html530/TMatrixTSym_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixTSym_float_.html
https://root.cern/root/html530/TMatrixT_double_.html:3131,Availability,error,error,3131,"ect::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual doubleTMatrixTBase<double>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; const TMatrixT<double>EigenVectors(TVectorT<double>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<double>::ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<double>::GetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<",MatchSource.WIKI,root/html530/TMatrixT_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_double_.html
https://root.cern/root/html530/TMatrixT_double_.html:3215,Availability,error,error,3215,"Clone(const char* newname = """") const; virtual doubleTMatrixTBase<double>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<double>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual doubleTMatrixTBase<double>::E2Norm() const; const TMatrixT<double>EigenVectors(TVectorT<double>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<double>::ExtractRow(Int_t row, Int_t col, double* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<double>::GetColLwb() const; Int_tTMatrixTBase<double>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<double>::GetMatrix2Array(double* data, Option_t* option = """") const; virtual const double*GetMatrixArray() const; virtual double*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<double>::GetNcols() const; Int_tTMatrixTBase<double>::GetNoElements() const; Int_tTM",MatchSource.WIKI,root/html530/TMatrixT_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_double_.html
https://root.cern/root/html530/TMatrixT_double_.html:17390,Integrability,rout,routine,17390,"lement> Minus(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix summation. Create a matrix C such that C = A - B. void TMatrixT<Element> Minus(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); General matrix summation. Create a matrix C such that C = A - B. void TMatrixT<Element> Mult(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Matrix multiplication, with A general and B symmetric.; Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixTSym<Element> &a,const TMatrixTSym<Element> &b); Matrix multiplication, with A symmetric and B symmetric.; (Actually copied for the moment routine for B general); Create a matrix C such that C = A * B. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixT<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> MultT(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B^T. void TMatrixT<Element> MultT(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B^T. TMatrixT<Element> &TMatrixT<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, double* data); Use the array data to fill the matrix ([row_lwb..row_upb] x [col_lwb..col_upb]). TMatrixTBase<Element> &TMatrixT<Element> GetSub(Int_t row_l",MatchSource.WIKI,root/html530/TMatrixT_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_double_.html
https://root.cern/root/html530/TMatrixT_double_.html:18612,Integrability,depend,depends,18612," = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> MultT(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B^T. void TMatrixT<Element> MultT(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B^T. TMatrixT<Element> &TMatrixT<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, double* data); Use the array data to fill the matrix ([row_lwb..row_upb] x [col_lwb..col_upb]). TMatrixTBase<Element> &TMatrixT<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<double>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb] x [col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb][0..col_upb-col_lwb] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTBase<Element> &TMatrixT<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<double>& source); Insert matrix source starting at [row_lwb][col_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][col_lwb..col_lwb+ncols_source];. TMatrixTBase<Element> &TMatrixT<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set size of the matrix to nrows x ncols; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixT<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb]; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, th",MatchSource.WIKI,root/html530/TMatrixT_double_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_double_.html
https://root.cern/root/html530/TMatrixT_float_.html:3135,Availability,error,error,3135,"ar*TObject::ClassName() const; virtual voidClear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual floatTMatrixTBase<float>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; const TMatrixT<float>EigenVectors(TVectorT<float>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<float>::ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<float>::GetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::",MatchSource.WIKI,root/html530/TMatrixT_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_float_.html
https://root.cern/root/html530/TMatrixT_float_.html:3219,Availability,error,error,3219,"bject::Clone(const char* newname = """") const; virtual floatTMatrixTBase<float>::ColNorm() const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDeterminant() const; virtual voidDeterminant(Double_t& d1, Double_t& d2) const; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTMatrixTBase<float>::Draw(Option_t* option = """")MENU ; virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual floatTMatrixTBase<float>::E2Norm() const; const TMatrixT<float>EigenVectors(TVectorT<float>& eigenValues) const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTMatrixTBase<float>::ExtractRow(Int_t row, Int_t col, float* v, Int_t n = -1) const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual const Int_t*GetColIndexArray() const; virtual Int_t*GetColIndexArray(); Int_tTMatrixTBase<float>::GetColLwb() const; Int_tTMatrixTBase<float>::GetColUpb() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual voidTMatrixTBase<float>::GetMatrix2Array(float* data, Option_t* option = """") const; virtual const float*GetMatrixArray() const; virtual float*GetMatrixArray(); virtual const char*TObject::GetName() const; Int_tTMatrixTBase<float>::GetNcols() const; Int_tTMatrixTBase<float>::GetNoElements() const; Int_tTMatrixTBase",MatchSource.WIKI,root/html530/TMatrixT_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_float_.html
https://root.cern/root/html530/TMatrixT_float_.html:17180,Integrability,rout,routine,17180,"lement> Minus(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix summation. Create a matrix C such that C = A - B. void TMatrixT<Element> Minus(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); General matrix summation. Create a matrix C such that C = A - B. void TMatrixT<Element> Mult(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Matrix multiplication, with A general and B symmetric.; Create a matrix C such that C = A * B. void TMatrixT<Element> Mult(const TMatrixTSym<Element> &a,const TMatrixTSym<Element> &b); Matrix multiplication, with A symmetric and B symmetric.; (Actually copied for the moment routine for B general); Create a matrix C such that C = A * B. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixT<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> MultT(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B^T. void TMatrixT<Element> MultT(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B^T. TMatrixT<Element> &TMatrixT<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, float* data); Use the array data to fill the matrix ([row_lwb..row_upb] x [col_lwb..col_upb]). TMatrixTBase<Element> &TMatrixT<Element> GetSub(Int_t row_lw",MatchSource.WIKI,root/html530/TMatrixT_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_float_.html
https://root.cern/root/html530/TMatrixT_float_.html:18400,Integrability,depend,depends,18400,"j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> TMult(const TMatrixT<Element> &a,const TMatrixTSym<Element> &b); Create a matrix C such that C = A' * B. In other words,; c[i,j] = SUM{ a[k,i] * b[k,j] }. void TMatrixT<Element> MultT(const TMatrixT<Element> &a,const TMatrixT<Element> &b); General matrix multiplication. Create a matrix C such that C = A * B^T. void TMatrixT<Element> MultT(const TMatrixTSym<Element> &a,const TMatrixT<Element> &b); Matrix multiplication, with A symmetric and B general.; Create a matrix C such that C = A * B^T. TMatrixT<Element> &TMatrixT<Element> Use(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, float* data); Use the array data to fill the matrix ([row_lwb..row_upb] x [col_lwb..col_upb]). TMatrixTBase<Element> &TMatrixT<Element> GetSub(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, TMatrixTBase<float>& target, Option_t* option = ""S"") const; Get submatrix [row_lwb..row_upb] x [col_lwb..col_upb]; The indexing range of the; returned matrix depends on the argument option:. option == ""S"" : return [0..row_upb-row_lwb][0..col_upb-col_lwb] (default); else : return [row_lwb..row_upb][col_lwb..col_upb]. TMatrixTBase<Element> &TMatrixT<Element> SetSub(Int_t row_lwb, Int_t col_lwb, const TMatrixTBase<float>& source); Insert matrix source starting at [row_lwb][col_lwb], thereby overwriting the part; [row_lwb..row_lwb+nrows_source][col_lwb..col_lwb+ncols_source];. TMatrixTBase<Element> &TMatrixT<Element> ResizeTo(Int_t nrows, Int_t ncols, Int_t = -1); Set size of the matrix to nrows x ncols; New dynamic elements are created, the overlapping part of the old ones are; copied to the new structures, then the old elements are deleted. TMatrixTBase<Element> &TMatrixT<Element> ResizeTo(Int_t row_lwb, Int_t row_upb, Int_t col_lwb, Int_t col_upb, Int_t = -1); Set size of the matrix to [row_lwb:row_upb] x [col_lwb:col_upb]; New dynamic elemenst are created, the overlapping part of the old ones are; copied to the new structures, the",MatchSource.WIKI,root/html530/TMatrixT_float_.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMatrixT_float_.html
https://root.cern/root/html530/TMCParticle.html:1663,Availability,error,error,1663,"ethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; Int_tTAttLine::DistancetoLine(Int_t px, Int_t py, Double_t xp1, Double_t yp1, Double_t xp2, Double_t yp2); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Float_tGetEnergy() const; Int_tGetFirstChild() const; virtual const char*TObject::GetIconName() const; Int_tGetKF() const; Int_tGetKS() const; Int_tGetLastChild() const; Float_tGetLifetime() const; virtual Color_tTAttLine::GetLineColor() const; virtual Style_tTAttLine::GetLineStyle() const; virtual Width_tTAttLine::GetLineWidth() const; Float_tGetMass() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetP",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:1747,Availability,error,error,1747,"""); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; Int_tTAttLine::DistancetoLine(Int_t px, Int_t py, Double_t xp1, Double_t yp1, Double_t xp2, Double_t yp2); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Float_tGetEnergy() const; Int_tGetFirstChild() const; virtual const char*TObject::GetIconName() const; Int_tGetKF() const; Int_tGetKS() const; Int_tGetLastChild() const; Float_tGetLifetime() const; virtual Color_tTAttLine::GetLineColor() const; virtual Style_tTAttLine::GetLineStyle() const; virtual Width_tTAttLine::GetLineWidth() const; Float_tGetMass() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetParent() const; Float_tGetPx() const; Float_tGetPy() const; Float_tGetPz() const; Flo",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:530,Energy Efficiency,energy,energy,530," TMCParticle(); TMCParticle(const TMCParticle&); TMCParticle(Int_t kS, Int_t kF, Int_t parent, Int_t firstchild, Int_t lastchild, Float_t px, Float_t py, Float_t pz, Float_t energy, Float_t mass, Float_t vx, Float_t vy, Float_t vz, Float_t time, Float_t lifetime); virtual~TMCParticle(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; Int_tTAttLine::DistancetoLine(Int_t px, Int_t py, Double_t xp1, Double_t yp1, Double_t xp2, Double_t yp2); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(con",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:5052,Energy Efficiency,energy,energy,5052,"erator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMCParticle&operator=(const TMCParticle&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); virtual voidTAttLine::ResetAttLine(Option_t* option = """"); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTAttLine::SaveLineAttributes(ostream& out, const char* name, Int_t coldef = 1, Int_t stydef = 1, Int_t widdef = 1); virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetEnergy(Float_t energy); virtual voidSetFirstChild(Int_t first); virtual voidSetKF(Int_t kF); virtual voidSetKS(Int_t kS); virtual voidSetLastChild(Int_t last); virtual voidSetLifetime(Float_t lifetime); virtual voidTAttLine::SetLineAttributes()MENU ; virtual voidTAttLine::SetLineColor(Color_t lcolor); virtual voidTAttLine::SetLineStyle(Style_t lstyle); virtual voidTAttLine::SetLineWidth(Width_t lwidth); virtual voidSetMass(Float_t mass); static voidTObject::SetObjectStat(Bool_t stat); virtual voidSetParent(Int_t parent); virtual voidSetPx(Float_t px); virtual voidSetPy(Float_t py); virtual voidSetPz(Float_t pz); virtual voidSetTime(Float_t time); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidSetVx(Float_t vx); virtual voidSetVy(Float_t vy); virtual voidSetVz(Float_t vz); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:7977,Energy Efficiency,energy,energy,7977,"tfEnergyEnergy [GeV] ( LUJETS P[4] ); Int_tfFirstChildid of first child ( LUJETS K[4] ); Int_tfKFKF flavour code ( LUJETS K[2] ); Int_tfKSstatus of particle ( LUJETS K[1] ); Int_tfLastChildid of last child ( LUJETS K[5] ); Float_tfLifetimeproper lifetime [mm/c] ( LUJETS V[5] ); Float_tfMassMass [Gev/c^2] ( LUJETS P[5] ); Int_tfParentparrent's id ( LUJETS K[3] ); Float_tfPxX momenta [GeV/c] ( LUJETS P[1] ); Float_tfPyY momenta [GeV/c] ( LUJETS P[2] ); Float_tfPzZ momenta [GeV/c] ( LUJETS P[3] ); Float_tfTimetime of procuction [mm/c]( LUJETS V[4] ); Float_tfVxX vertex [mm] ( LUJETS V[1] ); Float_tfVyY vertex [mm] ( LUJETS V[2] ); Float_tfVzZ vertex [mm] ( LUJETS V[3] ). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void ls(Option_t* option) const. const char * GetName() const; Return name of this particle via Pythia. TMCParticle(); {}. TMCParticle(Int_t kS, Int_t kF, Int_t parent, Int_t firstchild, Int_t lastchild, Float_t px, Float_t py, Float_t pz, Float_t energy, Float_t mass, Float_t vx, Float_t vy, Float_t vz, Float_t time, Float_t lifetime); { }. virtual ~TMCParticle(); { }. Int_t GetKS() const; {return fKS;}. Int_t GetKF() const; {return fKF;}. Int_t GetParent() const; {return fParent;}. Int_t GetFirstChild() const; {return fFirstChild;}. Int_t GetLastChild() const; {return fLastChild;}. Float_t GetPx() const; {return fPx;}. Float_t GetPy() const; {return fPy;}. Float_t GetPz() const; {return fPz;}. Float_t GetEnergy() const; {return fEnergy;}. Float_t GetMass() const; {return fMass;}. Float_t GetVx() const; {return fVx;}. Float_t GetVy() const; {return fVy;}. Float_t GetVz() const; {return fVz;}. Float_t GetTime() const; {return fTime;}. Float_t GetLifetime() const; {return fLifetime;}. void SetKS(Int_t kS); {fKS=kS;}. void SetKF(Int_t kF); {fKF=kF;}. void SetParent(Int_t parent); {fParent=parent;}. void SetFirstChild(Int_t first); {fFirstChild=first;}. void SetLastChild(Int_t last); {fLastChild=last;}. void SetPx(Fl",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:9077,Energy Efficiency,energy,energy,9077,"tation; void ls(Option_t* option) const. const char * GetName() const; Return name of this particle via Pythia. TMCParticle(); {}. TMCParticle(Int_t kS, Int_t kF, Int_t parent, Int_t firstchild, Int_t lastchild, Float_t px, Float_t py, Float_t pz, Float_t energy, Float_t mass, Float_t vx, Float_t vy, Float_t vz, Float_t time, Float_t lifetime); { }. virtual ~TMCParticle(); { }. Int_t GetKS() const; {return fKS;}. Int_t GetKF() const; {return fKF;}. Int_t GetParent() const; {return fParent;}. Int_t GetFirstChild() const; {return fFirstChild;}. Int_t GetLastChild() const; {return fLastChild;}. Float_t GetPx() const; {return fPx;}. Float_t GetPy() const; {return fPy;}. Float_t GetPz() const; {return fPz;}. Float_t GetEnergy() const; {return fEnergy;}. Float_t GetMass() const; {return fMass;}. Float_t GetVx() const; {return fVx;}. Float_t GetVy() const; {return fVy;}. Float_t GetVz() const; {return fVz;}. Float_t GetTime() const; {return fTime;}. Float_t GetLifetime() const; {return fLifetime;}. void SetKS(Int_t kS); {fKS=kS;}. void SetKF(Int_t kF); {fKF=kF;}. void SetParent(Int_t parent); {fParent=parent;}. void SetFirstChild(Int_t first); {fFirstChild=first;}. void SetLastChild(Int_t last); {fLastChild=last;}. void SetPx(Float_t px); {fPx=px;}. void SetPy(Float_t py); {fPy=py;}. void SetPz(Float_t pz); {fPz=pz;}. void SetEnergy(Float_t energy); {fEnergy=energy;}. void SetMass(Float_t mass); {fMass=mass;}. void SetVx(Float_t vx); {fVx=vx;}. void SetVy(Float_t vy); {fVy=vy;}. void SetVz(Float_t vz); {fVz=vz;}. void SetTime(Float_t time); {fTime=time;}. void SetLifetime(Float_t lifetime); {fLifetime=lifetime;}. » Author: Piotr Golonka 17/09/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/pythia6:$Id: TMCParticle.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCParticle.html:9095,Energy Efficiency,energy,energy,9095,"tation; void ls(Option_t* option) const. const char * GetName() const; Return name of this particle via Pythia. TMCParticle(); {}. TMCParticle(Int_t kS, Int_t kF, Int_t parent, Int_t firstchild, Int_t lastchild, Float_t px, Float_t py, Float_t pz, Float_t energy, Float_t mass, Float_t vx, Float_t vy, Float_t vz, Float_t time, Float_t lifetime); { }. virtual ~TMCParticle(); { }. Int_t GetKS() const; {return fKS;}. Int_t GetKF() const; {return fKF;}. Int_t GetParent() const; {return fParent;}. Int_t GetFirstChild() const; {return fFirstChild;}. Int_t GetLastChild() const; {return fLastChild;}. Float_t GetPx() const; {return fPx;}. Float_t GetPy() const; {return fPy;}. Float_t GetPz() const; {return fPz;}. Float_t GetEnergy() const; {return fEnergy;}. Float_t GetMass() const; {return fMass;}. Float_t GetVx() const; {return fVx;}. Float_t GetVy() const; {return fVy;}. Float_t GetVz() const; {return fVz;}. Float_t GetTime() const; {return fTime;}. Float_t GetLifetime() const; {return fLifetime;}. void SetKS(Int_t kS); {fKS=kS;}. void SetKF(Int_t kF); {fKF=kF;}. void SetParent(Int_t parent); {fParent=parent;}. void SetFirstChild(Int_t first); {fFirstChild=first;}. void SetLastChild(Int_t last); {fLastChild=last;}. void SetPx(Float_t px); {fPx=px;}. void SetPy(Float_t py); {fPy=py;}. void SetPz(Float_t pz); {fPz=pz;}. void SetEnergy(Float_t energy); {fEnergy=energy;}. void SetMass(Float_t mass); {fMass=mass;}. void SetVx(Float_t vx); {fVx=vx;}. void SetVy(Float_t vy); {fVy=vy;}. void SetVz(Float_t vz); {fVz=vz;}. void SetTime(Float_t time); {fTime=time;}. void SetLifetime(Float_t lifetime); {fLifetime=lifetime;}. » Author: Piotr Golonka 17/09/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/pythia6:$Id: TMCParticle.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMCParticle.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCParticle.html
https://root.cern/root/html530/TMCVerbose.html:1681,Availability,error,error,1681,"idAddParticles(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBeginEvent(); virtual voidBeginPrimary(); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidConstructGeometry(); virtual voidConstructOpGeometry(); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidFinishEvent(); virtual voidFinishPrimary(); virtual voidFinishRun(); virtual voidGeneratePrimaries(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::",MatchSource.WIKI,root/html530/TMCVerbose.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCVerbose.html
https://root.cern/root/html530/TMCVerbose.html:1765,Availability,error,error,1765,"dBeginEvent(); virtual voidBeginPrimary(); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidConstructGeometry(); virtual voidConstructOpGeometry(); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidFinishEvent(); virtual voidFinishPrimary(); virtual voidFinishRun(); virtual voidGeneratePrimaries(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsF",MatchSource.WIKI,root/html530/TMCVerbose.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMCVerbose.html
https://root.cern/root/html530/TMD5.html:508,Availability,avail,available,508,". TMD5. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMD5. class TMD5. TMD5. This code implements the MD5 message-digest algorithm.; The algorithm is due to Ron Rivest. This code was; written by Colin Plumb in 1993, no copyright is claimed.; This code is in the public domain; do with it what you wish. Equivalent code is available from RSA Data Security, Inc.; This code has been tested against that, and is equivalent,; except that you don't need to include two pages of legalese; with every copy. To compute the message digest of a chunk of bytes, create an; TMD5 object, call Update() as needed on buffers full of bytes, and; then call Final(), which will, optionally, fill a supplied 16-byte; array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; In",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4126,Availability,error,error,4126,"Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's mo",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4405,Availability,error,error,4405,"ple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatical",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4639,Availability,error,error,4639,"reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4946,Availability,error,error,4946,"reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:3146,Energy Efficiency,allocate,allocated,3146,"ious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:292,Integrability,message,message-digest,292,". TMD5. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMD5. class TMD5. TMD5. This code implements the MD5 message-digest algorithm.; The algorithm is due to Ron Rivest. This code was; written by Colin Plumb in 1993, no copyright is claimed.; This code is in the public domain; do with it what you wish. Equivalent code is available from RSA Data Security, Inc.; This code has been tested against that, and is equivalent,; except that you don't need to include two pages of legalese; with every copy. To compute the message digest of a chunk of bytes, create an; TMD5 object, call Update() as needed on buffers full of bytes, and; then call Final(), which will, optionally, fill a supplied 16-byte; array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; In",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:701,Integrability,message,message,701,". TMD5. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMD5. class TMD5. TMD5. This code implements the MD5 message-digest algorithm.; The algorithm is due to Ron Rivest. This code was; written by Colin Plumb in 1993, no copyright is claimed.; This code is in the public domain; do with it what you wish. Equivalent code is available from RSA Data Security, Inc.; This code has been tested against that, and is equivalent,; except that you don't need to include two pages of legalese; with every copy. To compute the message digest of a chunk of bytes, create an; TMD5 object, call Update() as needed on buffers full of bytes, and; then call Final(), which will, optionally, fill a supplied 16-byte; array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; In",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:1869,Integrability,message,message,1869," array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the;",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:1909,Integrability,message,message,1909," array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the;",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2699,Integrability,message,message-digest,2699," UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII re",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2742,Integrability,message,message,2742," UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII re",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2845,Integrability,message,message-digest,2845,"t[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 oth",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2888,Integrability,message,message,2888,"t[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 oth",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:3020,Integrability,message,message,3020,"ers; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). T",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:3631,Integrability,rout,routine,3631,"ation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case t",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2313,Safety,avoid,avoids,2313,"ar* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:2457,Safety,avoid,avoids,2457,"eamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMD5(); Create TMD5 object. Set bit count to 0 and buffer to mysterious; initialization constants. TMD5(const UChar_t* digest); Create finalized TMD5 object containing passed in 16 byte digest. TMD5(const TMD5& md5); MD5 copy ctor. Special copy ctor avoids copying unnecessary; temp arrays when finalized. TMD5 & operator=(const TMD5& rhs); MD5 assignment operator. Special assignment operator avoids; copying unnecessary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algori",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4708,Safety,safe,safely,4708,"reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:5026,Safety,safe,safely,5026,"reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:3503,Security,hash,hash,3503,"essary temp arrays when finalized. void Update(const UChar_t* buf, UInt_t len); Update TMD5 object to reflect the concatenation of another buffer full; of bytes. void Final(UChar_t* digest); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context.; Returns digest. void Final(); MD5 finalization, ends an MD5 message-digest operation, writing the; the message digest and zeroizing the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const c",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:3920,Security,checksum,checksum,3920,"the context. void Print() const; Print digest in ascii hex form. const char * AsString() const; Return message digest as string. Returns """" in case Final() has; not yet been called. Copy result because it points to a statically; allocated string. void Encode(UChar_t* out, const UInt_t* in, UInt_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argum",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4220,Security,checksum,checksum,4220,"Int_t len); Encodes input into output. Assumes len is a multiple of 4. void Decode(UInt_t* out, const UChar_t* in, UInt_t len); Decodes input into output. Assumes len is a multiple of 4. void Transform(UInt_t* buf, const UChar_t* in); The core of the MD5 algorithm, this alters an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4498,Security,checksum,checksum,4498,"an existing MD5 hash to; reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:4876,Security,checksum,checksum,4876,"reflect the addition of 16 longwords of new data. Update() blocks; the data and converts bytes into longwords for this routine. Int_t SetDigest(const char* md5ascii); Set the digest from the ASCII representation 'md5ascii'. The caller; is responsible to make sure that the 32 chars md5ascii are valid.; Returns -1 if md5ascii is malformed, returns 0 otherwise. TMD5 * ReadChecksum(const char* file); Returns checksum stored in ASCII in specified file. Use to read files; created via WriteChecksum(). The returned TMD5 object must be deleted; by the user. Returns 0 in case the file cannot be opened or in case of; error. Static utlity function. Int_t WriteChecksum(const char* file, const TMD5* md5); Writes checksum in ASCII format to specified file. This file can; directly be read by ReadChecksum(). The md5 must have been finalized.; Returns -1 in case file cannot be opened or in case of error,; 0 otherwise. Static utility function. TMD5 * FileChecksum(const char* file); Returns checksum of specified file. The returned TMD5 object must; be deleted by the user. Returns 0 in case the file does not exists; or in case of error. This function preserves the modtime of the file; so it can be safely used in conjunction with methods that keep track; of the file's modtime. Static utility function. Int_t FileChecksum(const char* file, UChar_t* digest); Returns checksum of specified file in digest argument. Returns -1 in; case of error, 0 otherwise. This method preserves the modtime of the; file so it can be safely used in conjunction with methods that keep; track of the file's modtime. Static utility function. virtual ~TMD5(); { }. » Author: Fons Rademakers 29/9/2001 » Copyright (C) 1995-2001, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMD5.h 33386 2010-05-05 13:41:15Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMD5.html:567,Testability,test,tested,567,". TMD5. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMD5. class TMD5. TMD5. This code implements the MD5 message-digest algorithm.; The algorithm is due to Ron Rivest. This code was; written by Colin Plumb in 1993, no copyright is claimed.; This code is in the public domain; do with it what you wish. Equivalent code is available from RSA Data Security, Inc.; This code has been tested against that, and is equivalent,; except that you don't need to include two pages of legalese; with every copy. To compute the message digest of a chunk of bytes, create an; TMD5 object, call Update() as needed on buffers full of bytes, and; then call Final(), which will, optionally, fill a supplied 16-byte; array with the digest. Function Members (Methods); public:. TMD5(); TMD5(const UChar_t* digest); TMD5(const TMD5& md5); virtual~TMD5(); const char*AsString() const; static TClass*Class(); static TMD5*FileChecksum(const char* file); static Int_tFileChecksum(const char* file, UChar_t* digest); voidFinal(); voidFinal(UChar_t* digest); virtual TClass*IsA() const; TMD5&operator=(const TMD5& rhs); voidPrint() const; static TMD5*ReadChecksum(const char* file); Int_tSetDigest(const char* md5ascii); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUpdate(const UChar_t* buf, UInt_t len); static Int_tWriteChecksum(const char* file, const TMD5* md5). private:. voidDecode(UInt_t* out, const UChar_t* in, UInt_t len); voidEncode(UChar_t* out, const UInt_t* in, UInt_t len); voidTransform(UInt_t* buf, const UChar_t* in). Data Members; private:. UInt_tfBits[2]!temp buffer; UInt_tfBuf[4]!temp buffer; UChar_tfDigest[16]message digest; Bool_tfFinalizedtrue if message digest has been finalized; UChar_tfIn[64]!temp buffer. Class Charts. Inheritance; In",MatchSource.WIKI,root/html530/TMD5.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMD5.html
https://root.cern/root/html530/TMehrotraSolver.html:2441,Availability,error,error,2441,"taBase* data, TQpVar* vars, TQpResidual* resids, Int_t i, Double_t mu, Int_t level); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTQpSolverBase::DoMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t stop_code, Int_t level); virtual Int_tTQpSolverBase::DoStatus(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Int_t i, Double_t mu, Int_t level); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTQpSolverBase::DumbStart(TQpProbBase* formulation, TQpVar* iterate, TQpDataBase* prob, TQpResidual* resid, TQpVar* step); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual Double_tTQpSolverBase::FinalStepLength(TQpVar* iterate, TQpVar* step); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tTQpSolverBase::GetArTol(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TQpLinSolverBase*TQpSolverBase::GetLinearSystem(); Double_tTQpSolverBase::GetMuTol(); virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::H",MatchSource.WIKI,root/html530/TMehrotraSolver.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMehrotraSolver.html
https://root.cern/root/html530/TMehrotraSolver.html:2525,Availability,error,error,2525," virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTQpSolverBase::DoMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t stop_code, Int_t level); virtual Int_tTQpSolverBase::DoStatus(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Int_t i, Double_t mu, Int_t level); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTQpSolverBase::DumbStart(TQpProbBase* formulation, TQpVar* iterate, TQpDataBase* prob, TQpResidual* resid, TQpVar* step); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual Double_tTQpSolverBase::FinalStepLength(TQpVar* iterate, TQpVar* step); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tTQpSolverBase::GetArTol(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TQpLinSolverBase*TQpSolverBase::GetLinearSystem(); Double_tTQpSolverBase::GetMuTol(); virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject",MatchSource.WIKI,root/html530/TMehrotraSolver.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMehrotraSolver.html
https://root.cern/root/html530/TMehrotraSolver.html:8799,Energy Efficiency,monitor,monitor,8799," Double_tTQpSolverBase::fPhimerit function, defined as the sum of the complementarity gap; Double_t*TQpSolverBase::fPhi_history[fMaxit] history of values of phi obtained on all iterations to date; Double_t*TQpSolverBase::fPhi_min_history[fMaxit] the i-th entry of this array contains the minimum value of phi; Int_tfPrintlevelparameter in range [0,100] determines verbosity. (Higher value; Double_t*TQpSolverBase::fRnorm_history[fMaxit] history of values of residual norm obtained on all iterations to date; TQpVar*fStepstorage for step vectors; TQpLinSolverBase*TQpSolverBase::fSys; Double_tfTsigexponent in Mehrotra's centering parameter, which is usually. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMehrotraSolver(); Default constructor. TMehrotraSolver(TQpProbBase* of, TQpDataBase* prob, Int_t verbose = 0); Constructor. TMehrotraSolver(const TMehrotraSolver& another); Copy constructor. Int_t Solve(TQpDataBase* prob, TQpVar* iterate, TQpResidual* resid); Solve the quadratic programming problem as formulated through prob, store; the final solution in iterate->fX . Monitor the residuals during the iterations; through resid . The status is returned as defined in TQpSolverBase::ETerminationCode . void DefMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t status_code, Int_t level); Print information about the optimization process and monitor the convergence; status of thye algorithm. ~TMehrotraSolver(); Deconstructor. TMehrotraSolver & operator=(const TMehrotraSolver& source); Assignment operator. » Author: Eddy Offermann May 2004 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/quadp:$Id: TMehrotraSolver.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMehrotraSolver.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMehrotraSolver.html
https://root.cern/root/html530/TMehrotraSolver.html:8774,Performance,optimiz,optimization,8774," Double_tTQpSolverBase::fPhimerit function, defined as the sum of the complementarity gap; Double_t*TQpSolverBase::fPhi_history[fMaxit] history of values of phi obtained on all iterations to date; Double_t*TQpSolverBase::fPhi_min_history[fMaxit] the i-th entry of this array contains the minimum value of phi; Int_tfPrintlevelparameter in range [0,100] determines verbosity. (Higher value; Double_t*TQpSolverBase::fRnorm_history[fMaxit] history of values of residual norm obtained on all iterations to date; TQpVar*fStepstorage for step vectors; TQpLinSolverBase*TQpSolverBase::fSys; Double_tfTsigexponent in Mehrotra's centering parameter, which is usually. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMehrotraSolver(); Default constructor. TMehrotraSolver(TQpProbBase* of, TQpDataBase* prob, Int_t verbose = 0); Constructor. TMehrotraSolver(const TMehrotraSolver& another); Copy constructor. Int_t Solve(TQpDataBase* prob, TQpVar* iterate, TQpResidual* resid); Solve the quadratic programming problem as formulated through prob, store; the final solution in iterate->fX . Monitor the residuals during the iterations; through resid . The status is returned as defined in TQpSolverBase::ETerminationCode . void DefMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t status_code, Int_t level); Print information about the optimization process and monitor the convergence; status of thye algorithm. ~TMehrotraSolver(); Deconstructor. TMehrotraSolver & operator=(const TMehrotraSolver& source); Assignment operator. » Author: Eddy Offermann May 2004 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/quadp:$Id: TMehrotraSolver.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMehrotraSolver.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMehrotraSolver.html
https://root.cern/root/html530/TMehrotraSolver.html:397,Safety,predict,predictor-corrector,397,". TMehrotraSolver. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » QUADP; » TMehrotraSolver. class TMehrotraSolver: public TQpSolverBase. TMehrotraSolver. Derived class of TQpSolverBase implementing the original Mehrotra; predictor-corrector algorithm. Function Members (Methods); public:. TMehrotraSolver(); TMehrotraSolver(const TMehrotraSolver& another); TMehrotraSolver(TQpProbBase* of, TQpDataBase* prob, Int_t verbose = 0); virtual~TMehrotraSolver(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; Double_tTQpSolverBase::DataNorm(); virtual voidDefMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t status_code, Int_t level); virtual voidTQpSolverBase::DefStart(TQpProbBase* formulation, TQpVar* iterate, TQpDataBase* prob, TQpResidual* resid, TQpVar* step); virtual Int_tTQpSolverBase::DefStatus(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Int_t i, Double_t mu, Int_t level); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTQpSolverBase::DoMonitor(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Double_t alpha, Double_t sigma, Int_t i, Double_t mu, Int_t stop_code, Int_t level); virtual Int_tTQpSolverBase::DoStatus(TQpDataBase* data, TQpVar* vars, TQpResidual* resids, Int_t i, Double_t mu, Int_t level); virtual voidTObject::Draw(Option_t* option = """");",MatchSource.WIKI,root/html530/TMehrotraSolver.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMehrotraSolver.html
https://root.cern/root/html530/TMemberInspector.html:684,Availability,avail,available,684,". TMemberInspector. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMemberInspector. class TMemberInspector. TMemberInspector. Abstract base class for accessing the datamembers of a class.; Classes derived from this class can be given as argument to the; ShowMembers() methods of ROOT classes. This feature facilitates; the writing of class browsers and inspectors. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMemberInspector(); voidAddToParent(const char* name); static TClass*Class(); voidGenericShowMembers(const char* topClassName, void* obj, Bool_t transientMember); const char*GetParent() const; Ssiz_tGetParentLen() const; virtual voidInspect(TClass* cl, const char* parent, const char* name, const void* addr); voidInspectMember(TObject& obj, const char* name); voidInspectMember(TClass* cl, void* pobj, const char* name); voidInspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient); virtual TClass*IsA() const; TMemberInspector&operator=(const TMemberInspector&); voidRemoveFromParent(Ssiz_t startingAt); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. TMemberInspector::TParentBuf*fParentcurrent inspection ""path"". Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMemberInspector(); Destruct a member inspector. const char* GetParent() const; Get the parent string. Ssiz_t GetParentLen() const; Get the length of the parent string. void AddToParent(const char* name); Append ""name"" to the parent string. void RemoveFromParent(Ssiz_t startingAt); Remove trailing characters starting at ""startingAt"". void G",MatchSource.WIKI,root/html530/TMemberInspector.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberInspector.html
https://root.cern/root/html530/TMemberInspector.html:2320,Availability,error,error,2320,"obj, const char* name); voidInspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient); virtual TClass*IsA() const; TMemberInspector&operator=(const TMemberInspector&); voidRemoveFromParent(Ssiz_t startingAt); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. TMemberInspector::TParentBuf*fParentcurrent inspection ""path"". Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMemberInspector(); Destruct a member inspector. const char* GetParent() const; Get the parent string. Ssiz_t GetParentLen() const; Get the length of the parent string. void AddToParent(const char* name); Append ""name"" to the parent string. void RemoveFromParent(Ssiz_t startingAt); Remove trailing characters starting at ""startingAt"". void GenericShowMembers(const char* topClassName, void* obj, Bool_t transientMember); Call ShowMember() on obj.; This could be faster if we implemented this either as a templated; function or by rootcint-generated code using the typeid (i.e. the; difference is a lookup in a TList instead of in a map).; To avoid a spurrious error message in case the data member is; transient and does not have a dictionary we check first. void InspectMember(TObject& obj, const char* name). void InspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient). void InspectMember(TClass* cl, void* pobj, const char* name). void Inspect(TClass* cl, const char* parent, const char* name, const void* addr). obj. ShowMembers(TMemberInspector& insp). » Author: Fons Rademakers 15/07/96 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMemberInspector.h 35394 2010-09-17 19:40:12Z pcanal $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemberInspector.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberInspector.html
https://root.cern/root/html530/TMemberInspector.html:2326,Integrability,message,message,2326,"obj, const char* name); voidInspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient); virtual TClass*IsA() const; TMemberInspector&operator=(const TMemberInspector&); voidRemoveFromParent(Ssiz_t startingAt); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. TMemberInspector::TParentBuf*fParentcurrent inspection ""path"". Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMemberInspector(); Destruct a member inspector. const char* GetParent() const; Get the parent string. Ssiz_t GetParentLen() const; Get the length of the parent string. void AddToParent(const char* name); Append ""name"" to the parent string. void RemoveFromParent(Ssiz_t startingAt); Remove trailing characters starting at ""startingAt"". void GenericShowMembers(const char* topClassName, void* obj, Bool_t transientMember); Call ShowMember() on obj.; This could be faster if we implemented this either as a templated; function or by rootcint-generated code using the typeid (i.e. the; difference is a lookup in a TList instead of in a map).; To avoid a spurrious error message in case the data member is; transient and does not have a dictionary we check first. void InspectMember(TObject& obj, const char* name). void InspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient). void InspectMember(TClass* cl, void* pobj, const char* name). void Inspect(TClass* cl, const char* parent, const char* name, const void* addr). obj. ShowMembers(TMemberInspector& insp). » Author: Fons Rademakers 15/07/96 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMemberInspector.h 35394 2010-09-17 19:40:12Z pcanal $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemberInspector.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberInspector.html
https://root.cern/root/html530/TMemberInspector.html:2302,Safety,avoid,avoid,2302,"obj, const char* name); voidInspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient); virtual TClass*IsA() const; TMemberInspector&operator=(const TMemberInspector&); voidRemoveFromParent(Ssiz_t startingAt); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. TMemberInspector::TParentBuf*fParentcurrent inspection ""path"". Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMemberInspector(); Destruct a member inspector. const char* GetParent() const; Get the parent string. Ssiz_t GetParentLen() const; Get the length of the parent string. void AddToParent(const char* name); Append ""name"" to the parent string. void RemoveFromParent(Ssiz_t startingAt); Remove trailing characters starting at ""startingAt"". void GenericShowMembers(const char* topClassName, void* obj, Bool_t transientMember); Call ShowMember() on obj.; This could be faster if we implemented this either as a templated; function or by rootcint-generated code using the typeid (i.e. the; difference is a lookup in a TList instead of in a map).; To avoid a spurrious error message in case the data member is; transient and does not have a dictionary we check first. void InspectMember(TObject& obj, const char* name). void InspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient). void InspectMember(TClass* cl, void* pobj, const char* name). void Inspect(TClass* cl, const char* parent, const char* name, const void* addr). obj. ShowMembers(TMemberInspector& insp). » Author: Fons Rademakers 15/07/96 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMemberInspector.h 35394 2010-09-17 19:40:12Z pcanal $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemberInspector.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberInspector.html
https://root.cern/root/html530/TMemberInspector.html:335,Security,access,accessing,335,". TMemberInspector. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMemberInspector. class TMemberInspector. TMemberInspector. Abstract base class for accessing the datamembers of a class.; Classes derived from this class can be given as argument to the; ShowMembers() methods of ROOT classes. This feature facilitates; the writing of class browsers and inspectors. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMemberInspector(); voidAddToParent(const char* name); static TClass*Class(); voidGenericShowMembers(const char* topClassName, void* obj, Bool_t transientMember); const char*GetParent() const; Ssiz_tGetParentLen() const; virtual voidInspect(TClass* cl, const char* parent, const char* name, const void* addr); voidInspectMember(TObject& obj, const char* name); voidInspectMember(TClass* cl, void* pobj, const char* name); voidInspectMember(const char* topclassname, void* pobj, const char* name, Bool_t transient); virtual TClass*IsA() const; TMemberInspector&operator=(const TMemberInspector&); voidRemoveFromParent(Ssiz_t startingAt); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. TMemberInspector::TParentBuf*fParentcurrent inspection ""path"". Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMemberInspector(); Destruct a member inspector. const char* GetParent() const; Get the parent string. Ssiz_t GetParentLen() const; Get the length of the parent string. void AddToParent(const char* name); Append ""name"" to the parent string. void RemoveFromParent(Ssiz_t startingAt); Remove trailing characters starting at ""startingAt"". void G",MatchSource.WIKI,root/html530/TMemberInspector.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberInspector.html
https://root.cern/root/html530/TMemberStreamer.html:1415,Modifiability,variab,variable,1415,". TMemberStreamer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » CORE; » META; » TMemberStreamer. class TMemberStreamer. TMemberStreamer is used to stream a data member. The address passed to operator() will be the address of the data; member. Function Members (Methods); public:. TMemberStreamer(MemberStreamerFunc_t pointer); TMemberStreamer(const TMemberStreamer& rhs); virtual~TMemberStreamer(); virtual const TClass*GetOnFileClass() const; virtual voidoperator()(TBuffer& b, void* pmember, Int_t size = 0); TMemberStreamer&operator=(const TMemberStreamer&); virtual voidSetOnFileClass(const TClass* cl). protected:. TMemberStreamer(). Data Members; private:. TClassReffOnFileClass; MemberStreamerFunc_tfStreamer. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMemberStreamer(); {}. TMemberStreamer(MemberStreamerFunc_t pointer); {}. TMemberStreamer(const TMemberStreamer& rhs); {}. virtual ~TMemberStreamer(); {}. void SetOnFileClass(const TClass* cl); { fOnFileClass = const_cast<TClass*>(cl); }. const TClass* GetOnFileClass() const; { return fOnFileClass; }. void operator()(TBuffer& b, void* pmember, Int_t size = 0); The address passed to operator() will be the address of the data member.; If the data member is a variable size array, 'size' is the number of elements; to read/write. » Author: Victor Perev and Philippe Canal 08/05/02 » Copyright (C) 1995-2003, Rene Brun, Fons Rademakers and al. *; » Last changed: root/base:$Id: TMemberStreamer.h 25450 2008-09-18 21:13:42Z pcanal $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemberStreamer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemberStreamer.html
https://root.cern/root/html530/TMemStat.html:4618,Availability,error,error,4618,"virtual~TMemStat(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; static voidClose(); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidDisable(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidEnable(); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) con",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:4702,Availability,error,error,4702,"oidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; static voidClose(); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidDisable(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidEnable(); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:3043,Deployability,update,updated,3043,"m.rootrc; Root.TMemStat.system gnubuiltin; Root.TMemStat.buffersize 100000; Root.TMemStat.maxcalls 5000000. TMemStat::Show creates 3 canvases.; -In canvas1 it displays a dynamic histogram showing for pages (10 kbytes by default); the percentage of the page used.; A summary pave shows the total memory still in use when the TMemStat object; goes out of scope and the average occupancy of the pages.; The average occupancy gives a good indication of the memory fragmentation. -In canvas2 it displays the histogram of memory leaks in decreasing order.; when moving the mouse on this canvas, a tooltip shows the backtrace for the leak; in the bin below the mouse. -In canvas3 it displays the histogram of the nbigleaks largest leaks (default is 20); for each leak, the number of allocs and average alloc size is shown. Simply do:; root > TMemStat::Show(); or specifying arguments; root > TMemStat::Show(0.1,20,""mydir/mymemstat.root"");. The first argument to Show is the percentage of the time of the original job; that produced the file after which the display is updated. By default update=0.1,; ie 10 time intervals will be shown.; The second argument is nbigleaks.; The third argument is the imput file name (result of TMemStat).; If this argument is omitted, Show will take the most recent file; generated by TMemStat. You can restrict the address range to be analyzed via TMemStatShow::SetAddressRange; You can restrict the entry range to be analyzed via TMemStatShow::SetEntryRange. Function Members (Methods); public:. TMemStat(const TMemStat&); TMemStat(Option_t* option = ""read"", Int_t buffersize = 10000, Int_t maxcalls = 5000000); virtual~TMemStat(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; static voidC",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:3063,Deployability,update,update,3063,"t.TMemStat.maxcalls 5000000. TMemStat::Show creates 3 canvases.; -In canvas1 it displays a dynamic histogram showing for pages (10 kbytes by default); the percentage of the page used.; A summary pave shows the total memory still in use when the TMemStat object; goes out of scope and the average occupancy of the pages.; The average occupancy gives a good indication of the memory fragmentation. -In canvas2 it displays the histogram of memory leaks in decreasing order.; when moving the mouse on this canvas, a tooltip shows the backtrace for the leak; in the bin below the mouse. -In canvas3 it displays the histogram of the nbigleaks largest leaks (default is 20); for each leak, the number of allocs and average alloc size is shown. Simply do:; root > TMemStat::Show(); or specifying arguments; root > TMemStat::Show(0.1,20,""mydir/mymemstat.root"");. The first argument to Show is the percentage of the time of the original job; that produced the file after which the display is updated. By default update=0.1,; ie 10 time intervals will be shown.; The second argument is nbigleaks.; The third argument is the imput file name (result of TMemStat).; If this argument is omitted, Show will take the most recent file; generated by TMemStat. You can restrict the address range to be analyzed via TMemStatShow::SetAddressRange; You can restrict the entry range to be analyzed via TMemStatShow::SetEntryRange. Function Members (Methods); public:. TMemStat(const TMemStat&); TMemStat(Option_t* option = ""read"", Int_t buffersize = 10000, Int_t maxcalls = 5000000); virtual~TMemStat(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; static voidClose(); virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTO",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:7400,Deployability,update,update,7400,"tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMemStat&operator=(const TMemStat&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); static voidShow(Double_t update = 0.",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:9079,Deployability,update,update,9079,"onst char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Bool_tfIsActiveis object attached to MemStat. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMemStat(Option_t* option = ""read"", Int_t buffersize = 10000, Int_t maxcalls = 5000000); Supported options:; ""gnubuiltin"" - if declared, then MemStat will use gcc build-in function,; otherwise glibc backtrace will be used. Note: Currently MemStat uses a hard-coded output file name (for writing) = ""memstat.root"";. ~TMemStat(); destructor. void Close(); close the TMemStat manager. void Disable(); Disable memory statistics. void Enable(); Enable memory statistics. void Show(Double_t update = 0.1, Int_t nbigleaks = 20, const char* fname = ""*""); Show results. TMemStat(const TMemStat& ). » Author: D.Bertini and M.Ivanov 18/06/2007 -- Anar Manafov (A.Manafov@gsi.de) 28/04/2008 » Copyright (C) 1995-2008, Rene Brun and Fons Rademakers. *; » Last changed: root/memstat:$Name$:$Id: TMemStat.h 30815 2009-10-20 13:49:22Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:395,Energy Efficiency,allocate,allocated,395,". TMemStat. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MISC; » MEMSTAT; » TMemStat. class TMemStat: public TObject. TMemStat records all the calls to malloc and free and write a TTree; with the position where the memory is allocated/freed , as well as; the number of bytes. To use the class TMemStat, add the following statement at the beginning; of your script or program; TMemStat mm(""gnubuiltin"");; or in an interactive session do something like:; root > TMemStat mm(""gnubuiltin"");; root > .x somescript.C; root > .q. another (may be more practical way) is to modify $ROOTSYS/etc/system.rootrc; and activate the variable; Root.TMemStat: 1. The file collected by TMemStat is named memstat_ProcessID and can be analyzed and results shown; by executing the static function Show.; When TMemStat is active it recors every call to malloc/free in a ROOT Tree.; You must be careful when running jobs with many millions (or more) of calls; to malloc/free because the generated Tree may become very large.; The TMemStat constructor TMemStat(const char* system, Int_t buffersize, Int_t maxcalls); has its 3 arguments optional:; -system refers to the internal algorithm to compute the back traces.; the recommended value is ""gnubuiltin""; -buffersize is the number of calls to malloc or free that can be stored in one memory buffer.; when the buffer is full, the calls to malloc/free pointing to the same location; are eliminated and not written to the final Tree. The default value 100000; is such that between 50 and 90% of the calls are eliminated depending on the application.; You can set buffersize <=1 to keep every single call to malloc/free.; -maxcalls can set a limit for the maximum number of calls to be registered in the Tree.; The default value is 5000000.; The 3 arguments can be set in $ROOTSYS/etc/system.rootrc; Root.TMem",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:1713,Integrability,depend,depending,1713,"ot > .q. another (may be more practical way) is to modify $ROOTSYS/etc/system.rootrc; and activate the variable; Root.TMemStat: 1. The file collected by TMemStat is named memstat_ProcessID and can be analyzed and results shown; by executing the static function Show.; When TMemStat is active it recors every call to malloc/free in a ROOT Tree.; You must be careful when running jobs with many millions (or more) of calls; to malloc/free because the generated Tree may become very large.; The TMemStat constructor TMemStat(const char* system, Int_t buffersize, Int_t maxcalls); has its 3 arguments optional:; -system refers to the internal algorithm to compute the back traces.; the recommended value is ""gnubuiltin""; -buffersize is the number of calls to malloc or free that can be stored in one memory buffer.; when the buffer is full, the calls to malloc/free pointing to the same location; are eliminated and not written to the final Tree. The default value 100000; is such that between 50 and 90% of the calls are eliminated depending on the application.; You can set buffersize <=1 to keep every single call to malloc/free.; -maxcalls can set a limit for the maximum number of calls to be registered in the Tree.; The default value is 5000000.; The 3 arguments can be set in $ROOTSYS/etc/system.rootrc; Root.TMemStat.system gnubuiltin; Root.TMemStat.buffersize 100000; Root.TMemStat.maxcalls 5000000. TMemStat::Show creates 3 canvases.; -In canvas1 it displays a dynamic histogram showing for pages (10 kbytes by default); the percentage of the page used.; A summary pave shows the total memory still in use when the TMemStat object; goes out of scope and the average occupancy of the pages.; The average occupancy gives a good indication of the memory fragmentation. -In canvas2 it displays the histogram of memory leaks in decreasing order.; when moving the mouse on this canvas, a tooltip shows the backtrace for the leak; in the bin below the mouse. -In canvas3 it displays the histogram of ",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStat.html:787,Modifiability,variab,variable,787,". TMemStat. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MISC; » MEMSTAT; » TMemStat. class TMemStat: public TObject. TMemStat records all the calls to malloc and free and write a TTree; with the position where the memory is allocated/freed , as well as; the number of bytes. To use the class TMemStat, add the following statement at the beginning; of your script or program; TMemStat mm(""gnubuiltin"");; or in an interactive session do something like:; root > TMemStat mm(""gnubuiltin"");; root > .x somescript.C; root > .q. another (may be more practical way) is to modify $ROOTSYS/etc/system.rootrc; and activate the variable; Root.TMemStat: 1. The file collected by TMemStat is named memstat_ProcessID and can be analyzed and results shown; by executing the static function Show.; When TMemStat is active it recors every call to malloc/free in a ROOT Tree.; You must be careful when running jobs with many millions (or more) of calls; to malloc/free because the generated Tree may become very large.; The TMemStat constructor TMemStat(const char* system, Int_t buffersize, Int_t maxcalls); has its 3 arguments optional:; -system refers to the internal algorithm to compute the back traces.; the recommended value is ""gnubuiltin""; -buffersize is the number of calls to malloc or free that can be stored in one memory buffer.; when the buffer is full, the calls to malloc/free pointing to the same location; are eliminated and not written to the final Tree. The default value 100000; is such that between 50 and 90% of the calls are eliminated depending on the application.; You can set buffersize <=1 to keep every single call to malloc/free.; -maxcalls can set a limit for the maximum number of calls to be registered in the Tree.; The default value is 5000000.; The 3 arguments can be set in $ROOTSYS/etc/system.rootrc; Root.TMem",MatchSource.WIKI,root/html530/TMemStat.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStat.html
https://root.cern/root/html530/TMemStatShow.html:1511,Availability,error,error,1511,"idTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; static voidEventInfo1(Int_t event, Int_t px, Int_t py, TObject* selected); static voidEventInfo2(Int_t event, Int_t px, Int_t py, TObject* selected); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; static voidFillBTString(Int_t bin, Int_t mode, TString& btstring); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) co",MatchSource.WIKI,root/html530/TMemStatShow.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStatShow.html
https://root.cern/root/html530/TMemStatShow.html:1595,Availability,error,error,1595,"); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; static voidEventInfo1(Int_t event, Int_t px, Int_t py, TObject* selected); static voidEventInfo2(Int_t event, Int_t px, Int_t py, TObject* selected); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; static voidFillBTString(Int_t bin, Int_t mode, TString& btstring); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_",MatchSource.WIKI,root/html530/TMemStatShow.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStatShow.html
https://root.cern/root/html530/TMemStatShow.html:4506,Deployability,update,update,4506,"t; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMemStatShow&operator=(const TMemStatShow&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); static voidSetAddressRange(Long64_t nbytes = 0, Long64_t first = 0); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidSetEntryRange(Long64_t nentries = 0, Long64_t first = 0); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); static voidShow(Double_t update = 0.",MatchSource.WIKI,root/html530/TMemStatShow.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStatShow.html
https://root.cern/root/html530/TMemStatShow.html:7249,Deployability,update,update,7249,"cess; static TObjArray*fgBtidlistlist of back trace ids; static TCanvas*fgC1pointer to canvas showing allocs/deallocs vs time; static TCanvas*fgC2pointer to canvas with leaks in decreasing order; static TCanvas*fgC3pointer to canvas showing the main leaks; static Long64_tfgEntryFirstfirst entry to process; static Long64_tfgEntryNnumber of entries to process; static TH1D*fgHhistogram with allocations - frees; static TH1D*fgHallochistogram with allocations; static TH1I*fgHdiffhistogram with diff of entry number between alloc/free; static TH1I*fgHentryhistogram with entry numbers in the TObjArray; static TH1D*fgHfreehistogram with frees; static TH1I*fgHleakshistogram with leaks; static TTree*fgTTMemStat Tree; static TGToolTip*fgTip1pointer to tool tip for canvas 1; static TGToolTip*fgTip2pointer to tool tip for canvas 2; static Double_t*fgV1pointer to V1 array of TTree::Draw (pos); static Double_t*fgV2pointer to V2 array of TTree::Draw (nbytes); static Double_t*fgV3pointer to V3 array of TTree::Draw (time); static Double_t*fgV4pointer to V4 array of TTree::Draw (btid). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMemStatShow(); {;}. virtual ~TMemStatShow(); {;}. void EventInfo1(Int_t event, Int_t px, Int_t py, TObject* selected). void EventInfo2(Int_t event, Int_t px, Int_t py, TObject* selected). void FillBTString(Int_t bin, Int_t mode, TString& btstring). void SetAddressRange(Long64_t nbytes = 0, Long64_t first = 0). void SetEntryRange(Long64_t nentries = 0, Long64_t first = 0). void Show(Double_t update = 0.1, Int_t nbigleaks = 20, const char* fname = ""*""). » Author: Rene Brun 21/09/2010 » Copyright (C) 1995-2010, Rene Brun and Fons Rademakers. *; » Last changed: root/treeviewer:$Id: TMemStatShow.h 37300 2010-12-05 17:25:20Z brun $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMemStatShow.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMemStatShow.html
https://root.cern/root/html530/TMergerInfo.html:1708,Availability,error,error,1708,"idAddMergedObjects(Int_t objects); voidAddWorker(TSlave* sl); virtual voidTObject::AppendPad(Option_t* option = """"); Bool_tAreAllWorkersAssigned(); Bool_tAreAllWorkersMerged(); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidDeactivate(); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Int_tGetMergedObjects(); Int_tGetMergedWorkers(); TSlave*GetMerger(); virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetPort(); virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; TList*GetWorkers(); Int_tGetWorkersToMerge(); virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; vir",MatchSource.WIKI,root/html530/TMergerInfo.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMergerInfo.html
https://root.cern/root/html530/TMergerInfo.html:1792,Availability,error,error,1792,"ppendPad(Option_t* option = """"); Bool_tAreAllWorkersAssigned(); Bool_tAreAllWorkersMerged(); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidDeactivate(); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Int_tGetMergedObjects(); Int_tGetMergedWorkers(); TSlave*GetMerger(); virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetPort(); virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; TList*GetWorkers(); Int_tGetWorkersToMerge(); virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_t",MatchSource.WIKI,root/html530/TMergerInfo.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMergerInfo.html
https://root.cern/root/html530/TMergerInfo.html:482,Integrability,message,messages,482,". TMergerInfo. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » PROOF; » PROOF; » TMergerInfo. class TMergerInfo: public TObject. TProof. This class controls a Parallel ROOT Facility, PROOF, cluster.; It fires the worker servers, it keeps track of how many workers are; running, it keeps track of the workers running status, it broadcasts; messages to all workers, it collects results, etc. Function Members (Methods); public:. TMergerInfo(TSlave* t, Int_t port, Int_t forHowManyWorkers); virtual~TMergerInfo(); voidTObject::AbstractMethod(const char* method) const; voidAddMergedObjects(Int_t objects); voidAddWorker(TSlave* sl); virtual voidTObject::AppendPad(Option_t* option = """"); Bool_tAreAllWorkersAssigned(); Bool_tAreAllWorkersMerged(); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidDeactivate(); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) c",MatchSource.WIKI,root/html530/TMergerInfo.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMergerInfo.html
https://root.cern/root/html530/TMessage.html:2402,Availability,error,error,2402," char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; char*CompBuffer() const; Int_tCompLength() const; Int_tCompress(); virtual voidTObject::Copy(TObject& object) const; virtual voidTBufferFile::DecrementLevel(TVirtualStreamerInfo*); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTBuffer::DetachBuffer(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; voidEnableSchemaEvolution(Bool_t enable = kTRUE); static voidEnableSchemaEvolutionForAll(Bool_t enable = kTRUE); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidTBuffer::Expand(Int_t newsize, Bool_t copy = kTRUE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); virtual voidTBufferFile::ForceWriteInfoClones(TClonesArray* a); voidForward(); virtual Int_tTBufferFile::GetBufferDisplacement() const; Int_tTBuffer::GetBufferVersion() const; TClass*GetClass() const; Int_tGetCompressionAlgorithm() const; Int_tGetCompressionLevel() const; Int_tGetCompressionSettings() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); static Int_tTBufferFile::GetGlobalReadParam(); static Int_tTBufferFile::GetGlobalWriteParam(); virtual const char*TObj",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:2486,Availability,error,error,2486,"l TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; char*CompBuffer() const; Int_tCompLength() const; Int_tCompress(); virtual voidTObject::Copy(TObject& object) const; virtual voidTBufferFile::DecrementLevel(TVirtualStreamerInfo*); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTBuffer::DetachBuffer(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; voidEnableSchemaEvolution(Bool_t enable = kTRUE); static voidEnableSchemaEvolutionForAll(Bool_t enable = kTRUE); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidTBuffer::Expand(Int_t newsize, Bool_t copy = kTRUE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); virtual voidTBufferFile::ForceWriteInfoClones(TClonesArray* a); voidForward(); virtual Int_tTBufferFile::GetBufferDisplacement() const; Int_tTBuffer::GetBufferVersion() const; TClass*GetClass() const; Int_tGetCompressionAlgorithm() const; Int_tGetCompressionLevel() const; Int_tGetCompressionSettings() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); static Int_tTBufferFile::GetGlobalReadParam(); static Int_tTBufferFile::GetGlobalWriteParam(); virtual const char*TObject::GetIconName() const; virtual TVirtualStreamerInfo*TBufferFile::GetInfo(); virtu",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23978,Availability,error,error,23978,"at was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 ",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24226,Availability,error,error,24226,"(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 where uid id the uid of the ProcessID. Int_t GetCompressionAlgorithm() const. Int_t GetCompressionLevel() const. Int_t GetCompressionSettings() const. TMessage(const TMessage& ); TMessage objects ca",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:21167,Integrability,message,message,21167,"ading the buffer; vector<TStreamerInfo*>TBufferFile::fInfoStackStack of pointers to the TStreamerInfos; TExMap*TBufferFile::fMapMap containing object,offset pairs for reading/writing; Int_tTBufferFile::fMapCountNumber of objects or classes in map; Int_tTBufferFile::fMapSizeDefault size of map; Bool_tTBuffer::fModeRead or write mode; TObject*TBuffer::fParentPointer to parent object owning this buffer; UShort_tTBufferFile::fPidOffsetOffset to be added to the pid index in this key/buffer.; ReAllocCharFun_tTBuffer::fReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only i",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:21279,Integrability,message,message,21279,"ading the buffer; vector<TStreamerInfo*>TBufferFile::fInfoStackStack of pointers to the TStreamerInfos; TExMap*TBufferFile::fMapMap containing object,offset pairs for reading/writing; Int_tTBufferFile::fMapCountNumber of objects or classes in map; Int_tTBufferFile::fMapSizeDefault size of map; Bool_tTBuffer::fModeRead or write mode; TObject*TBuffer::fParentPointer to parent object owning this buffer; UShort_tTBufferFile::fPidOffsetOffset to be added to the pid index in this key/buffer.; ReAllocCharFun_tTBuffer::fReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only i",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:21368,Integrability,message,message,21368,"ading the buffer; vector<TStreamerInfo*>TBufferFile::fInfoStackStack of pointers to the TStreamerInfos; TExMap*TBufferFile::fMapMap containing object,offset pairs for reading/writing; Int_tTBufferFile::fMapCountNumber of objects or classes in map; Int_tTBufferFile::fMapSizeDefault size of map; Bool_tTBuffer::fModeRead or write mode; TObject*TBuffer::fParentPointer to parent object owning this buffer; UShort_tTBufferFile::fPidOffsetOffset to be added to the pid index in this key/buffer.; ReAllocCharFun_tTBuffer::fReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only i",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:21913,Integrability,message,message,21913,"ReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteI",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:21945,Integrability,message,message,21945,"buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writin",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22011,Integrability,message,message,22011,":fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was re",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22059,Integrability,message,message,22059,":fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was re",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22155,Integrability,message,message,22155,"e message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22307,Integrability,message,message,22307,"r*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message leng",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22379,Integrability,message,message,22379,"r*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message leng",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22555,Integrability,message,message,22555," WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of message. Predifined ROOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kM",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:22982,Integrability,message,message,22982,"OOT system message types; can be found in MessageTypes.h. Make sure your own message types are; unique from the ROOT defined message types (i.e. 0 - 10000 are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the mess",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23098,Integrability,message,message,23098,"are; reserved by ROOT). In case you OR ""what"" with kMESS_ACK, the message; will wait for an acknowledgement from the remote side. This makes; the sending process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise re",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23238,Integrability,message,message,23238,"g process synchronous. In case you OR ""what"" with kMESS_ZIP,; the message will be compressed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwi",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23321,Integrability,message,message,23321,"ed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support fo",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23360,Integrability,message,message,23360,"ed in TSocket using the zip algorithm; (only if message is > 256 bytes). TMessage(void* buf, Int_t bufsize); Create a TMessage object for reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support fo",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23488,Integrability,message,message,23488," reading objects. The objects will be; read from buf. Use the What() method to get the message type. ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSock",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23558,Integrability,message,message,23558,". ~TMessage(); Clean up compression buffer. void EnableSchemaEvolutionForAll(Bool_t enable = kTRUE); Static function enabling or disabling the automatic schema evolution.; By default schema evolution support is off. Bool_t UsesSchemaEvolutionForAll(); Static function returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to st",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23841,Integrability,message,message,23841,"ction returning status of global schema evolution. void ForceWriteInfo(TVirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. USh",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23854,Integrability,message,message,23854,"VirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is alre",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:23931,Integrability,message,message,23931,"VirtualStreamerInfo* info, Bool_t force); Force writing the TStreamerInfo to the message. void Forward(); Change a buffer that was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is alre",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24021,Integrability,message,message,24021,"at was received into one that can be send, i.e.; forward a just received message. void TagStreamerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 ",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24133,Integrability,message,message,24133,"amerInfo(TVirtualStreamerInfo* info); Remember that the StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 where uid id the uid of the ProcessID. Int_t GetCompressionAlgorithm() const. Int_t GetCompre",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24146,Integrability,message,message,24146,"he StreamerInfo is being used in writing. void Reset(); Reset the message buffer so we can use (i.e. fill) it again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 where uid id the uid of the ProcessID. Int_t GetCompressionAlgorithm() const. Int_t GetCompressionLevel() const. Int_t GetCompressionSettings() co",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24300,Integrability,message,message,24300,"t again. void SetLength() const; Set the message length at the beginning of the message buffer.; This method is only called by TSocket::Send(). void SetWhat(UInt_t what); Using this method one can change the message type a-posteriory.; In case you OR ""what"" with kMESS_ACK, the message will wait for; an acknowledgement from the remote side. This makes the sending; process synchronous. void SetCompressionAlgorithm(Int_t algorithm = 0). void SetCompressionLevel(Int_t level = 1). void SetCompressionSettings(Int_t settings = 1). Int_t Compress(); Compress the message. The message will only be compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 where uid id the uid of the ProcessID. Int_t GetCompressionAlgorithm() const. Int_t GetCompressionLevel() const. Int_t GetCompressionSettings() const. TMessage(const TMessage& ); TMessage objects cannot be copied or assigned. void operator=(const TMessag",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:24913,Integrability,message,message,24913,"e compressed if the; compression level > 0 and the if the message is > 256 bytes.; Returns -1 in case of error (when compression fails or; when the message increases in size in some pathological cases),; otherwise returns 0. Int_t Uncompress(); Uncompress the message. The message will only be uncompressed when; kMESS_ZIP is set. Returns -1 in case of error, 0 otherwise. void WriteObject(const TObject* obj); Write object to message buffer.; When support for schema evolution is enabled the list of TStreamerInfo; used to stream this object is kept in fInfos. This information is used; by TSocket::Send that sends this list through the socket. This list is in; turn used by TSocket::Recv to store the TStreamerInfo objects in the; relevant TClass in case the TClass does not know yet about a particular; class version. This feature is implemented to support clients and servers; with either different ROOT versions or different user classes versions. UShort_t WriteProcessID(TProcessID* pid); Check if the ProcessID pid is already in the message.; If not, then:; - mark bit 0 of fBitsPIDs to indicate that a ProcessID has been found; - mark bit uid+1 where uid id the uid of the ProcessID. Int_t GetCompressionAlgorithm() const. Int_t GetCompressionLevel() const. Int_t GetCompressionSettings() const. TMessage(const TMessage& ); TMessage objects cannot be copied or assigned. void operator=(const TMessage& ). Bool_t TestBitNumber(UInt_t bitnumber) const; used by friend TSocket. { return fBitsPIDs.TestBitNumber(bitnumber); }. TClass * GetClass() const; { return fClass;}. void Reset(). UInt_t What() const; { return fWhat; }. void EnableSchemaEvolution(Bool_t enable = kTRUE); { fEvolution = enable; }. Bool_t UsesSchemaEvolution() const; { return fEvolution; }. char * CompBuffer() const; { return fBufComp; }. Int_t CompLength() const; { return (Int_t)(fBufCompCur - fBufComp); }. » Author: Fons Rademakers 19/12/96 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: ",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:392,Modifiability,inherit,inherits,392,". TMessage. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » NET; » TMessage. class TMessage: public TBufferFile. TMessage. Message buffer class used for serializing objects and sending them; over a network. This class inherits from TBuffer the basic I/O; serializer. Function Members (Methods); public:. TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); virtual~TMessage(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); voidTBuffer::AutoExpand(Int_t size_needed); virtual voidTObject::Browse(TBrowser* b); char*TBuffer::Buffer() const; Int_tTBuffer::BufferSize() const; virtual Int_tTBufferFile::CheckByteCount(UInt_t startpos, UInt_t bcnt, const TClass* clss); virtual Int_tTBufferFile::CheckByteCount(UInt_t startpos, UInt_t bcnt, const char* classname); virtual Bool_tTBufferFile::CheckObject(const TObject* obj); virtual Bool_tTBufferFile::CheckObject(const void* obj, const TClass* ptrClass); static TClass*Class(); virtual voidTBufferFile::ClassBegin(const TClass*, Version_t = -1); virtual voidTBufferFile::ClassEnd(const TClass*); virtual voidTBufferFile::ClassMember(const char*, const char* = 0, Int_t = -1, Int_t = -1); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; char*CompBuffer() const; Int_tCompLength() const; Int_tCompress(); virtual voidTObject::Copy(TObject& object) const; virtual voidTBufferFile::DecrementLevel(TVirtualStreamerInfo*); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTBuffer::DetachBuffer(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObje",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:20941,Modifiability,extend,extending,20941,"MaxEnd of buffer; Int_tTBuffer::fBufSizeSize of buffer; char*TBuffer::fBufferBuffer used to store objects; vector<TVirtualArray*>TBuffer::fCacheStackStack of pointers to the cache where to temporarily store the value of 'missing' data members; TExMap*TBufferFile::fClassMapMap containing object,class pairs for reading; Int_tTBufferFile::fDisplacementValue to be added to the map offsets; TStreamerInfo*TBufferFile::fInfoPointer to TStreamerInfo object writing/reading the buffer; vector<TStreamerInfo*>TBufferFile::fInfoStackStack of pointers to the TStreamerInfos; TExMap*TBufferFile::fMapMap containing object,offset pairs for reading/writing; Int_tTBufferFile::fMapCountNumber of objects or classes in map; Int_tTBufferFile::fMapSizeDefault size of map; Bool_tTBuffer::fModeRead or write mode; TObject*TBuffer::fParentPointer to parent object owning this buffer; UShort_tTBufferFile::fPidOffsetOffset to be added to the pid index in this key/buffer.; ReAllocCharFun_tTBuffer::fReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fBufCur when message was compressed; Int_tfCompressCompression level and algorithm; Bool_tfEvolutionTrue if support for schema evolution required; TList*fInfosArray of TStreamerInfo used in WriteObject; UInt_tfWhatMessage type; static Bool_tfgEvolutionTrue if global support for schema evolution required. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessage(UInt_t what = kMESS_ANY, Int_t bufsiz = TBuffer::kInitialSize); Create a TMessage object for storing objects. The ""what"" integer; describes the type of me",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessage.html:20088,Performance,cache,cache,20088,"amedMemberWise; kNotDecompressed; kTextBasedStreaming; kUser1; kUser2; kUser3; };; enum TBuffer::EMode { kRead; kWrite; };; enum TBuffer::[unnamed] { kIsOwner; kCannotHandleMemberWiseStreaming; kInitialSize; kMinimalSize; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. char*TBuffer::fBufCurCurrent position in buffer; char*TBuffer::fBufMaxEnd of buffer; Int_tTBuffer::fBufSizeSize of buffer; char*TBuffer::fBufferBuffer used to store objects; vector<TVirtualArray*>TBuffer::fCacheStackStack of pointers to the cache where to temporarily store the value of 'missing' data members; TExMap*TBufferFile::fClassMapMap containing object,class pairs for reading; Int_tTBufferFile::fDisplacementValue to be added to the map offsets; TStreamerInfo*TBufferFile::fInfoPointer to TStreamerInfo object writing/reading the buffer; vector<TStreamerInfo*>TBufferFile::fInfoStackStack of pointers to the TStreamerInfos; TExMap*TBufferFile::fMapMap containing object,offset pairs for reading/writing; Int_tTBufferFile::fMapCountNumber of objects or classes in map; Int_tTBufferFile::fMapSizeDefault size of map; Bool_tTBuffer::fModeRead or write mode; TObject*TBuffer::fParentPointer to parent object owning this buffer; UShort_tTBufferFile::fPidOffsetOffset to be added to the pid index in this key/buffer.; ReAllocCharFun_tTBuffer::fReAllocFunc! Realloc function to be used when extending the buffer.; Int_tTBuffer::fVersionBuffer format version; static Int_tTBufferFile::fgMapSizeDefault map size for all TBuffer objects. private:. TBitsfBitsPIDsArray of bits to mark the TProcessIDs uids written to the message; char*fBufCompCompressed buffer; char*fBufCompCurCurrent position in compressed buffer; TClass*fClassIf message is kMESS_OBJECT pointer to object's class; char*fCompPosPosition of fB",MatchSource.WIKI,root/html530/TMessage.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessage.html
https://root.cern/root/html530/TMessageHandler.html:4274,Availability,error,error,4274,"* params); voidTQObject::Emit(const char* signal, Double_t param); voidTQObject::Emit(const char* signal, Long_t param); voidTQObject::Emit(const char* signal, Long64_t param); voidTQObject::Emit(const char* signal, Bool_t param); voidTQObject::Emit(const char* signal, Char_t param); voidTQObject::Emit(const char* signal, UChar_t param); voidTQObject::Emit(const char* signal, Short_t param); voidTQObject::Emit(const char* signal, UShort_t param); voidTQObject::Emit(const char* signal, Int_t param); voidTQObject::Emit(const char* signal, UInt_t param); voidTQObject::Emit(const char* signal, ULong_t param); voidTQObject::Emit(const char* signal, ULong64_t param); voidTQObject::Emit(const char* signal, Float_t param); voidTQObject::EmitVA(const char* signal, Int_t nargs); voidTQObject::EmitVA(const char* signal, Int_t nargs, va_list va); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TList*TQObject::GetListOfClassSignals() const; TList*TQObject::GetListOfConnections() const; TList*TQObject::GetListOfSignals() const; virtual Int_tGetMessageCount(Int_t messId) const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetSize() const; virtual const char*TNamed::GetTitle() const; virtual Int_tGet",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:4358,Availability,error,error,4358,"t(const char* signal, Long_t param); voidTQObject::Emit(const char* signal, Long64_t param); voidTQObject::Emit(const char* signal, Bool_t param); voidTQObject::Emit(const char* signal, Char_t param); voidTQObject::Emit(const char* signal, UChar_t param); voidTQObject::Emit(const char* signal, Short_t param); voidTQObject::Emit(const char* signal, UShort_t param); voidTQObject::Emit(const char* signal, Int_t param); voidTQObject::Emit(const char* signal, UInt_t param); voidTQObject::Emit(const char* signal, ULong_t param); voidTQObject::Emit(const char* signal, ULong64_t param); voidTQObject::Emit(const char* signal, Float_t param); voidTQObject::EmitVA(const char* signal, Int_t nargs); voidTQObject::EmitVA(const char* signal, Int_t nargs, va_list va); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TList*TQObject::GetListOfClassSignals() const; TList*TQObject::GetListOfConnections() const; TList*TQObject::GetListOfSignals() const; virtual Int_tGetMessageCount(Int_t messId) const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetSize() const; virtual const char*TNamed::GetTitle() const; virtual Int_tGetTotalMessageCount() const; virtual UInt_tTObject::GetUniqueID() const; Bool_tHandleD",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:682,Deployability,install,install,682,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:346,Integrability,message,messages,346,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:450,Integrability,message,messages,450,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:570,Integrability,message,message,570,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:623,Integrability,message,message,623,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:665,Integrability,message,message,665,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:704,Integrability,message,message,704,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:734,Integrability,message,message,734,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:829,Integrability,message,message,829,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:875,Integrability,message,message,875,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:924,Integrability,message,message,924,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:970,Integrability,message,message,970,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:9674,Integrability,message,message,9674,"lot); static Bool_tTQObject::ConnectToClass(const char* sender_class, const char* signal, TClass* receiver_class, void* receiver, const char* slot); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual void*GetSender(); virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, c",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:9722,Integrability,message,message,9722,"lot); static Bool_tTQObject::ConnectToClass(const char* sender_class, const char* signal, TClass* receiver_class, void* receiver, const char* slot); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual void*GetSender(); virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, c",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:9760,Integrability,message,messages,9760,"lot); static Bool_tTQObject::ConnectToClass(const char* sender_class, const char* signal, TClass* receiver_class, void* receiver, const char* slot); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual void*GetSender(); virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, c",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10065,Integrability,message,message,10065,"lot); static Bool_tTQObject::ConnectToClass(const char* sender_class, const char* signal, TClass* receiver_class, void* receiver, const char* slot); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual void*GetSender(); virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, c",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10214,Integrability,message,messages,10214,"lot); static Bool_tTQObject::ConnectToClass(const char* sender_class, const char* signal, TClass* receiver_class, void* receiver, const char* slot); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual void*GetSender(); virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, c",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10514,Integrability,message,message,10514,"idObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10570,Integrability,message,message,10570,"idObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. const TClass*fClassclass for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10658,Integrability,message,message,10658,"s for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fo",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10720,Integrability,message,message,10720,"s for which message has to be handled; Int_t*fCntscount per message; Bool_tfDerivedif true handle messages also for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fo",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10759,Integrability,message,message,10759,"o for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last gene",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10790,Integrability,message,messages,10790,"o for derived classes; TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last gene",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10871,Integrability,message,message,10871,"to this object; TList*TQObject::fListOfSignals! list of signals from this object; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comme",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:10954,Integrability,message,messages,10954,"ect; Int_tfMessIdmessage id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:11020,Integrability,message,message,11020,"id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:11216,Integrability,message,message,11216,"id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:11260,Integrability,message,message,11260,"id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:11293,Integrability,message,messages,11293,"id (often matching specific enum in fClass); Int_t*fMessIdsmessage ids; const TObject*fMessObjobject generating message; TStringTNamed::fNameobject identifier; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; Int_tfSizenumber of different messages handled; TStringTNamed::fTitleobject title; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); Create a new message handler for class cl and add it to the list; of message handlers. TMessageHandler(const char* cl, Bool_t derived = kTRUE); Create a new message handler for class named cl and add it to the list; of message handlers. void Add(); Add this message handler to the list of messages handlers. Int_t GetMessageCount(Int_t messId) const; Return counter for message with ID=messid. Int_t GetTotalMessageCount() const; Return total number of messages. void HandleMessage(Int_t id, const TObject* obj); Store message origin, keep statistics and call Notify(). Bool_t Notify(); This method must be overridden to handle object notifcation. void Print(Option_t* option = """") const; Print statistics for this message handler. void Remove(); Remove this message handler from the list of messages handlers. void * GetSender(); { return this; }. virtual ~TMessageHandler(). Int_t GetSize() const; { return fSize; }. Bool_t HandleDerived() const; { return fDerived; }. void Added(); { Emit(""Added()""); }. void Removed(); { Emit(""Removed()""); }. void Notified(); { Emit(""Notified()""); }. » Author: Rene Brun 11/11/99 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/base:$Id: TMessageHandler.h 22415 2008-03-01 11:00:27Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:609,Security,access,access,609,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:819,Testability,log,logged,819,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:865,Testability,log,logged,865,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:914,Testability,log,logged,914,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMessageHandler.html:960,Testability,log,logged,960,". TMessageHandler. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » BASE; » TMessageHandler. class TMessageHandler: public TNamed, public TQObject. TMessageHandler. Handle messages that might be generated by the system.; By default a handler only keeps track of the different messages; generated for a specific class. By deriving from this class and; overriding Notify() one can implement custom message handling.; In Notify() one has access to the message id and the object; generating the message. One can install more than one message; handler per class. A message handler can be removed or again; added when needed.; All Root ""Warnings"" are logged as message 1001; All Root ""Errors"" are logged as message 1002; All Root ""SysErrors"" are logged as message 1003; All Root ""Fatals"" are logged as message 1004. Function Members (Methods); public:. TMessageHandler(const TClass* cl, Bool_t derived = kTRUE); TMessageHandler(const char* cl, Bool_t derived = kTRUE); virtual~TMessageHandler(); voidTObject::AbstractMethod(const char* method) const; virtual voidAdd(); virtual voidAdded()SIGNAL ; virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTNamed::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const ",MatchSource.WIKI,root/html530/TMessageHandler.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMessageHandler.html
https://root.cern/root/html530/TMethod.html:1585,Availability,error,error,1585,"d(const TMethod& org); TMethod(MethodInfo_t* info = 0, TClass* cl = 0); virtual~TMethod(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TDataMember*FindDataMember(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TClass*GetClass() const; virtual const char*GetCommentString(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual TList*GetListOfMethodArgs(); virtual const char*TFunction::GetMangledName() const; virtual const char*TNamed::GetName() const; Int_tTFunction::GetNargs() const; Int_tTFunction::GetNargsOpt() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virt",MatchSource.WIKI,root/html530/TMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethod.html
https://root.cern/root/html530/TMethod.html:1669,Availability,error,error,1669,"hod(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TDataMember*FindDataMember(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TClass*GetClass() const; virtual const char*GetCommentString(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual TList*GetListOfMethodArgs(); virtual const char*TFunction::GetMangledName() const; virtual const char*TNamed::GetName() const; Int_tTFunction::GetNargs() const; Int_tTFunction::GetNargsOpt() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TFunction::GetPrototype() const; const char*TFunction::GetReturnTypeN",MatchSource.WIKI,root/html530/TMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethod.html
https://root.cern/root/html530/TMethod.html:8540,Deployability,update,updates,8540,"hodInfo_t* info = 0, TClass* cl = 0); Default TMethod ctor. TMethods are constructed in TClass.; Comment strings are pre-parsed to find out whether the method is; a context-menu item. TMethod(const TMethod& org); Copy ctor. TMethod& operator=(const TMethod& rhs); Assignment operator. ~TMethod(); Cleanup. TObject * Clone(const char* newname = """") const; Clone method. const char * GetCommentString(); Returns a comment string from the class declaration. void CreateSignature(); Using the CINT method arg information create a complete signature string. TDataMember * FindDataMember(); Tries to guess DataMember from comment string; and Method's name <==(only if 1 Argument!).; If more then one argument=> returns pointer to the last argument.; It also sets MethodArgs' pointers to point to specified data members. The form of comment string defining arguments is:; void XXX(Int_t x1, Float_t y2) //*ARGS={x1=>fX1,y2=>fY2}; where fX1, fY2 are data fields in the same class.; (""pointers"" to data members). TMethodCall * GetterMethod(); Return call environment for the getter method in case this is a; *TOGGLE method (for the context menu). TMethodCall * SetterMethod(); Return call environment for this method in case this is a; *TOGGLE method which takes a single boolean or integer argument. TList * GetListOfMethodArgs(); Returns methodarg list and additionally updates fDataMember in TMethod by; calling FindDataMember();. TClass * GetClass() const; { return fClass; }. EMenuItemKind IsMenuItem() const; { return fMenuItem; }. const char * Getter() const; { return fGetter; }. void SetMenuItem(EMenuItemKind menuItem); {fMenuItem=menuItem;}. » Author: Rene Brun 09/02/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/meta:$Id: TMethod.h 24077 2008-05-31 19:39:09Z brun $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethod.html
https://root.cern/root/html530/TMethodArg.html:1606,Availability,error,error,1606,"MethodArg(MethodArgInfo_t* info = 0, TFunction* method = 0); virtual~TMethodArg(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TDataMember*GetDataMember() const; const char*GetDefault() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); const char*GetFullTypeName() const; virtual const char*TObject::GetIconName() const; TFunction*GetMethod() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; TList*GetOptions() const; virtual const char*TNamed::GetTitle() const; const char*GetTypeName() const; virtual UInt_tTObject::GetUniqueID",MatchSource.WIKI,root/html530/TMethodArg.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodArg.html
https://root.cern/root/html530/TMethodArg.html:1690,Availability,error,error,1690,"oidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TDataMember*GetDataMember() const; const char*GetDefault() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); const char*GetFullTypeName() const; virtual const char*TObject::GetIconName() const; TFunction*GetMethod() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; TList*GetOptions() const; virtual const char*TNamed::GetTitle() const; const char*GetTypeName() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::",MatchSource.WIKI,root/html530/TMethodArg.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodArg.html
https://root.cern/root/html530/TMethodArg.html:7673,Usability,learn,learn,7673,"udes; Libraries. Function documentation; TMethodArg(MethodArgInfo_t* info = 0, TFunction* method = 0); Default TMethodArg ctor. TMethodArgs are constructed in TFunction; via a call to TCint::CreateListOfMethodArgs(). ~TMethodArg(); TMethodArg dtor deletes adopted CINT MethodArgInfo object. const char * GetDefault() const; Get default value of method argument. const char * GetTypeName() const; Get type of method argument, e.g.: ""class TDirectory*"" -> ""TDirectory""; Result needs to be used or copied immediately. const char * GetFullTypeName() const; Get full type description of method argument, e.g.: ""class TDirectory*"". Long_t Property() const; Get property description word. For meaning of bits see EProperty. TList * GetOptions() const; Returns list of possible options - according to pointed datamember.; If there is no datamember field assigned to this methodarg - returns 0. TDataMember * GetDataMember() const; Returns TDataMember pointed by this methodarg.; If you want to specify list of options or current value for your; MethodArg (i.e. it is used as initial values in argument-asking dialogs; popped up from context-meny),you can get this value from one of data; members of the class.; The only restriction is, that this DataMember object must have its; Getter/Setter methods set-up correctly - for details look at TDataMember.; To learn how to specify the data member to which the argument should; ""point"", look at TMethod. This is TMethod which sets up fDataMember,; so it could work correctly. TMethodArg(const TMethodArg& ). TMethodArg& operator=(const TMethodArg& ). TFunction * GetMethod() const; { return fMethod; }. » Author: Rene Brun 04/02/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/meta:$Id: TMethodArg.h 25986 2008-10-28 08:39:44Z brun $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMethodArg.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodArg.html
https://root.cern/root/html530/TMethodBrowsable.html:3205,Availability,error,error,3205,"hodBrowsable(const TMethodBrowsable&); virtual~TMethodBrowsable(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTVirtualBranchBrowsable::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); static Int_tTVirtualBranchBrowsable::FillListOfBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const TBranch*TVirtualBranchBrowsable::GetBranch() const; static Int_tGetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); TClass*TVirtualBranchBrowsable::GetClassType() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*GetIconName() const; TList*TVirtualBranchBrowsable::GetLeaves() const; virtual const char*TNamed::GetName() const; virtual char*TObje",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:3289,Availability,error,error,3289,"ractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTVirtualBranchBrowsable::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); static Int_tTVirtualBranchBrowsable::FillListOfBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const TBranch*TVirtualBranchBrowsable::GetBranch() const; static Int_tGetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); TClass*TVirtualBranchBrowsable::GetClassType() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*GetIconName() const; TList*TVirtualBranchBrowsable::GetLeaves() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:10688,Integrability,depend,depending,10688,"alling TBranch, otherwise ""parent"" should; be set to the TVirtualBranchBrowsable being browsed, and branch; should be the branch of the parent. Int_t GetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); This methods fills list with TMethodBrowsables; for the branch's or parent's class and its base classes, and returns; the number of added elements. If called from a TBranch::Browse; overload, ""branch"" should be set to the calling TBranch, otherwise; ""parent"" should be set to the TVirtualBranchBrowsable being browsed. Bool_t IsMethodBrowsable(const TMethod* m); A TMethod is browsable if it is const, public and not pure virtual,; if does not have any parameter without default value, and if it has; a (non-void) return value.; A method called *, Get*, or get* will not be browsable if there is a; persistent data member called f*, _*, or m*, as data member access is; faster than method access. Examples: if one of fX, _X, or mX is a; persistent data member, the methods GetX(), getX(), and X() will not; be browsable. void Register(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... void Unregister(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... const char * GetIconName() const; return icon shown when browsing a TVirtualBranchBrowsable. ~TMethodBrowsable(); {}. TMethodBrowsable(const TBranch* branch, TMethod* m, const TVirtualBranchBrowsable* parent = 0). » Author: Axel Naumann 14/10/2004 » Copyright (C) 1995-2004, Rene Brun and Fons Rademakers. *; » Last changed: root/tree:$Id: TBranchBrowsable.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:10865,Integrability,depend,depending,10865,"alling TBranch, otherwise ""parent"" should; be set to the TVirtualBranchBrowsable being browsed, and branch; should be the branch of the parent. Int_t GetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); This methods fills list with TMethodBrowsables; for the branch's or parent's class and its base classes, and returns; the number of added elements. If called from a TBranch::Browse; overload, ""branch"" should be set to the calling TBranch, otherwise; ""parent"" should be set to the TVirtualBranchBrowsable being browsed. Bool_t IsMethodBrowsable(const TMethod* m); A TMethod is browsable if it is const, public and not pure virtual,; if does not have any parameter without default value, and if it has; a (non-void) return value.; A method called *, Get*, or get* will not be browsable if there is a; persistent data member called f*, _*, or m*, as data member access is; faster than method access. Examples: if one of fX, _X, or mX is a; persistent data member, the methods GetX(), getX(), and X() will not; be browsable. void Register(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... void Unregister(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... const char * GetIconName() const; return icon shown when browsing a TVirtualBranchBrowsable. ~TMethodBrowsable(); {}. TMethodBrowsable(const TBranch* branch, TMethod* m, const TVirtualBranchBrowsable* parent = 0). » Author: Axel Naumann 14/10/2004 » Copyright (C) 1995-2004, Rene Brun and Fons Rademakers. *; » Last changed: root/tree:$Id: TBranchBrowsable.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:435,Modifiability,extend,extend,435,". TMethodBrowsable. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TREE; » TREE; » TMethodBrowsable. class TMethodBrowsable: public TVirtualBranchBrowsable. TVirtualBranchBrowsable is a base class (not really abstract, but useless; by itself) for helper objects that extend TBranch's browsing support.; Each registered derived class's generator method is called, which fills; all created helper objects into a list which can then be browsed.; For details of what these browser helper objects can do, see e.g.; TMethodBrowsable, which allows methods to show up in the TBrowser. Only registered helper objects are created. By default, only; TMethodBrowsable, TNonSplitBrowsable, and TCollectionPropertyBrowsable; are registered (see RegisterDefaultGenerators). You can prevent any of; their objects to show up in the browser by unregistering the generator:; TMethodBrowsable::Unregister(); will stop creating browsable method helper objects from that call on.; Note that these helper objects are cached (in TBranch::fBrowsables);; already created (and thus cached) browsables will still appear in the; browser even after unregistering the corresponding generator. You can implement your own browsable objects and thier generator; see; e.g. the simple TCollectionPropertyBrowsable. Note that you will have; to register your generator just like any other, and that you should; implement the following methods for your own class, mainly for; consistency reasons:; static void Register() {; TVirtualBranchBrowsable::RegisterGenerator(GetBrowsables); }; static void Unregister() {; TVirtualBranchBrowsable::UnregisterGenerator(GetBrowsables); }; where GetBrowsables is a static member function of your class, that; creates the browsable helper objects, and has the signature; static Int_t GetBrowsables(TList& list, const TBranch* branch,; ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:1162,Performance,cache,cached,1162,"ROOT; » TREE; » TREE; » TMethodBrowsable. class TMethodBrowsable: public TVirtualBranchBrowsable. TVirtualBranchBrowsable is a base class (not really abstract, but useless; by itself) for helper objects that extend TBranch's browsing support.; Each registered derived class's generator method is called, which fills; all created helper objects into a list which can then be browsed.; For details of what these browser helper objects can do, see e.g.; TMethodBrowsable, which allows methods to show up in the TBrowser. Only registered helper objects are created. By default, only; TMethodBrowsable, TNonSplitBrowsable, and TCollectionPropertyBrowsable; are registered (see RegisterDefaultGenerators). You can prevent any of; their objects to show up in the browser by unregistering the generator:; TMethodBrowsable::Unregister(); will stop creating browsable method helper objects from that call on.; Note that these helper objects are cached (in TBranch::fBrowsables);; already created (and thus cached) browsables will still appear in the; browser even after unregistering the corresponding generator. You can implement your own browsable objects and thier generator; see; e.g. the simple TCollectionPropertyBrowsable. Note that you will have; to register your generator just like any other, and that you should; implement the following methods for your own class, mainly for; consistency reasons:; static void Register() {; TVirtualBranchBrowsable::RegisterGenerator(GetBrowsables); }; static void Unregister() {; TVirtualBranchBrowsable::UnregisterGenerator(GetBrowsables); }; where GetBrowsables is a static member function of your class, that; creates the browsable helper objects, and has the signature; static Int_t GetBrowsables(TList& list, const TBranch* branch,; const TVirtualBranchBrowsable* parent=0);; It has to return the number of browsable helper objects for parent; (or, if NULL, for branch) which are added to the list. Function Members (Methods); public:. TMethodBrowsable(const ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:1223,Performance,cache,cached,1223,"ROOT; » TREE; » TREE; » TMethodBrowsable. class TMethodBrowsable: public TVirtualBranchBrowsable. TVirtualBranchBrowsable is a base class (not really abstract, but useless; by itself) for helper objects that extend TBranch's browsing support.; Each registered derived class's generator method is called, which fills; all created helper objects into a list which can then be browsed.; For details of what these browser helper objects can do, see e.g.; TMethodBrowsable, which allows methods to show up in the TBrowser. Only registered helper objects are created. By default, only; TMethodBrowsable, TNonSplitBrowsable, and TCollectionPropertyBrowsable; are registered (see RegisterDefaultGenerators). You can prevent any of; their objects to show up in the browser by unregistering the generator:; TMethodBrowsable::Unregister(); will stop creating browsable method helper objects from that call on.; Note that these helper objects are cached (in TBranch::fBrowsables);; already created (and thus cached) browsables will still appear in the; browser even after unregistering the corresponding generator. You can implement your own browsable objects and thier generator; see; e.g. the simple TCollectionPropertyBrowsable. Note that you will have; to register your generator just like any other, and that you should; implement the following methods for your own class, mainly for; consistency reasons:; static void Register() {; TVirtualBranchBrowsable::RegisterGenerator(GetBrowsables); }; static void Unregister() {; TVirtualBranchBrowsable::UnregisterGenerator(GetBrowsables); }; where GetBrowsables is a static member function of your class, that; creates the browsable helper objects, and has the signature; static Int_t GetBrowsables(TList& list, const TBranch* branch,; const TVirtualBranchBrowsable* parent=0);; It has to return the number of browsable helper objects for parent; (or, if NULL, for branch) which are added to the list. Function Members (Methods); public:. TMethodBrowsable(const ",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:10400,Security,access,access,10400,"lass and its base classes, and returns the number of; added elements. If called from a TBranch::Browse overload, ""branch""; should be set to the calling TBranch, otherwise ""parent"" should; be set to the TVirtualBranchBrowsable being browsed, and branch; should be the branch of the parent. Int_t GetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); This methods fills list with TMethodBrowsables; for the branch's or parent's class and its base classes, and returns; the number of added elements. If called from a TBranch::Browse; overload, ""branch"" should be set to the calling TBranch, otherwise; ""parent"" should be set to the TVirtualBranchBrowsable being browsed. Bool_t IsMethodBrowsable(const TMethod* m); A TMethod is browsable if it is const, public and not pure virtual,; if does not have any parameter without default value, and if it has; a (non-void) return value.; A method called *, Get*, or get* will not be browsable if there is a; persistent data member called f*, _*, or m*, as data member access is; faster than method access. Examples: if one of fX, _X, or mX is a; persistent data member, the methods GetX(), getX(), and X() will not; be browsable. void Register(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... void Unregister(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... const char * GetIconName() const; return icon shown when browsing a TVirtualBranchBrowsable. ~TMethodBrowsable(); {}. TMethodBrowsable(const TBranch* branch, TMethod* m, const TVirtualBranchBrowsable* parent = 0). » Author: Axel Naumann 14/10/2004 » Copyright (C) 1995-2004, Rene Brun and Fons Rademakers. *; » Last changed: root/tree:$Id: TBranchBrowsable.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page h",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:10430,Security,access,access,10430,"lass and its base classes, and returns the number of; added elements. If called from a TBranch::Browse overload, ""branch""; should be set to the calling TBranch, otherwise ""parent"" should; be set to the TVirtualBranchBrowsable being browsed, and branch; should be the branch of the parent. Int_t GetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); This methods fills list with TMethodBrowsables; for the branch's or parent's class and its base classes, and returns; the number of added elements. If called from a TBranch::Browse; overload, ""branch"" should be set to the calling TBranch, otherwise; ""parent"" should be set to the TVirtualBranchBrowsable being browsed. Bool_t IsMethodBrowsable(const TMethod* m); A TMethod is browsable if it is const, public and not pure virtual,; if does not have any parameter without default value, and if it has; a (non-void) return value.; A method called *, Get*, or get* will not be browsable if there is a; persistent data member called f*, _*, or m*, as data member access is; faster than method access. Examples: if one of fX, _X, or mX is a; persistent data member, the methods GetX(), getX(), and X() will not; be browsable. void Register(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... void Unregister(); Wrapper for the registration method. Needed against MSVC, which; assigned different addr to the same method, depending on what; translation unit you're in... const char * GetIconName() const; return icon shown when browsing a TVirtualBranchBrowsable. ~TMethodBrowsable(); {}. TMethodBrowsable(const TBranch* branch, TMethod* m, const TVirtualBranchBrowsable* parent = 0). » Author: Axel Naumann 14/10/2004 » Copyright (C) 1995-2004, Rene Brun and Fons Rademakers. *; » Last changed: root/tree:$Id: TBranchBrowsable.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page h",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:1410,Usability,simpl,simple,1410,"ects that extend TBranch's browsing support.; Each registered derived class's generator method is called, which fills; all created helper objects into a list which can then be browsed.; For details of what these browser helper objects can do, see e.g.; TMethodBrowsable, which allows methods to show up in the TBrowser. Only registered helper objects are created. By default, only; TMethodBrowsable, TNonSplitBrowsable, and TCollectionPropertyBrowsable; are registered (see RegisterDefaultGenerators). You can prevent any of; their objects to show up in the browser by unregistering the generator:; TMethodBrowsable::Unregister(); will stop creating browsable method helper objects from that call on.; Note that these helper objects are cached (in TBranch::fBrowsables);; already created (and thus cached) browsables will still appear in the; browser even after unregistering the corresponding generator. You can implement your own browsable objects and thier generator; see; e.g. the simple TCollectionPropertyBrowsable. Note that you will have; to register your generator just like any other, and that you should; implement the following methods for your own class, mainly for; consistency reasons:; static void Register() {; TVirtualBranchBrowsable::RegisterGenerator(GetBrowsables); }; static void Unregister() {; TVirtualBranchBrowsable::UnregisterGenerator(GetBrowsables); }; where GetBrowsables is a static member function of your class, that; creates the browsable helper objects, and has the signature; static Int_t GetBrowsables(TList& list, const TBranch* branch,; const TVirtualBranchBrowsable* parent=0);; It has to return the number of browsable helper objects for parent; (or, if NULL, for branch) which are added to the list. Function Members (Methods); public:. TMethodBrowsable(const TMethodBrowsable&); virtual~TMethodBrowsable(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTVirtualBranchBrowsable::Brow",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodBrowsable.html:9084,Usability,simpl,simple,9084,"tualBranchBrowsable::RegisterGenerator(TVirtualBranchBrowsable::MethodCreateListOfBrowsables_t generator); voidTVirtualBranchBrowsable::SetType(TClass* type); voidTVirtualBranchBrowsable::SetTypeIsPointer(Bool_t set = kTRUE); static voidTVirtualBranchBrowsable::UnregisterGenerator(TVirtualBranchBrowsable::MethodCreateListOfBrowsables_t generator). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. private:. TMethod*fMethodpointer to a method. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMethodBrowsable(const TBranch* branch, TMethod* m, const TVirtualBranchBrowsable* parent = 0); Constructor.; Links a TBranchElement to a TMethod, allowing the TBrowser to; browse simple methods. The c'tor sets the name for a method ""Class::Method(params) const""; to ""Method(params)"", title to TMethod::GetPrototype. void GetBrowsableMethodsForClass(TClass* cl, TList& list); Given a class, this methods fills list with TMethodBrowsables; for the class and its base classes, and returns the number of; added elements. If called from a TBranch::Browse overload, ""branch""; should be set to the calling TBranch, otherwise ""parent"" should; be set to the TVirtualBranchBrowsable being browsed, and branch; should be the branch of the parent. Int_t GetBrowsables(TList& list, const TBranch* branch, const TVirtualBranchBrowsable* parent = 0); This methods fills list with TMethodBrowsables; for the branch's or parent's class and its base classes, and returns; the number of added elements. If called from a TBranch::Browse; overload, ""branch"" should be set to the calling TBranch, otherwise; ""parent"" should be set to the TVirtualBranchBrowsable being brows",MatchSource.WIKI,root/html530/TMethodBrowsable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodBrowsable.html
https://root.cern/root/html530/TMethodCall.html:7937,Energy Efficiency,efficient,efficient,7937,"kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TClass*fClasspointer to the class info; Bool_tfDtorOnlycall only dtor and not delete when calling ~xxx; CallFunc_t*fFuncCINT method invocation environment; TFunction*fMetPtrpointer to the method or function info; TStringfMethodmethod name; Long_tfOffsetoffset added to object pointer before method invocation; TStringfParamsargument string; TStringfProtoprototype string; TMethodCall::EReturnTypefRetTypemethod return type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMethodCall(); Default TMethodCall ctor. Use Init() to initialize the method call; environment. TMethodCall(TClass* cl, const char* method, const char* params); Create a method invocation environment for a specific class, method and; parameters. The parameter string has the form: ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const char* function, const char* params); Create a global function invocation environment. The parameter; string has the form: ""\""aap\"", 3, 4,35"". To execute the; function call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const TMethodCall& org); Copy ctor. TMethodCall & operator=(const TMethodCall& rhs); Assignement operator. ~TMethodCall(); TMethodCall dtor. TObject * Clone(const char* newname = """") const; Return an exact copy of this object. void Init(TClass* cl, const char* method, const char* params); Initialize the method invocation environment. Necessary input; information: the class, method name and the parameter string; of the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Exe",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:8262,Energy Efficiency,efficient,efficient,8262,"ffset added to object pointer before method invocation; TStringfParamsargument string; TStringfProtoprototype string; TMethodCall::EReturnTypefRetTypemethod return type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMethodCall(); Default TMethodCall ctor. Use Init() to initialize the method call; environment. TMethodCall(TClass* cl, const char* method, const char* params); Create a method invocation environment for a specific class, method and; parameters. The parameter string has the form: ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const char* function, const char* params); Create a global function invocation environment. The parameter; string has the form: ""\""aap\"", 3, 4,35"". To execute the; function call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const TMethodCall& org); Copy ctor. TMethodCall & operator=(const TMethodCall& rhs); Assignement operator. ~TMethodCall(); TMethodCall dtor. TObject * Clone(const char* newname = """") const; Return an exact copy of this object. void Init(TClass* cl, const char* method, const char* params); Initialize the method invocation environment. Necessary input; information: the class, method name and the parameter string; of the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void Init(const char* function, const char* params); Initialize the function invocation environment. Necessary input; information: the function name and the parameter string of; the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than ca",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:8891,Energy Efficiency,efficient,efficient,8891," two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const char* function, const char* params); Create a global function invocation environment. The parameter; string has the form: ""\""aap\"", 3, 4,35"". To execute the; function call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). TMethodCall(const TMethodCall& org); Copy ctor. TMethodCall & operator=(const TMethodCall& rhs); Assignement operator. ~TMethodCall(); TMethodCall dtor. TObject * Clone(const char* newname = """") const; Return an exact copy of this object. void Init(TClass* cl, const char* method, const char* params); Initialize the method invocation environment. Necessary input; information: the class, method name and the parameter string; of the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void Init(const char* function, const char* params); Initialize the function invocation environment. Necessary input; information: the function name and the parameter string of; the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitImplementation(const char* methodname, const char* params, const char* proto, TClass* cl, const ClassInfo_t* cinfo); This function implements Init and InitWithPrototype. void InitWithPrototype(TClass* cl, const char* method, const char* proto); Initialize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execut",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:9261,Energy Efficiency,efficient,efficient,9261,"calling for; every invocation TInterpreter::Execute(...). TMethodCall(const TMethodCall& org); Copy ctor. TMethodCall & operator=(const TMethodCall& rhs); Assignement operator. ~TMethodCall(); TMethodCall dtor. TObject * Clone(const char* newname = """") const; Return an exact copy of this object. void Init(TClass* cl, const char* method, const char* params); Initialize the method invocation environment. Necessary input; information: the class, method name and the parameter string; of the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void Init(const char* function, const char* params); Initialize the function invocation environment. Necessary input; information: the function name and the parameter string of; the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitImplementation(const char* methodname, const char* params, const char* proto, TClass* cl, const ClassInfo_t* cinfo); This function implements Init and InitWithPrototype. void InitWithPrototype(TClass* cl, const char* method, const char* proto); Initialize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitWithPrototype(const char* function, const char* proto); Initialize the function invocation environment. Necessary input; information: the function name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpr",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:9842,Energy Efficiency,efficient,efficient,9842,"his two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void Init(const char* function, const char* params); Initialize the function invocation environment. Necessary input; information: the function name and the parameter string of; the form ""\""aap\"", 3, 4.35"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitImplementation(const char* methodname, const char* params, const char* proto, TClass* cl, const ClassInfo_t* cinfo); This function implements Init and InitWithPrototype. void InitWithPrototype(TClass* cl, const char* method, const char* proto); Initialize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitWithPrototype(const char* function, const char* proto); Initialize the function invocation environment. Necessary input; information: the function name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). Bool_t IsValid() const; Return true if the method call has been properly initialized and is; usable. TFunction * GetMethod(); Returns the TMethod describing the method to be executed. This takes; all overriding and overloading into account (call TClass::GetMethod()).; Since finding the method is expensive the result is cached. void Execute(void* object); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params); Execute the method for the specified object and argument values. void Execute(void* obj",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:10224,Energy Efficiency,efficient,efficient,10224," method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitImplementation(const char* methodname, const char* params, const char* proto, TClass* cl, const ClassInfo_t* cinfo); This function implements Init and InitWithPrototype. void InitWithPrototype(TClass* cl, const char* method, const char* proto); Initialize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitWithPrototype(const char* function, const char* proto); Initialize the function invocation environment. Necessary input; information: the function name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). Bool_t IsValid() const; Return true if the method call has been properly initialized and is; usable. TFunction * GetMethod(); Returns the TMethod describing the method to be executed. This takes; all overriding and overloading into account (call TClass::GetMethod()).; Since finding the method is expensive the result is cached. void Execute(void* object); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params); Execute the method for the specified object and argument values. void Execute(void* object, Long_t& retLong); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, Long_t& retLong); Execute the method for the specified object and argument values. void Execute(void* object, Double_t& retDouble); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* par",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:334,Integrability,interface,interface,334,". TMethodCall. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » META; » TMethodCall. class TMethodCall: public TObject. TMethodCall. Method or function calling interface. Objects of this class contain; the (CINT) environment to call a global function or a method for an; object of a specific class with the desired arguments. This class is; espicially useful when a method has to be called more times for; different objects and/or with different arguments. If a function or; method needs to be called only once one better uses; TInterpreter::Execute(). Function Members (Methods); public:. TMethodCall(); TMethodCall(const TMethodCall& org); TMethodCall(const char* function, const char* params); TMethodCall(TClass* cl, const char* method, const char* params); virtual~TMethodCall(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCallDtorOnly(Bool_t set = kTRUE); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidExecute(); voidExecute(void* object); voidExecute(const char* params); voidExecute(Long_t& retLong); voidExecute(Double_t& retDouble); voidExecute(void* object, const char* ",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:10618,Performance,cache,cached,10618,"lize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitWithPrototype(const char* function, const char* proto); Initialize the function invocation environment. Necessary input; information: the function name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). Bool_t IsValid() const; Return true if the method call has been properly initialized and is; usable. TFunction * GetMethod(); Returns the TMethod describing the method to be executed. This takes; all overriding and overloading into account (call TClass::GetMethod()).; Since finding the method is expensive the result is cached. void Execute(void* object); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params); Execute the method for the specified object and argument values. void Execute(void* object, Long_t& retLong); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, Long_t& retLong); Execute the method for the specified object and argument values. void Execute(void* object, Double_t& retDouble); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, Double_t& retDouble); Execute the method for the specified object and argument values. void Execute(void* object, char** retText); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, char** retText); Execute the method for the specified object and argument values. void SetParamPtrs(voi",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMethodCall.html:10390,Usability,usab,usable,10390,"lementation(const char* methodname, const char* params, const char* proto, TClass* cl, const ClassInfo_t* cinfo); This function implements Init and InitWithPrototype. void InitWithPrototype(TClass* cl, const char* method, const char* proto); Initialize the method invocation environment. Necessary input; information: the class, method name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(object,...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). void InitWithPrototype(const char* function, const char* proto); Initialize the function invocation environment. Necessary input; information: the function name and the prototype string of; the form: ""char*,int,float"".; To execute the method call TMethodCall::Execute(...).; This two step method is much more efficient than calling for; every invocation TInterpreter::Execute(...). Bool_t IsValid() const; Return true if the method call has been properly initialized and is; usable. TFunction * GetMethod(); Returns the TMethod describing the method to be executed. This takes; all overriding and overloading into account (call TClass::GetMethod()).; Since finding the method is expensive the result is cached. void Execute(void* object); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params); Execute the method for the specified object and argument values. void Execute(void* object, Long_t& retLong); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, Long_t& retLong); Execute the method for the specified object and argument values. void Execute(void* object, Double_t& retDouble); Execute the method (with preset arguments) for the specified object. void Execute(void* object, const char* params, Double_t& retDouble); Execute the method for the specified object and argument values. void Execute(vo",MatchSource.WIKI,root/html530/TMethodCall.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMethodCall.html
https://root.cern/root/html530/TMinuit.html:3439,Availability,down,down,3439,"lected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4111,Availability,error,error,4111,"mit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakn",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4176,Availability,error,error,4176,"mit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakn",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4223,Availability,error,errors,4223,"mit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakn",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4798,Availability,error,error,4798,"value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6445,Availability,error,errors,6445,"imits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the minimum, this may be because the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels s",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6562,Availability,error,error,6562,"n the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the minimum, this may be because the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6594,Availability,error,errors,6594,"n the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the minimum, this may be because the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6811,Availability,error,errors,6811,"ause the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carri",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6949,Availability,error,error,6949,"if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given po",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:6988,Availability,error,error,6988," to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by t",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7034,Availability,error,errors,7034," to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by t",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7170,Availability,reliab,reliability,7170,"/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indic",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7195,Availability,error,error,7195,"/partial Pint is zero no matter; what the real derivative partial F/partial Pext is. ((partial F)/(partial P ))= ((partial F)/(partial P ))((partial P )/(partial P )) =((partial F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indic",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7387,Availability,error,error,7387,"F)/(partial P ))= 0; int ext ext int ext. Getting the right parameter errors with limits. In the best case, where the minimum is far from any limits, MINUIT will; correctly transform the error matrix, and the parameter errors it reports; should be accurate and very close to those you would have got without; limits. In other cases (which should be more common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7729,Availability,error,error,7729,"ore common, since otherwise you; wouldn't need limits), the very meaning of parameter errors becomes; problematic. Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:7819,Availability,error,errors,7819,". Mathematically, since the limit is an absolute constraint on; the parameter, a parameter at its limit has no error, at least in one; direction. The error matrix, which can assign only symmetric errors, then; becomes essentially meaningless. Interpretation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlat",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8066,Availability,error,errors,8066,"retation of Parameter Errors:. There are two kinds of problems that can arise: the reliability of; MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which ha",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8162,Availability,error,error,8162,"MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so h",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8211,Availability,reliab,reliable,8211,"MINUIT's error estimates, and their statistical interpretation, assuming; they are accurate. Statistical interpretation:. For discussuion of basic concepts, such as the meaning of the elements of; the error matrix, or setting of exact confidence levels see:. F.James.; Determining the statistical Significance of experimental Results.; Technical Report DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so h",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8527,Availability,error,errors,8527,"ort DD/81/02 and CERN Report 81-03, CERN, 1981.; W.T.Eadie, D.Drijard, F.James, M.Roos, and B.Sadoulet.; Statistical Methods in Experimental Physics.; North-Holland, 1971. Reliability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them,",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8729,Availability,error,error,8729,"liability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9134,Availability,error,errors,9134," there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9331,Availability,error,errors,9331,"are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; tha",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9406,Availability,error,errors,9406,"ed but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data poi",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9471,Availability,error,errors,9471,"lieves the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other pr",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9564,Availability,error,errors,9564,"lieves the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other pr",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10146,Availability,recover,recovers,10146,"s been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10566,Availability,error,error,10566,"of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of e",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10871,Availability,error,errors,10871,"hat it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This conce",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11297,Availability,error,error,11297,"nimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the sec",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11813,Availability,error,errors,11813,"undoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11913,Availability,error,errors,11913,"undoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11961,Availability,error,errors,11961,", but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:12037,Availability,error,errors,12037," are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in extern",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:12346,Availability,error,error,12346," of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:12471,Availability,error,error,12471," of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:12780,Availability,error,error,12780,"errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; e",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:12844,Availability,error,error,12844,"errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; e",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13132,Availability,error,error,13132,"g that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13239,Availability,error,errors,13239,"rts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13382,Availability,error,error,13382," exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voi",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13637,Availability,error,errors,13637,"ransformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired limits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); virtual voidBuildArrays(Int_t maxpar = 15); static TClass*Class(); virtual const char*T",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13729,Availability,error,error,13729,"mits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); virtual voidBuildArrays(Int_t maxpar = 15); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tCommand(const char* command); virtual In",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:13827,Availability,error,error,13827,"mits). Therefore the internal error matrix kept by; Minuit must be transformed to an external error matrix for the user.; This is done by multiplying the (I,J)th element by DEXDIN(I)*DEXDIN(J),; where DEXDIN is the derivative of the external value with respect to the; internal value at the minimum. This is a linearization of the; transformation, and is the only way to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); virtual voidBuildArrays(Int_t maxpar = 15); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tCommand(const char* command); virtual In",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:14126,Availability,error,errors,14126,"to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); virtual voidBuildArrays(Int_t maxpar = 15); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tCommand(const char* command); virtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tDefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virt",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:14163,Availability,error,errors,14163,"to produce an error matrix in external; coordinates meaningful to the user. But when reporting the individual; parabolic errors for limited parameters, Minuit can do a little better, so; it does. In this case, Minuit actually transforms the ends of the; internal ""error bar"" to external coordinates and reports the length of; this transformed interval. Strictly speaking, it is now asymmetric, but; since the origin of the asymmetry is only an artificial transformation it; does not make much sense, so the transformed errors are symmetrized. The result of all the above is that for parameters with limits, the error; reported by Minuit is not exactly equal to the square root of the diagonal; element of the error matrix. The difference is a measure of how much the; limits deform the problem. If possible, it is suggested not to use limits; on parameters, and the problem goes away. If for some reason limits are; necessary, and you are sensitive to the difference between the two ways of; calculating the errors, it is suggested to use Minos errors which take; into account the non-linearities much more precisely. Function Members (Methods); public:. TMinuit(); TMinuit(Int_t maxpar); virtual~TMinuit(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); virtual voidBuildArrays(Int_t maxpar = 15); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*Clone(const char* newname = """") const; virtual Int_tCommand(const char* command); virtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tDefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virt",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:15651,Availability,error,error,15651,"ect*Clone(const char* newname = """") const; virtual Int_tCommand(const char* command); virtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tDefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidDeleteArrays(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Int_tEval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Int_tFixParameter(Int_t parNo); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Int_tGetMaxIterations() const; TMethodCall*GetMethodCall() const; virtual const char*TNamed::GetName() const; virtual Int_tGetNumFixedPars() const; virtual Int_tGetNumFreePars() const; virtual Int_tGetNumPars() const; TObject*GetObjectFit() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual Int_tGetParamete",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:15735,Availability,error,error,15735,"; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tDefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidDeleteArrays(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Int_tEval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Int_tFixParameter(Int_t parNo); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Int_tGetMaxIterations() const; TMethodCall*GetMethodCall() const; virtual const char*TNamed::GetName() const; virtual Int_tGetNumFixedPars() const; virtual Int_tGetNumFreePars() const; virtual Int_tGetNumPars() const; TObject*GetObjectFit() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual Int_tGetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; virtual TObjec",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:19217,Availability,toler,toler,19217,"l voidmncuve(); virtual voidmnderi(); virtual voidmndxdi(Double_t pint, Int_t ipar, Double_t& dxdi); virtual voidmneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); virtual voidmnemat(Double_t* emat, Int_t ndim); virtual voidmnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); virtual voidmneval(Double_t anext, Double_t& fnext, Int_t& ierev); virtual voidmnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); virtual voidmnexin(Double_t* pint); virtual voidmnfixp(Int_t iint, Int_t& ierr); virtual voidmnfree(Int_t k); virtual voidmngrad(); virtual voidmnhelp(TString comd); virtual voidmnhelp(const char* command = """"); virtual voidmnhes1(); virtual voidmnhess(); virtual voidmnimpr(); virtual voidmninex(Double_t* pint); virtual voidmninit(Int_t i1, Int_t i2, Int_t i3); virtual voidmnlims(); virtual voidmnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); virtual voidmnmatu(Int_t kode); virtual voidmnmigr(); virtual voidmnmnos(); virtual voidmnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); virtual voidmnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); virtual voidmnpars(TString& crdbuf, Int_t& icondn); virtual voidmnpfit(Double_t* parx2p, Double_t* pary2p, Int_t npar2p, Double_t* coef2p, Double_t& sdev2p); virtual voidmnpint(Double_t& pexti, Int_t i, Double_t& pinti); virtual voidmnplot(Double_t* xpt, Double_t* ypt, char* chpt, Int_t nxypt, Int_t npagwd, Int_t npagln); virtual voidmnpout(Int_t iuext, TString& chnam, Double_t& val, Double_t& err, Double_t& xlolim, Double_t& xuplim, Int_t& iuint) const; virtual voidmnprin(Int_t inkode, Double_t fval); virtual voidmnpsdf(); virtual voidmnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); virtual voidmnrn15(Double_t& val, Int_t& inseed); virtual voidmnrset(Int_t iopt); virtual voidmnsave(); virtual v",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:24669,Availability,error,errors,24669,"Minimum value found for FCN; Double_tfApsi; Double_tfBigedmBig EDM = 123456; Double_t*fBlim[fMaxpar2] Upper limits for parameters; Double_t*fCOMDplist[fMaxpar] array used in mncomd; Double_t*fCONTgcc[fMaxpar] array used in mncont; Double_t*fCONTw[fMaxpar] array used in mncont; TStringfCfrom; char*fChpt!Character to be plotted at the X,Y contour positions; TStringfCovmes[4]; TString*fCpnam[fMaxpar2] Array of parameters names; TStringfCstatu; TStringfCtitl; TStringfCundef; TStringfCvrsn; TStringfCword; Double_tfDcovarRelative change in covariance matrix; Double_t*fDgrd[fMaxpar] Uncertainties; Double_t*fDirin[fMaxpar] (Internal) step sizes for current step; Double_t*fDirins[fMaxpar] (Internal) step sizes for current step for fixed params; Double_tfEDMEstimated vertical distance to the minimum; Int_tfEmptyInitialization flag (1 = Minuit initialized); Double_tfEpsi; Double_tfEpsma2sqrt(fEpsmac); Double_tfEpsmacmachine precision for floating points:; Double_t*fErn[fMaxpar] Negative Minos errors if calculated; Double_t*fErp[fMaxpar] Positive Minos errors if calculated; voidfFCN!; Double_t*fFIXPyy[fMaxpar] array used in mnfixp; Double_tfFval3; Double_t*fG2[fMaxpar] ; Double_t*fG2s[fMaxpar] ; Double_t*fGRADgf[fMaxpar] array used in mngrad; Double_t*fGin[fMaxpar2] ; Double_t*fGlobcc[fMaxpar] Global Correlation Coefficients; Bool_tfGraphicsModetrue if graphics mode on (default); Double_t*fGrd[fMaxpar] First derivatives; Double_t*fGrds[fMaxpar] ; Double_t*fGstep[fMaxpar] Step sizes; Double_t*fGsteps[fMaxpar] ; Double_t*fHESSyy[fMaxpar] array used in mnhess; Double_t*fIMPRdsav[fMaxpar] array used in mnimpr; Double_t*fIMPRy[fMaxpar] array used in mnimpr; Int_tfISW[7]Array of switches; Int_tfIcirc[2]; Int_tfIcomndNumber of commands; Int_tfIdbg[11]Array of internal debug switches; Int_t*fIpfix[fMaxpar] List of fixed parameters; Int_tfIstkrd[10]; Int_tfIstkwr[10]; Int_tfIstrat; Int_tfIsysrdstandardInput unit; Int_tfIsyssa; Int_tfIsyswrstandard output unit; Int_tfItaur; Int_tfKe1cr; I",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:24729,Availability,error,errors,24729,"ig EDM = 123456; Double_t*fBlim[fMaxpar2] Upper limits for parameters; Double_t*fCOMDplist[fMaxpar] array used in mncomd; Double_t*fCONTgcc[fMaxpar] array used in mncont; Double_t*fCONTw[fMaxpar] array used in mncont; TStringfCfrom; char*fChpt!Character to be plotted at the X,Y contour positions; TStringfCovmes[4]; TString*fCpnam[fMaxpar2] Array of parameters names; TStringfCstatu; TStringfCtitl; TStringfCundef; TStringfCvrsn; TStringfCword; Double_tfDcovarRelative change in covariance matrix; Double_t*fDgrd[fMaxpar] Uncertainties; Double_t*fDirin[fMaxpar] (Internal) step sizes for current step; Double_t*fDirins[fMaxpar] (Internal) step sizes for current step for fixed params; Double_tfEDMEstimated vertical distance to the minimum; Int_tfEmptyInitialization flag (1 = Minuit initialized); Double_tfEpsi; Double_tfEpsma2sqrt(fEpsmac); Double_tfEpsmacmachine precision for floating points:; Double_t*fErn[fMaxpar] Negative Minos errors if calculated; Double_t*fErp[fMaxpar] Positive Minos errors if calculated; voidfFCN!; Double_t*fFIXPyy[fMaxpar] array used in mnfixp; Double_tfFval3; Double_t*fG2[fMaxpar] ; Double_t*fG2s[fMaxpar] ; Double_t*fGRADgf[fMaxpar] array used in mngrad; Double_t*fGin[fMaxpar2] ; Double_t*fGlobcc[fMaxpar] Global Correlation Coefficients; Bool_tfGraphicsModetrue if graphics mode on (default); Double_t*fGrd[fMaxpar] First derivatives; Double_t*fGrds[fMaxpar] ; Double_t*fGstep[fMaxpar] Step sizes; Double_t*fGsteps[fMaxpar] ; Double_t*fHESSyy[fMaxpar] array used in mnhess; Double_t*fIMPRdsav[fMaxpar] array used in mnimpr; Double_t*fIMPRy[fMaxpar] array used in mnimpr; Int_tfISW[7]Array of switches; Int_tfIcirc[2]; Int_tfIcomndNumber of commands; Int_tfIdbg[11]Array of internal debug switches; Int_t*fIpfix[fMaxpar] List of fixed parameters; Int_tfIstkrd[10]; Int_tfIstkwr[10]; Int_tfIstrat; Int_tfIsysrdstandardInput unit; Int_tfIsyssa; Int_tfIsyswrstandard output unit; Int_tfItaur; Int_tfKe1cr; Int_tfKe2cr; Bool_tfLimsettrue if a parameter is up against l",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:28344,Availability,error,errors,28344,"er of fixed parameters; Int_tfNstkrd; Int_tfNstkwr; Int_tfNu; Int_t*fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant..); Int_tfNwrmes[2]; TObject*fObjectFitPointer to object being fitted; TStringfOrigin[100]; Double_t*fP[fMaxpar1] ; Double_t*fPARSplist[fMaxpar] array used in mnpars; Double_t*fPSDFs[fMaxpar] array used in mnpsdf; Double_t*fPbar[fMaxpar] ; TObject*fPlotPointer to TGraph object created by mncont; Double_t*fPrho[fMaxpar] Minimum point of parabola; Double_t*fPstar[fMaxpar2] ; Double_t*fPstst[fMaxpar] ; Double_t*fSEEKxbest[fMaxpar] array used in mnseek; Double_t*fSEEKxmid[fMaxpar] array used in mnseek; Double_t*fSIMPy[fMaxpar] array used in mnsimp; Int_tfStatusStatus flag for the last called Minuit function; Double_t*fU[fMaxpar2] External (visible to user in FCN) value of parameters; Double_tfUndefiUndefined number = -54321; Double_tfUpFCN+-UP defines errors (for chisquare fits UP=1); Double_tfUpdflt; Double_t*fVERTpp[fMaxpar] array used in mnvert; Double_t*fVERTq[fMaxpar] array used in mnvert; Double_t*fVERTs[fMaxpar] array used in mnvert; Double_t*fVhmat[fMaxpar5] (Internal) error matrix stored as Half MATrix, since it is symmetric; Double_tfVlimhi; Double_tfVlimlo; Double_t*fVthmat[fMaxpar5] VHMAT is sometimes saved in VTHMAT, especially in MNMNOT; TStringfWarmes[100]; Double_t*fWerr[fMaxpar] External parameters error (standard deviation, defined by UP); Double_t*fWord7[fMaxpar] ; Double_t*fX[fMaxpar] Internal parameters values; Double_tfXdircr; Double_tfXmidcr; Double_t*fXpt[fMaxcpt] X array of points for contours; Double_t*fXs[fMaxpar] Internal parameters values saved for fixed params; Double_t*fXt[fMaxpar] Internal parameters values X saved as Xt; Double_t*fXts[fMaxpar] Internal parameters values X saved as Xt for fixed params; Double_tfYdircr; Double_tfYmidcr; Double_t*fYpt[fMaxcpt] Y array of points for contours. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. Class Charts. Inheritance; Inherited Memb",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:28574,Availability,error,error,28574,"er of fixed parameters; Int_tfNstkrd; Int_tfNstkwr; Int_tfNu; Int_t*fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant..); Int_tfNwrmes[2]; TObject*fObjectFitPointer to object being fitted; TStringfOrigin[100]; Double_t*fP[fMaxpar1] ; Double_t*fPARSplist[fMaxpar] array used in mnpars; Double_t*fPSDFs[fMaxpar] array used in mnpsdf; Double_t*fPbar[fMaxpar] ; TObject*fPlotPointer to TGraph object created by mncont; Double_t*fPrho[fMaxpar] Minimum point of parabola; Double_t*fPstar[fMaxpar2] ; Double_t*fPstst[fMaxpar] ; Double_t*fSEEKxbest[fMaxpar] array used in mnseek; Double_t*fSEEKxmid[fMaxpar] array used in mnseek; Double_t*fSIMPy[fMaxpar] array used in mnsimp; Int_tfStatusStatus flag for the last called Minuit function; Double_t*fU[fMaxpar2] External (visible to user in FCN) value of parameters; Double_tfUndefiUndefined number = -54321; Double_tfUpFCN+-UP defines errors (for chisquare fits UP=1); Double_tfUpdflt; Double_t*fVERTpp[fMaxpar] array used in mnvert; Double_t*fVERTq[fMaxpar] array used in mnvert; Double_t*fVERTs[fMaxpar] array used in mnvert; Double_t*fVhmat[fMaxpar5] (Internal) error matrix stored as Half MATrix, since it is symmetric; Double_tfVlimhi; Double_tfVlimlo; Double_t*fVthmat[fMaxpar5] VHMAT is sometimes saved in VTHMAT, especially in MNMNOT; TStringfWarmes[100]; Double_t*fWerr[fMaxpar] External parameters error (standard deviation, defined by UP); Double_t*fWord7[fMaxpar] ; Double_t*fX[fMaxpar] Internal parameters values; Double_tfXdircr; Double_tfXmidcr; Double_t*fXpt[fMaxcpt] X array of points for contours; Double_t*fXs[fMaxpar] Internal parameters values saved for fixed params; Double_t*fXt[fMaxpar] Internal parameters values X saved as Xt; Double_t*fXts[fMaxpar] Internal parameters values X saved as Xt for fixed params; Double_tfYdircr; Double_tfYmidcr; Double_t*fYpt[fMaxcpt] Y array of points for contours. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. Class Charts. Inheritance; Inherited Memb",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:28817,Availability,error,error,28817,"er of fixed parameters; Int_tfNstkrd; Int_tfNstkwr; Int_tfNu; Int_t*fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant..); Int_tfNwrmes[2]; TObject*fObjectFitPointer to object being fitted; TStringfOrigin[100]; Double_t*fP[fMaxpar1] ; Double_t*fPARSplist[fMaxpar] array used in mnpars; Double_t*fPSDFs[fMaxpar] array used in mnpsdf; Double_t*fPbar[fMaxpar] ; TObject*fPlotPointer to TGraph object created by mncont; Double_t*fPrho[fMaxpar] Minimum point of parabola; Double_t*fPstar[fMaxpar2] ; Double_t*fPstst[fMaxpar] ; Double_t*fSEEKxbest[fMaxpar] array used in mnseek; Double_t*fSEEKxmid[fMaxpar] array used in mnseek; Double_t*fSIMPy[fMaxpar] array used in mnsimp; Int_tfStatusStatus flag for the last called Minuit function; Double_t*fU[fMaxpar2] External (visible to user in FCN) value of parameters; Double_tfUndefiUndefined number = -54321; Double_tfUpFCN+-UP defines errors (for chisquare fits UP=1); Double_tfUpdflt; Double_t*fVERTpp[fMaxpar] array used in mnvert; Double_t*fVERTq[fMaxpar] array used in mnvert; Double_t*fVERTs[fMaxpar] array used in mnvert; Double_t*fVhmat[fMaxpar5] (Internal) error matrix stored as Half MATrix, since it is symmetric; Double_tfVlimhi; Double_tfVlimlo; Double_t*fVthmat[fMaxpar5] VHMAT is sometimes saved in VTHMAT, especially in MNMNOT; TStringfWarmes[100]; Double_t*fWerr[fMaxpar] External parameters error (standard deviation, defined by UP); Double_t*fWord7[fMaxpar] ; Double_t*fX[fMaxpar] Internal parameters values; Double_tfXdircr; Double_tfXmidcr; Double_t*fXpt[fMaxcpt] X array of points for contours; Double_t*fXs[fMaxpar] Internal parameters values saved for fixed params; Double_t*fXt[fMaxpar] Internal parameters values X saved as Xt; Double_t*fXts[fMaxpar] Internal parameters values X saved as Xt for fixed params; Double_tfYdircr; Double_tfYmidcr; Double_t*fYpt[fMaxcpt] Y array of points for contours. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. Class Charts. Inheritance; Inherited Memb",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:30392,Availability,avail,available,30392,"amed::fTitleobject title. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMinuit(); Minuit normal constructor*-*-*-*-; *-* ========================. TMinuit(Int_t maxpar); Minuit normal constructor*-*-*-*-; *-* ========================. maxpar is the maximum number of parameters used with this TMinuit object. TMinuit(const TMinuit& m); Private TMinuit copy ctor. TMinuit can not be copied. ~TMinuit(); Minuit default destructor*-*-*-*-; *-* =========================. void BuildArrays(Int_t maxpar = 15); -*-*-*Create internal Minuit arrays for the maxpar parameters; *-* =======================================================. TObject * Clone(const char* newname = """") const; Make a clone of an object using the Streamer facility.; Function pointer is copied to Clone. Int_t Command(const char* command); execute a Minuit command; Equivalent to MNEXCM except that the command is given as a; character string.; See TMinuit::mnhelp for the full list of available commands; See also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for; a complete documentation of all the available commands. Returns the status of the execution:; = 0: command executed normally; 1: command is blank, ignored; 2: command line unreadable, ignored; 3: unknown command, ignored; 4: abnormal termination (e.g., MIGRAD not converged); 5: command is a request to read PARAMETER definitions; 6: 'SET INPUT' command; 7: 'SET TITLE' command; 8: 'SET COVAR' command; 9: reserved; 10: END command; 11: EXIT or STOP command; 12: RETURN command. *. TObject * Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); Creates a TGraph object describing the n-sigma contour of a; TMinuit fit. The contour of the parameters pa1 and pa2 is calculated; unsing npoints (>=4) points. The TMinuit status will be; 0 on success and; -1 if errors in the calling sequence (pa1, pa2 not variable); 1 if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:30518,Availability,avail,available,30518,"tion; TMinuit(); Minuit normal constructor*-*-*-*-; *-* ========================. TMinuit(Int_t maxpar); Minuit normal constructor*-*-*-*-; *-* ========================. maxpar is the maximum number of parameters used with this TMinuit object. TMinuit(const TMinuit& m); Private TMinuit copy ctor. TMinuit can not be copied. ~TMinuit(); Minuit default destructor*-*-*-*-; *-* =========================. void BuildArrays(Int_t maxpar = 15); -*-*-*Create internal Minuit arrays for the maxpar parameters; *-* =======================================================. TObject * Clone(const char* newname = """") const; Make a clone of an object using the Streamer facility.; Function pointer is copied to Clone. Int_t Command(const char* command); execute a Minuit command; Equivalent to MNEXCM except that the command is given as a; character string.; See TMinuit::mnhelp for the full list of available commands; See also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for; a complete documentation of all the available commands. Returns the status of the execution:; = 0: command executed normally; 1: command is blank, ignored; 2: command line unreadable, ignored; 3: unknown command, ignored; 4: abnormal termination (e.g., MIGRAD not converged); 5: command is a request to read PARAMETER definitions; 6: 'SET INPUT' command; 7: 'SET TITLE' command; 8: 'SET COVAR' command; 9: reserved; 10: END command; 11: EXIT or STOP command; 12: RETURN command. *. TObject * Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); Creates a TGraph object describing the n-sigma contour of a; TMinuit fit. The contour of the parameters pa1 and pa2 is calculated; unsing npoints (>=4) points. The TMinuit status will be; 0 on success and; -1 if errors in the calling sequence (pa1, pa2 not variable); 1 if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF paramet",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:31245,Availability,error,errors,31245," as a; character string.; See TMinuit::mnhelp for the full list of available commands; See also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for; a complete documentation of all the available commands. Returns the status of the execution:; = 0: command executed normally; 1: command is blank, ignored; 2: command line unreadable, ignored; 3: unknown command, ignored; 4: abnormal termination (e.g., MIGRAD not converged); 5: command is a request to read PARAMETER definitions; 6: 'SET INPUT' command; 7: 'SET TITLE' command; 8: 'SET COVAR' command; 9: reserved; 10: END command; 11: EXIT or STOP command; 12: RETURN command. *. TObject * Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); Creates a TGraph object describing the n-sigma contour of a; TMinuit fit. The contour of the parameters pa1 and pa2 is calculated; unsing npoints (>=4) points. The TMinuit status will be; 0 on success and; -1 if errors in the calling sequence (pa1, pa2 not variable); 1 if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF parameter in Minuit has to set; to n^2. The fcn function has to be set before the routine is called. The TGraph object is created via the interpreter. The user must cast it; to a TGraph*. Note that the TGraph is created with npoints+1 in order to; close the contour (setting last point equal to first point). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:33668,Availability,error,error,33668," who uses the values of those parameters to calculate his function value.; The starting values must be specified by the user.; Later values are determined by Minuit as it searches for the minimum; or performs whatever analysis is requested by the user. Note that this virtual function may be redefined in a class derived from TMinuit.; The default function calls the function specified in SetFCN. Example of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log likelihood.; if (iflag == 3) {; will come here only after the fit is finished.; Perform any final calculations, output fitted data, etc.; }. See concrete examples in TH1::H1FitChisquare, H1FitLikelihood. Int_t FixParameter(Int_t parNo); fix a parameter. Int_t GetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; return parameter value and error. Int_t GetNumFixedPars() const; returns the number of currently fixed parameters. Int_t GetNumFreePars() const; returns the number of currently free parameters. Int_t GetNumPars() const; returns the total number of parameters that have been defined.; (fixed and free). Int_t Migrad(); invokes the MIGRAD minimizer. Int_t Release(Int_t parNo); release a parameter. Int_t SetErrorDef(Double_t up); To get the n-sigma contour the error def parameter ""up"" has to set to n^2. void SetFCN(void (*fcn)(Int_t &, Double_t *, Double_t &f, Double_t *, Int_t)); To set the address of the minimization function*-; *-* ===============================================; *. void SetFCN(void* fcn); To set the address of the minimization function*-; *-* ===============================================; this function is called by CINT instead of the function above; *. Int_t SetPrintLevel(Int_t printLevel = 0); set Minuit print level; printlevel = -1 quiet ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:34101,Availability,error,error,34101," any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log likelihood.; if (iflag == 3) {; will come here only after the fit is finished.; Perform any final calculations, output fitted data, etc.; }. See concrete examples in TH1::H1FitChisquare, H1FitLikelihood. Int_t FixParameter(Int_t parNo); fix a parameter. Int_t GetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; return parameter value and error. Int_t GetNumFixedPars() const; returns the number of currently fixed parameters. Int_t GetNumFreePars() const; returns the number of currently free parameters. Int_t GetNumPars() const; returns the total number of parameters that have been defined.; (fixed and free). Int_t Migrad(); invokes the MIGRAD minimizer. Int_t Release(Int_t parNo); release a parameter. Int_t SetErrorDef(Double_t up); To get the n-sigma contour the error def parameter ""up"" has to set to n^2. void SetFCN(void (*fcn)(Int_t &, Double_t *, Double_t &f, Double_t *, Int_t)); To set the address of the minimization function*-; *-* ===============================================; *. void SetFCN(void* fcn); To set the address of the minimization function*-; *-* ===============================================; this function is called by CINT instead of the function above; *. Int_t SetPrintLevel(Int_t printLevel = 0); set Minuit print level; printlevel = -1 quiet (also suppresse all warnings); = 0 normal; = 1 verbose. void mnamin(); Initialize AMIN*-*-*-*-; *-* ===============; *-*C Called from many places. Initializes the value of AMIN by; *-*C calling the user function. Prints out the function value and; *-*C parameter values if Print Flag value is high enough.; *. void mnbins(Double_t a1, Double_t a2, Int_t naa, Double_t& bl, Double_t& bh, Int_t& nb, Double_t& bwid); -*-*Compute reasonable histogram intervals; *-* ==============",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:37348,Availability,error,errors,37348,"rmally; *-* 1: command is blank, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 5: command is a request to read PARAMETER definitions; *-* 6: 'SET INPUT' command; *-* 7: 'SET TITLE' command; *-* 8: 'SET COVAR' command; *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *. void mncont(Int_t ke1, Int_t ke2, Int_t nptu, Double_t* xptu, Double_t* yptu, Int_t& ierrf); Find points along a contour where FCN is minimum; *-* ================================================; *-* Find NPTU points along a contour where the function; *-* FMIN (X(KE1),X(KE2)) = AMIN+UP; *-* where FMIN is the minimum of FCN with respect to all; *-* the other NPAR-2 variable parameters (if any).; *-* IERRF on return will be equal to the number of points found:; *-* NPTU if normal termination with NPTU points found; *-* -1 if errors in the calling sequence (KE1, KE2 not variable); *-* 0 if less than four points can be found (using MNMNOT); *-* n>3 if only n points can be found (n < NPTU); -; *-* input arguments: parx, pary, devs, ngrid; *; System generated locals. void mncrck(TString crdbuf, Int_t maxcwd, TString& comand, Int_t& lnc, Int_t mxp, Double_t* plist, Int_t& llist, Int_t& ierr, Int_t isyswr); Cracks the free-format input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric fields are put into; *-* the LLIST (but at most MXP) elements of PLIST.; *-* IERR = 0 if no errors,; *-* = 1 if error(s).; -; *; Initialized data. void mncros(Double_t& aopt, Int_t& iercr); Find point where MNEVAL=AMIN+UP*-; *-* ===============================; *-* Find point where MNEVAL=AMIN+UP, along the line through; *-* XMIDCR,YMIDCR with direction XDIRCR,YDIRCR, where X and Y; *-",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:38107,Availability,error,errors,38107,"where FMIN is the minimum of FCN with respect to all; *-* the other NPAR-2 variable parameters (if any).; *-* IERRF on return will be equal to the number of points found:; *-* NPTU if normal termination with NPTU points found; *-* -1 if errors in the calling sequence (KE1, KE2 not variable); *-* 0 if less than four points can be found (using MNMNOT); *-* n>3 if only n points can be found (n < NPTU); -; *-* input arguments: parx, pary, devs, ngrid; *; System generated locals. void mncrck(TString crdbuf, Int_t maxcwd, TString& comand, Int_t& lnc, Int_t mxp, Double_t* plist, Int_t& llist, Int_t& ierr, Int_t isyswr); Cracks the free-format input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric fields are put into; *-* the LLIST (but at most MXP) elements of PLIST.; *-* IERR = 0 if no errors,; *-* = 1 if error(s).; -; *; Initialized data. void mncros(Double_t& aopt, Int_t& iercr); Find point where MNEVAL=AMIN+UP*-; *-* ===============================; *-* Find point where MNEVAL=AMIN+UP, along the line through; *-* XMIDCR,YMIDCR with direction XDIRCR,YDIRCR, where X and Y; *-* are parameters KE1CR and KE2CR. If KE2CR=0 (from MINOS),; *-* only KE1CR is varied. From MNCONT, both are varied.; *-* Crossing point is at; *-* (U(KE1),U(KE2)) = (XMID,YMID) + AOPT*(XDIR,YDIR); -; *. void mncuve(); -*-*-*Makes sure that the current point is a local minimum; *-* ====================================================; *-* Makes sure that the current point is a local; *-* minimum and that the error matrix exists,; *-* or at least something good enough for MINOS and MNCONT; *. void mnderi(); Calculates the first derivatives of FCN (GRD); *-* =============================================; *-* Calculates the first derivatives of FCN (GRD),; *-* either by finite differences or by transfor",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:38127,Availability,error,error,38127,"where FMIN is the minimum of FCN with respect to all; *-* the other NPAR-2 variable parameters (if any).; *-* IERRF on return will be equal to the number of points found:; *-* NPTU if normal termination with NPTU points found; *-* -1 if errors in the calling sequence (KE1, KE2 not variable); *-* 0 if less than four points can be found (using MNMNOT); *-* n>3 if only n points can be found (n < NPTU); -; *-* input arguments: parx, pary, devs, ngrid; *; System generated locals. void mncrck(TString crdbuf, Int_t maxcwd, TString& comand, Int_t& lnc, Int_t mxp, Double_t* plist, Int_t& llist, Int_t& ierr, Int_t isyswr); Cracks the free-format input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric fields are put into; *-* the LLIST (but at most MXP) elements of PLIST.; *-* IERR = 0 if no errors,; *-* = 1 if error(s).; -; *; Initialized data. void mncros(Double_t& aopt, Int_t& iercr); Find point where MNEVAL=AMIN+UP*-; *-* ===============================; *-* Find point where MNEVAL=AMIN+UP, along the line through; *-* XMIDCR,YMIDCR with direction XDIRCR,YDIRCR, where X and Y; *-* are parameters KE1CR and KE2CR. If KE2CR=0 (from MINOS),; *-* only KE1CR is varied. From MNCONT, both are varied.; *-* Crossing point is at; *-* (U(KE1),U(KE2)) = (XMID,YMID) + AOPT*(XDIR,YDIR); -; *. void mncuve(); -*-*-*Makes sure that the current point is a local minimum; *-* ====================================================; *-* Makes sure that the current point is a local; *-* minimum and that the error matrix exists,; *-* or at least something good enough for MINOS and MNCONT; *. void mnderi(); Calculates the first derivatives of FCN (GRD); *-* =============================================; *-* Calculates the first derivatives of FCN (GRD),; *-* either by finite differences or by transfor",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:38814,Availability,error,error,38814,"mat input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric fields are put into; *-* the LLIST (but at most MXP) elements of PLIST.; *-* IERR = 0 if no errors,; *-* = 1 if error(s).; -; *; Initialized data. void mncros(Double_t& aopt, Int_t& iercr); Find point where MNEVAL=AMIN+UP*-; *-* ===============================; *-* Find point where MNEVAL=AMIN+UP, along the line through; *-* XMIDCR,YMIDCR with direction XDIRCR,YDIRCR, where X and Y; *-* are parameters KE1CR and KE2CR. If KE2CR=0 (from MINOS),; *-* only KE1CR is varied. From MNCONT, both are varied.; *-* Crossing point is at; *-* (U(KE1),U(KE2)) = (XMID,YMID) + AOPT*(XDIR,YDIR); -; *. void mncuve(); -*-*-*Makes sure that the current point is a local minimum; *-* ====================================================; *-* Makes sure that the current point is a local; *-* minimum and that the error matrix exists,; *-* or at least something good enough for MINOS and MNCONT; *. void mnderi(); Calculates the first derivatives of FCN (GRD); *-* =============================================; *-* Calculates the first derivatives of FCN (GRD),; *-* either by finite differences or by transforming the user-; *-* supplied derivatives to internal coordinates,; *-* according to whether fISW[2] is zero or one.; *. void mndxdi(Double_t pint, Int_t ipar, Double_t& dxdi); -*-*Calculates the transformation factor between ext/internal values; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:39873,Availability,error,error,39873,"ng good enough for MINOS and MNCONT; *. void mnderi(); Calculates the first derivatives of FCN (GRD); *-* =============================================; *-* Calculates the first derivatives of FCN (GRD),; *-* either by finite differences or by transforming the user-; *-* supplied derivatives to internal coordinates,; *-* according to whether fISW[2] is zero or one.; *. void mndxdi(Double_t pint, Int_t ipar, Double_t& dxdi); -*-*Calculates the transformation factor between ext/internal values; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable paramet",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40192,Availability,error,errors,40192,"coordinates,; *-* according to whether fISW[2] is zero or one.; *. void mndxdi(Double_t pint, Int_t ipar, Double_t& dxdi); -*-*Calculates the transformation factor between ext/internal values; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); In",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40360,Availability,error,errors,40360,"lues; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); Interprets a command and takes appropriate action*-*-; *-* =================================================; *-* either directly by skipping to the corresponding code in; *-* MNEXCM, or by",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40415,Availability,error,error,40415,"lues; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); Interprets a command and takes appropriate action*-*-; *-* =================================================; *-* either directly by skipping to the corresponding code in; *-* MNEXCM, or by",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40427,Availability,error,error,40427,"lues; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); Interprets a command and takes appropriate action*-*-; *-* =================================================; *-* either directly by skipping to the corresponding code in; *-* MNEXCM, or by",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40531,Availability,error,error,40531," *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); Interprets a command and takes appropriate action*-*-; *-* =================================================; *-* either directly by skipping to the corresponding code in; *-* MNEXCM, or by setting up a call to a function; -; *-* recognized MINUIT commands:; *-* obsolete commands:; *-* IERFLG is now (94.5) defined the same as ICO",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:45727,Availability,toler,toler,45727,"MNCALF; *-* and this transformed function is minimized using the simplex; *-* method from several random starting points.; *-* ref. -- Goldstein and Price, Math.Comp. 25, 569 (1971); *. void mninex(Double_t* pint); -*Transforms from internal coordinates (PINT) to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =========================================; *-* along direction STEP, where the length of vector STEP; *-* gives the expected position of minimum.; *-* FSTART is value of function at START; *-* SLOPE (if non-zero) is df/dx along STEP at START; *-* TOLER is initial tolerance of minimum in direction STEP; -; *-* SLAMBG and ALPHA control the maximum individual steps allowed.; *-* The first step is always =1. The max length of second step is SLAMBG.; *-* The max size of subsequent steps is the maximum previous successful; *-* step multiplied by ALPHA + the size of most recent successful step,; *-* but cannot be smaller than SLAMBG.; *. void mnmatu(Int_t kode); Prints the covariance matrix v when KODE=1*-; *-* ==========================================; *-* always prints the global correlations, and; *-* calculates and prints the individual correlation coefficients; *. void mnmigr(); Performs a local function minimization*-; *-* ======================================; *-* Performs a local f",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:46050,Availability,toler,tolerance,46050," to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =========================================; *-* along direction STEP, where the length of vector STEP; *-* gives the expected position of minimum.; *-* FSTART is value of function at START; *-* SLOPE (if non-zero) is df/dx along STEP at START; *-* TOLER is initial tolerance of minimum in direction STEP; -; *-* SLAMBG and ALPHA control the maximum individual steps allowed.; *-* The first step is always =1. The max length of second step is SLAMBG.; *-* The max size of subsequent steps is the maximum previous successful; *-* step multiplied by ALPHA + the size of most recent successful step,; *-* but cannot be smaller than SLAMBG.; *. void mnmatu(Int_t kode); Prints the covariance matrix v when KODE=1*-; *-* ==========================================; *-* always prints the global correlations, and; *-* calculates and prints the individual correlation coefficients; *. void mnmigr(); Performs a local function minimization*-; *-* ======================================; *-* Performs a local function minimization using basically the; *-* method of Davidon-Fletcher-Powell as modified by Fletcher; *-* ref. -- Fletcher, Comp.J. 13,317 (1970) ""switching method""; *. void mnmnos(); Performs a MINOS error analysis*-; *-* ===============================; *",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:46989,Availability,error,error,46989,"ion STEP; -; *-* SLAMBG and ALPHA control the maximum individual steps allowed.; *-* The first step is always =1. The max length of second step is SLAMBG.; *-* The max size of subsequent steps is the maximum previous successful; *-* step multiplied by ALPHA + the size of most recent successful step,; *-* but cannot be smaller than SLAMBG.; *. void mnmatu(Int_t kode); Prints the covariance matrix v when KODE=1*-; *-* ==========================================; *-* always prints the global correlations, and; *-* calculates and prints the individual correlation coefficients; *. void mnmigr(); Performs a local function minimization*-; *-* ======================================; *-* Performs a local function minimization using basically the; *-* method of Davidon-Fletcher-Powell as modified by Fletcher; *-* ref. -- Fletcher, Comp.J. 13,317 (1970) ""switching method""; *. void mnmnos(); Performs a MINOS error analysis*-; *-* ===============================; *-* Performs a MINOS error analysis on those parameters for; *-* which it is requested on the MINOS command by calling; *-* MNMNOT for each parameter requested.; *. void mnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); Performs a MINOS error analysis on one parameter*-*-*-; *-* ================================================; *-* The parameter ILAX is varied, and the minimum of the; *-* function with respect to the other parameters is followed; *-* until it crosses the value FMIN+UP.; *. void mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); Implements one parameter definition*-*-*-; *-* ===================================; *-* Called from MNPARS and user-callable; *-* Implements one parameter definition, that is:; *-* K (external) parameter number; *-* CNAMK parameter name; *-* UK starting value; *-* WK starting step size or uncertainty; *-* A, B lower and upper physical parameter limits; *-* and sets up (updates) the parameter lists.; *-* Output: IERFL",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:47065,Availability,error,error,47065,"ion STEP; -; *-* SLAMBG and ALPHA control the maximum individual steps allowed.; *-* The first step is always =1. The max length of second step is SLAMBG.; *-* The max size of subsequent steps is the maximum previous successful; *-* step multiplied by ALPHA + the size of most recent successful step,; *-* but cannot be smaller than SLAMBG.; *. void mnmatu(Int_t kode); Prints the covariance matrix v when KODE=1*-; *-* ==========================================; *-* always prints the global correlations, and; *-* calculates and prints the individual correlation coefficients; *. void mnmigr(); Performs a local function minimization*-; *-* ======================================; *-* Performs a local function minimization using basically the; *-* method of Davidon-Fletcher-Powell as modified by Fletcher; *-* ref. -- Fletcher, Comp.J. 13,317 (1970) ""switching method""; *. void mnmnos(); Performs a MINOS error analysis*-; *-* ===============================; *-* Performs a MINOS error analysis on those parameters for; *-* which it is requested on the MINOS command by calling; *-* MNMNOT for each parameter requested.; *. void mnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); Performs a MINOS error analysis on one parameter*-*-*-; *-* ================================================; *-* The parameter ILAX is varied, and the minimum of the; *-* function with respect to the other parameters is followed; *-* until it crosses the value FMIN+UP.; *. void mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); Implements one parameter definition*-*-*-; *-* ===================================; *-* Called from MNPARS and user-callable; *-* Implements one parameter definition, that is:; *-* K (external) parameter number; *-* CNAMK parameter name; *-* UK starting value; *-* WK starting step size or uncertainty; *-* A, B lower and upper physical parameter limits; *-* and sets up (updates) the parameter lists.; *-* Output: IERFL",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:47300,Availability,error,error,47300,"; *-* but cannot be smaller than SLAMBG.; *. void mnmatu(Int_t kode); Prints the covariance matrix v when KODE=1*-; *-* ==========================================; *-* always prints the global correlations, and; *-* calculates and prints the individual correlation coefficients; *. void mnmigr(); Performs a local function minimization*-; *-* ======================================; *-* Performs a local function minimization using basically the; *-* method of Davidon-Fletcher-Powell as modified by Fletcher; *-* ref. -- Fletcher, Comp.J. 13,317 (1970) ""switching method""; *. void mnmnos(); Performs a MINOS error analysis*-; *-* ===============================; *-* Performs a MINOS error analysis on those parameters for; *-* which it is requested on the MINOS command by calling; *-* MNMNOT for each parameter requested.; *. void mnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); Performs a MINOS error analysis on one parameter*-*-*-; *-* ================================================; *-* The parameter ILAX is varied, and the minimum of the; *-* function with respect to the other parameters is followed; *-* until it crosses the value FMIN+UP.; *. void mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); Implements one parameter definition*-*-*-; *-* ===================================; *-* Called from MNPARS and user-callable; *-* Implements one parameter definition, that is:; *-* K (external) parameter number; *-* CNAMK parameter name; *-* UK starting value; *-* WK starting step size or uncertainty; *-* A, B lower and upper physical parameter limits; *-* and sets up (updates) the parameter lists.; *-* Output: IERFLG=0 if no problems; *-* >0 if MNPARM unable to implement definition; *. void mnpars(TString& crdbuf, Int_t& icondn); Implements one parameter definition*-*-*-*-*-; *-* =========== =======================; *-* Called from MNREAD and user-callable; *-* Implements one parameter definition, that is:; *-*",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:48490,Availability,error,error,48490,"========================; *-* The parameter ILAX is varied, and the minimum of the; *-* function with respect to the other parameters is followed; *-* until it crosses the value FMIN+UP.; *. void mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); Implements one parameter definition*-*-*-; *-* ===================================; *-* Called from MNPARS and user-callable; *-* Implements one parameter definition, that is:; *-* K (external) parameter number; *-* CNAMK parameter name; *-* UK starting value; *-* WK starting step size or uncertainty; *-* A, B lower and upper physical parameter limits; *-* and sets up (updates) the parameter lists.; *-* Output: IERFLG=0 if no problems; *-* >0 if MNPARM unable to implement definition; *. void mnpars(TString& crdbuf, Int_t& icondn); Implements one parameter definition*-*-*-*-*-; *-* =========== =======================; *-* Called from MNREAD and user-callable; *-* Implements one parameter definition, that is:; *-* parses the string CRDBUF and calls MNPARM; -; *-* output conditions:; *-* ICONDN = 0 all OK; *-* ICONDN = 1 error, attempt to define parameter is ignored; *-* ICONDN = 2 end of parameter definitions; *. void mnpfit(Double_t* parx2p, Double_t* pary2p, Int_t npar2p, Double_t* coef2p, Double_t& sdev2p); To fit a parabola to npar2p points*-; *-* ==================================; *-* npar2p no. of points; *-* parx2p(i) x value of point i; *-* pary2p(i) y value of point i; -; *-* coef2p(1...3) coefficients of the fitted parabola; *-* y=coef2p(1) + coef2p(2)*x + coef2p(3)*x**2; *-* sdev2p= variance; *-* method : chi**2 = min equation solved explicitly; *. void mnpint(Double_t& pexti, Int_t i, Double_t& pinti); Calculates the internal parameter value PINTI*-; *-* =============================================; *-* corresponding to the external value PEXTI for parameter I.; *. void mnplot(Double_t* xpt, Double_t* ypt, char* chpt, Int_t nxypt, Int_t npagwd, Int_t npagln); Plots po",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51099,Availability,error,errors,51099,"hnam, Double_t& val, Double_t& err, Double_t& xlolim, Double_t& xuplim, Int_t& iuint) const; -*Provides the user with information concerning the current status; *-* ================================================================; *-* of parameter number IUEXT. Namely, it returns:; *-* CHNAM: the name of the parameter; *-* VAL: the current (external) value of the parameter; *-* ERR: the current estimate of the parameter uncertainty; *-* XLOLIM: the lower bound (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated dis",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51254,Availability,error,errors,51254,"rns:; *-* CHNAM: the name of the parameter; *-* VAL: the current (external) value of the parameter; *-* ERR: the current estimate of the parameter uncertainty; *-* XLOLIM: the lower bound (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Not",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51284,Availability,error,errors,51284,"rns:; *-* CHNAM: the name of the parameter; *-* VAL: the current (external) value of the parameter; *-* ERR: the current estimate of the parameter uncertainty; *-* XLOLIM: the lower bound (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Not",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51335,Availability,error,errors,51335,"rns:; *-* CHNAM: the name of the parameter; *-* VAL: the current (external) value of the parameter; *-* ERR: the current estimate of the parameter uncertainty; *-* XLOLIM: the lower bound (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Not",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51394,Availability,error,errors,51394,"d (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* ======================",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51408,Availability,error,errors,51408,"d (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* ======================",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:52383,Availability,error,errors,52383,"W[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* =============================================; *-* If IOPT=1,; *-* If IOPT=0, sets only MINOS errors to undefined; *-* Called from MNCLER and whenever problem changes, for example; *-* after SET LIMITS, SET PARAM, CALL FCN 6; *. void mnsave(); -*Writes current parameter values and step sizes onto file ISYSSA; *-* ===============================================================; *-* in format which can be reread by Minuit for restarting.; *-* The covariance matrix is also output if it exists.; *. void mnscan(); Scans the values of FCN as a function of one parameter*-; *-* ======================================================; *-* and plots the resulting values as a curve using MNPLOT.; *-* It may be called to scan one parameter or all parameters.; *-* retains the best function and parameter values found.; *. void mnseek(); -*-*Performs a rough (but global) minimization by monte carlo search; *-* ================================================================; *-* Each time a new minimum is found, the search area is shifted; *-* to be centered at the best value",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:52502,Availability,error,errors,52502,"W[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* =============================================; *-* If IOPT=1,; *-* If IOPT=0, sets only MINOS errors to undefined; *-* Called from MNCLER and whenever problem changes, for example; *-* after SET LIMITS, SET PARAM, CALL FCN 6; *. void mnsave(); -*Writes current parameter values and step sizes onto file ISYSSA; *-* ===============================================================; *-* in format which can be reread by Minuit for restarting.; *-* The covariance matrix is also output if it exists.; *. void mnscan(); Scans the values of FCN as a function of one parameter*-; *-* ======================================================; *-* and plots the resulting values as a curve using MNPLOT.; *-* It may be called to scan one parameter or all parameters.; *-* retains the best function and parameter values found.; *. void mnseek(); -*-*Performs a rough (but global) minimization by monte carlo search; *-* ================================================================; *-* Each time a new minimum is found, the search area is shifted; *-* to be centered at the best value",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56728,Availability,error,errors,56728,"id mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fObjectFit=obj;}. » Author: Rene Brun, Frederick James 12/08/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/minuit:$Id: TMinuit.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56887,Availability,avail,available,56887,"id mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fObjectFit=obj;}. » Author: Rene Brun, Frederick James 12/08/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/minuit:$Id: TMinuit.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:436,Deployability,patch,patch,436,". TMinuit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuit. class TMinuit: public TNamed. The Minimization package*-; -* ======================== ; -* ; -* This package was originally written in Fortran by Fred James ; -* and part of PACKLIB (patch D506) ; -* ; -* It has been converted to a C++ class by R.Brun ; -* The current implementation in C++ is a straightforward conversion ; -* of the original Fortran version: The main changes are: ; -* ; -* - The variables in the various Minuit labelled common blocks ; -* have been changed to the TMinuit class data members. ; -* - The internal arrays with a maximum dimension depending on the ; -* maximum number of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a mu",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:34017,Deployability,release,release,34017,"ample of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log likelihood.; if (iflag == 3) {; will come here only after the fit is finished.; Perform any final calculations, output fitted data, etc.; }. See concrete examples in TH1::H1FitChisquare, H1FitLikelihood. Int_t FixParameter(Int_t parNo); fix a parameter. Int_t GetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; return parameter value and error. Int_t GetNumFixedPars() const; returns the number of currently fixed parameters. Int_t GetNumFreePars() const; returns the number of currently free parameters. Int_t GetNumPars() const; returns the total number of parameters that have been defined.; (fixed and free). Int_t Migrad(); invokes the MIGRAD minimizer. Int_t Release(Int_t parNo); release a parameter. Int_t SetErrorDef(Double_t up); To get the n-sigma contour the error def parameter ""up"" has to set to n^2. void SetFCN(void (*fcn)(Int_t &, Double_t *, Double_t &f, Double_t *, Int_t)); To set the address of the minimization function*-; *-* ===============================================; *. void SetFCN(void* fcn); To set the address of the minimization function*-; *-* ===============================================; this function is called by CINT instead of the function above; *. Int_t SetPrintLevel(Int_t printLevel = 0); set Minuit print level; printlevel = -1 quiet (also suppresse all warnings); = 0 normal; = 1 verbose. void mnamin(); Initialize AMIN*-*-*-*-; *-* ===============; *-*C Called from many places. Initializes the value of AMIN by; *-*C calling the user function. Prints out the function value and; *-*C parameter values if Print Flag value is high enough.; *. void mnbins(Double_t a1, Double_t a2, Int_t naa, Double_t& bl, Double_t& bh, Int_t& nb, D",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:48032,Deployability,update,updates,48032,"ng basically the; *-* method of Davidon-Fletcher-Powell as modified by Fletcher; *-* ref. -- Fletcher, Comp.J. 13,317 (1970) ""switching method""; *. void mnmnos(); Performs a MINOS error analysis*-; *-* ===============================; *-* Performs a MINOS error analysis on those parameters for; *-* which it is requested on the MINOS command by calling; *-* MNMNOT for each parameter requested.; *. void mnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); Performs a MINOS error analysis on one parameter*-*-*-; *-* ================================================; *-* The parameter ILAX is varied, and the minimum of the; *-* function with respect to the other parameters is followed; *-* until it crosses the value FMIN+UP.; *. void mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); Implements one parameter definition*-*-*-; *-* ===================================; *-* Called from MNPARS and user-callable; *-* Implements one parameter definition, that is:; *-* K (external) parameter number; *-* CNAMK parameter name; *-* UK starting value; *-* WK starting step size or uncertainty; *-* A, B lower and upper physical parameter limits; *-* and sets up (updates) the parameter lists.; *-* Output: IERFLG=0 if no problems; *-* >0 if MNPARM unable to implement definition; *. void mnpars(TString& crdbuf, Int_t& icondn); Implements one parameter definition*-*-*-*-*-; *-* =========== =======================; *-* Called from MNREAD and user-callable; *-* Implements one parameter definition, that is:; *-* parses the string CRDBUF and calls MNPARM; -; *-* output conditions:; *-* ICONDN = 0 all OK; *-* ICONDN = 1 error, attempt to define parameter is ignored; *-* ICONDN = 2 end of parameter definitions; *. void mnpfit(Double_t* parx2p, Double_t* pary2p, Int_t npar2p, Double_t* coef2p, Double_t& sdev2p); To fit a parabola to npar2p points*-; *-* ==================================; *-* npar2p no. of points; *-* parx2p(i) x value",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:817,Integrability,depend,depending,817,". TMinuit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuit. class TMinuit: public TNamed. The Minimization package*-; -* ======================== ; -* ; -* This package was originally written in Fortran by Fred James ; -* and part of PACKLIB (patch D506) ; -* ; -* It has been converted to a C++ class by R.Brun ; -* The current implementation in C++ is a straightforward conversion ; -* of the original Fortran version: The main changes are: ; -* ; -* - The variables in the various Minuit labelled common blocks ; -* have been changed to the TMinuit class data members. ; -* - The internal arrays with a maximum dimension depending on the ; -* maximum number of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a mu",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:2249,Integrability,depend,depend,2249,"mber functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice line",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:2474,Integrability,depend,depending,2474,"sses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does r",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:5179,Integrability,depend,depends,5179,"ameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the minimum, this may be because the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.; The minimizer can become blocked at a limit, because at a limit the; derivative seen by the minimizer partial F/partial Pint is zer",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:8684,Integrability,message,messages,8684,"liability of MINUIT error estimates. MINUIT always carries around its own current estimates of the parameter; errors, which it will print out on request, no matter how accurate they; are at any given point in the execution. For example, at initialization,; these estimates are just the starting step sizes as specified by the user.; After a HESSE step, the errors are usually quite accurate,; unless there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9273,Integrability,message,message,9273,"are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; tha",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10453,Integrability,depend,dependence,10453,"s; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11408,Integrability,depend,dependence,11408," the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root o",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:31580,Integrability,rout,routine,31580,"cution:; = 0: command executed normally; 1: command is blank, ignored; 2: command line unreadable, ignored; 3: unknown command, ignored; 4: abnormal termination (e.g., MIGRAD not converged); 5: command is a request to read PARAMETER definitions; 6: 'SET INPUT' command; 7: 'SET TITLE' command; 8: 'SET COVAR' command; 9: reserved; 10: END command; 11: EXIT or STOP command; 12: RETURN command. *. TObject * Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); Creates a TGraph object describing the n-sigma contour of a; TMinuit fit. The contour of the parameters pa1 and pa2 is calculated; unsing npoints (>=4) points. The TMinuit status will be; 0 on success and; -1 if errors in the calling sequence (pa1, pa2 not variable); 1 if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF parameter in Minuit has to set; to n^2. The fcn function has to be set before the routine is called. The TGraph object is created via the interpreter. The user must cast it; to a TGraph*. Note that the TGraph is created with npoints+1 in order to; close the contour (setting last point equal to first point). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and variable) parameters; flag: Indicates what is to be calculated (see example below); grad: array of gradients; Output parameters:; fval: The calculated function value.; grad: The (optional) vector of first derivatives). The meaning of the para",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40171,Integrability,rout,routine,40171,"coordinates,; *-* according to whether fISW[2] is zero or one.; *. void mndxdi(Double_t pint, Int_t ipar, Double_t& dxdi); -*-*Calculates the transformation factor between ext/internal values; *-* =====================================================================; *-* calculates the transformation factor between external and; *-* internal parameter values. this factor is one for; *-* parameters which are not limited. called from MNEMAT.; *. void mneig(Double_t* a, Int_t ndima, Int_t n, Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); In",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:43455,Integrability,interface,interface,43455,"es one or more fixed parameter(s) to variable status*-*-; *-* ==========================================================; *-* Restores one or more fixed parameter(s) to variable status; *-* by inserting it into the internal parameter list at the; *-* appropriate place.; -; *-* K = 0 means restore all parameters; *-* K = 1 means restore the last parameter fixed; *-* K = -I means restore external parameter I (if possible); *-* IQ = fix-location where internal parameters were stored; *-* IR = external number of parameter being restored; *-* IS = internal number of parameter being restored; *. void mngrad(); Interprets the SET GRAD command*-*-*-; *-* ===============================; *-* Called from MNSET; *-* Interprets the SET GRAD command, which informs MINUIT whether; *-* the first derivatives of FCN will be calculated by the user; *-* inside FCN. It can check the user derivative calculation; *-* by comparing it with a finite difference approximation.; *. void mnhelp(const char* command = """"); interface to Minuit help. void mnhelp(TString comd); HELP routine for MINUIT interactive commands*-; *-* ============================================; -; *-* COMD ='*' or """" prints a global help for all commands; *-* COMD =Command_name: print detailed help for one command.; *-* Note that at least 3 characters must be given for the command; *-* name.; -; *-* Author: Rene Brun; *-* comments extracted from the MINUIT documentation file.; -; *. void mnhess(); Calculates the full second-derivative matrix of FCN*-*-; *-* ===================================================; *-* by taking finite differences. When calculating diagonal; *-* elements, it may iterate so that step size is nearly that; *-* which gives function change= UP/10. The first derivatives; *-* of course come as a free side effect, but with a smaller; *-* step size in order to obtain a known accuracy.; *. void mnhes1(); Calculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ================================",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:43513,Integrability,rout,routine,43513,"meter(s) to variable status; *-* by inserting it into the internal parameter list at the; *-* appropriate place.; -; *-* K = 0 means restore all parameters; *-* K = 1 means restore the last parameter fixed; *-* K = -I means restore external parameter I (if possible); *-* IQ = fix-location where internal parameters were stored; *-* IR = external number of parameter being restored; *-* IS = internal number of parameter being restored; *. void mngrad(); Interprets the SET GRAD command*-*-*-; *-* ===============================; *-* Called from MNSET; *-* Interprets the SET GRAD command, which informs MINUIT whether; *-* the first derivatives of FCN will be calculated by the user; *-* inside FCN. It can check the user derivative calculation; *-* by comparing it with a finite difference approximation.; *. void mnhelp(const char* command = """"); interface to Minuit help. void mnhelp(TString comd); HELP routine for MINUIT interactive commands*-; *-* ============================================; -; *-* COMD ='*' or """" prints a global help for all commands; *-* COMD =Command_name: print detailed help for one command.; *-* Note that at least 3 characters must be given for the command; *-* name.; -; *-* Author: Rene Brun; *-* comments extracted from the MINUIT documentation file.; -; *. void mnhess(); Calculates the full second-derivative matrix of FCN*-*-; *-* ===================================================; *-* by taking finite differences. When calculating diagonal; *-* elements, it may iterate so that step size is nearly that; *-* which gives function change= UP/10. The first derivatives; *-* of course come as a free side effect, but with a smaller; *-* step size in order to obtain a known accuracy.; *. void mnhes1(); Calculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ==========================================================; *-* and appropriate step sizes GSTEP; *-* Called from MNHESS and MNGRAD; *. void mnimpr(); Attempts to improve on a good local m",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:45147,Integrability,rout,routines,45147,"s, it may iterate so that step size is nearly that; *-* which gives function change= UP/10. The first derivatives; *-* of course come as a free side effect, but with a smaller; *-* step size in order to obtain a known accuracy.; *. void mnhes1(); Calculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ==========================================================; *-* and appropriate step sizes GSTEP; *-* Called from MNHESS and MNGRAD; *. void mnimpr(); Attempts to improve on a good local minimum*-*-*-; *-* ===========================================; *-* Attempts to improve on a good local minimum by finding a; *-* better one. The quadratic part of FCN is removed by MNCALF; *-* and this transformed function is minimized using the simplex; *-* method from several random starting points.; *-* ref. -- Goldstein and Price, Math.Comp. 25, 569 (1971); *. void mninex(Double_t* pint); -*Transforms from internal coordinates (PINT) to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =========================================; *-* along direction STEP, where the length of vector STEP; *-* gives the expected position of minimum.; *-* FSTART is value of function at START; *-* SLOPE (if non-zero) is df/dx along STEP at START; *-* TOLER is initial tolerance of minimum in direction STEP; -; *-* SLAMB",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:45206,Integrability,rout,routine,45206,"s, it may iterate so that step size is nearly that; *-* which gives function change= UP/10. The first derivatives; *-* of course come as a free side effect, but with a smaller; *-* step size in order to obtain a known accuracy.; *. void mnhes1(); Calculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ==========================================================; *-* and appropriate step sizes GSTEP; *-* Called from MNHESS and MNGRAD; *. void mnimpr(); Attempts to improve on a good local minimum*-*-*-; *-* ===========================================; *-* Attempts to improve on a good local minimum by finding a; *-* better one. The quadratic part of FCN is removed by MNCALF; *-* and this transformed function is minimized using the simplex; *-* method from several random starting points.; *-* ref. -- Goldstein and Price, Math.Comp. 25, 569 (1971); *. void mninex(Double_t* pint); -*Transforms from internal coordinates (PINT) to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =========================================; *-* along direction STEP, where the length of vector STEP; *-* gives the expected position of minimum.; *-* FSTART is value of function at START; *-* SLOPE (if non-zero) is df/dx along STEP at START; *-* TOLER is initial tolerance of minimum in direction STEP; -; *-* SLAMB",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56169,Integrability,message,messages,56169,"t all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() co",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56247,Integrability,message,message,56247,"t all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() co",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56300,Integrability,message,message,56300,"te covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(In",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56373,Integrability,rout,routine,56373,"achine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fO",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56405,Integrability,message,message,56405,"achine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fO",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56485,Integrability,message,message,56485,"d returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fObjectFit=obj;}. » Author: Rene Brun, Frederick James 12/08/95 » Copyright (C) 1995-2000, Rene Brun and Fons Radema",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:56599,Integrability,message,messages,56599,"Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=CMES='SHO', it prints the messages in; *-* the circular buffer, FIFO, and empties the buffer.; *. void mnwerr(); -*Calculates the WERR, external parameter errors; *-* ==============================================; *-* and the global correlation coefficients, to be called; *-* whenever a new covariance matrix is available.; *. TMinuit& operator=(const TMinuit& m). TMethodCall * GetMethodCall() const; {return fMethodCall;}. TObject * GetObjectFit() const; {return fObjectFit;}. Int_t GetMaxIterations() const; {return fMaxIterations;}. TObject * GetPlot() const; {return fPlot;}. Int_t GetStatus() const; {return fStatus;}. void SetGraphicsMode(Bool_t mode = kTRUE); {fGraphicsMode = mode;}. void SetMaxIterations(Int_t maxiter = 500); {fMaxIterations = maxiter;}. void SetObjectFit(TObject* obj); {fObjectFit=obj;}. » Author: Rene Brun, Frederick James 12/08/95 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/minuit:$Id: TMinuit.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:652,Modifiability,variab,variables,652,". TMinuit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuit. class TMinuit: public TNamed. The Minimization package*-; -* ======================== ; -* ; -* This package was originally written in Fortran by Fred James ; -* and part of PACKLIB (patch D506) ; -* ; -* It has been converted to a C++ class by R.Brun ; -* The current implementation in C++ is a straightforward conversion ; -* of the original Fortran version: The main changes are: ; -* ; -* - The variables in the various Minuit labelled common blocks ; -* have been changed to the TMinuit class data members. ; -* - The internal arrays with a maximum dimension depending on the ; -* maximum number of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a mu",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:1519,Modifiability,flexible,flexible,1519,"nt implementation in C++ is a straightforward conversion ; -* of the original Fortran version: The main changes are: ; -* ; -* - The variables in the various Minuit labelled common blocks ; -* have been changed to the TMinuit class data members. ; -* - The internal arrays with a maximum dimension depending on the ; -* maximum number of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisq",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:1926,Modifiability,variab,variables,1926,"mber of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. F",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:2272,Modifiability,variab,variable,2272,"mber functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice line",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:2852,Modifiability,variab,variable,2852,"ed object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4532,Modifiability,variab,variable,4532,"troduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the exis",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:5028,Modifiability,variab,variable-metric,5028,"also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the minimum, this may be because the true; minimum is indeed at a limit, or it may be because the minimizer has; become ``blocked'' at a limit. This may normally happen only if the; parameter is so close to a limit (internal value at an odd multiple of #((pi)/(2)); that MINUIT prints a warning to this effect when it prints; the parameter values.",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:9101,Modifiability,parameteriz,parameterized,9101," there has been a problem. MINUIT, when it prints out error values,; also gives some indication of how reliable it thinks they are. For; example, those marked CURRENT GUESS ERROR are only working values; not to be believed, and APPROXIMATE ERROR means that they have; been calculated but there is reason to believe that they may not be; accurate. If no mitigating adjective is given, then at least MINUIT believes the; errors are accurate, although there is always a small chance that MINUIT; has been fooled. Some visible signs that MINUIT may have been fooled are:. Warning messages produced during the minimization or error analysis.; Failure to find new minimum.; Value of EDM too big (estimated Distance to Minimum).; Correlation coefficients exactly equal to zero, unless some parameters; are known to be uncorrelated with the others.; Correlation coefficients very close to one (greater than 0.99). This; indicates both an exceptionally difficult problem, and one which has been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10406,Modifiability,parameteriz,parameterization,10406,"s; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10691,Modifiability,parameteriz,parameterization,10691,"of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of e",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:11784,Modifiability,variab,variables,11784," inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly scaled (not all of the same order of magnitude),; and correlations are also large. In any case, whether the; non-positive-definiteness is real or only numerical is largely irrelevant,; since in both cases the error matrix will be unreliable and the minimum; suspicious. An ill-posed problem:. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the following:. Excessive numerical roundoff:. Be especially careful of exponential and factorial functions which get big; very quickly and lose accuracy. Starting too far from the solution:. The function may have unphysical local minima, especially at infinity in; some variables.; Minuit parameter errors in the presence of limits; This concerns the way Minuit reports the symmetric (or parabolic) errors; on parameters. It does not apply to the errors reported from Minos, which; are in general asymmetric. The symmetric errors reported by Minuit are always calculated from; the covariance matrix, assuming that this matrix has been calculated,; usually as the result of a Migrad minimization or a direct; calculation by Hesse which inverts the second derivative matrix. When there are no limits on the parameter in question, the error reported; by Minuit should therefore be exactly equal to the square root of the; corresponding diagonal element of the error matrix reported by Minuit. However, when there are limits on the parameter, there is a transformation; between the internal parameter values seen by Minuit (which are unbounded); and the external parameter values seen by the user in FCN (which remain; inside the desired l",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:27074,Modifiability,variab,variable,27074,"dInput unit; Int_tfIsyssa; Int_tfIsyswrstandard output unit; Int_tfItaur; Int_tfKe1cr; Int_tfKe2cr; Bool_tfLimsettrue if a parameter is up against limits (for MINOS); Bool_tfLnewmntrue if the previous process has unexpectedly improved FCN; Bool_tfLnolimtrue if there are no limits on any parameters (not yet used); Bool_tfLpheadtrue if a heading should be put out for the next parameter definition; Bool_tfLreportrue if exceptional conditions are put out (default=false); Bool_tfLwarntrue if warning messges are to be put out (default=true); Double_t*fMATUvline[fMaxpar] array used in mnmatu; Double_t*fMIGRflnu[fMaxpar] array used in mnmigr; Double_t*fMIGRgs[fMaxpar] array used in mnmigr; Double_t*fMIGRstep[fMaxpar] array used in mnmigr; Double_t*fMIGRvg[fMaxpar] array used in mnmigr; Double_t*fMIGRxxs[fMaxpar] array used in mnmigr; Double_t*fMNOTgcc[fMaxpar] array used in mnmnot; Double_t*fMNOTw[fMaxpar] array used in mnmnot; Double_t*fMNOTxdev[fMaxpar] array used in mnmnot; Int_tfMaxIterationsMaximum number of iterations; Int_tfMaxcpt; Int_tfMaxextMaximum number of external parameters; Int_tfMaxintMaximum number of internal parameters; Int_tfMaxparMaximum number of parameters; Int_tfMaxpar1fMaxpar*(fMaxpar+1); Int_tfMaxpar2fMaxpar*fMaxpar; Int_tfMaxpar5fMaxpar*(fMaxpar+1)/2; TMethodCall*fMethodCallPointer to MethodCall in case of interpreted function; Int_tfNblockNumber of Minuit data blocks; Int_tfNewpag; Int_t*fNexofi[fMaxpar] External parameters number for currently variable parameters; Int_tfNfcnNumber of calls to FCN; Int_tfNfcnfr; Int_tfNfcnlc; Int_tfNfcnmxMaximum number of calls to FCN; Int_tfNfcwar[20]; Int_t*fNiofex[fMaxpar2] Internal parameters number, or zero if not currently variable; Int_tfNpaglnNumber of lines per page; Int_tfNpagwdPage width; Int_tfNparNumber of free parameters (total number of pars = fNpar + fNfix); Int_tfNpfixNumber of fixed parameters; Int_tfNstkrd; Int_tfNstkwr; Int_tfNu; Int_t*fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant.",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:27296,Modifiability,variab,variable,27296,"dInput unit; Int_tfIsyssa; Int_tfIsyswrstandard output unit; Int_tfItaur; Int_tfKe1cr; Int_tfKe2cr; Bool_tfLimsettrue if a parameter is up against limits (for MINOS); Bool_tfLnewmntrue if the previous process has unexpectedly improved FCN; Bool_tfLnolimtrue if there are no limits on any parameters (not yet used); Bool_tfLpheadtrue if a heading should be put out for the next parameter definition; Bool_tfLreportrue if exceptional conditions are put out (default=false); Bool_tfLwarntrue if warning messges are to be put out (default=true); Double_t*fMATUvline[fMaxpar] array used in mnmatu; Double_t*fMIGRflnu[fMaxpar] array used in mnmigr; Double_t*fMIGRgs[fMaxpar] array used in mnmigr; Double_t*fMIGRstep[fMaxpar] array used in mnmigr; Double_t*fMIGRvg[fMaxpar] array used in mnmigr; Double_t*fMIGRxxs[fMaxpar] array used in mnmigr; Double_t*fMNOTgcc[fMaxpar] array used in mnmnot; Double_t*fMNOTw[fMaxpar] array used in mnmnot; Double_t*fMNOTxdev[fMaxpar] array used in mnmnot; Int_tfMaxIterationsMaximum number of iterations; Int_tfMaxcpt; Int_tfMaxextMaximum number of external parameters; Int_tfMaxintMaximum number of internal parameters; Int_tfMaxparMaximum number of parameters; Int_tfMaxpar1fMaxpar*(fMaxpar+1); Int_tfMaxpar2fMaxpar*fMaxpar; Int_tfMaxpar5fMaxpar*(fMaxpar+1)/2; TMethodCall*fMethodCallPointer to MethodCall in case of interpreted function; Int_tfNblockNumber of Minuit data blocks; Int_tfNewpag; Int_t*fNexofi[fMaxpar] External parameters number for currently variable parameters; Int_tfNfcnNumber of calls to FCN; Int_tfNfcnfr; Int_tfNfcnlc; Int_tfNfcnmxMaximum number of calls to FCN; Int_tfNfcwar[20]; Int_t*fNiofex[fMaxpar2] Internal parameters number, or zero if not currently variable; Int_tfNpaglnNumber of lines per page; Int_tfNpagwdPage width; Int_tfNparNumber of free parameters (total number of pars = fNpar + fNfix); Int_tfNpfixNumber of fixed parameters; Int_tfNstkrd; Int_tfNstkwr; Int_tfNu; Int_t*fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant.",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:31290,Modifiability,variab,variable,31290," as a; character string.; See TMinuit::mnhelp for the full list of available commands; See also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for; a complete documentation of all the available commands. Returns the status of the execution:; = 0: command executed normally; 1: command is blank, ignored; 2: command line unreadable, ignored; 3: unknown command, ignored; 4: abnormal termination (e.g., MIGRAD not converged); 5: command is a request to read PARAMETER definitions; 6: 'SET INPUT' command; 7: 'SET TITLE' command; 8: 'SET COVAR' command; 9: reserved; 10: END command; 11: EXIT or STOP command; 12: RETURN command. *. TObject * Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); Creates a TGraph object describing the n-sigma contour of a; TMinuit fit. The contour of the parameters pa1 and pa2 is calculated; unsing npoints (>=4) points. The TMinuit status will be; 0 on success and; -1 if errors in the calling sequence (pa1, pa2 not variable); 1 if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF parameter in Minuit has to set; to n^2. The fcn function has to be set before the routine is called. The TGraph object is created via the interpreter. The user must cast it; to a TGraph*. Note that the TGraph is created with npoints+1 in order to; close the contour (setting last point equal to first point). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:32277,Modifiability,variab,variable,32277," if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF parameter in Minuit has to set; to n^2. The fcn function has to be set before the routine is called. The TGraph object is created via the interpreter. The user must cast it; to a TGraph*. Note that the TGraph is created with npoints+1 in order to; close the contour (setting last point equal to first point). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and variable) parameters; flag: Indicates what is to be calculated (see example below); grad: array of gradients; Output parameters:; fval: The calculated function value.; grad: The (optional) vector of first derivatives). The meaning of the parameters par is of course defined by the user,; who uses the values of those parameters to calculate his function value.; The starting values must be specified by the user.; Later values are determined by Minuit as it searches for the minimum; or performs whatever analysis is requested by the user. Note that this virtual function may be redefined in a class derived from TMinuit.; The default function calls the function specified in SetFCN. Example of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log li",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:32326,Modifiability,variab,variable,32326," if less than four points can be found; 2 if npoints<4; n>3 if only n points can be found (n < npoints); The status can be obtained via TMinuit::GetStatus(). To get the n-sigma contour the ERRDEF parameter in Minuit has to set; to n^2. The fcn function has to be set before the routine is called. The TGraph object is created via the interpreter. The user must cast it; to a TGraph*. Note that the TGraph is created with npoints+1 in order to; close the contour (setting last point equal to first point). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and variable) parameters; flag: Indicates what is to be calculated (see example below); grad: array of gradients; Output parameters:; fval: The calculated function value.; grad: The (optional) vector of first derivatives). The meaning of the parameters par is of course defined by the user,; who uses the values of those parameters to calculate his function value.; The starting values must be specified by the user.; Later values are determined by Minuit as it searches for the minimum; or performs whatever analysis is requested by the user. Note that this virtual function may be redefined in a class derived from TMinuit.; The default function calls the function specified in SetFCN. Example of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log li",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:35946,Modifiability,variab,variables,35946,"ble_t& bl, Double_t& bh, Int_t& nb, Double_t& bwid); -*-*Compute reasonable histogram intervals; *-* ======================================; *-* Function TO DETERMINE REASONABLE HISTOGRAM INTERVALS; *-* GIVEN ABSOLUTE UPPER AND LOWER BOUNDS A1 AND A2; *-* AND DESIRED MAXIMUM NUMBER OF BINS NAA; *-* PROGRAM MAKES REASONABLE BINNING FROM BL TO BH OF WIDTH BWID; *-* F. JAMES, AUGUST, 1974 , stolen for Minuit, 1988; *. void mncalf(Double_t* pvec, Double_t& ycalf); Transform FCN to find further minima; *-* ====================================; *-* Called only from MNIMPR. Transforms the function FCN; *-* by dividing out the quadratic part in order to find further; *-* minima. Calculates ycalf = (f-fmin)/(x-xmin)*v*(x-xmin); *. void mncler(); -*-*-*Resets the parameter list to UNDEFINED; *-* ======================================; *-* Called from MINUIT and by option from MNEXCM; *. void mncntr(Int_t ke1, Int_t ke2, Int_t& ierrf); Print function contours in two variables, on line printer; *-* =========================================================; -; *-* input arguments: parx, pary, devs, ngrid; *. void mncomd(const char* crdbin, Int_t& icondn); -*Reads a command string and executes; *-* ===================================; *-* Called by user. 'Reads' a command string and executes.; *-* Equivalent to MNEXCM except that the command is given as a; *-* character string.; -; *-* ICONDN = 0: command executed normally; *-* 1: command is blank, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 5: command is a request to read PARAMETER definitions; *-* 6: 'SET INPUT' command; *-* 7: 'SET TITLE' command; *-* 8: 'SET COVAR' command; *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *. void mncont(Int_t ke1, Int_t ke2, Int_t nptu, Double_t* xptu, Double_t* yptu, Int_t& ierrf); Find points along a contour where FCN is minimum; *-* =============",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:37186,Modifiability,variab,variable,37186,"====================; -; *-* input arguments: parx, pary, devs, ngrid; *. void mncomd(const char* crdbin, Int_t& icondn); -*Reads a command string and executes; *-* ===================================; *-* Called by user. 'Reads' a command string and executes.; *-* Equivalent to MNEXCM except that the command is given as a; *-* character string.; -; *-* ICONDN = 0: command executed normally; *-* 1: command is blank, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 5: command is a request to read PARAMETER definitions; *-* 6: 'SET INPUT' command; *-* 7: 'SET TITLE' command; *-* 8: 'SET COVAR' command; *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *. void mncont(Int_t ke1, Int_t ke2, Int_t nptu, Double_t* xptu, Double_t* yptu, Int_t& ierrf); Find points along a contour where FCN is minimum; *-* ================================================; *-* Find NPTU points along a contour where the function; *-* FMIN (X(KE1),X(KE2)) = AMIN+UP; *-* where FMIN is the minimum of FCN with respect to all; *-* the other NPAR-2 variable parameters (if any).; *-* IERRF on return will be equal to the number of points found:; *-* NPTU if normal termination with NPTU points found; *-* -1 if errors in the calling sequence (KE1, KE2 not variable); *-* 0 if less than four points can be found (using MNMNOT); *-* n>3 if only n points can be found (n < NPTU); -; *-* input arguments: parx, pary, devs, ngrid; *; System generated locals. void mncrck(TString crdbuf, Int_t maxcwd, TString& comand, Int_t& lnc, Int_t mxp, Double_t* plist, Int_t& llist, Int_t& ierr, Int_t isyswr); Cracks the free-format input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric f",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:37393,Modifiability,variab,variable,37393,"rmally; *-* 1: command is blank, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 5: command is a request to read PARAMETER definitions; *-* 6: 'SET INPUT' command; *-* 7: 'SET TITLE' command; *-* 8: 'SET COVAR' command; *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *. void mncont(Int_t ke1, Int_t ke2, Int_t nptu, Double_t* xptu, Double_t* yptu, Int_t& ierrf); Find points along a contour where FCN is minimum; *-* ================================================; *-* Find NPTU points along a contour where the function; *-* FMIN (X(KE1),X(KE2)) = AMIN+UP; *-* where FMIN is the minimum of FCN with respect to all; *-* the other NPAR-2 variable parameters (if any).; *-* IERRF on return will be equal to the number of points found:; *-* NPTU if normal termination with NPTU points found; *-* -1 if errors in the calling sequence (KE1, KE2 not variable); *-* 0 if less than four points can be found (using MNMNOT); *-* n>3 if only n points can be found (n < NPTU); -; *-* input arguments: parx, pary, devs, ngrid; *; System generated locals. void mncrck(TString crdbuf, Int_t maxcwd, TString& comand, Int_t& lnc, Int_t mxp, Double_t* plist, Int_t& llist, Int_t& ierr, Int_t isyswr); Cracks the free-format input*-; *-* ============================; *-* Cracks the free-format input, expecting zero or more; *-* alphanumeric fields (which it joins into COMAND(1:LNC)); *-* followed by one or more numeric fields separated by; *-* blanks and/or one comma. The numeric fields are put into; *-* the LLIST (but at most MXP) elements of PLIST.; *-* IERR = 0 if no errors,; *-* = 1 if error(s).; -; *; Initialized data. void mncros(Double_t& aopt, Int_t& iercr); Find point where MNEVAL=AMIN+UP*-; *-* ===============================; *-* Find point where MNEVAL=AMIN+UP, along the line through; *-* XMIDCR,YMIDCR with direction XDIRCR,YDIRCR, where X and Y; *-",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:40843,Modifiability,variab,variable,40843,"t_t& ifault); Compute matrix eigen values*-; *-* ===========================; System generated locals. void mnemat(Double_t* emat, Int_t ndim); Calculates the external error matrix from the internal matrix. Note that if the matrix is declared like Double_t matrix[5][5]; in the calling program, one has to call mnemat with, eg; gMinuit->mnemat(&matrix[0][0],5);. void mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); Utility routine to get MINOS errors*-; *-* ===================================; *-* Called by user.; *-* NUMBER is the parameter number; *-* values returned by MNERRS:; *-* EPLUS, EMINUS are MINOS errors of parameter NUMBER,; *-* EPARAB is 'parabolic' error (from error matrix).; *-* (Errors not calculated are set = 0); *-* GCC is global correlation coefficient from error matrix; *. void mneval(Double_t anext, Double_t& fnext, Int_t& ierev); Evaluates the function being analyzed by MNCROS*-; *-* ===============================================; *-* Evaluates the function being analyzed by MNCROS, which is; *-* generally the minimum of FCN with respect to all remaining; *-* variable parameters. The class data members contains the; *-* data necessary to know the values of U(KE1CR) and U(KE2CR); *-* to be used, namely U(KE1CR) = XMIDCR + ANEXT*XDIRCR; *-* and (if KE2CR .NE. 0) U(KE2CR) = YMIDCR + ANEXT*YDIRCR; *. void mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); Interprets a command and takes appropriate action*-*-; *-* =================================================; *-* either directly by skipping to the corresponding code in; *-* MNEXCM, or by setting up a call to a function; -; *-* recognized MINUIT commands:; *-* obsolete commands:; *-* IERFLG is now (94.5) defined the same as ICONDN in MNCOMD; *-* = 0: command executed normally; *-* 1: command is blank, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not conver",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:42484,Modifiability,variab,variable,42484,"k, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *-* see also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for the possible list; *-* of all Minuit commands; -; *. void mnexin(Double_t* pint); -*-*Transforms the external parameter values U to internal values; *-* =============================================================; *-* Transforms the external parameter values U to internal; *-* values in the dense array PINT.; *. void mnfixp(Int_t iint, Int_t& ierr); -*-*-*-*Removes parameter IINT from the internal parameter list; *-* =======================================================; *-* and arranges the rest of the list to fill the hole.; *. void mnfree(Int_t k); Restores one or more fixed parameter(s) to variable status*-*-; *-* ==========================================================; *-* Restores one or more fixed parameter(s) to variable status; *-* by inserting it into the internal parameter list at the; *-* appropriate place.; -; *-* K = 0 means restore all parameters; *-* K = 1 means restore the last parameter fixed; *-* K = -I means restore external parameter I (if possible); *-* IQ = fix-location where internal parameters were stored; *-* IR = external number of parameter being restored; *-* IS = internal number of parameter being restored; *. void mngrad(); Interprets the SET GRAD command*-*-*-; *-* ===============================; *-* Called from MNSET; *-* Interprets the SET GRAD command, which informs MINUIT whether; *-* the first derivatives of FCN will be calculated by the user; *-* inside FCN. It can check the user derivative calculation; *-* by comparing it with a finite difference approximation.; *. void mnhelp(const char* command = """"); interface to Minuit help. void mnhelp(TString comd); HELP routine for MINUIT interactive commands*-; *-* =======",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:42616,Modifiability,variab,variable,42616,"k, ignored; *-* 2: command line unreadable, ignored; *-* 3: unknown command, ignored; *-* 4: abnormal termination (e.g., MIGRAD not converged); *-* 9: reserved; *-* 10: END command; *-* 11: EXIT or STOP command; *-* 12: RETURN command; -; *-* see also http://wwwasdoc.web.cern.ch/wwwasdoc/minuit/node18.html for the possible list; *-* of all Minuit commands; -; *. void mnexin(Double_t* pint); -*-*Transforms the external parameter values U to internal values; *-* =============================================================; *-* Transforms the external parameter values U to internal; *-* values in the dense array PINT.; *. void mnfixp(Int_t iint, Int_t& ierr); -*-*-*-*Removes parameter IINT from the internal parameter list; *-* =======================================================; *-* and arranges the rest of the list to fill the hole.; *. void mnfree(Int_t k); Restores one or more fixed parameter(s) to variable status*-*-; *-* ==========================================================; *-* Restores one or more fixed parameter(s) to variable status; *-* by inserting it into the internal parameter list at the; *-* appropriate place.; -; *-* K = 0 means restore all parameters; *-* K = 1 means restore the last parameter fixed; *-* K = -I means restore external parameter I (if possible); *-* IQ = fix-location where internal parameters were stored; *-* IR = external number of parameter being restored; *-* IS = internal number of parameter being restored; *. void mngrad(); Interprets the SET GRAD command*-*-*-; *-* ===============================; *-* Called from MNSET; *-* Interprets the SET GRAD command, which informs MINUIT whether; *-* the first derivatives of FCN will be calculated by the user; *-* inside FCN. It can check the user derivative calculation; *-* by comparing it with a finite difference approximation.; *. void mnhelp(const char* command = """"); interface to Minuit help. void mnhelp(TString comd); HELP routine for MINUIT interactive commands*-; *-* =======",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:50564,Modifiability,variab,variable,50564,"xes*-; *-* ===========================================================; *-* NXYPT is the number of points to be plotted; *-* XPT(I) = x-coord. of ith point; *-* YPT(I) = y-coord. of ith point; *-* CHPT(I) = character to be plotted at this position; *-* the input point arrays XPT, YPT, CHPT are destroyed.; -; -; *-* If fGraphicsmode is true (default), a TGraph object is produced; *-* via the Plug-in handler. To get the plot, you can do:; *-* TGraph *gr = (TGraph*)gMinuit->GetPlot();; *-* gr->Draw(""al"");; -; *. void mnpout(Int_t iuext, TString& chnam, Double_t& val, Double_t& err, Double_t& xlolim, Double_t& xuplim, Int_t& iuint) const; -*Provides the user with information concerning the current status; *-* ================================================================; *-* of parameter number IUEXT. Namely, it returns:; *-* CHNAM: the name of the parameter; *-* VAL: the current (external) value of the parameter; *-* ERR: the current estimate of the parameter uncertainty; *-* XLOLIM: the lower bound (or zero if no limits); *-* XUPLIM: the upper bound (or zero if no limits); *-* IUINT: the internal parameter number (or zero if not variable,; *-* or negative if undefined).; *-* Note also: If IUEXT is negative, then it is -internal parameter; *-* number, and IUINT is returned as the EXTERNAL number.; *-* Except for IUINT, this is exactly the inverse of MNPARM; *-* User-called; *. void mnprin(Int_t inkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:52048,Modifiability,portab,portable,52048,"m, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* =============================================; *-* If IOPT=1,; *-* If IOPT=0, sets only MINOS errors to undefined; *-* Called from MNCLER and whenever problem changes, for example; *-* after SET LIMITS, SET PARAM, CALL FCN 6; *. void mnsave(); -*Writes current parameter values and step sizes onto file ISYSSA; *-* ===============================================================; *-* in format which can be reread by Minuit for restarting.; *-* The covariance matrix is also output if it exists.; *. void mnscan(); Scans the values of FCN as a function of one parameter*-; *-* ======================================================; *-* and plots the resulting values as a curve ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:54988,Modifiability,variab,variable,54988,"================================; *-* Called from MNEXCM; *-* file characteristics for SET INPUT; *-* 'SET ' or 'SHOW', 'ON ' or 'OFF', 'SUPPRESSED' or 'REPORTED '; *-* explanation of print level numbers -1:3 and strategies 0:2; *-* identification of debug options; *-* things that can be set or shown; *-* options not intended for normal users; *. void mnsimp(); Minimization using the simplex method of Nelder and Mead; *-* ========================================================; *-* Performs a minimization using the simplex method of Nelder; *-* and Mead (ref. -- Comp. J. 7,308 (1965)).; *. void mnstat(Double_t& fmin, Double_t& fedm, Double_t& errdef, Int_t& npari, Int_t& nparx, Int_t& istat); Returns concerning the current status of the minimization; *-* =========================================================; *-* User-called; *-* Namely, it returns:; *-* FMIN: the best function value found so far; *-* FEDM: the estimated vertical distance remaining to minimum; *-* ERRDEF: the value of UP defining parameter uncertainties; *-* NPARI: the number of currently variable parameters; *-* NPARX: the highest (external) parameter number defined by user; *-* ISTAT: a status integer indicating how good is the covariance; *-* matrix: 0= not calculated at all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symm",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4771,Performance,perform,perform,4771,"value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:4785,Performance,perform,perform,4785,"value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. Users should however; realize that the transformation is only a linear approximation, and that; it cannot give a meaningful result if one or more parameters is very close; to a limit, where partial Pext /partial Pint #0. Therefore, it is; recommended that:. Limits on variable parameters should be used only when needed in order; to prevent the parameter from taking on unphysical values.; When a satisfactory minimum has been found using limits, the limits; should then be removed if possible, in order to perform or re-perform the; error analysis without limits. How to get the right answer from MINUIT. MINUIT offers the user a choice of several minimization algorithms. The; MIGRAD algorithm is in general the best minimizer for; nearly all functions. It is a variable-metric method with inexact line; search, a stable metric updating scheme, and checks for; positive-definiteness. Its main weakness is that it depends heavily on; knowledge of the first derivatives, and fails miserably if they are very; inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. Getting the right minimum with limits. If MIGRAD converges normally to a point where no parameter is near one of; its limits, then the existence of limits has probably not prevented MINUIT; from finding the right minimum. On the other hand, if one or more; parameters is near its limit at the",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:32813,Performance,perform,performs,32813,"int). You can find an example in $ROOTSYS/tutorials/fit/fitcont.C. Int_t DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); Define a parameter. void DeleteArrays(); -*-*-*Delete internal Minuit arrays; *-* =============================. Int_t Eval(Int_t npar, Double_t* grad, Double_t& fval, Double_t* par, Int_t flag); Evaluate the minimisation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and variable) parameters; flag: Indicates what is to be calculated (see example below); grad: array of gradients; Output parameters:; fval: The calculated function value.; grad: The (optional) vector of first derivatives). The meaning of the parameters par is of course defined by the user,; who uses the values of those parameters to calculate his function value.; The starting values must be specified by the user.; Later values are determined by Minuit as it searches for the minimum; or performs whatever analysis is requested by the user. Note that this virtual function may be redefined in a class derived from TMinuit.; The default function calls the function specified in SetFCN. Example of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log likelihood.; if (iflag == 3) {; will come here only after the fit is finished.; Perform any final calculations, output fitted data, etc.; }. See concrete examples in TH1::H1FitChisquare, H1FitLikelihood. Int_t FixParameter(Int_t parNo); fix a parameter. Int_t GetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; return parameter value and error. Int_t GetNumFixedPars() const; returns the number of currently fixed parameters. Int_t GetNumFreePars() const; returns the numb",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:55592,Performance,optimiz,optimizer,55592,"nt_t& npari, Int_t& nparx, Int_t& istat); Returns concerning the current status of the minimization; *-* =========================================================; *-* User-called; *-* Namely, it returns:; *-* FMIN: the best function value found so far; *-* FEDM: the estimated vertical distance remaining to minimum; *-* ERRDEF: the value of UP defining parameter uncertainties; *-* NPARI: the number of currently variable parameters; *-* NPARX: the highest (external) parameter number defined by user; *-* ISTAT: a status integer indicating how good is the covariance; *-* matrix: 0= not calculated at all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:3335,Safety,avoid,avoided,3335,"or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does require some computer time, so it slows down the; computation a little bit, and more importantly, it introduces additional; numerical inaccuracy into the problem in addition to what is introduced in; the numerical calculation of the FCN value. The effects of; non-linearity and numerical roundoff both become more important as the; external value gets closer to one of the limits (expressed as the distance; to nearest limit divided by distance between limits). The user must; therefore be aware of the fact that, for example, if he puts limits of; (0,10^10 ) on a parameter, then the values 0.0 and 1. 0 will be; indistinguishable to the accuracy of most machines. The transformation also affects the parameter error matrix, of course, so; MINUIT does a transformation of the error matrix (and the ``parabolic''; parameter errors) when there are parameter limits. U",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:10146,Safety,recover,recovers,10146,"s been; badly parameterized so that individual errors are not very meaningful; because they are so highly correlated.; Parameter at limit. This condition, signalled by a MINUIT warning; message, may make both the function minimum and parameter errors; unreliable. See the discussion above ``Getting the right parameter errors; with limits''. The best way to be absolutely sure of the errors, is to use; ``independent'' calculations and compare them, or compare the calculated; errors with a picture of the function. Theoretically, the covariance; matrix for a ``physical'' function must be positive-definite at the; minimum, although it may not be so for all points far away from the; minimum, even for a well-determined physical problem. Therefore, if MIGRAD; reports that it has found a non-positive-definite covariance matrix, this; may be a sign of one or more of the following:. A non-physical region:. On its way to the minimum, MIGRAD may have traversed a region which has; unphysical behaviour, which is of course not a serious problem as long as; it recovers and leaves such a region. An underdetermined problem:. If the matrix is not positive-definite even at the minimum, this may mean; that the solution is not well-defined, for example that there are more; unknowns than there are data points, or that the parameterization of the; fit contains a linear dependence. If this is the case, then MINUIT (or any; other program) cannot solve your problem uniquely, and the error matrix; will necessarily be largely meaningless, so the user must remove the; underdeterminedness by reformulating the parameterization. MINUIT cannot; do this itself. Numerical inaccuracies:. It is possible that the apparent lack of positive-definiteness is in fact; only due to excessive roundoff errors in numerical calculations in the; user function or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or if; ; the parameters are badly",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:55562,Safety,safe,safely,55562,"nt_t& npari, Int_t& nparx, Int_t& istat); Returns concerning the current status of the minimization; *-* =========================================================; *-* User-called; *-* Namely, it returns:; *-* FMIN: the best function value found so far; *-* FEDM: the estimated vertical distance remaining to minimum; *-* ERRDEF: the value of UP defining parameter uncertainties; *-* NPARI: the number of currently variable parameters; *-* NPARX: the highest (external) parameter number defined by user; *-* ISTAT: a status integer indicating how good is the covariance; *-* matrix: 0= not calculated at all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To find the machine precision*-*-*-*-*-*-*-; *-* =============================; *-* Compares its argument with the value 1.0, and returns; *-* the value .TRUE. if they are equal. To find EPSMAC; *-* safely by foiling the Fortran optimizer; *. Bool_t mnunpt(TString& cfname); -*-*Returns .TRUE. if CFNAME contains unprintable characters; *-* ========================================================; *. void mnvert(Double_t* a, Int_t l, Int_t m, Int_t n, Int_t& ifail); Inverts a symmetric matrix*-; *-* ==========================; *-* inverts a symmetric matrix. matrix is first scaled to; *-* have all ones on the diagonal (equivalent to change of units); *-* but no pivoting is done since matrix is positive-definite.; *. void mnwarn(const char* copt, const char* corg, const char* cmes); Prints Warning messages*-*-; *-* =======================; *-* If COPT='W', CMES is a WARning message from CORG.; *-* If COPT='D', CMES is a DEBug message from CORG.; *-* If SET WARnings is in effect (the default), this routine; *-* prints the warning message CMES coming from CORG.; *-* If SET NOWarnings is in effect, the warning message is; *-* stored in a circular buffer of length kMAXMES.; *-* If called with CORG=",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:33296,Testability,log,log,33296,"sation function; Input parameters:; npar: number of currently variable parameters; par: array of (constant and variable) parameters; flag: Indicates what is to be calculated (see example below); grad: array of gradients; Output parameters:; fval: The calculated function value.; grad: The (optional) vector of first derivatives). The meaning of the parameters par is of course defined by the user,; who uses the values of those parameters to calculate his function value.; The starting values must be specified by the user.; Later values are determined by Minuit as it searches for the minimum; or performs whatever analysis is requested by the user. Note that this virtual function may be redefined in a class derived from TMinuit.; The default function calls the function specified in SetFCN. Example of Minimisation function:. if (flag == 1) {; read input data,; calculate any necessary constants, etc.; }; if (flag == 2) {; calculate GRAD, the first derivatives of FVAL; (this is optional); }; Always calculate the value of the function, FVAL,; which is usually a chisquare or log likelihood.; if (iflag == 3) {; will come here only after the fit is finished.; Perform any final calculations, output fitted data, etc.; }. See concrete examples in TH1::H1FitChisquare, H1FitLikelihood. Int_t FixParameter(Int_t parNo); fix a parameter. Int_t GetParameter(Int_t parNo, Double_t& currentValue, Double_t& currentError) const; return parameter value and error. Int_t GetNumFixedPars() const; returns the number of currently fixed parameters. Int_t GetNumFreePars() const; returns the number of currently free parameters. Int_t GetNumPars() const; returns the total number of parameters that have been defined.; (fixed and free). Int_t Migrad(); invokes the MIGRAD minimizer. Int_t Release(Int_t parNo); release a parameter. Int_t SetErrorDef(Double_t up); To get the n-sigma contour the error def parameter ""up"" has to set to n^2. void SetFCN(void (*fcn)(Int_t &, Double_t *, Double_t &f, Double_t *, I",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:45441,Testability,log,logical,45441,"alculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ==========================================================; *-* and appropriate step sizes GSTEP; *-* Called from MNHESS and MNGRAD; *. void mnimpr(); Attempts to improve on a good local minimum*-*-*-; *-* ===========================================; *-* Attempts to improve on a good local minimum by finding a; *-* better one. The quadratic part of FCN is removed by MNCALF; *-* and this transformed function is minimized using the simplex; *-* method from several random starting points.; *-* ref. -- Goldstein and Price, Math.Comp. 25, 569 (1971); *. void mninex(Double_t* pint); -*Transforms from internal coordinates (PINT) to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =========================================; *-* along direction STEP, where the length of vector STEP; *-* gives the expected position of minimum.; *-* FSTART is value of function at START; *-* SLOPE (if non-zero) is df/dx along STEP at START; *-* TOLER is initial tolerance of minimum in direction STEP; -; *-* SLAMBG and ALPHA control the maximum individual steps allowed.; *-* The first step is always =1. The max length of second step is SLAMBG.; *-* The max size of subsequent steps is the maximum previous successful; *-* step multiplied by ALPHA + the size o",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:976,Usability,simpl,simply,976,". TMinuit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuit. class TMinuit: public TNamed. The Minimization package*-; -* ======================== ; -* ; -* This package was originally written in Fortran by Fred James ; -* and part of PACKLIB (patch D506) ; -* ; -* It has been converted to a C++ class by R.Brun ; -* The current implementation in C++ is a straightforward conversion ; -* of the original Fortran version: The main changes are: ; -* ; -* - The variables in the various Minuit labelled common blocks ; -* have been changed to the TMinuit class data members. ; -* - The internal arrays with a maximum dimension depending on the ; -* maximum number of parameters are now data members arrays with ; -* a dynamic dimension such that one can fit very large problems ; -* by simply initialising the TMinuit constructor with the maximum ; -* number of parameters. ; -* - The include file Minuit.h has been commented as much as possible; -* using existing comments in the code or the printed documentation; -* - The original Minuit subroutines are now member functions. ; -* - Constructors and destructor have been added. ; -* - Instead of passing the FCN function in the argument ; -* list, the addresses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a mu",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:2303,Usability,simpl,simple,2303,"sses of this function is stored as pointer ; -* in the data members of the class. This is by far more elegant ; -* and flexible in an interactive environment. ; -* The member function SetFCN can be used to define this pointer. ; -* - The ROOT static function Printf is provided to replace all ; -* format statements and to print on currently defined output file.; -* - The functions SetObjectFit(TObject *obj)/GetObjectFit() can be ; -* used inside the FCN function to set/get a referenced object ; -* instead of using global variables. ; *. . Basic concepts of MINUIT. The MINUIT package acts on a multiparameter Fortran function to which one; must give the generic name FCN. In the ROOT implementation,; the function FCN is defined via the MINUIT SetFCN member function; when an Histogram.Fit command is invoked.; The value of FCN will in general depend on one; or more variable parameters. To take a simple example, in case of ROOT histograms (classes TH1C,TH1S,TH1F,TH1D); the Fit function defines the Minuit fitting function as being H1FitChisquare; or H1FitLikelihood depending on the options selected.; H1FitChisquare; calculates the chisquare between the user fitting function (gaussian, polynomial,; user defined,etc) and the data for given values of the parameters.; It is the task of MINUIT to find those values of the parameters; which give the lowest value of chisquare. Basic concepts - The transformation for parameters with limits. For variable parameters with limits, MINUIT uses the following; transformation:. P = arcsin(2((P -a)/(b- a))-1) P = a+((b- a)/(2))(sinP +1); int ext ext int. so that the internal value P can take on any value, while the external; int; value P can take on values only between the lower limit a and the; ext; upper limit b. Since the transformation is necessarily non-linear, it; would transform a nice linear problem into a nasty non-linear one, which; is the reason why limits should be avoided if not necessary. In addition,; the transformation does r",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:44850,Usability,simpl,simplex,44850,"ne Brun; *-* comments extracted from the MINUIT documentation file.; -; *. void mnhess(); Calculates the full second-derivative matrix of FCN*-*-; *-* ===================================================; *-* by taking finite differences. When calculating diagonal; *-* elements, it may iterate so that step size is nearly that; *-* which gives function change= UP/10. The first derivatives; *-* of course come as a free side effect, but with a smaller; *-* step size in order to obtain a known accuracy.; *. void mnhes1(); Calculate first derivatives (GRD) and uncertainties (DGRD)*-*-; *-* ==========================================================; *-* and appropriate step sizes GSTEP; *-* Called from MNHESS and MNGRAD; *. void mnimpr(); Attempts to improve on a good local minimum*-*-*-; *-* ===========================================; *-* Attempts to improve on a good local minimum by finding a; *-* better one. The quadratic part of FCN is removed by MNCALF; *-* and this transformed function is minimized using the simplex; *-* method from several random starting points.; *-* ref. -- Goldstein and Price, Math.Comp. 25, 569 (1971); *. void mninex(Double_t* pint); -*Transforms from internal coordinates (PINT) to external (U); *-* ===========================================================; *-* The minimizing routines which work in; *-* internal coordinates call this routine before calling FCN.; *. void mninit(Int_t i1, Int_t i2, Int_t i3); Main initialization member function for MINUIT*-*-*-; *-* ==============================================; *-* It initializes some constants; *-* (including the logical I/O unit nos.),; *. void mnlims(); Interprets the SET LIM command, to reset the parameter limits; *-* =============================================================; *-* Called from MNSET; *. void mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); -*-*Perform a line search from position START; *-* =======================================",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:51928,Usability,simpl,simplex,51928,"nkode, Double_t fval); Prints the values of the parameters at the time of the call*-; *-* ===========================================================; *-* also prints other relevant information such as function value,; *-* estimated distance to minimum, parameter errors, step sizes.; -; *-* According to the value of IKODE, the printout is:; *-* IKODE=INKODE= 0 only info about function value; *-* 1 parameter values, errors, limits; *-* 2 values, errors, step sizes, internal values; *-* 3 values, errors, step sizes, first derivs.; *-* 4 values, parabolic errors, MINOS errors; *-* when INKODE=5, MNPRIN chooses IKODE=1,2, or 3, according to fISW[1]; *. void mnpsdf(); -*Calculates the eigenvalues of v to see if positive-def; *-* ======================================================; *-* if not, adds constant along diagonal to make positive.; *. void mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& jl); Called only by MNSIMP (and MNIMPR) to add a new point*-*-; *-* =====================================================; *-* and remove an old one from the current simplex, and get the; *-* estimated distance to minimum.; *. void mnrn15(Double_t& val, Int_t& inseed); This is a super-portable random number generator; *-* ================================================; *-* It should not overflow on any 32-bit machine.; *-* The cycle is only ~10**9, so use with care!; *-* Note especially that VAL must not be undefined on input.; *-* Set Default Starting Seed; *. void mnrset(Int_t iopt); Resets function value and errors to UNDEFINED; *-* =============================================; *-* If IOPT=1,; *-* If IOPT=0, sets only MINOS errors to undefined; *-* Called from MNCLER and whenever problem changes, for example; *-* after SET LIMITS, SET PARAM, CALL FCN 6; *. void mnsave(); -*Writes current parameter values and step sizes onto file ISYSSA; *-* ===============================================================; *-* in format which can be reread by Minuit for ",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:54299,Usability,simpl,simplex,54299,"===========; *-* Each time a new minimum is found, the search area is shifted; *-* to be centered at the best value. Random points are chosen; *-* uniformly over a hypercube determined by current step sizes.; *-* The Metropolis algorithm accepts a worse point with probability; *-* exp(-d/UP), where d is the degradation. Improved points; *-* are of course always accepted. Actual steps are random; *-* multiples of the nominal steps (DIRIN).; *. void mnset(); Interprets the commands that start with SET and SHOW*-*-; *-* ====================================================; *-* Called from MNEXCM; *-* file characteristics for SET INPUT; *-* 'SET ' or 'SHOW', 'ON ' or 'OFF', 'SUPPRESSED' or 'REPORTED '; *-* explanation of print level numbers -1:3 and strategies 0:2; *-* identification of debug options; *-* things that can be set or shown; *-* options not intended for normal users; *. void mnsimp(); Minimization using the simplex method of Nelder and Mead; *-* ========================================================; *-* Performs a minimization using the simplex method of Nelder; *-* and Mead (ref. -- Comp. J. 7,308 (1965)).; *. void mnstat(Double_t& fmin, Double_t& fedm, Double_t& errdef, Int_t& npari, Int_t& nparx, Int_t& istat); Returns concerning the current status of the minimization; *-* =========================================================; *-* User-called; *-* Namely, it returns:; *-* FMIN: the best function value found so far; *-* FEDM: the estimated vertical distance remaining to minimum; *-* ERRDEF: the value of UP defining parameter uncertainties; *-* NPARI: the number of currently variable parameters; *-* NPARX: the highest (external) parameter number defined by user; *-* ISTAT: a status integer indicating how good is the covariance; *-* matrix: 0= not calculated at all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To fin",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuit.html:54434,Usability,simpl,simplex,54434,"===========; *-* Each time a new minimum is found, the search area is shifted; *-* to be centered at the best value. Random points are chosen; *-* uniformly over a hypercube determined by current step sizes.; *-* The Metropolis algorithm accepts a worse point with probability; *-* exp(-d/UP), where d is the degradation. Improved points; *-* are of course always accepted. Actual steps are random; *-* multiples of the nominal steps (DIRIN).; *. void mnset(); Interprets the commands that start with SET and SHOW*-*-; *-* ====================================================; *-* Called from MNEXCM; *-* file characteristics for SET INPUT; *-* 'SET ' or 'SHOW', 'ON ' or 'OFF', 'SUPPRESSED' or 'REPORTED '; *-* explanation of print level numbers -1:3 and strategies 0:2; *-* identification of debug options; *-* things that can be set or shown; *-* options not intended for normal users; *. void mnsimp(); Minimization using the simplex method of Nelder and Mead; *-* ========================================================; *-* Performs a minimization using the simplex method of Nelder; *-* and Mead (ref. -- Comp. J. 7,308 (1965)).; *. void mnstat(Double_t& fmin, Double_t& fedm, Double_t& errdef, Int_t& npari, Int_t& nparx, Int_t& istat); Returns concerning the current status of the minimization; *-* =========================================================; *-* User-called; *-* Namely, it returns:; *-* FMIN: the best function value found so far; *-* FEDM: the estimated vertical distance remaining to minimum; *-* ERRDEF: the value of UP defining parameter uncertainties; *-* NPARI: the number of currently variable parameters; *-* NPARX: the highest (external) parameter number defined by user; *-* ISTAT: a status integer indicating how good is the covariance; *-* matrix: 0= not calculated at all; *-* 1= approximation only, not accurate; *-* 2= full matrix, but forced positive-definite; *-* 3= full accurate covariance matrix; *. void mntiny(Double_t epsp1, Double_t& epsbak); To fin",MatchSource.WIKI,root/html530/TMinuit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuit.html
https://root.cern/root/html530/TMinuitMinimizer.html:5063,Availability,error,errors,5063,"egy() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); doubleROOT::Math::Minimizer::Tolerance() const; static boolUseStaticMinuit(bool on = true); virtual intVariableIndex(const string& name) const; virtual stringVariableName(unsigned int ivar) const; virtual const double*X() const. protected:. voidDoClear(); voidDoReleaseFixParameter(int ivar); static voidFcn(int&, double*, double& f, double*, int); static voidFcnGrad(int&, double* g, double& f, double*, int); voidInitTMinuit(int ndim); voidRetrieveErrorMatrix(); voidRetrieveParams(). private:. TMinuitMinimizer(const TMinuitMinimizer&); TMinuitMinimizer&operator=(const TMinuitMinimizer& rhs). Data Members; protected:. intROOT::Math::Minimizer::fDebugprint level; unsigned intROOT::Math::Minimizer::fMaxCallsmax number of function calls ; unsigned intROOT::Math::Minimizer::fMaxItermax number or iterations used to find the minimum; doubleROOT::Math::Minimizer::fPrecprecision; intROOT::Math::Minimizer::fStatusstatus of minimizer ; intROOT::Math::Minimizer::fStrategyminimizer strategy; doubleROOT::Math::Minimizer::fToltolerance (absolute); doubleROOT::Math::Minimizer::fUperror scale ; boolROOT::Math::Minimizer::fValidErrorflag to control if errors have been validated (Hesse has been run in case of Minuit). private:. vector<double>fCovar; unsigned intfDim; vector<double>fErrors; boolfMinosRun; TMinuit*fMinuit; vector<double>fParams; unsigned intfStrategy; ROOT::Minuit::EMinimizerTypefType; boolfUsed; static ROOT::Math::IBaseFunctionMultiDim*fgFunc; static TMinuit*fgMinuit; static boolfgUseStaticMinuitflag to control if using global TMInuit instance (gMinuit); static boolfgUsedflag to control if static instance has done minimization. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); Constructor for TMinuitMinimier class via an enumeration specifying the minim",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8499,Availability,error,errors,8499,"d FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= appro",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8707,Availability,error,errors,8707,"; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMino",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8758,Availability,error,error,8758,"ble. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10536,Availability,error,error,10536,", but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Auth",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10550,Availability,error,errors,10550,", but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Auth",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10733,Availability,error,errors,10733,", but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Auth",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11175,Availability,error,error,11175,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11185,Availability,error,error,11185,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11255,Availability,error,errors,11255,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11494,Availability,error,errors,11494,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8448,Deployability,update,update,8448,"d FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= appro",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:9913,Deployability,release,released,9913,"of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() cons",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:9946,Deployability,release,release,9946,"of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() cons",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10014,Deployability,release,release,10014,"of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() cons",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:387,Integrability,interface,interface,387,". TMinuitMinimizer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuitMinimizer. class TMinuitMinimizer: public ROOT::Math::Minimizer. TMinuitMinimizer class implementing the ROOT::Math::Minimizer interface using; TMinuit.; This class is normally instantiates using the plug-in manager; (plug-in with name Minuit or TMinuit); In addition the user can choose the minimizer algorithm: Migrad (the default one), Simplex, or Minimize (combined Migrad + Simplex). Function Members (Methods); public:. TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); TMinuitMinimizer(const char* type, unsigned int ndim = 0); virtual~TMinuitMinimizer(); static TClass*Class(); virtual voidROOT::Math::Minimizer::Clear(); virtual boolContour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); virtual doubleROOT::Math::Minimizer::Correlation(unsigned int i, unsigned int j) const; virtual doubleCovMatrix(unsigned int i, unsigned int j) const; virtual intCovMatrixStatus() const; virtual doubleEdm() const; doubleROOT::Math::Minimizer::ErrorDef() const; virtual const double*Errors() const; virtual boolGetCovMatrix(double* cov) const; virtual boolGetHessianMatrix(double* h) const; virtual boolGetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); virtual doubleGlobalCC(unsigned int) const; virtual boolHesse(); virtual TClass*IsA() const; boolROOT::Math::Minimizer::IsValidError() const; unsigned intROOT::Math::Minimizer::MaxFunctionCalls() const; unsigned intROOT::Math::Minimizer::MaxIterations() const; virtual const double*MinGradient() const; virtual boolMinimize(); virtual doubleMinValue() const; virtual unsigned intNCalls() const; virtual unsigned intNDim() const; virtual unsigned intNFree() const; virtual ROOT::Math::Mini",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:6800,Integrability,interface,interface,6800,"uit::kMigrad, unsigned int ndim = 0); Constructor for TMinuitMinimier class via an enumeration specifying the minimization; algorithm type. Supported types are : kMigrad, kSimplex, kCombined (a combined; Migrad + Simplex minimization) and kMigradImproved (a Migrad mininimization folloed by an; improved search for global minima). The default type is Migrad (kMigrad). TMinuitMinimizer(const char* type, unsigned int ndim = 0); constructor from a char * for the algorithm type, used by the plug-in manager; The names supported (case unsensitive) are:; Migrad (default), Simplex, Minimize (for the combined Migrad+ Simplex) and Migrad_imp. ~TMinuitMinimizer(); Destructor implementation. TMinuitMinimizer(const TMinuitMinimizer& ); Implementation of copy constructor (it is private). bool UseStaticMinuit(bool on = true); static method to control usage of global TMinuit instance. void InitTMinuit(int ndim). void SetFunction(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigne",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7144,Integrability,interface,interface,7144," type is Migrad (kMigrad). TMinuitMinimizer(const char* type, unsigned int ndim = 0); constructor from a char * for the algorithm type, used by the plug-in manager; The names supported (case unsensitive) are:; Migrad (default), Simplex, Minimize (for the combined Migrad+ Simplex) and Migrad_imp. ~TMinuitMinimizer(); Destructor implementation. TMinuitMinimizer(const TMinuitMinimizer& ); Implementation of copy constructor (it is private). bool UseStaticMinuit(bool on = true); static method to control usage of global TMinuit instance. void InitTMinuit(int ndim). void SetFunction(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7228,Integrability,interface,interface,7228,"n manager; The names supported (case unsensitive) are:; Migrad (default), Simplex, Minimize (for the combined Migrad+ Simplex) and Migrad_imp. ~TMinuitMinimizer(); Destructor implementation. TMinuitMinimizer(const TMinuitMinimizer& ); Implementation of copy constructor (it is private). bool UseStaticMinuit(bool on = true); static method to control usage of global TMinuit instance. void InitTMinuit(int ndim). void SetFunction(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. i",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7419,Integrability,interface,interface,7419," TMinuitMinimizer& ); Implementation of copy constructor (it is private). bool UseStaticMinuit(bool on = true); static method to control usage of global TMinuit instance. void InitTMinuit(int ndim). void SetFunction(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7612,Integrability,interface,interface,7612,"ion(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void Re",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:460,Modifiability,plug-in,plug-in,460,". TMinuitMinimizer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuitMinimizer. class TMinuitMinimizer: public ROOT::Math::Minimizer. TMinuitMinimizer class implementing the ROOT::Math::Minimizer interface using; TMinuit.; This class is normally instantiates using the plug-in manager; (plug-in with name Minuit or TMinuit); In addition the user can choose the minimizer algorithm: Migrad (the default one), Simplex, or Minimize (combined Migrad + Simplex). Function Members (Methods); public:. TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); TMinuitMinimizer(const char* type, unsigned int ndim = 0); virtual~TMinuitMinimizer(); static TClass*Class(); virtual voidROOT::Math::Minimizer::Clear(); virtual boolContour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); virtual doubleROOT::Math::Minimizer::Correlation(unsigned int i, unsigned int j) const; virtual doubleCovMatrix(unsigned int i, unsigned int j) const; virtual intCovMatrixStatus() const; virtual doubleEdm() const; doubleROOT::Math::Minimizer::ErrorDef() const; virtual const double*Errors() const; virtual boolGetCovMatrix(double* cov) const; virtual boolGetHessianMatrix(double* h) const; virtual boolGetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); virtual doubleGlobalCC(unsigned int) const; virtual boolHesse(); virtual TClass*IsA() const; boolROOT::Math::Minimizer::IsValidError() const; unsigned intROOT::Math::Minimizer::MaxFunctionCalls() const; unsigned intROOT::Math::Minimizer::MaxIterations() const; virtual const double*MinGradient() const; virtual boolMinimize(); virtual doubleMinValue() const; virtual unsigned intNCalls() const; virtual unsigned intNDim() const; virtual unsigned intNFree() const; virtual ROOT::Math::Mini",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:478,Modifiability,plug-in,plug-in,478,". TMinuitMinimizer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MINUIT; » TMinuitMinimizer. class TMinuitMinimizer: public ROOT::Math::Minimizer. TMinuitMinimizer class implementing the ROOT::Math::Minimizer interface using; TMinuit.; This class is normally instantiates using the plug-in manager; (plug-in with name Minuit or TMinuit); In addition the user can choose the minimizer algorithm: Migrad (the default one), Simplex, or Minimize (combined Migrad + Simplex). Function Members (Methods); public:. TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); TMinuitMinimizer(const char* type, unsigned int ndim = 0); virtual~TMinuitMinimizer(); static TClass*Class(); virtual voidROOT::Math::Minimizer::Clear(); virtual boolContour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); virtual doubleROOT::Math::Minimizer::Correlation(unsigned int i, unsigned int j) const; virtual doubleCovMatrix(unsigned int i, unsigned int j) const; virtual intCovMatrixStatus() const; virtual doubleEdm() const; doubleROOT::Math::Minimizer::ErrorDef() const; virtual const double*Errors() const; virtual boolGetCovMatrix(double* cov) const; virtual boolGetHessianMatrix(double* h) const; virtual boolGetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); virtual doubleGlobalCC(unsigned int) const; virtual boolHesse(); virtual TClass*IsA() const; boolROOT::Math::Minimizer::IsValidError() const; unsigned intROOT::Math::Minimizer::MaxFunctionCalls() const; unsigned intROOT::Math::Minimizer::MaxIterations() const; virtual const double*MinGradient() const; virtual boolMinimize(); virtual doubleMinValue() const; virtual unsigned intNCalls() const; virtual unsigned intNDim() const; virtual unsigned intNFree() const; virtual ROOT::Math::Mini",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:6207,Modifiability,plug-in,plug-in,6207,"inuit*fMinuit; vector<double>fParams; unsigned intfStrategy; ROOT::Minuit::EMinimizerTypefType; boolfUsed; static ROOT::Math::IBaseFunctionMultiDim*fgFunc; static TMinuit*fgMinuit; static boolfgUseStaticMinuitflag to control if using global TMInuit instance (gMinuit); static boolfgUsedflag to control if static instance has done minimization. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); Constructor for TMinuitMinimier class via an enumeration specifying the minimization; algorithm type. Supported types are : kMigrad, kSimplex, kCombined (a combined; Migrad + Simplex minimization) and kMigradImproved (a Migrad mininimization folloed by an; improved search for global minima). The default type is Migrad (kMigrad). TMinuitMinimizer(const char* type, unsigned int ndim = 0); constructor from a char * for the algorithm type, used by the plug-in manager; The names supported (case unsensitive) are:; Migrad (default), Simplex, Minimize (for the combined Migrad+ Simplex) and Migrad_imp. ~TMinuitMinimizer(); Destructor implementation. TMinuitMinimizer(const TMinuitMinimizer& ); Implementation of copy constructor (it is private). bool UseStaticMinuit(bool on = true); static method to control usage of global TMinuit instance. void InitTMinuit(int ndim). void SetFunction(const ROOT::Math::IMultiGenFunction & func); Set the objective function to be minimized, by passing a function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user v",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7786,Modifiability,variab,variable,7786," function object implement the; basic multi-dim Function interface. In this case the derivatives will be; calculated by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); g",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:7917,Modifiability,variab,variable,7917,"by Minuit; Here a TMinuit instance is created since only at this point we know the number of parameters. void SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8002,Modifiability,variab,variable,8002,"d SetFunction(const ROOT::Math::IMultiGradFunction & func); Set the objective function to be minimized, by passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8088,Modifiability,variab,variable,8088,"y passing a function object implement the; multi-dim gradient Function interface. In this case the function derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFr",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8198,Modifiability,variab,variable,8198,"unction derivatives are provided; by the user via this interface and there not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance ma",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8265,Modifiability,variab,variable,8265,"e not calculated by Minuit. void Fcn(int& , double* , double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of c",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10397,Modifiability,variab,variable,10397,", but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Auth",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11074,Modifiability,variab,variables,11074,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11408,Modifiability,variab,variable,11408,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:11466,Modifiability,variab,variables,11466,"fined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:8298,Performance,perform,perform,8298,"on of FCN static function used internally by TMinuit.; Adapt IMultiGenFunction interface to TMinuit FCN static function. void FcnGrad(int& , double* g, double& f, double* , int ); implementation of FCN static function used internally by TMinuit.; Adapt IMultiGradFunction interface to TMinuit FCN static function in the case of user; provided gradient. bool SetVariable(unsigned int ivar, const string& name, double val, double step); set a free variable. bool SetLimitedVariable(unsigned int ivar, const string& name, double val, double step, double , double ); set a limited variable. bool SetFixedVariable(unsigned int , const string& , double ); set a fixed variable. bool SetVariableValue(unsigned int , double ); set the value of an existing variable; parameter must exist or return false. std::string VariableName(unsigned int ivar) const; return the variable name. int VariableIndex(const string& name) const; return variable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the f",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:10756,Performance,perform,perform,10756,"the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise exits. bool Scan(unsigned int i, unsigned int& nstep, double* x, double* y, double xmin = 0, double xmax = 0); scan a parameter (variable) around the minimum value; the parameters must have been set before; if xmin=0 && xmax == 0 by default scan around 2 sigma of the error; if the errors are also zero then scan from min and max of parameter range; (if parameters are limited Minuit scan from min and max instead of 2 sigma by default); (force in that case to use errors). bool Hesse(); perform calculation of Hessian. const double * X() const; return pointer to X values at the minimum. { return &fParams.front(); }. const double * MinGradient() const; return pointer to gradient values at the minimum. { return 0; }. unsigned int NDim() const; this is <= Function().NDim() which is the total; number of variables (free+ constrained ones). { return fDim; }. bool ProvidesError() const; minimizer provides error and error matrix. { return true; }. const double * Errors() const; return errors at the minimum. { return &fErrors.front(); }. double CovMatrix(unsigned int i, unsigned int j) const; return covariance matrices elements; if the variable is fixed the matrix is zero; The ordering of the variables is the same as in errors. » Author: L. Moneta Wed Oct 25 16:28:55 2006 » Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; » Last changed: root/minuit:$Id: TMinuitMinimizer.h 39420 2011-05-26 15:00:28Z moneta $ » Last generated: 2011-07-04 15:35; This page has been automatically gene",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:9316,Safety,avoid,avoid,9316,"riable index. bool Minimize(); perform the minimization using the algorithm chosen previously by the user; By default Migrad is used.; Return true if the found minimum is valid and update internal chached values of; minimum values, errors and covariance matrix.; Status of minimizer is set to:; migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult. void RetrieveParams(); retrieve from TMinuit minimum parameter values; and errors. void RetrieveErrorMatrix(); get covariance error matrix from TMinuit; when some parameters are fixed filled the corresponding rows and column with zero's. unsigned int NCalls() const; return total number of function calls. double MinValue() const; return minimum function value. double Edm() const; return expected distance from the minimum. unsigned int NFree() const; return number of free parameters. bool GetCovMatrix(double* cov) const; get covariance matrix. bool GetHessianMatrix(double* h) const; get Hessian - inverse of covariance matrix; just invert it; but need to get the compact form to avoid the zero for the fixed parameters. int CovMatrixStatus() const; return status of covariance matrix; status: 0= not calculated at all; 1= approximation only, not accurate; 2= full matrix, but forced positive-definite; 3= full accurate covariance matrix. double GlobalCC(unsigned int ) const; global correlation coefficient for parameter i. bool GetMinosError(unsigned int i, double& errLow, double& errUp, int = 0); Perform Minos analysis for the given parameter i. void DoClear(); reset TMinuit. void DoReleaseFixParameter(int ivar); check if a parameter is defined and in case it was fixed released; TMinuit is not able to release free parameters by redefining them; so we need to force the release. void PrintResults(); print-out results using classic Minuit format (mnprin). bool Contour(unsigned int i, unsigned int j, unsigned int& npoints, double* xi, double* xj); contour plot for parameter i and j; need a valid FunctionMinimum otherwise ",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMinuitMinimizer.html:5080,Security,validat,validated,5080,"egy() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); doubleROOT::Math::Minimizer::Tolerance() const; static boolUseStaticMinuit(bool on = true); virtual intVariableIndex(const string& name) const; virtual stringVariableName(unsigned int ivar) const; virtual const double*X() const. protected:. voidDoClear(); voidDoReleaseFixParameter(int ivar); static voidFcn(int&, double*, double& f, double*, int); static voidFcnGrad(int&, double* g, double& f, double*, int); voidInitTMinuit(int ndim); voidRetrieveErrorMatrix(); voidRetrieveParams(). private:. TMinuitMinimizer(const TMinuitMinimizer&); TMinuitMinimizer&operator=(const TMinuitMinimizer& rhs). Data Members; protected:. intROOT::Math::Minimizer::fDebugprint level; unsigned intROOT::Math::Minimizer::fMaxCallsmax number of function calls ; unsigned intROOT::Math::Minimizer::fMaxItermax number or iterations used to find the minimum; doubleROOT::Math::Minimizer::fPrecprecision; intROOT::Math::Minimizer::fStatusstatus of minimizer ; intROOT::Math::Minimizer::fStrategyminimizer strategy; doubleROOT::Math::Minimizer::fToltolerance (absolute); doubleROOT::Math::Minimizer::fUperror scale ; boolROOT::Math::Minimizer::fValidErrorflag to control if errors have been validated (Hesse has been run in case of Minuit). private:. vector<double>fCovar; unsigned intfDim; vector<double>fErrors; boolfMinosRun; TMinuit*fMinuit; vector<double>fParams; unsigned intfStrategy; ROOT::Minuit::EMinimizerTypefType; boolfUsed; static ROOT::Math::IBaseFunctionMultiDim*fgFunc; static TMinuit*fgMinuit; static boolfgUseStaticMinuitflag to control if using global TMInuit instance (gMinuit); static boolfgUsedflag to control if static instance has done minimization. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMinuitMinimizer(ROOT::Minuit::EMinimizerType type = ROOT::Minuit::kMigrad, unsigned int ndim = 0); Constructor for TMinuitMinimier class via an enumeration specifying the minim",MatchSource.WIKI,root/html530/TMinuitMinimizer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMinuitMinimizer.html
https://root.cern/root/html530/TMixture.html:1476,Availability,error,error,1476,"l~TMixture(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidDefineElement(Int_t n, Float_t a, Float_t z, Float_t w); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tTMaterial::GetA() const; Float_t*GetAmixt() const; virtual Float_tTMaterial::GetDensity() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Float_tTMaterial::GetInterLength() const; virtual const char*TNamed::GetName() const; Int_tGetNmixt() const; virtual Int_tTMaterial::GetNumber() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjec",MatchSource.WIKI,root/html530/TMixture.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMixture.html
https://root.cern/root/html530/TMixture.html:1560,Availability,error,error,1560,"ject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidDefineElement(Int_t n, Float_t a, Float_t z, Float_t w); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tTMaterial::GetA() const; Float_t*GetAmixt() const; virtual Float_tTMaterial::GetDensity() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Color_tTAttFill::GetFillColor() const; virtual Style_tTAttFill::GetFillStyle() const; virtual const char*TObject::GetIconName() const; virtual Float_tTMaterial::GetInterLength() const; virtual const char*TNamed::GetName() const; Int_tGetNmixt() const; virtual Int_tTMaterial::GetNumber() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual Float_tTMaterial::GetR",MatchSource.WIKI,root/html530/TMixture.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMixture.html
https://root.cern/root/html530/TMixture.html:298,Safety,detect,detector,298,". TMixture. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » GRAF3D; » G3D; » TMixture. class TMixture: public TMaterial. Manages a detector mixture. See class TGeometry. Function Members (Methods); public:. TMixture(); TMixture(const TMixture&); TMixture(const char* name, const char* title, Int_t nmixt); virtual~TMixture(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidDefineElement(Int_t n, Float_t a, Float_t z, Float_t w); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tTMaterial::GetA() const; Float_t*GetAmixt() const; virtual Float_tTMaterial::GetDensity() const; virt",MatchSource.WIKI,root/html530/TMixture.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMixture.html
https://root.cern/root/html530/TMLPAnalyzer.html:1995,Availability,error,error,1995,"e = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawDInput(Int_t i); voidDrawDInputs(); voidDrawNetwork(Int_t neuron, const char* signal, const char* bg); TProfile*DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); TProfile*DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviations(Option_t* option = """"); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; voidGatherInformations(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TTree*GetIOTree() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Boo",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:2079,Availability,error,error,2079,"TObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawDInput(Int_t i); voidDrawDInputs(); voidDrawNetwork(Int_t neuron, const char* signal, const char* bg); TProfile*DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); TProfile*DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviations(Option_t* option = """"); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; voidGatherInformations(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TTree*GetIOTree() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::Inheri",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:8474,Deployability,continuous,continuous,8474,"sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus; the true value of outnode vs the input value innode, for all test; data events.; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfi",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:8942,Deployability,continuous,continuous,8942," the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus; the true value of outnode vs the input value innode, for all test; data events.; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus the; true value of outnode vs the input value, stacked for all inputs, for; all test data events.; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TMLPAnalyzer(TMultiLayerPerceptron& net); {}. TMLPAnalyzer(TMultiLayerPerce",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:433,Modifiability,variab,variables,433,". TMLPAnalyzer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMLPAnalyzer. class TMLPAnalyzer: public TObject. TMLPAnalyzer. This utility class contains a set of tests usefull when developing; a neural network.; It allows you to check for unneeded variables, and to control; the network structure. Function Members (Methods); public:. TMLPAnalyzer(TMultiLayerPerceptron& net); TMLPAnalyzer(TMultiLayerPerceptron* net); TMLPAnalyzer(const TMLPAnalyzer&); virtual~TMLPAnalyzer(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckNetwork(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawDInput(Int_t i); voidDrawDInputs(); voidDrawNetwork(Int_t neuron, const char* signal, const char* bg); TProfile*DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); TProfile*DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviations(Option_t* option = """"); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error ",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:6205,Modifiability,layers,layers,6205,"sgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; const char*GetInputNeuronTitle(Int_t in); Int_tGetLayers(); TStringGetNeuronFormula(Int_t idx); Int_tGetNeurons(Int_t layer); const char*GetOutputNeuronTitle(Int_t out); voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TTree*fAnalysisTree; TTree*fIOTree; TMultiLayerPerceptron*fNetwork. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMLPAnalyzer(); Destructor. Int_t GetLayers(); Returns the number of layers. Int_t GetNeurons(Int_t layer); Returns the number of neurons in given layer. TString GetNeuronFormula(Int_t idx); Returns the formula used as input for neuron (idx) in; the first layer. const char* GetInputNeuronTitle(Int_t in); Returns the name of any neuron from the input layer. const char* GetOutputNeuronTitle(Int_t out); Returns the name of any neuron from the output layer. void CheckNetwork(); Gives some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates th",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:7549,Modifiability,variab,variable,7549," some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TP",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:7845,Performance,optimiz,optimizing,7845," analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each outpu",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:7628,Safety,risk,risk,7628," some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TP",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:347,Testability,test,tests,347,". TMLPAnalyzer. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMLPAnalyzer. class TMLPAnalyzer: public TObject. TMLPAnalyzer. This utility class contains a set of tests usefull when developing; a neural network.; It allows you to check for unneeded variables, and to control; the network structure. Function Members (Methods); public:. TMLPAnalyzer(TMultiLayerPerceptron& net); TMLPAnalyzer(TMultiLayerPerceptron* net); TMLPAnalyzer(const TMLPAnalyzer&); virtual~TMLPAnalyzer(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckNetwork(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawDInput(Int_t i); voidDrawDInputs(); voidDrawNetwork(Int_t neuron, const char* signal, const char* bg); TProfile*DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); TProfile*DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); THStack*DrawTruthDeviations(Option_t* option = """"); virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error ",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:6909,Testability,test,test,6909,"kSingleKey; kOverwrite; kWriteDelete; };. private:. TTree*fAnalysisTree; TTree*fIOTree; TMultiLayerPerceptron*fNetwork. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~TMLPAnalyzer(); Destructor. Int_t GetLayers(); Returns the number of layers. Int_t GetNeurons(Int_t layer); Returns the number of neurons in given layer. TString GetNeuronFormula(Int_t idx); Returns the formula used as input for neuron (idx) in; the first layer. const char* GetInputNeuronTitle(Int_t in); Returns the name of any neuron from the input layer. const char* GetOutputNeuronTitle(Int_t out); Returns the name of any neuron from the output layer. void CheckNetwork(); Gives some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:7050,Testability,test,test,7050,"ce; Inherited Members; Includes; Libraries. Function documentation; ~TMLPAnalyzer(); Destructor. Int_t GetLayers(); Returns the number of layers. Int_t GetNeurons(Int_t layer); Returns the number of neurons in given layer. TString GetNeuronFormula(Int_t idx); Returns the formula used as input for neuron (idx) in; the first layer. const char* GetInputNeuronTitle(Int_t in); Returns the name of any neuron from the input layer. const char* GetOutputNeuronTitle(Int_t out); Returns the name of any neuron from the output layer. void CheckNetwork(); Gives some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:8110,Testability,test,test,8110,"ation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProf",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:8351,Testability,test,test,8351,". That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP o",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:8820,Testability,test,test,8820,"you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus; the true value of outnode vs the input value innode, for all test; data events.; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus the; true value of outnode vs the input value, stacked for all inputs, for; all test data events.; The ret",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:9331,Testability,test,test,9331,"fference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus; the true value of outnode vs the input value innode, for all test; data events.; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus the; true value of outnode vs the input value, stacked for all inputs, for; all test data events.; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TMLPAnalyzer(TMultiLayerPerceptron& net); {}. TMLPAnalyzer(TMultiLayerPerceptron* net); {}. TTree* GetIOTree() const; { return fIOTree;}. » Author: Christophe.Delaere@cern.ch 25/04/04 » Copyright (C) 1995-2003, Rene Brun and Fons Rademakers. *; » Last changed: root/mlp:$Id: TMLPAnalyzer.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:33; Th",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:9709,Testability,test,test,9709,"s mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviations(Option_t* option = """"); Creates TProfiles of the difference of the MLP output minus the; true value vs the true value, one for each output, filled with the; test data events. This method is mainly useful when doing regression; analysis with the MLP (i.e. not classification, but continuous truth; values).; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TProfile* DrawTruthDeviationInOut(Int_t innode, Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus; the true value of outnode vs the input value innode, for all test; data events.; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TProfile::Draw. THStack* DrawTruthDeviationInsOut(Int_t outnode = 0, Option_t* option = """"); Creates a profile of the difference of the MLP output outnode minus the; true value of outnode vs the input value, stacked for all inputs, for; all test data events.; The returned THStack contains all the TProfiles. It is drawn unless; the option ""goff"" is specified.; Options are passed to TProfile::Draw. TMLPAnalyzer(TMultiLayerPerceptron& net); {}. TMLPAnalyzer(TMultiLayerPerceptron* net); {}. TTree* GetIOTree() const; { return fIOTree;}. » Author: Christophe.Delaere@cern.ch 25/04/04 » Copyright (C) 1995-2003, Rene Brun and Fons Rademakers. *; » Last changed: root/mlp:$Id: TMLPAnalyzer.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TMLPAnalyzer.html:7523,Usability,learn,learn,7523," some information about the network in the terminal. void GatherInformations(); Collect informations about what is usefull in the network.; This method has to be called first when analyzing a network.; Fills the two analysis trees. void DrawDInput(Int_t i); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; the ith input. void DrawDInputs(); Draws the distribution (on the test sample) of the; impact on the network output of a small variation of; each input.; DrawDInputs() draws something that approximates the distribution of the; derivative of the NN w.r.t. each input. That quantity is recognized as; one of the measures to determine key quantities in the network. What is done is to vary one input around its nominal value and to see; how the NN changes. This is done for each entry in the sample and produces; a distribution. What you can learn from that is:; - is variable a really useful, or is my network insensitive to it ?; - is there any risk of big systematic ? Is the network extremely sensitive; to small variations of any of my inputs ?. As you might understand, this is to be considered with care and can serve; as input for an ""educated guess"" when optimizing the network. void DrawNetwork(Int_t neuron, const char* signal, const char* bg); Draws the distribution of the neural network (using ith neuron).; Two distributions are drawn, for events passing respectively the ""signal""; and ""background"" cuts. Only the test sample is used. TProfile* DrawTruthDeviation(Int_t outnode = 0, Option_t* option = """"); Create a profile of the difference of the MLP output minus the; true value for a given output node outnode, vs the true value for; outnode, for all test data events. This method is mainly useful; when doing regression analysis with the MLP (i.e. not classification,; but continuous truth values).; The resulting TProfile histogram is returned.; It is not drawn if option ""goff"" is specified.; Options are passed to TP",MatchSource.WIKI,root/html530/TMLPAnalyzer.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMLPAnalyzer.html
https://root.cern/root/html530/TModuleDocInfo.html:2058,Availability,error,error,2058," const char* doc = """"); virtual~TModuleDocInfo(); voidTObject::AbstractMethod(const char* method) const; voidAddClass(TClassDocInfo* cl); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TList*GetClasses(); const char*GetDoc() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; THashList&GetSub(); TModuleDocInfo*GetSuper() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash(",MatchSource.WIKI,root/html530/TModuleDocInfo.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TModuleDocInfo.html
https://root.cern/root/html530/TModuleDocInfo.html:2142,Availability,error,error,2142,"char* method) const; voidAddClass(TClassDocInfo* cl); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TList*GetClasses(); const char*GetDoc() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; THashList&GetSub(); TModuleDocInfo*GetSuper() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; vi",MatchSource.WIKI,root/html530/TModuleDocInfo.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TModuleDocInfo.html
https://root.cern/root/html530/TMonaLisaText.html:550,Availability,down,downloaded,550,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:682,Availability,down,download,682,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:2034,Availability,error,error,2034,"ext&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const char*GetText() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfm",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:2118,Availability,error,error,2118,"oidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const char*GetText() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual ",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:405,Energy Efficiency,monitor,monitoring,405,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:783,Energy Efficiency,monitor,monitoring,783,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:310,Integrability,interface,interface,310,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaText.html:756,Performance,optimiz,optimized,756,". TMonaLisaText. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaText. class TMonaLisaText: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaText(const TMonaLisaText&); TMonaLisaText(const char* name, const char* text); virtual~TMonaLisaText(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* me",MatchSource.WIKI,root/html530/TMonaLisaText.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaText.html
https://root.cern/root/html530/TMonaLisaValue.html:553,Availability,down,downloaded,553,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:685,Availability,down,download,685,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:2000,Availability,error,error,2000," TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:2084,Availability,error,error,2084,"oidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; Double_tGetValue() const; Double_t*GetValuePtr(); virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* clas",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:408,Energy Efficiency,monitor,monitoring,408,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:786,Energy Efficiency,monitor,monitoring,786,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:6230,Energy Efficiency,monitor,monitor,6230,"Int_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMonaLisaValue(const TMonaLisaValue&); TMonaLisaValue&operator=(const TMonaLisaValue&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. private:. Double_tfValuedouble monitor value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaValue(const TMonaLisaValue& ). TMonaLisaValue& operator=(const TMonaLisaValue& ). TMonaLisaValue(const char* name, Double_t value); { }. virtual ~TMonaLisaValue(); { }. Double_t GetValue() const; { return fValue; }. Double_t * GetValuePtr(); { return &fValue; }. » Author: Andreas Peters 5/10/2005 » Copyright (C) 1995-2006, Rene Brun and Fons Rademakers. *; » Last changed: root/monalisa:$Id: TMonaLisaWriter.h 23209 2008-04-14 13:25:09Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:313,Integrability,interface,interface,313,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaValue.html:759,Performance,optimiz,optimized,759,". TMonaLisaValue. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaValue. class TMonaLisaValue: public TNamed. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Function Members (Methods); public:. TMonaLisaValue(const char* name, Double_t value); virtual~TMonaLisaValue(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* e",MatchSource.WIKI,root/html530/TMonaLisaValue.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaValue.html
https://root.cern/root/html530/TMonaLisaWriter.html:598,Availability,down,downloaded,598,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:730,Availability,down,download,730,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:3088,Availability,error,error,3088," 0, const char* monsubid = 0, const char* option = """"); virtual~TMonaLisaWriter(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; ApMon*GetApMon() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) c",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:3172,Availability,error,error,3172,"oidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; ApMon*GetApMon() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:9629,Availability,down,downloaded,9629,"imetimestamp of the last send command for player process; Double_tfLastRWSendTimetimestamp of the last send command for file reads/writes; map<UInt_t,MonitoredTFileInfo*>*fMonInfoRepo! repo to gather per-file-instance mon info;; Int_tfPid! process id; Int_tfReportIntervalinterval after which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. Th",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:9761,Availability,down,download,9761,",MonitoredTFileInfo*>*fMonInfoRepo! repo to gather per-file-instance mon info;; Int_tfPid! process id; Int_tfReportIntervalinterval after which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session I",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:12269,Deployability,update,updates,12269,"l method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus050.cern.ch"");; Once when you create an analysis task, execute; gMonitoringWriter->SendInfoUser(""myname"");; gMonitoringWriter->SendInfoDescription(""My first Higgs analysis"");; gMonitoringWriter->SendInfoTime();; gMonitoringWriter->SendInfoStatus(""Submitted"");. On each node executing a subtask, you can set the status of this subtask:; gMonitoringWriter->SendProcessingStatus(""Started"");; During the processing of your analysis you can send progress updates:; gMonitoringWriter->SendProcessProgress(100,1000000); <= 100 events, 1MB processed. gMonitoringWriter-SendProcessingStatus(""Finished"");; delete gMonitoringWriter; gMonitoringWriter=0;. Example of use for any Generic Monitoring information:; TList *valuelist = new TList();; valuelist->SetOwner(kTRUE);; // append a text object; TMonaLisaText *valtext = new TMonaLisaText(""decaychannel"",""K->eeg"");; valuelist->Add(valtext);; // append a double value; TMonaLisaValue* valdouble = new TMonaLisaValue(""n-gamma"",5);; valuelist->Add(valdouble);; Bool_t success = SendParameters(valuelist);; delete valuelist;. option:; ""global"": gMonitoringWriter is initialized with this instance. ~TMonaLisaWriter(); Cleanup. Bool_t SendInfoStatus(const char* status); Sends a <status> text to MonaLisa following the process scheme:; <site> --> <jobid> --> 'status' = <status>; Used to set a global status for a groupjob, e.g.; a master-job or the general status ",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:453,Energy Efficiency,monitor,monitoring,453,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:829,Energy Efficiency,monitor,monitoring,829,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:1951,Energy Efficiency,monitor,monitoring,1951,"ctly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods); public:. TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); virtual~TMonaLisaWriter(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtua",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:9478,Energy Efficiency,monitor,monitoring,9478,"name! hostname of MonaLisa server; Bool_tfInitializedtrue if initialized; TStringfJobId! job id; Double_tfLastFCloseSendTimeIn order not to flood ML servers; time_tfLastProgressTimetimestamp of the last send command for player process; Double_tfLastRWSendTimetimestamp of the last send command for file reads/writes; map<UInt_t,MonitoredTFileInfo*>*fMonInfoRepo! repo to gather per-file-instance mon info;; Int_tfPid! process id; Int_tfReportIntervalinterval after which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is ",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:9861,Energy Efficiency,monitor,monitoring,9861,"ter which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:10337,Energy Efficiency,monitor,monitoring,10337,"it(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual no",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:10708,Energy Efficiency,monitor,monitoring,10708,"_Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the proc",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:10842,Energy Efficiency,monitor,monitoring,10842,"ion is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus0",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:11188,Energy Efficiency,monitor,monitoring,11188,"<nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus050.cern.ch"");; Once when you create an analysis task, execute; gMonitoringWriter->SendInfoUser(""myname"");; gMonitoringWriter->SendInfoDescription(""My first Higgs analysis"");; gMonitoringWriter->SendInfoTime();; gMonitoringWriter->SendInfoStatus(""Submitted"");. On each node executing a subtask, you ",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:358,Integrability,interface,interface,358,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:10525,Modifiability,variab,variables,10525,"ing the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environme",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:10958,Modifiability,variab,variable,10958,"onality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus050.cern.ch"");; Once when you create an analysis task, execute; gMonitoringWriter->SendInfoUser(""myname""",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:11529,Modifiability,variab,variable,11529," - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus050.cern.ch"");; Once when you create an analysis task, execute; gMonitoringWriter->SendInfoUser(""myname"");; gMonitoringWriter->SendInfoDescription(""My first Higgs analysis"");; gMonitoringWriter->SendInfoTime();; gMonitoringWriter->SendInfoStatus(""Submitted"");. On each node executing a subtask, you can set the status of this subtask:; gMonitoringWriter->SendProcessingStatus(""Started"");; During the processing of your analysis you can send progress updates:; gMonitoringWriter->SendProcessProgress(100,1000000); <= 100 events, 1MB processed. gMonitoringWriter-SendProcessingStatus(""Finished"");; delete gMonitoringWriter; gMonitoringWriter=0;. Example of use for any Generic Monitoring information:; TList *valuelist = new TList();; valuelist->SetOw",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:802,Performance,optimiz,optimized,802,". TMonaLisaWriter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:1101,Performance,throughput,throughput,1101,"ource. Sections:; class description; function members; data members; class charts. ROOT; » NET; » MONALISA; » TMonaLisaWriter. class TMonaLisaWriter: public TVirtualMonitoringWriter. TMonaLisaWriter. Class defining interface to MonaLisa Monitoring Services in ROOT.; The TMonaLisaWriter object is used to send monitoring information to; a MonaLisa server using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods); public:. TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """,MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:1542,Performance,latency,latency,1542,"rver using the ML ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_c-2.2.0.tar.gz. The ROOT implementation is primary optimized for process/job; monitoring, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods); public:. TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); virtual~TMonaLisaWriter(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newnam",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:1873,Performance,perform,performance,1873,"ng, although all other generic MonaLisa ApMon functionality; can be exploited through the ApMon class directly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods); public:. TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); virtual~TMonaLisaWriter(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TO",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:1939,Performance,perform,performance,1939,"ctly via; dynamic_cast<TMonaLisaWriter*>(gMonitoringWriter)->GetApMon(). Additions/modifications by Fabrizio Furano 10/04/2008; - The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; - Now TMonaLisaWriter keeps internally track of every activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; - Additionally, it's now finalized the infrastructure able to measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; - Now, the hook for the Close() func triggers sending of a packet; containing various information about the performance related to that; file only.; - Added support also for performance monitoring when writing. Function Members (Methods); public:. TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); virtual~TMonaLisaWriter(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtua",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:8420,Performance,throughput,throughputs,8420,"ntag, const char* monid, const char* monsubid, const char* option); TMonaLisaWriter&operator=(const TMonaLisaWriter&); Bool_tSendFileCheckpoint(TFile* file). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title; TList*TVirtualMonitoringWriter::fTmpOpenPhasesTo store open phases when there is not yet an object. private:. ApMon*fApmon! connection to MonaLisa; TStopwatchfFileStopwatchtime measurements for data access throughputs; TStringfHostname! hostname of MonaLisa server; Bool_tfInitializedtrue if initialized; TStringfJobId! job id; Double_tfLastFCloseSendTimeIn order not to flood ML servers; time_tfLastProgressTimetimestamp of the last send command for player process; Double_tfLastRWSendTimetimestamp of the last send command for file reads/writes; map<UInt_t,MonitoredTFileInfo*>*fMonInfoRepo! repo to gather per-file-instance mon info;; Int_tfPid! process id; Int_tfReportIntervalinterval after which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:9835,Performance,optimiz,optimized,9835,"ter which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download__ApMon.html,; current version:; http://monalisa.cacr.caltech.edu/download/apmon/ApMon_cpp-2.0.6.tar.gz. The ROOT implementation is primary optimized for process/job monitoring,; although all other generic MonaLisa ApMon functionality can be exploited; through the ApMon class directly (gMonitoringWriter->GetApMon()). Monitoring information in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:11030,Performance,load,loaded,11030,"formation in MonaLisa is structured in the following tree; structure:; <farmname>; |; ---> <nodename1>; |; ---> <key1> - <value1>; ---> <key2> - <value2>; ---> <nodename2>; |; ---> <key3> - <value3>; ---> <key4> - <value4>. The parameter monid is equivalent to the MonaLisa node name, for the; case of process monitoring it can be just an identifier to classify; the type of jobs e.g. ""PROOF_PROCESSING"".; If monid is not specified, TMonaLisaWriter tries to set it in this order; from environement variables:; - PROOF_JOB_ID; - GRID_JOB_ID; - LCG_JOB_ID; - ALIEN_MASTERJOB_ID; - ALIEN_PROC_ID. The parameter montag is equivalent to the MonaLisa farm name, for the; case of process monitoring it can be a process identifier e.g. a PROOF; session ID. The parameter monserver specifies the server to whom to send the; monitoring UDP packets. If not specified, the hostname (the port is; a default one) is specified in the environment variable APMON_CONFIG. To use TMonaLisaWriter, libMonaLisa.so has to be loaded. According to the fact, that the deepness of the MonaLisa naming scheme; is only 3 (<farm><node><value>), a special naming scheme is used for; process monitoring. There is a high-level method to send progress; information of Tree analysis (# of events, datasize).; To distinguish individual nodes running the processing, part of the; information is kept in the <value> parameter of ML.; <value> is named as:; <site-name>:<host-name>:<pid>:<valuetag>; <site-name> is taken from an environment variable in the following order:; - PROOF_SITE; - GRID_SITE; - ALIEN_SITE; - default 'none'; <host-name> is taken from gSystem->Hostname(); <pid> is the process ID of the ROOT process. Example of use for Process Monitoring:; new TMonaLisaWriter(""BATCH_ANALYSIS"",""AnalysisLoop-00001"",""lxplus050.cern.ch"");; Once when you create an analysis task, execute; gMonitoringWriter->SendInfoUser(""myname"");; gMonitoringWriter->SendInfoDescription(""My first Higgs analysis"");; gMonitoringWriter->SendInfoTime(",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:8413,Security,access,access,8413,"ntag, const char* monid, const char* monsubid, const char* option); TMonaLisaWriter&operator=(const TMonaLisaWriter&); Bool_tSendFileCheckpoint(TFile* file). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title; TList*TVirtualMonitoringWriter::fTmpOpenPhasesTo store open phases when there is not yet an object. private:. ApMon*fApmon! connection to MonaLisa; TStopwatchfFileStopwatchtime measurements for data access throughputs; TStringfHostname! hostname of MonaLisa server; Bool_tfInitializedtrue if initialized; TStringfJobId! job id; Double_tfLastFCloseSendTimeIn order not to flood ML servers; time_tfLastProgressTimetimestamp of the last send command for player process; Double_tfLastRWSendTimetimestamp of the last send command for file reads/writes; map<UInt_t,MonitoredTFileInfo*>*fMonInfoRepo! repo to gather per-file-instance mon info;; Int_tfPid! process id; Int_tfReportIntervalinterval after which to send the latest value; TStopwatchfStopwatchcpu and time measurement for job and proc status; TStringfSubJobId! sub job id; Bool_tfVerboseverbocity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonaLisaWriter(const char* monserver, const char* montag, const char* monid = 0, const char* monsubid = 0, const char* option = """"); Create MonaLisa write object. void Init(const char* monserver, const char* montag, const char* monid, const char* monsubid, const char* option); Creates a TMonaLisaWriter object to send monitoring information to a; MonaLisa server using the MonaLisa ApMon package (libapmoncpp.so/UDP; packets). The MonaLisa ApMon library for C++ can be downloaded at; http://monalisa.cacr.caltech.edu/monalisa__Download",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:6517,Testability,log,loglevel,6517,"t char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual Bool_tSendFileCloseEvent(TFile* file); virtual Bool_tSendFileOpenProgress(TFile* file, TList* openphases, const char* openphasename, Bool_t forcesend = kFALSE); virtual Bool_tSendFileReadProgress(TFile* file); virtual Bool_tSendFileWriteProgress(TFile* file); virtual Bool_tSendInfoDescription(const char* jobtag); virtual Bool_tSendInfoStatus(const char* status); virtual Bool_tSendInfoTime(); virtual Bool_tSendInfoUser(const char* user = 0); virtual Bool_tSendParameters(TList* valuelist, const char* identifier = 0); virtual Bool_tSendProcessingProgress(Double_t nevent, Double_t nbytes, Bool_t force = kFALSE); virtual Bool_tSendProcessingStatus(const char* status, Bool_t restarttimer = kFALSE); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetLogLevel(const char* loglevel = ""WARNING""); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidVerbose(Bool_t onoff); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:14975,Testability,log,loglevel,14975,"'time' = >unixtimestamp<. Bool_t SendProcessingStatus(const char* status, Bool_t restarttimer = kFALSE); Send the procesing status 'status' to MonaLisa following the; processing scheme:; <site> --> <jobid> --> 'status' = <status>; Used, to set the processing status of individual subtaks e.g. the; status of a batch (sub-)job or the status of a PROOF slave; participating in query <jobid>. Bool_t SendProcessingProgress(Double_t nevent, Double_t nbytes, Bool_t force = kFALSE); Send the procesing progress to MonaLisa. Bool_t SendFileOpenProgress(TFile* file, TList* openphases, const char* openphasename, Bool_t forcesend = kFALSE); Send the fileopen progress to MonaLisa.; If openphases=0 it means that the information is to be stored; in a temp space, since there is not yet an object where to attach it to.; This is typical in the static Open calls.; The temp openphases are put into a list as soon as one is specified. If thisopenphasename=0 it means that the stored phases (temp and object); have to be cleared. Bool_t SendFileCloseEvent(TFile* file). Bool_t SendFileReadProgress(TFile* file). Bool_t SendFileWriteProgress(TFile* file). Bool_t SendFileCheckpoint(TFile* file). Bool_t SendParameters(TList* valuelist, const char* identifier = 0); Send the parameters to MonaLisa. void SetLogLevel(const char* loglevel = ""WARNING""); Set MonaLisa log level. void Print(Option_t* option = """") const; Print info about MonaLisa object. TMonaLisaValue& operator=(const TMonaLisaWriter& ). TMonaLisaWriter(const TMonaLisaWriter& ). ApMon * GetApMon() const; { return fApmon; }. void Verbose(Bool_t onoff); { fVerbose = onoff; }. » Author: Andreas Peters 5/10/2005 » Copyright (C) 1995-2006, Rene Brun and Fons Rademakers. *; » Last changed: root/monalisa:$Id: TMonaLisaWriter.h 23209 2008-04-14 13:25:09Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:15011,Testability,log,log,15011,"'time' = >unixtimestamp<. Bool_t SendProcessingStatus(const char* status, Bool_t restarttimer = kFALSE); Send the procesing status 'status' to MonaLisa following the; processing scheme:; <site> --> <jobid> --> 'status' = <status>; Used, to set the processing status of individual subtaks e.g. the; status of a batch (sub-)job or the status of a PROOF slave; participating in query <jobid>. Bool_t SendProcessingProgress(Double_t nevent, Double_t nbytes, Bool_t force = kFALSE); Send the procesing progress to MonaLisa. Bool_t SendFileOpenProgress(TFile* file, TList* openphases, const char* openphasename, Bool_t forcesend = kFALSE); Send the fileopen progress to MonaLisa.; If openphases=0 it means that the information is to be stored; in a temp space, since there is not yet an object where to attach it to.; This is typical in the static Open calls.; The temp openphases are put into a list as soon as one is specified. If thisopenphasename=0 it means that the stored phases (temp and object); have to be cleared. Bool_t SendFileCloseEvent(TFile* file). Bool_t SendFileReadProgress(TFile* file). Bool_t SendFileWriteProgress(TFile* file). Bool_t SendFileCheckpoint(TFile* file). Bool_t SendParameters(TList* valuelist, const char* identifier = 0); Send the parameters to MonaLisa. void SetLogLevel(const char* loglevel = ""WARNING""); Set MonaLisa log level. void Print(Option_t* option = """") const; Print info about MonaLisa object. TMonaLisaValue& operator=(const TMonaLisaWriter& ). TMonaLisaWriter(const TMonaLisaWriter& ). ApMon * GetApMon() const; { return fApmon; }. void Verbose(Bool_t onoff); { fVerbose = onoff; }. » Author: Andreas Peters 5/10/2005 » Copyright (C) 1995-2006, Rene Brun and Fons Rademakers. *; » Last changed: root/monalisa:$Id: TMonaLisaWriter.h 23209 2008-04-14 13:25:09Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonaLisaWriter.html:14670,Usability,clear,cleared,14670,"cheme; <site> --> <jobid> --> 'time' = >unixtimestamp<. Bool_t SendProcessingStatus(const char* status, Bool_t restarttimer = kFALSE); Send the procesing status 'status' to MonaLisa following the; processing scheme:; <site> --> <jobid> --> 'status' = <status>; Used, to set the processing status of individual subtaks e.g. the; status of a batch (sub-)job or the status of a PROOF slave; participating in query <jobid>. Bool_t SendProcessingProgress(Double_t nevent, Double_t nbytes, Bool_t force = kFALSE); Send the procesing progress to MonaLisa. Bool_t SendFileOpenProgress(TFile* file, TList* openphases, const char* openphasename, Bool_t forcesend = kFALSE); Send the fileopen progress to MonaLisa.; If openphases=0 it means that the information is to be stored; in a temp space, since there is not yet an object where to attach it to.; This is typical in the static Open calls.; The temp openphases are put into a list as soon as one is specified. If thisopenphasename=0 it means that the stored phases (temp and object); have to be cleared. Bool_t SendFileCloseEvent(TFile* file). Bool_t SendFileReadProgress(TFile* file). Bool_t SendFileWriteProgress(TFile* file). Bool_t SendFileCheckpoint(TFile* file). Bool_t SendParameters(TList* valuelist, const char* identifier = 0); Send the parameters to MonaLisa. void SetLogLevel(const char* loglevel = ""WARNING""); Set MonaLisa log level. void Print(Option_t* option = """") const; Print info about MonaLisa object. TMonaLisaValue& operator=(const TMonaLisaWriter& ). TMonaLisaWriter(const TMonaLisaWriter& ). ApMon * GetApMon() const; { return fApmon; }. void Verbose(Bool_t onoff); { fVerbose = onoff; }. » Author: Andreas Peters 5/10/2005 » Copyright (C) 1995-2006, Rene Brun and Fons Rademakers. *; » Last changed: root/monalisa:$Id: TMonaLisaWriter.h 23209 2008-04-14 13:25:09Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please",MatchSource.WIKI,root/html530/TMonaLisaWriter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonaLisaWriter.html
https://root.cern/root/html530/TMonitor.html:4046,Availability,error,error,4046,"* params); voidTQObject::Emit(const char* signal, Double_t param); voidTQObject::Emit(const char* signal, Long_t param); voidTQObject::Emit(const char* signal, Long64_t param); voidTQObject::Emit(const char* signal, Bool_t param); voidTQObject::Emit(const char* signal, Char_t param); voidTQObject::Emit(const char* signal, UChar_t param); voidTQObject::Emit(const char* signal, Short_t param); voidTQObject::Emit(const char* signal, UShort_t param); voidTQObject::Emit(const char* signal, Int_t param); voidTQObject::Emit(const char* signal, UInt_t param); voidTQObject::Emit(const char* signal, ULong_t param); voidTQObject::Emit(const char* signal, ULong64_t param); voidTQObject::Emit(const char* signal, Float_t param); voidTQObject::EmitVA(const char* signal, Int_t nargs); voidTQObject::EmitVA(const char* signal, Int_t nargs, va_list va); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetActive(Long_t timeout = -1) const; Int_tGetDeActive() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TList*GetListOfActives() const; TList*TQObject::GetListOfClassSignals() const; TList*TQObject::GetListOfConnections() const; TList*GetListOfDeActives() const; TList*TQObject::GetListOfSignals() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:4130,Availability,error,error,4130,"t(const char* signal, Long_t param); voidTQObject::Emit(const char* signal, Long64_t param); voidTQObject::Emit(const char* signal, Bool_t param); voidTQObject::Emit(const char* signal, Char_t param); voidTQObject::Emit(const char* signal, UChar_t param); voidTQObject::Emit(const char* signal, Short_t param); voidTQObject::Emit(const char* signal, UShort_t param); voidTQObject::Emit(const char* signal, Int_t param); voidTQObject::Emit(const char* signal, UInt_t param); voidTQObject::Emit(const char* signal, ULong_t param); voidTQObject::Emit(const char* signal, ULong64_t param); voidTQObject::Emit(const char* signal, Float_t param); voidTQObject::EmitVA(const char* signal, Int_t nargs); voidTQObject::EmitVA(const char* signal, Int_t nargs, va_list va); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetActive(Long_t timeout = -1) const; Int_tGetDeActive() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TList*GetListOfActives() const; TList*TQObject::GetListOfClassSignals() const; TList*TQObject::GetListOfConnections() const; TList*GetListOfDeActives() const; TList*TQObject::GetListOfSignals() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTi",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10746,Availability,mask,mask,10746,"ll signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to s",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11667,Availability,error,error,11667,"write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12057,Availability,error,error,12057," readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send som",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12288,Availability,error,error,12288,"ivated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check i",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:321,Energy Efficiency,monitor,monitors,321,". TMonitor. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » NET; » TMonitor. class TMonitor: public TObject, public TQObject. TMonitor. This class monitors activity on a number of network sockets.; The actual monitoring is done by TSystem::DispatchOneEvent().; Typical usage: create a TMonitor object. Register a number of; TSocket objects and call TMonitor::Select(). Select() returns the; socket object which has data waiting. TSocket objects can be added,; removed, (temporary) enabled or disabled. Function Members (Methods); public:. TMonitor(Bool_t mainloop = kTRUE); TMonitor(const TMonitor& m); virtual~TMonitor(); voidTObject::AbstractMethod(const char* method) const; virtual voidActivate(TSocket* sock); virtual voidActivateAll(); virtual voidAdd(TSocket* sock, Int_t interest = kRead); virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTObject::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const char* slot); static Bool_tTQObject::Connect(TQObject* sender, const char* signal, const char* receiver_class, void* receiver, const char* slot); static Bool_tTQObject::Connect(const char* sender_class, const char* signal, const char* receiver_class, void* receiver, const char* slot); virtual voidT",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:383,Energy Efficiency,monitor,monitoring,383,". TMonitor. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » NET; » NET; » TMonitor. class TMonitor: public TObject, public TQObject. TMonitor. This class monitors activity on a number of network sockets.; The actual monitoring is done by TSystem::DispatchOneEvent().; Typical usage: create a TMonitor object. Register a number of; TSocket objects and call TMonitor::Select(). Select() returns the; socket object which has data waiting. TSocket objects can be added,; removed, (temporary) enabled or disabled. Function Members (Methods); public:. TMonitor(Bool_t mainloop = kTRUE); TMonitor(const TMonitor& m); virtual~TMonitor(); voidTObject::AbstractMethod(const char* method) const; virtual voidActivate(TSocket* sock); virtual voidActivateAll(); virtual voidAdd(TSocket* sock, Int_t interest = kRead); virtual voidTObject::AppendPad(Option_t* option = """"); static Bool_tTQObject::AreAllSignalsBlocked(); Bool_tTQObject::AreSignalsBlocked() const; static Bool_tTQObject::BlockAllSignals(Bool_t b); Bool_tTQObject::BlockSignals(Bool_t b); virtual voidTObject::Browse(TBrowser* b); virtual voidTQObject::ChangedBy(const char* method)SIGNAL ; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; voidTQObject::CollectClassSignalLists(TList& list, TClass* cls); virtual Int_tTObject::Compare(const TObject* obj) const; Bool_tTQObject::Connect(const char* signal, const char* receiver_class, void* receiver, const char* slot); static Bool_tTQObject::Connect(TQObject* sender, const char* signal, const char* receiver_class, void* receiver, const char* slot); static Bool_tTQObject::Connect(const char* sender_class, const char* signal, const char* receiver_class, void* receiver, const char* slot); virtual voidT",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:9781,Energy Efficiency,monitor,monitor,9781," voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). private:. virtual void*GetSender(); voidSetReady(TSocket* sock). Data Members; public:. enum EInterest { kRead; kWrite; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to mo",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:9912,Energy Efficiency,monitor,monitoring,9912," voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual const char*TQObject::GetSenderClassName() const; voidTObject::MakeZombie(). private:. virtual void*GetSender(); voidSetReady(TSocket* sock). Data Members; public:. enum EInterest { kRead; kWrite; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to mo",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10153,Energy Efficiency,monitor,monitor,10153," Members; public:. enum EInterest { kRead; kWrite; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. voi",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10193,Energy Efficiency,monitor,monitoring,10193,"ts { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10314,Energy Efficiency,monitor,monitor,10314,"lidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivat",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10360,Energy Efficiency,monitor,monitored,10360,"kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. v",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10438,Energy Efficiency,monitor,monitor,10438," kWriteDelete; };. protected:. TList*TQObject::fListOfConnections! list of connections to this object; TList*TQObject::fListOfSignals! list of signals from this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket *",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10496,Energy Efficiency,monitor,monitor,10496,"rom this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handl",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10563,Energy Efficiency,monitor,monitor,10563,"rom this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handl",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10637,Energy Efficiency,monitor,monitor,10637,"rom this object; Bool_tTQObject::fSignalsBlocked! flag used for suppression of signals; static Bool_tTQObject::fgAllSignalsBlockedflag used for suppression of all signals. private:. TList*fActivelist of sockets to monitor; TList*fDeActivelist of (temporary) disabled sockets; Bool_tfInterruptflags an interrupt to Select; Bool_tfMainLooptrue if monitoring sockets within the main event loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handl",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10881,Energy Efficiency,monitor,monitor,10881," loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:10948,Energy Efficiency,monitor,monitor,10948," loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11022,Energy Efficiency,monitor,monitor,11022," loop; TSocket*fReadysocket which is ready to be read or written. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11114,Energy Efficiency,monitor,monitor,11114,"on documentation; TMonitor(Bool_t mainloop = kTRUE); Create a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TLis",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11169,Energy Efficiency,monitor,monitor,11169,"e a monitor object. If mainloop is true the monitoring will be; done in the main event loop. TMonitor(const TMonitor& m); Copy constructor. ~TMonitor(); Cleanup the monitor object. Does not delete sockets being monitored. void Add(TSocket* sock, Int_t interest = kRead); Add socket to the monitor's active list. If interest=kRead then we; want to monitor the socket for read readiness, if interest=kWrite; then we monitor the socket for write readiness, if interest=kRead|kWrite; then we monitor both read and write readiness. void SetInterest(TSocket* sock, Int_t interest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:13601,Energy Efficiency,monitor,monitor,13601,"e also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. void Ready(TSocket* sock); Emit signal when some socket is ready. void * GetSender(); { return this; }. void Interrupt(); { fInterrupt = kTRUE; }. void ResetInterrupt(); { fInterrupt = kFALSE; }. » Author: Fons Rademakers 09/01/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/net:$Id: TMonitor.h 31598 2009-12-07 15:21:47Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:13827,Energy Efficiency,monitor,monitor,13827,"e also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. void Ready(TSocket* sock); Emit signal when some socket is ready. void * GetSender(); { return this; }. void Interrupt(); { fInterrupt = kTRUE; }. void ResetInterrupt(); { fInterrupt = kFALSE; }. » Author: Fons Rademakers 09/01/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/net:$Id: TMonitor.h 31598 2009-12-07 15:21:47Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12557,Integrability,rout,routine,12557," with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will ",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:4430,Safety,timeout,timeout,4430,"t param); voidTQObject::Emit(const char* signal, UShort_t param); voidTQObject::Emit(const char* signal, Int_t param); voidTQObject::Emit(const char* signal, UInt_t param); voidTQObject::Emit(const char* signal, ULong_t param); voidTQObject::Emit(const char* signal, ULong64_t param); voidTQObject::Emit(const char* signal, Float_t param); voidTQObject::EmitVA(const char* signal, Int_t nargs); voidTQObject::EmitVA(const char* signal, Int_t nargs, va_list va); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetActive(Long_t timeout = -1) const; Int_tGetDeActive() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TList*GetListOfActives() const; TList*TQObject::GetListOfClassSignals() const; TList*TQObject::GetListOfConnections() const; TList*GetListOfDeActives() const; TList*TQObject::GetListOfSignals() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTQObject::HasConnection(const char* signal_name) const; virtual ULong_tTObject::Hash() const; virtual voidTQObject::HighPriority(const char* signal_name, const char* slot_name = 0); virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObje",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:7460,Safety,timeout,timeout,7460,"::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidReady(TSocket* sock)SIGNAL ; virtual voidTObject::RecursiveRemove(TObject* obj); virtual voidRemove(TSocket* sock); virtual voidRemoveAll(); voidTObject::ResetBit(UInt_t f); voidResetInterrupt(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); TSocket*Select(); TSocket*Select(Long_t timeout); Int_tSelect(TList* rdready, TList* wrready, Long_t timeout); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetInterest(TSocket* sock, Int_t interest = kRead); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:7521,Safety,timeout,timeout,7521,"::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidReady(TSocket* sock)SIGNAL ; virtual voidTObject::RecursiveRemove(TObject* obj); virtual voidRemove(TSocket* sock); virtual voidRemoveAll(); voidTObject::ResetBit(UInt_t f); voidResetInterrupt(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); TSocket*Select(); TSocket*Select(Long_t timeout); Int_tSelect(TList* rdready, TList* wrready, Long_t timeout); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetInterest(TSocket* sock, Int_t interest = kRead); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11698,Safety,timeout,timeout,11698,"rest = kRead); Set interest mask for socket sock to interest. If the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) con",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11783,Safety,timeout,timeout,11783,"the socket is not; in the active list move it or add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, r",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:11826,Safety,timeout,timeout,11826," add it there.; If interest=kRead then we want to monitor the socket for read readiness,; if interest=kWrite then we monitor the socket for write readiness,; if interest=kRead|kWrite then we monitor both read and write readiness. void Remove(TSocket* sock); Remove a socket from the monitor. void RemoveAll(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12126,Safety,timeout,timeout,12126,"l(); Remove all sockets from the monitor. void Activate(TSocket* sock); Activate a de-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12220,Safety,timeout,timeout,12220,"e-activated socket. void ActivateAll(); Activate all de-activated sockets. void DeActivate(TSocket* sock); De-activate a socket. void DeActivateAll(); De-activate all activated sockets. TSocket * Select(); Return pointer to socket for which an event is waiting.; Select can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of error. TSocket * Select(Long_t timeout); Return pointer to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12701,Safety,timeout,timeout,12701,"r to socket for which an event is waiting.; Wait a maximum of timeout milliseconds.; If return is due to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12770,Safety,timeout,timeout,12770,"e to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used b",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12857,Safety,timeout,timeout,12857,"e to timeout it returns (TSocket *)-1.; Select() can be interrupt by a call to Interrupt() (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used b",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:12880,Safety,timeout,timeout,12880," (e.g. connected with a; Ctrl-C handler); a call to ResetInterrupt() before Select() is advisable; in such a case.; Return 0 in case of any other error situation. Int_t Select(TList* rdready, TList* wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. void Ready(TSocket* sock); Emit signal when some socket is ready. void * Ge",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMonitor.html:13074,Safety,timeout,timeout,13074," wrready, Long_t timeout); Return numbers of sockets that are ready for reading or writing.; Wait a maximum of timeout milliseconds.; Return 0 if timed-out. Return < 0 in case of error.; If rdready and/or wrready are not 0, the lists of sockets with; something to read and/or write are also returned. void SetReady(TSocket* sock); Called by TSocketHandler::Notify() to signal which socket is ready; to be read or written. User should not call this routine. The ready; socket will be returned via the Select() user function.; The Ready(TSocket *sock) signal is emitted. Int_t GetActive(Long_t timeout = -1) const; Return number of sockets in the active list. If timeout > 0, remove from; the list those sockets which did not have any activity since timeout; millisecs. If timeout = 0, then reset activity timestamp on all active; sockets. This time out is typically used if GetActive() is used to see; how many remotes still need to send something. If they pass the timeout; they will be skipped and GetActive() will return 0 and the loop can be; exited. Int_t GetDeActive() const; Return number of sockets in the de-active list. Bool_t IsActive(TSocket* s) const; Check if socket 's' is in the active list. Avoids the duplication; of active list via TMonitor::GetListOfActives(). TList * GetListOfActives() const; Returns a list with all active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. TList * GetListOfDeActives() const; Returns a list with all de-active sockets. This list must be deleted; by the user. DO NOT call Delete() on this list as it will delete; the sockets that are still being used by the monitor. void Ready(TSocket* sock); Emit signal when some socket is ready. void * GetSender(); { return this; }. void Interrupt(); { fInterrupt = kTRUE; }. void ResetInterrupt(); { fInterrupt = kFALSE; }. » Author: Fons Rademakers 09/01/97 » Copyright (C) 1995-2000, Rene Brun and F",MatchSource.WIKI,root/html530/TMonitor.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMonitor.html
https://root.cern/root/html530/TMultiDimFit.html:1086,Availability,reliab,reliably,1086," Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:1808,Availability,error,errors,1808," which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2514,Availability,error,error,2514,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3084,Availability,error,error,3084,"wo excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only i",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:9464,Availability,error,errors,9464," difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a trac",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11962,Availability,error,error,11962,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12104,Availability,error,error,12104,"ng themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Da",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:14746,Availability,error,error,14746,"e_t E = 0); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """")MENU ; virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* = ""d""); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEval(const Double_t* x, const Double_t* coeff = 0) const; virtual Double_tEvalError(const Double_t* x, const Double_t* coeff = 0) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidFindParameterization(Option_t* option = """")MENU ; virtual voidFit(Option_t* option = """")MENU ; Double_tGetChi2() const; const TVectorD*GetCoefficients() const; const TMatrixD*GetCorrelationMatrix() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetError() const; Int_t*GetFunctionCodes() const; const TMatrixD*GetFunctions() const; virtual TList*GetHistograms() const; virtual const char*TObject::GetIconName() const; Double_tGetMaxAngle() const; Int_tGetMaxFunctions() const; Int_t*GetMaxPowers() const; Double_tGetMaxQuantity(",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:14830,Availability,error,error,14830,"e(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """")MENU ; virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* = ""d""); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEval(const Double_t* x, const Double_t* coeff = 0) const; virtual Double_tEvalError(const Double_t* x, const Double_t* coeff = 0) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual voidFindParameterization(Option_t* option = """")MENU ; virtual voidFit(Option_t* option = """")MENU ; Double_tGetChi2() const; const TVectorD*GetCoefficients() const; const TMatrixD*GetCorrelationMatrix() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetError() const; Int_t*GetFunctionCodes() const; const TMatrixD*GetFunctions() const; virtual TList*GetHistograms() const; virtual const char*TObject::GetIconName() const; Double_tGetMaxAngle() const; Int_tGetMaxFunctions() const; Int_t*GetMaxPowers() const; Double_tGetMaxQuantity() const; Int_tGetMaxStudy() const; Int_tGetMaxTerms() const; const TVectorD*GetMaxVa",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:19644,Availability,error,error,19644," sz); void*TObject::operator new[](size_t sz, void* vp); TMultiDimFit&operator=(const TMultiDimFit&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* option = ""ps"") constMENU ; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBinVarX(Int_t nbbinvarx); voidSetBinVarY(Int_t nbbinvary); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxAngle(Double_t angle = 0); voidSetMaxFunctions(Int_t n); voidSetMaxPowers(const Int_t* powers); voidSetMaxStudy(Int_t n); voidSetMaxTerms(Int_t terms); voidSetMinAngle(Double_t angle = 1); voidSetMinRelativeError(Double_t error); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); voidSetPowerLimit(Double_t limit = 1e-3); virtual voidSetPowers(const Int_t* powers, Int_t terms); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23169,Availability,error,error,23169,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24264,Availability,error,error,24264,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25630,Availability,error,error,25630,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25912,Availability,error,error,25912," Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25973,Availability,error,error,25973," Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26238,Availability,error,error,26238,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26427,Availability,error,error,26427," Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameter",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26488,Availability,error,error,26488," Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameter",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27034,Availability,error,error,27034,"value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); C",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:28929,Availability,error,errors,28929,"on. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoefficients; Double_t gDMean; Double_t gXMean[]; Double_t gXMin[]; Double_t gXMax[]; Double_t gCoefficient[]; Int_t gPower[]. are initialized. The only ROOT header file needed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34292,Availability,error,error,34292,". See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions() const; { return fMaxFunctions; }. Int_t* GetMaxPowers() const; { return fMaxPowers; }. Double_t GetMaxQuantity() const; { return fMaxQuantity; }. Int_",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34328,Availability,error,error,34328,". See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions() const; { return fMaxFunctions; }. Int_t* GetMaxPowers() const; { return fMaxPowers; }. Double_t GetMaxQuantity() const; { return fMaxQuantity; }. Int_",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:540,Energy Efficiency,energy,energy,540,". TMultiDimFit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:595,Energy Efficiency,charge,charged,595,". TMultiDimFit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3245,Energy Efficiency,power,powers,3245,"uantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3850,Energy Efficiency,power,power,3850,"(or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3993,Energy Efficiency,power,power,3993," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4112,Energy Efficiency,power,power,4112,"d when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4134,Energy Efficiency,power,power,4134,"d when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4397,Energy Efficiency,power,power,4397,"ways when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4509,Energy Efficiency,power,power,4509,"lways possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4689,Energy Efficiency,reduce,reduce,4689,"axTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4786,Energy Efficiency,reduce,reduce,4786,"axTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:8699,Energy Efficiency,reduce,reduced,8699,"tly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12374,Energy Efficiency,reduce,reduced,12374," from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(co",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12493,Energy Efficiency,reduce,reduced,12493," from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(co",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:19509,Energy Efficiency,power,powers,19509,"oid*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMultiDimFit&operator=(const TMultiDimFit&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* option = ""ps"") constMENU ; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBinVarX(Int_t nbbinvarx); voidSetBinVarY(Int_t nbbinvary); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxAngle(Double_t angle = 0); voidSetMaxFunctions(Int_t n); voidSetMaxPowers(const Int_t* powers); voidSetMaxStudy(Int_t n); voidSetMaxTerms(Int_t terms); voidSetMinAngle(Double_t angle = 1); voidSetMinRelativeError(Double_t error); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); voidSetPowerLimit(Double_t limit = 1e-3); virtual voidSetPowers(const Int_t* powers, Int_t terms); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t opt",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:19900,Energy Efficiency,power,powers,19900," sz); void*TObject::operator new[](size_t sz, void* vp); TMultiDimFit&operator=(const TMultiDimFit&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* option = ""ps"") constMENU ; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBinVarX(Int_t nbbinvarx); voidSetBinVarY(Int_t nbbinvary); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxAngle(Double_t angle = 0); voidSetMaxFunctions(Int_t n); voidSetMaxPowers(const Int_t* powers); voidSetMaxStudy(Int_t n); voidSetMaxTerms(Int_t terms); voidSetMinAngle(Double_t angle = 1); voidSetMinRelativeError(Double_t error); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); voidSetPowerLimit(Double_t limit = 1e-3); virtual voidSetPowers(const Int_t* powers, Int_t terms); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:20787,Energy Efficiency,power,powers,20787,"oidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; virtual Double_tEvalControl(const Int_t* powers) const; virtual Double_tEvalFactor(Int_t p, Double_t x) const; virtual voidMakeCandidates(); virtual voidMakeCoefficientErrors(); virtual voidMakeCoefficients(); virtual voidMakeCorrelation(); virtual Double_tMakeGramSchmidt(Int_t function); virtual voidMakeNormalized(); virtual voidMakeParameterization(); virtual voidMakeRealCode(const char* filename, const char* classname, Option_t* option = """"); voidTObject::MakeZombie(); virtual Bool_tSelect(const Int_t* iv); virtual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrix",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22564,Energy Efficiency,power,powers,22564,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22615,Energy Efficiency,power,powers,22615,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23837,Energy Efficiency,power,powers,23837,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27196,Energy Efficiency,power,powers,27196,"lly, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27276,Energy Efficiency,power,powers,27276,"lly, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27372,Energy Efficiency,power,power,27372," This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:31649,Energy Efficiency,power,powers,31649,"method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""p",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:32855,Energy Efficiency,power,powers,32855,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:32922,Energy Efficiency,power,powers,32922,"eParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. voi",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:33579,Energy Efficiency,power,powers,33579,"mula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34150,Energy Efficiency,power,powers,34150,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34175,Energy Efficiency,power,power,34175,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:943,Integrability,depend,dependent,943,". TMultiDimFit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:1113,Integrability,depend,dependence,1113," Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:1319,Integrability,depend,dependent,1319,"ltiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2233,Integrability,depend,dependent,2233,"e; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified f",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2271,Integrability,depend,depends,2271,"e; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified f",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2478,Integrability,depend,dependent,2478,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4049,Integrability,depend,dependent,4049," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:5951,Integrability,depend,dependent,5951," will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspac",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10330,Integrability,depend,dependence,10330," (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameteri",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10498,Integrability,depend,dependent,10498,"inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11923,Integrability,depend,dependent,11923,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:21764,Integrability,depend,dependent,21764,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22666,Integrability,depend,dependent,22666,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22945,Integrability,depend,dependent,22945,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23111,Integrability,depend,dependent,23111,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24036,Integrability,depend,dependent,24036,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24374,Integrability,depend,dependent,24374,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24620,Integrability,depend,dependent,24620,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25583,Integrability,depend,dependent,25583,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25644,Integrability,depend,dependent,25644,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26002,Integrability,depend,dependent,26002," Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26191,Integrability,depend,dependent,26191,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26252,Integrability,depend,dependent,26252,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26517,Integrability,depend,dependent,26517," Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameter",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29753,Integrability,message,message,29753,"ed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29926,Integrability,depend,dependent,29926,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29993,Integrability,depend,dependent,29993,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:30088,Integrability,depend,dependent,30088,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:32764,Integrability,message,message,32764,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:1508,Modifiability,variab,variables,1508,"ty in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2444,Modifiability,variab,variables,2444,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2572,Modifiability,parameteriz,parameterization,2572,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:2705,Modifiability,variab,variable,2705,"l sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to pro",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3260,Modifiability,variab,variable,3260,"uantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:3867,Modifiability,variab,variable,3867,"Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The func",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4002,Modifiability,variab,variable,4002," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4518,Modifiability,variab,variable,4518,"lways possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:5527,Modifiability,variab,variables,5527,"e leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Bas",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:8810,Modifiability,parameteriz,parameterization,8810," of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolat",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:9915,Modifiability,variab,variables,9915,"the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a li",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10077,Modifiability,variab,variables,10077," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10118,Modifiability,variab,variables,10118," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10218,Modifiability,variab,variable,10218," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10372,Modifiability,variab,variables,10372," (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameteri",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11232,Modifiability,variab,variables,11232,"le as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlati",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11390,Modifiability,parameteriz,parameterization,11390,"the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; sam",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11652,Modifiability,parameteriz,parameterization,11652," Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevin",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11758,Modifiability,parameteriz,parameterization,11758,"e values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11901,Modifiability,variab,variables,11901,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12005,Modifiability,parameteriz,parameterization,12005," a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Fun",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:13044,Modifiability,parameteriz,parameterization,13044,"y ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(const TMultiDimFit&); TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); virtual~TMultiDimFit(); voidTObject::AbstractMethod(const char* method) const; virtual voidAddRow(const Double_t* x, Double_t D, Double_t E = 0); virtual voidAddTestRow(const Double_t* x, Double_t D, Double_t E = 0); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """")MENU ; virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTName",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:21723,Modifiability,variab,variables,21723,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:21774,Modifiability,variab,variables,21774,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22054,Modifiability,parameteriz,parameterization,22054,"l Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; unsigned charfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:22905,Modifiability,variab,variables,22905,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23013,Modifiability,variab,variables,23013,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23317,Modifiability,variab,variables,23317,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:23418,Modifiability,variab,variables,23418,,MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24780,Modifiability,variab,variables,24780,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24873,Modifiability,variab,variables,24873,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25560,Modifiability,variab,variables,25560,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25707,Modifiability,parameteriz,parameterization,25707,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:25742,Modifiability,variab,variables,25742,"dent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26168,Modifiability,variab,variables,26168,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26323,Modifiability,parameteriz,parameterization,26323,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26710,Modifiability,variab,variables,26710,"mple to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Opt",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26797,Modifiability,parameteriz,parameterization,26797,"ulated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27017,Modifiability,parameteriz,parameterization,27017,"value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); C",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27383,Modifiability,variab,variable,27383," This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27460,Modifiability,parameteriz,parameterization,27460,"ven Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementatio",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:28587,Modifiability,variab,variables,28587,"tion. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoefficients; Double_t gDMean; Double_t gXMean[]; Double_t gXMin[]; Double_t gXMax[]; Double_t gCoefficient[]; Int_t gPower[]. are initialized. The only ROOT header file needed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this a",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29836,Modifiability,parameteriz,parameterization,29836,"ed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29904,Modifiability,variab,variables,29904,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29936,Modifiability,variab,variables,29936,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:29972,Modifiability,variab,variables,29972,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:30003,Modifiability,variab,variables,30003,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:30057,Modifiability,variab,variables,30057,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:30098,Modifiability,variab,variable,30098,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:31238,Modifiability,variab,variables,31238,"method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""p",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:31954,Modifiability,parameteriz,parameterization,31954,"lized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For exa",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:32246,Modifiability,parameteriz,parameterization,32246,"assname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vec",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:32866,Modifiability,variab,variables,32866,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:33842,Modifiability,variab,variable,33842," is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; {",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34071,Modifiability,variab,variable,34071,"xAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fH",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:34219,Modifiability,variab,variable,34219,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:4020,Performance,perform,perform,4020," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:6564,Performance,perform,performed,6564,"r function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data ve",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:8150,Performance,perform,performing,8150," length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper tri",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:8551,Performance,perform,perform,8551,"tween ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the cu",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:9982,Performance,perform,perform,9982,"the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a li",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:6816,Testability,test,test,6816,"tain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically re",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:7265,Testability,test,test,7265,"is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from t",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:8173,Testability,test,test,8173," length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper tri",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11712,Testability,test,testing,11712,"e values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:11834,Testability,test,test,11834,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12059,Testability,test,test,12059," a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Fun",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12119,Testability,test,test,12119,"ng themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Da",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:12573,Testability,test,test,12573,"ermind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(const TMultiDimFit&); TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """");",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24530,Testability,test,test,24530,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24580,Testability,test,test,24580,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:24668,Testability,test,test,24668,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26279,Testability,test,test,26279,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:26311,Testability,test,test,26311,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:27666,Testability,test,test,27666,"he TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoeffic",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:28029,Testability,test,test,28029,"ff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoefficients; Double_t gDMean; Double_t gXMean[]; Double_t gXMin[]; Double_t gXMax[]; Double_t gCoefficient[]; Int_t gPower[]. are initialized. The only ROOT header file needed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature ",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:30175,Testability,test,test,30175,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiDimFit.html:10707,Usability,simpl,simple,10707,"sentive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functio",MatchSource.WIKI,root/html530/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiDimFit.html
https://root.cern/root/html530/TMultiGraph.html:7153,Availability,error,error,7153,"ject::AbstractMethod(const char* method) const; virtual voidAdd(TGraph* graph, Option_t* chopt = """"); virtual voidAdd(TMultiGraph* multigraph, Option_t* chopt = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* chopt = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual TFitResultPtrFit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); virtual TFitResultPtrFit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFuncti",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:7237,Availability,error,error,7237,"n_t* chopt = """"); virtual voidAdd(TMultiGraph* multigraph, Option_t* chopt = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* chopt = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual TFitResultPtrFit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); virtual TFitResultPtrFit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFunctions() const; TList*GetListOfGraphs() const; virtual const char*TNamed::GetName() con",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:14662,Availability,error,errors,14662," If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. Use GetDrawOption to return the option specified; when drawing the TMultiGraph. TFitResultPtr Fit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); Fit this graph with function with name fname. interface to TF1::Fit(TF1 *f1... TFitResultPtr Fit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); Fit this multigraph with function f1. In this function all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitted function to the list of fitted functions; (by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::P",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:15503,Availability,robust,robust,15503,"unction all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitted function to the list of fitted functions; (by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::Paint for a complete; list of these options. In order to use the Range option, one must first create a function; with the expression to be fitted. For example, if your graph; has a defined range between -4 and 4 and you want to fit a gaussian; only in the interval 1 to 3, you can do:; TF1 *f1 = new TF1(""f1"",""gaus"",1,3);; graph->Fit(""f1"",""R"");. who is calling this function. Note that this function is called when calling TGraphErrors::Fit; or TGraphAsymmErrors::Fit ot TGraphBentErrors::Fit; see the discussion below on the errors calulation. Setting initial conditions. Parameters must b",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:16320,Availability,error,errors,16320,"by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::Paint for a complete; list of these options. In order to use the Range option, one must first create a function; with the expression to be fitted. For example, if your graph; has a defined range between -4 and 4 and you want to fit a gaussian; only in the interval 1 to 3, you can do:; TF1 *f1 = new TF1(""f1"",""gaus"",1,3);; graph->Fit(""f1"",""R"");. who is calling this function. Note that this function is called when calling TGraphErrors::Fit; or TGraphAsymmErrors::Fit ot TGraphBentErrors::Fit; see the discussion below on the errors calulation. Setting initial conditions. Parameters must be initialized before invoking the Fit function.; The setting of the parameter initial values is automatic for the; predefined functions : poln, expo, gaus, landau. One can however disable; this automatic computation by specifying the option ""B"".; You can specify boundary limits for some or all parameters via; f1->SetParLimits(p_number, parmin, parmax);; if parmin>=parmax, the parameter is fixed; Note that you are not forced to fix the limits for all parameters.; For example, if you fit a function with 6 parameters, you can do:; func->SetParameters(0,3.1,1.e-6,0.1,-8,100);; func->SetParLimits(4,-10,-4);; func->SetParLimits(5, 1,1);; With this setup, parameters 0->3 can vary freely; Parameter 4 has boundaries [-10,-4] with initial value -8; Parameter 5 is fixed to 100. Fit range. The fit range can be specified in two ways:; - specify rxmax > rxmin (default is ",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:18576,Availability,error,error,18576,"::EvaluateChi2.; In case of TGraphErrors an effective chi2 is used; (see TGraphErrors fit in TGraph::Fit) and is implemented in; FitUtil::EvaluateChi2Effective; To specify a User defined fitting function, specify option ""U"" and; call the following functions:; TVirtualFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParErr",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:18743,Availability,error,error,18743,"lFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; prin",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:19521,Availability,error,error,19521,"GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel fo",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:19780,Availability,error,errors,19780,"e retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exp",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:19984,Availability,error,errors,19984,"ctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exponential. void InitPolynom(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a polynom. void LeastSquareFit(Int_t m, Double_t*",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:14192,Integrability,interface,interface,14192,"Multigraph is still active. void Add(TMultiGraph* multigraph, Option_t* chopt = """"); add all the graphs in ""multigraph"" to the list of graphs. void Browse(TBrowser* b); Browse multigraph. Int_t DistancetoPrimitive(Int_t px, Int_t py); Compute distance from point px,py to each graph. void Draw(Option_t* chopt = """"); Draw this multigraph with its current attributes. Options to draw a graph are described in TGraph::PaintGraph. The drawing option for each TGraph may be specified as an optional; second argument of the Add function. You can use GetGraphDrawOption; to return this option.; If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. Use GetDrawOption to return the option specified; when drawing the TMultiGraph. TFitResultPtr Fit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); Fit this graph with function with name fname. interface to TF1::Fit(TF1 *f1... TFitResultPtr Fit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); Fit this multigraph with function f1. In this function all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitt",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:21186,Integrability,rout,routine,21186,"NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exponential. void InitPolynom(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a polynom. void LeastSquareFit(Int_t m, Double_t* a, Double_t xmin, Double_t xmax); Least squares lpolynomial fitting without weights. m number of parameters; a array of parameters; first 1st point number to fit (default =0); last last point number to fit (default=fNpoints-1). based on CERNLIB routine LSQ: Translated to C++ by Rene Brun. void LeastSquareLinearFit(Int_t ndata, Double_t& a0, Double_t& a1, Int_t& ifail, Double_t xmin, Double_t xmax); Least square linear fit without weights. Fit a straight line (a0 + a1*x) to the data in this graph.; ndata: number of points to fit; first: first point number to fit; last: last point to fit O(ndata should be last-first; ifail: return parameter indicating the status of the fit (ifail=0, fit is OK). extracted from CERNLIB LLSQ: Translated to C++ by Rene Brun. Int_t IsInside(Double_t x, Double_t y) const; Return 1 if the point (x,y) is inside one of the graphs 0 otherwise. TH1F * GetHistogram() const; Returns a pointer to the histogram used to draw the axis; Takes into account the two following cases.; 1- option 'A' was specified in TMultiGraph::Draw. Return fHistogram; 2- user had called TPad::DrawFrame. return pointer to hframe histogram. TF1 * GetFunction(const char* name) const; Return pointer to function with name. Functions such as TGraph::",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:747,Performance,perform,performed,747,". TMultiGraph. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiGraph. class TMultiGraph: public TNamed. TMultiGraph class; A TMultiGraph is a collection of TGraph (or derived) objects. It allows to; manipulate a set of graphs as a single entity. In particular, when drawn,; the X and Y axis ranges are automatically computed such as all the graphs; will be visible. TMultiGraph::Add should be used to add a new graph to the list. The TMultiGraph owns the objects in the list. The drawing options are the same as for TGraph.; Like for TGraph, the painting is performed thanks to the; TGraphPainter; class. All details about the various painting options are given in; this class.; Example:. TGraph *gr1 = new TGraph(...; TGraphErrors *gr2 = new TGraphErrors(...; TMultiGraph *mg = new TMultiGraph();; mg->Add(gr1,""lp"");; mg->Add(gr2,""cp"");; mg->Draw(""a"");. The number of graphs in a multigraph can be retrieve with:. mg->GetListOfGraphs()->GetSize();. The drawing option for each TGraph may be specified as an optional; second argument of the Add function. If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. The following example shows how to fit a TMultiGraph. Picture; Source. {; TCanvas *c1 = new TCanvas(""c1"",""c1"",600,400);. Double_t x1[2] = {2.,4.};; Double_t dx1[2] = {0.1,0.1};; Double_t y1[2] = {2.1,4.0};; Double_t dy1[2] = {0.3,0.2};. Double_t x2[2] = {3.,5.};; Double_t dx2[2] = {0.1,0.1};; Double_t y2[2] = {3.2,4.8};; Double_t dy2[2] = {0.3,0.2};. gStyle->SetOptFit(0001);. TGraphErrors *g1 = new TGraphErrors(2,x1,y1,dx1,dy1);; g1->SetMarkerStyle(21);; g1->SetMarkerColor(2);. TGraphErrors *g2 = new TGraphErrors(2,x2,y2,dx2,dy2);; g2->SetMarkerStyle(22);; g2->SetMarkerColor(3);. TMultiGraph *g = new",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiGraph.html:18422,Security,access,access,18422,"::EvaluateChi2.; In case of TGraphErrors an effective chi2 is used; (see TGraphErrors fit in TGraph::Fit) and is implemented in; FitUtil::EvaluateChi2Effective; To specify a User defined fitting function, specify option ""U"" and; call the following functions:; TVirtualFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParErr",MatchSource.WIKI,root/html530/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiGraph.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:981,Availability,avail,available,981,"erceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial mo",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:1681,Availability,error,errors,1681,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3588,Availability,error,error,3588,"ver a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3630,Availability,error,error,3630,"tor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The p",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3697,Availability,error,error,3697,"tor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The p",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3818,Availability,error,error,3818," made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch le",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4216,Availability,error,errors,4216,"ear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8276,Availability,avail,available,8276,"; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:11090,Availability,error,error,11090,"n = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStri",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:11174,Availability,error,error,11174,"nst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStringGetStructure() const; Double_tGetTau() const; virtual const char*TObject::GetTitle",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25238,Availability,error,error,25238,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25315,Availability,error,error,25315,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25378,Availability,avail,available,25378,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25823,Availability,error,error,25823,"nt_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayer",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25924,Availability,error,error,25924,"terations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3344,Deployability,continuous,continuous,3344,"LPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimi",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4482,Deployability,update,updated,4482,"methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients wi",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4872,Deployability,update,updated,4872,"ights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matr",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8129,Deployability,update,update,8129,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8172,Deployability,update,update,8172,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8327,Deployability,update,update,8327,"ne them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD =",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25042,Deployability,update,update,25042,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25084,Deployability,update,update,25084,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:27000,Deployability,update,updates,27000," output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:28729,Deployability,update,updated,28729,"pWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:28833,Deployability,update,updated,28833,"filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:29187,Deployability,update,updated,29187,"non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(TMatrixD& , TMatrixD& , Double_t* ); Sets the gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}) vectors; Gamma is computed here, so ComputeDEDw cannot have been called before,; and delta is a direct translation of buffer into a TMatrixD. Double_t DerivDir(Double_t* ); scalar product between gradient and direction; = derivative along direction. void BFGSDir(TMatrixD& ,",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:29641,Deployability,update,update,29641," void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(TMatrixD& , TMatrixD& , Double_t* ); Sets the gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}) vectors; Gamma is computed here, so ComputeDEDw cannot have been called before,; and delta is a direct translation of buffer into a TMatrixD. Double_t DerivDir(Double_t* ); scalar product between gradient and direction; = derivative along direction. void BFGSDir(TMatrixD& , Double_t* ); Computes the direction for the BFGS algorithm as the product; between the Hessian estimate (bfgsh) and the dir. void Draw(Option_t* option = """"); Draws the network structure.; Neurons are depicted by a blue disk, and synapses by; lines connecting neurons.; The line width is proportionnal to the weight. TMultiLayerPerceptron(). Double_t GetEta() const; { return fEta; }. Doubl",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:5879,Energy Efficiency,power,powerful,5879,"nimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:28219,Integrability,depend,dependant,28219,"moid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used b",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:1315,Modifiability,layers,layers,1315,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:1368,Modifiability,layers,layers,1368,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:2518,Modifiability,flexible,flexible,2518,"f; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3240,Modifiability,layers,layers,3240,"iscrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computatio",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:6341,Modifiability,layers,layers,6341," line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TC",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:6430,Modifiability,layers,layers,6430,"the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning m",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:6487,Modifiability,layers,layers,6487," Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8979,Modifiability,layers,layers,8979,"e; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); virtua",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19123,Modifiability,layers,layers,19123,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19198,Modifiability,layers,layers,19198,"rch - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: """,MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19255,Modifiability,layers,layers,19255,"fining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' i",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19348,Modifiability,variab,variable,19348," flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20049,Modifiability,layers,layers,20049,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20124,Modifiability,layers,layers,20124,"giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20181,Modifiability,layers,layers,20181,"dden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20274,Modifiability,variab,variable,20274,"ers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be fol",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20980,Modifiability,layers,layers,20980,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21055,Modifiability,layers,layers,21055,"g; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just desc",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21112,Modifiability,layers,layers,21112,"layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are s",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21205,Modifiability,variab,variable,21205,"re separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepende",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21981,Modifiability,layers,layers,21981,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22056,Modifiability,layers,layers,22056,"bed by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. vo",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22113,Modifiability,layers,layers,22113,"parated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets th",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22206,Modifiability,variab,variable,22206," by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimizati",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:26228,Modifiability,layers,layers,26228," canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:26850,Modifiability,layers,layers,26850," for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Opti",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:27022,Modifiability,layers,layers,27022," output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:26401,Performance,perform,performance,26401,"ble. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:2023,Safety,predict,predictions,2023,"ion, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:753,Testability,test,test,753,". TMultiLayerPerceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:6991,Testability,test,test,6991," direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the n",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:7223,Testability,test,test,7223,"uctor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations;",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:9222,Testability,test,test,9222,,MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:9416,Testability,test,test,9416,,MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:9645,Testability,test,test,9645,,MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:9859,Testability,test,test,9859,,MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:10782,Testability,test,test,10782,"layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); virtual~TMultiLayerPerceptron(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:14604,Testability,test,test,14604,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:14642,Testability,test,test,14642,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:18292,Testability,test,test,18292,"FirstLayerCollection of the input neurons; subset of fNetwork; Double_tfLastAlpha! internal parameter used in line search; TObjArrayfLastLayerCollection of the output neurons; subset of fNetwork; TMultiLayerPerceptron::ELearningMethodfLearningMethod! The Learning Method; TTreeFormulaManager*fManager! TTreeFormulaManager for the weight and neurons; TObjArrayfNetworkCollection of all the neurons in the network; TNeuron::ENeuronTypefOutTypeType of output neurons; Int_tfReset! number of epochs between two resets of the search direction to the steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:18960,Testability,test,test,18960,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19576,Testability,test,test,19576,"ing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and th",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19886,Testability,test,test,19886,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20502,Testability,test,test,20502,"ven as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testin",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20812,Testability,test,test,20812,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21433,Testability,test,test,21433,"rgument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21533,Testability,test,testing,21533,"rgument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21813,Testability,test,test,21813,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22434,Testability,test,test,22434,"vents; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod met",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22534,Testability,test,testing,22534,"vents; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod met",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:22976,Testability,test,test,22976,"output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constru",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:23272,Testability,test,test,23272,"!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= E",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:25328,Testability,test,test,25328,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:27351,Testability,test,test,27351,"ince this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or T",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:27534,Testability,test,test,27534,"ldNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for st",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:960,Usability,learn,learning,960,"erceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial mo",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:2508,Usability,clear,clear,2508,"f; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:2729,Usability,simpl,simple,2729,"cation based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In a",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:3546,Usability,learn,learning,3546,"ver a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4275,Usability,learn,learning,4275,". A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4361,Usability,learn,learning,4361,"; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum alo",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:4793,Usability,learn,learning,4793,"ights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matr",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:6308,Usability,simpl,simple,6308," line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TC",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:7359,Usability,learn,learning,7359,"uron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8058,Usability,simpl,simple,8058,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8652,Usability,learn,learning,8652," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:8860,Usability,learn,learning,8860," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:19090,Usability,simpl,simple,19090,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20016,Usability,simpl,simple,20016,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:20947,Usability,simpl,simple,20947,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:21948,Usability,simpl,simple,21948,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:23496,Usability,learn,learning,23496,"ormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constru",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:23678,Usability,learn,learning,23678,"uited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:23841,Usability,learn,learning,23841," char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry in",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24012,Usability,learn,learning,24012,"aSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; -",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24181,Usability,learn,learning,24181,"raining dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24351,Usability,learn,learning,24351,"t.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24502,Usability,learn,learning,24502,"n::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the outpu",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24714,Usability,learn,learning,24714,"arameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:24969,Usability,simpl,simple,24969,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMultiLayerPerceptron.html:26763,Usability,simpl,simple,26763,") const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the ",MatchSource.WIKI,root/html530/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMultiLayerPerceptron.html
https://root.cern/root/html530/TMutex.html:1510,Availability,error,error,1510," = kFALSE); virtual~TMutex(); voidTObject::AbstractMethod(const char* method) const; Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virt",MatchSource.WIKI,root/html530/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutex.html
https://root.cern/root/html530/TMutex.html:1594,Availability,error,error,1594," Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject:",MatchSource.WIKI,root/html530/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutex.html
https://root.cern/root/html530/TMutex.html:5769,Availability,error,error,5769,"onst char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-07-04 15:35; This page",MatchSource.WIKI,root/html530/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutex.html
https://root.cern/root/html530/TMutex.html:5917,Availability,error,error,5917,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutex.html
https://root.cern/root/html530/TMutex.html:6063,Availability,error,error,6063,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-07-04 15:35; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutex.html
https://root.cern/root/html530/TMutexImp.html:543,Availability,avail,available,543,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html530/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutexImp.html
https://root.cern/root/html530/TMutexImp.html:1510,Availability,error,error,1510," virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html530/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutexImp.html
https://root.cern/root/html530/TMutexImp.html:1594,Availability,error,error,1594," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html530/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutexImp.html
https://root.cern/root/html530/TMutexImp.html:333,Integrability,interface,interface,333,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html530/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutexImp.html
https://root.cern/root/html530/TMutexImp.html:353,Integrability,depend,dependent,353,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html530/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMutexImp.html
https://root.cern/root/html530/TMVA_Index.html:742,Deployability,configurat,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:3382,Integrability,interface,interface,3382,"gory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoa",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:4109,Integrability,interface,interface,4109,ility density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Fr,MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:4364,Integrability,interface,interface,4364,mentation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in tr,MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:4782,Integrability,wrap,wrapper,4782,rface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation f,MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:742,Modifiability,config,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:4854,Modifiability,variab,variables,4854,:PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function,MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:7132,Modifiability,variab,variable,7132,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:1154,Performance,perform,performs,1154," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:1182,Testability,test,testing,1182," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:3679,Testability,log,logging,3679,"t (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class f",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA_Index.html:2759,Usability,simpl,simple,2759,"ethod Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TMVA ANNs; TMVA::MethodBDT Analysis of Boosted Decision Trees; TMVA::MethodBase Virtual base class for all TMVA method; TMVA::MethodBayesClassifier Friedman's BayesClassifier method ; TMVA::MethodBoost ; TMVA::MethodCFMlpANN Interface for Clermond-Ferrand artificial neural network; TMVA::MethodCFMlpANN_Utils Implementation of Clermond-Ferrand artificial neural network; TMVA::MethodCategory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::Optimi",MatchSource.WIKI,root/html530/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA_Index.html
https://root.cern/root/html530/TMVA__BDTEventWrapper.html:955,Modifiability,variab,variable,955,". TMVA::BDTEventWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Mon Jul 4 15:33:57 2011 » Last generated: 2011-07-04 15:33; Th",MatchSource.WIKI,root/html530/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BDTEventWrapper.html
https://root.cern/root/html530/TMVA__BDTEventWrapper.html:1578,Modifiability,variab,variable,1578,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Mon Jul 4 15:33:57 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BDTEventWrapper.html
https://root.cern/root/html530/TMVA__BDTEventWrapper.html:1631,Modifiability,variab,variable,1631,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Mon Jul 4 15:33:57 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BDTEventWrapper.html
https://root.cern/root/html530/TMVA__BDTEventWrapper.html:1741,Modifiability,variab,variable,1741,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Mon Jul 4 15:33:57 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BDTEventWrapper.html
https://root.cern/root/html530/TMVA__BDTEventWrapper.html:1795,Modifiability,variab,variable,1795,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Mon Jul 4 15:33:57 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BDTEventWrapper.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:3882,Modifiability,variab,variable,3882,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4003,Modifiability,variab,variable,4003,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4077,Modifiability,variab,variable,4077,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4148,Modifiability,variab,variable,4148,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4347,Modifiability,variab,variables,4347,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4420,Modifiability,variab,variable,4420,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4598,Modifiability,variab,variable,4598,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:4759,Modifiability,variab,variable,4759,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:6026,Modifiability,variab,variables,6026,"::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:6196,Modifiability,variab,variables,6196,"e, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basi",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7182,Modifiability,variab,variable,7182,"create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSig",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7718,Modifiability,variab,variables,7718,"nts that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Ste",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7801,Modifiability,variab,variables,7801,"lume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7935,Modifiability,variab,variable,7935,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has bee",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8093,Modifiability,variab,variable,8093," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8253,Modifiability,variab,variable,8253," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8413,Modifiability,variab,variable,8413," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8518,Modifiability,variab,variable,8518," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7885,Security,access,access,7885,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has bee",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8044,Security,access,access,8044," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8200,Security,access,access,8200," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8360,Security,access,access,8360," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:8495,Security,access,access,8495," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:3762,Testability,log,logger,3762,"aryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. voidDestroyNode(TMVA::BinarySearchTreeNode*); voidInsert(const TMVA::Event*, TMVA::Node*); Bool_tInVolume(const vector<Float_t>&, TMVA::Volume*) const; voidNormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:7023,Testability,test,test,7023,"ng ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Typ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:348,Usability,simpl,simple,348,". TMVA::BinarySearchTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTree. class TMVA::BinarySearchTree: public TMVA::BinaryTree. BinarySearchTree. A simple Binary search tree including a volume search method. Function Members (Methods); public:. virtual~BinarySearchTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeBinarySearchTree(); TMVA::BinarySearchTreeBinarySearchTree(const TMVA::BinarySearchTree& b); voidCalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); static TClass*Class(); virtual const char*ClassName() const; voidClear(TMVA::Node* n = 0); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::BinarySearchTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::Node*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; Double_tFill(const vector<TMVA::Event*>& events, Int_t theType = -1); Double_tFill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; UInt_tGetPeriode() const; TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*TMVA::BinaryTree::GetRoot() const; Double_tGetSumOfWeights() const; Double_tGetSumOfWeights(Int_t theType) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; voidInsert(const TMVA::Event*); virtual TClass*IsA() const; Float_tMax(TMVA::Types::ESBType sb, UInt_t var); Float_tMean(TMVA::Types::ESBType sb, UInt_t var); Float_tMin(TMVA::Types::ESBType sb, UInt_t var); voidNormalizeTree(); TMVA::BinarySearchTree&operator=(const TMVA::BinarySearchTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; virtual voidTMVA::BinaryTree::Read(istream& istr, UI",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTree.html:6538,Usability,clear,clear,6538,"he tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(",MatchSource.WIKI,root/html530/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTree.html
https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html:570,Modifiability,variab,variable,570,". TMVA::BinarySearchTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTreeNode. class TMVA::BinarySearchTreeNode: public TMVA::Node. Node for the BinarySearch or Decision Trees. for the binary search tree, it basically consists of the EVENT, and; pointers to the parent and daughters. in case of the Decision Tree, it specifies parent and daughters, as; well as ""which variable is used"" in the selection of this node, including; the respective cut value. Function Members (Methods); public:. virtual~BinarySearchTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; void*TMVA::Node::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); static TClass*Class(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; virtual Bool_tEqualsMe(const TMVA::Event&) const; UInt_tGetClass() const; intTMVA::Node::GetCount(); UInt_tTMVA::Node::GetDepth() const; const vector<Float_t>&GetEventV() const; virtual TMVA::Node*TMVA::Node::GetLeft() const; virtual TMVA::Node*TMVA::Node::GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Node::GetPos() const; virtual TMVA::Node*TMVA::Node::GetRight() const; Short_tGetSelector() const; const vector<Float_t>&GetTargets() const; Float_tGetWeight() const; virtual Bool_tGoesLeft(const TMVA::Event&) const; virtual Bool_tGoesRight(const TMVA::Event&) const; virtual TClass*IsA() const; TMVA::BinarySearchTreeNode&operator=(const TMVA::",MatchSource.WIKI,root/html530/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html:3376,Modifiability,variab,variable,3376,"::Node::SetPos(char s); virtual voidTMVA::Node::SetRight(TMVA::Node* r); voidSetSelector(Short_t i); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; protected:. UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes. private:. UInt_tfClass; vector<Float_t>fEventV; Short_tfSelectorindex of variable used in node selection (decision tree) ; vector<Float_t>fTargets; Float_tfWeight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); constructor of a node for the search tree. BinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); constructor of a daughter node as a daughter of 'p'. BinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the e",MatchSource.WIKI,root/html530/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html:5121,Modifiability,variab,variable,5121,"he node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html:5233,Modifiability,variab,variable,5233,"he node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html530/TMVA__BinaryTree.html:479,Availability,avail,available,479,". TMVA::BinaryTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinaryTree. class TMVA::BinaryTree. BinaryTree. Base class for BinarySearch and Decision Trees. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~BinaryTree(); virtual void*AddXMLTo(void* parent) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCountNodes(TMVA::Node* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recurs",MatchSource.WIKI,root/html530/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinaryTree.html
https://root.cern/root/html530/TMVA__BinaryTree.html:2706,Integrability,depend,depends,2706,"fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an input stream.; The input stream format depends on the tree type,; it is defined be the node of the tree. void SetTotalTreeDepth( Node *n); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. Node* CreateNode(UInt_t size = 0) const. BinaryTree* CreateTree() const; virtual BinaryTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE) = 0;. const char* ClassName() const. void SetRoot(TMVA::Node* r); set the root node of the tree. { fRoot = r; }. Node* GetRoot() const; Retrieves the address of the root node. { return fRoot; }. UInt_t GetNNodes() const; get number of Nodes in the Tree as counted while booking the nodes;. { return fNNodes; }. UInt_t GetTotalTreeDepth() const; { return fDepth; }. void SetTotalTreeDepth(Int_t depth); { fDepth = depth; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: BinaryTree.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:33; This ",MatchSource.WIKI,root/html530/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinaryTree.html
https://root.cern/root/html530/TMVA__BinaryTree.html:1741,Testability,log,logger,1741,"* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an",MatchSource.WIKI,root/html530/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__BinaryTree.html
https://root.cern/root/html530/TMVA__CCPruner.html:459,Security,validat,validationSample,459,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCPruner.html:592,Security,validat,validationSample,592,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCPruner.html:1838,Security,validat,validationSample,1838,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Mon Jul 4 15:33:58 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCPruner.html:1947,Security,validat,validationSample,1947,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Mon Jul 4 15:33:58 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCPruner.html:2301,Security,validat,validationSample,2301,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Mon Jul 4 15:33:58 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCPruner.html:2432,Security,validat,validation,2432,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Mon Jul 4 15:33:58 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCPruner.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:1156,Integrability,wrap,wrapped,1156,"x; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::S",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:840,Security,validat,validationSample,840,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:904,Security,validat,validationSample,904,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:1617,Security,validat,validationSample,1617,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Mon Jul 4 15:33:59 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:1694,Security,validat,validation,1694,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Mon Jul 4 15:33:59 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:1780,Security,validat,validationSample,1780,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Mon Jul 4 15:33:59 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__CCTreeWrapper.html:1857,Security,validat,validation,1857,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Mon Jul 4 15:33:59 2011 » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CCTreeWrapper.html
https://root.cern/root/html530/TMVA__Config.html:1316,Testability,log,logger,1316,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html530/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config.html
https://root.cern/root/html530/TMVA__Config.html:1240,Usability,progress bar,progress bar,1240,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html530/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config.html
https://root.cern/root/html530/TMVA__Configurable.html:1474,Availability,error,error,1474," voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const cha",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:1558,Availability,error,error,1558,"ption = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:6183,Integrability,message,message,6183,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:8136,Integrability,message,message,8136,"void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fConfigName; }. const char* GetConfigDescription() const; { return fConfigDescription; }. void SetConfigName(const char* n); { fConfigName = TString(n); }. void SetConfigDescription(const char* d); { fConfigDescription = TString(d); }. const TString& GetOptions() const; { return fOptions; }. void SetOptions(const TString& s); { fOptions = s; }. Bool_t LooseOptionCheckingEnabled() const; { return fLooseOptionCheckingEnabled; }. void EnableLooseOptions(Bool_t b = kTRUE); { fLooseOptionCheckingEnabled = b; }. const TString& GetReferenceFile() const; { return fReferenceFile; }. void SetMsgType(TMVA::EMsgType t); set message type. { fLogger->SetMinType(t); }. Log(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Configurable.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:6001,Modifiability,config,configurable,6001,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:6050,Modifiability,config,configurable,6050,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Configurable.html:6191,Testability,log,logger,6191,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html530/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Configurable.html
https://root.cern/root/html530/TMVA__Config__IONames.html:311,Deployability,configurat,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config__IONames.html
https://root.cern/root/html530/TMVA__Config__IONames.html:311,Modifiability,config,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:33; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config__IONames.html
https://root.cern/root/html530/TMVA__Config__VariablePlotting.html:338,Deployability,configurat,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config__VariablePlotting.html
https://root.cern/root/html530/TMVA__Config__VariablePlotting.html:338,Modifiability,config,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Config__VariablePlotting.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:2134,Availability,down,down,2134,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Mon Jul 4 15:34:00 2011 » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:2462,Availability,error,error,2462,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Mon Jul 4 15:34:00 2011 » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:545,Testability,test,testEvents,545,". TMVA::CostComplexityPruneTool. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(T",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:1084,Testability,log,logging,1084,"wVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc.",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:1922,Testability,test,testEvents,1922,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Mon Jul 4 15:34:00 2011 » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html:2436,Testability,test,test,2436,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Mon Jul 4 15:34:00 2011 » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html530/TMVA__CrossEntropy.html:383,Testability,log,log,383,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CrossEntropy.html
https://root.cern/root/html530/TMVA__CrossEntropy.html:398,Testability,log,log,398,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CrossEntropy.html
https://root.cern/root/html530/TMVA__CrossEntropy.html:1406,Testability,log,log,1406,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CrossEntropy.html
https://root.cern/root/html530/TMVA__CrossEntropy.html:1421,Testability,log,log,1421,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40012 2011-06-27 16:03:11Z stelzer $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__CrossEntropy.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11858,Availability,down,down,11858,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:526,Modifiability,variab,variable,526,". TMVA::DecisionTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& even",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:1062,Modifiability,variab,variable,1062,"h. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:3745,Modifiability,variab,variableMap,3745,,MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:6529,Modifiability,variab,variables,6529,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:6817,Modifiability,variab,variable,6817,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:6964,Modifiability,variab,variables,6964,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:7334,Modifiability,variab,variables,7334,"on(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Librari",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:7680,Modifiability,variab,variables,7680," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:7881,Modifiability,variab,variables,7881," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:8174,Modifiability,variab,variables,8174,"_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further splitting, the; number of bins in the grid used in applying the cut for the node; splitting. DecisionTree(const TMVA::DecisionTree& d",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:10978,Modifiability,variab,variable,10978,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11171,Modifiability,variab,variables,11171,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11535,Modifiability,variab,variable,11535,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:12957,Modifiability,variab,variableMap,12957,"ere from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13134,Modifiability,variab,variables,13134,"ing validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFA",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13229,Modifiability,variab,variable,13229," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13393,Modifiability,variab,variables,13393,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13481,Modifiability,variab,variables,13481,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13737,Modifiability,variab,variables,13737,"Long_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The impor",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:14550,Modifiability,variab,variable,14550,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:14590,Modifiability,variab,variables,14590,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:14702,Modifiability,variab,variable,14702,"ents for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() c",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:14854,Modifiability,variab,variable,14854,"mple, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePuri",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:15352,Modifiability,variab,variable,15352,". the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePurityLimit() const; { return fNodePurityLimit; }. void SetTreeID(Int_t treeID); {fTreeID = treeID;}. Int_t GetTreeID(); {return fTreeID;}. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. void SetAnalysisType(TMVA::Types::EAnalysisType t); { fAnalysisType = t;}. Types::EAnalysisType GetAnalysisType( void ); { return fAnalysisType;}. void SetUseFisherCuts(Bool_t t = kTRUE); { fUseFisherCuts = t;}. void SetMinLinCorrForFisher(Double_t min); {fM",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:6647,Performance,perform,perform,6647,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:13303,Performance,perform,performed,13303," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:10888,Safety,avoid,avoid,10888,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:1919,Security,validat,validationSample,1919,"constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, Bool_t UseYesNoLeaf = kFALSE) const; voidCheckEventWithPrunedTree(const TMVA::Event&) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCleanTree(TMVA::DecisionTreeNode* node = NULL); voidClearTree(); UInt_tCountLeafNodes(TMVA::Node* n = NULL); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::DecisionTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::DecisionTreeNode*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::DecisionTreeDecisionTree(); TMVA::DecisionTreeDecisionTree(const TMVA::DecisionTree& d); TMVA::DecisionTreeDecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); voidDescendTree(TMVA::Node* n = NULL); Bool_tDoRegression() const; voidFillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); voidFillTree(TMVA::DecisionTree::EventList& eventSample); TMVA::Types::EAnalysisTypeGetAnalysisType(); TMVA::DecisionTreeNode*GetEventNode(const TMVA::Event& e) const; vector<Double_t>GetFisherCoefficients(const TMVA::DecisionT",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:3943,Security,validat,validationSample,3943,,MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:4409,Security,validat,validationSample,4409," UInt_t nFisherVars, UInt_t* mapVarInFisher); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; TMVA::Node*GetNode(ULong_t sequence, UInt_t depth); Double_tGetNodePurityLimit() const; Double_tGetPruneStrength() const; voidGetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars); TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::DecisionTreeNode*GetRoot() const; Double_tGetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; Int_tGetTreeID(); vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); virtual TClass*IsA() const; TMVA::DecisionTree&operator=(const TMVA::DecisionTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; voidPruneNode(TMVA::DecisionTreeNode* node); voidPruneNodeInPlace(TMVA::DecisionTreeNode* node); Double_tPruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); virtual voidTMVA::BinaryTree::Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidTMVA::BinaryTree::ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetAnalysisType(TMVA::Types::EAnalysisType t); voidSetMinLinCorrForFisher(Double_t min); voidSetNodePurityLimit(Double_t p); voidSetPairNegWeightsInNode(); voidSetParentTreeInNodes(TMVA::Node* n = NULL); voidSetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); voidSetPruneStrength(Double_t p); voidTMVA::BinaryTree::SetRoot(TMVA::Node* r); voidTMVA::BinaryTree::SetTotalTreeDepth(Int_t depth); voidTMVA::BinaryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); voidSetTreeID(Int_t treeID); voidSetUseExclusiveVars(Bool_t t = kTRUE); voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:10807,Security,validat,validationSample,10807,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11067,Security,validat,validationSample,11067,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11100,Security,validat,validation,11100,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11273,Security,validat,validation,11273,"nd up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11797,Security,validat,validation,11797,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:12021,Security,validat,validationSample,12021,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:12095,Security,validat,validation,12095,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:6297,Testability,log,logger,6297," voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; Double_tTrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_t",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11610,Testability,test,testing,11610,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:11641,Testability,test,test,11641,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:12526,Testability,test,testing,12526,"runed tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; p",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:8078,Usability,simpl,simple,8078," with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further s",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTree.html:10279,Usability,clear,clear,10279,"odes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. TMVA::DecisionTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. UInt_t BuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); building the decision tree by recursively calling the splitting of; one (root-) node into two daughter nodes (returns the number of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later ",MatchSource.WIKI,root/html530/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTree.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:373,Modifiability,variab,variable,373,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:416,Modifiability,variab,variable,416,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:513,Modifiability,enhance,enhanced,513,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:543,Modifiability,enhance,enhanced,543,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:4712,Modifiability,variab,variable,4712,"ouble_t s); voidSetNTerminal(Int_t n); virtual voidSetParent(TMVA::Node* p); virtual voidTMVA::Node::SetParentTree(TMVA::BinaryTree* t); voidTMVA::Node::SetPos(char s); voidSetPurity(); voidSetResponse(Float_t r); virtual voidSetRight(TMVA::Node* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRigh",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:4814,Modifiability,variab,variable,4814,"e* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:5791,Modifiability,variab,variable,5791,"hase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; RE",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:7656,Modifiability,variab,variable,7656,"to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used i",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:7790,Modifiability,variab,variable,7790,"round nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* C",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:7926,Modifiability,variab,variable,7926,"st; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFis",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:8062,Modifiability,variab,variable,8062,"MVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coeffic",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:9146,Modifiability,variab,variable,9146,"butes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResp",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:9258,Modifiability,variab,variable,9258,"d attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:9558,Modifiability,variab,variable,9558," we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;}. void SetRMS(Float_t r); set the RMS of the response of the node (for regression). { fRMS = r;}. Float_t GetRMS( void ); return the RMS of the response of the node (for regression). { return fRMS;}. void SetNSigEvents(Float_t s); set the sum of the signal weights in the node. { fTrainInfo->fNSigEve",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:7349,Security,validat,validation,7349,"node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher co",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:15154,Security,validat,validation,15154,"ionTreeNode*>(p);}. void SetNodeR(Double_t r); the node resubstitution estimate, R(t), for Cost Complexity pruning. { fTrainInfo->fNodeR = r; }. Double_t GetNodeR() const; { return fTrainInfo->fNodeR; }. void SetSubTreeR(Double_t r); the resubstitution estimate, R(T_t), of the tree rooted at this node. { fTrainInfo->fSubTreeR = r; }. Double_t GetSubTreeR() const; { return fTrainInfo->fSubTreeR; }. void SetAlpha(Double_t alpha); R(t) - R(T_t); the critical point alpha = -------------; |~T_t| - 1. { fTrainInfo->fAlpha = alpha; }. Double_t GetAlpha() const; { return fTrainInfo->fAlpha; }. void SetAlphaMinSubtree(Double_t g); the minimum alpha in the tree rooted at this node. { fTrainInfo->fG = g; }. Double_t GetAlphaMinSubtree() const; { return fTrainInfo->fG; }. void SetNTerminal(Int_t n); number of terminal nodes in the subtree rooted here. { fTrainInfo->fNTerminal = n; }. Int_t GetNTerminal() const; { return fTrainInfo->fNTerminal; }. void SetNBValidation(Double_t b); number of background/signal events from the pruning validation sample. { fTrainInfo->fNB = b; }. void SetNSValidation(Double_t s); { fTrainInfo->fNS = s; }. Double_t GetNBValidation() const; { return fTrainInfo->fNB; }. Double_t GetNSValidation() const; { return fTrainInfo->fNS; }. void SetSumTarget(Float_t t); {fTrainInfo->fSumTarget = t; }. void SetSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 = t2; }. void AddToSumTarget(Float_t t); {fTrainInfo->fSumTarget += t; }. void AddToSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 += t2; }. Float_t GetSumTarget() const; {return fTrainInfo? fTrainInfo->fSumTarget : -9999;}. Float_t GetSumTarget2() const; {return fTrainInfo? fTrainInfo->fSumTarget2: -9999;}. Bool_t IsTerminal() const; flag indicates whether this node is terminal. { return fIsTerminalNode; }. void SetTerminal(Bool_t s = kTRUE); { fIsTerminalNode = s; }. Double_t GetCC() const; {return (fTrainInfo? fTrainInfo->fCC : -1.);}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckha",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:6507,Testability,test,test,6507,"tion, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) con",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:6612,Testability,test,test,6612,"S of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__DecisionTreeNode.html:7137,Usability,clear,clear,7137," p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* ",MatchSource.WIKI,root/html530/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__DecisionTreeNode.html
https://root.cern/root/html530/TMVA__Event.html:1618,Energy Efficiency,charge,charge,1618,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:1157,Modifiability,variab,variable,1157,escription; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //N,MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:2881,Modifiability,variab,variables,2881,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:4972,Modifiability,variab,variables,4972,"_tGetNVariables() const; Double_tGetOriginalWeight() const; Float_tGetSpectator(UInt_t ivar) const; vector<Float_t>&GetSpectators() const; Float_tGetTarget(UInt_t itgt) const; vector<Float_t>&GetTargets() const; Float_tGetValue(UInt_t ivar) const; const vector<Float_t>&GetValues() const; Double_tGetWeight() const; Bool_tIsDynamic() const; TMVA::Event&operator=(const TMVA::Event&); voidPrint(ostream& o) const; voidScaleBoostWeight(Double_t s); voidScaleWeight(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*",MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:5409,Modifiability,variab,variable,5409,"(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<F",MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:2902,Performance,perform,performance,2902,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:5866,Security,access,accessors,5866,"ative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<Float_t>& GetTargets() const; { return fTargets; }. Float_t GetSpectator(UInt_t ivar) const. std::vector<Float_t>& GetSpectators() const; { return fSpectators; }. void ScaleWeight(Double_t s); { fWeight*=s; }. void SetWeight(Double_t w); { fWeight=w; }. void SetBoostWeight(Double_t w); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight=w; }. void ScaleBoostWeight(Double_t s); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight *= s; }. void SetClass",MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Event.html:322,Usability,simpl,simple,322,. TMVA::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of ,MatchSource.WIKI,root/html530/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Event.html
https://root.cern/root/html530/TMVA__Factory.html:4539,Availability,error,error,4539,"nst; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:4623,Availability,error,error,4623,"oidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18639,Deployability,configurat,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18848,Deployability,configurat,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:13061,Integrability,message,message,13061,"t; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:19658,Integrability,message,message,19658,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:19796,Integrability,message,message,19796,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:8498,Modifiability,variab,variable,8498,"al voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& va",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:9579,Modifiability,variab,variable,9579,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:9778,Modifiability,variab,variable,9778,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:11678,Modifiability,variab,variables,11678,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:14342,Modifiability,variab,variables,14342,"A::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalTree(TTree* signal, Double_t weight, const TString& treetype). void AddBackgroundTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of s",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:16534,Modifiability,variab,variable,16534,"om text file. void AddBackgroundTree(TTree* background, Double_t weight, const TString& treetype). void SetSignalTree(TTree* signal, Double_t weight = 1.0). void SetBackgroundTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:16687,Modifiability,variab,variable,16687,"dTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TSt",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:17182,Modifiability,variab,variables,17182," SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& s",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:17251,Modifiability,variab,variable,17251,"ound from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal an",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:17312,Modifiability,variab,variable,17312,"ckground events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, ",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:17363,Modifiability,variab,variable,17363,"nst TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase*",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18639,Modifiability,config,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18848,Modifiability,config,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18825,Performance,perform,performance,18825," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:407,Testability,test,testing,407,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:12531,Testability,test,test,12531,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:12917,Testability,test,test,12917,"ssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:13697,Testability,test,testing,13697,"ation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, c",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:14164,Testability,test,test,14164,"Msg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalT",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:17931,Testability,test,test,17931," 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of v",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18050,Testability,test,test,18050," user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put corr",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18195,Testability,test,test,18195," fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"",",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:18356,Testability,test,test,18356,"ring& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. c",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:19706,Testability,test,test,19706,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:19844,Testability,test,test,19844,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__Factory.html:373,Usability,guid,guides,373,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html530/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__Factory.html
https://root.cern/root/html530/TMVA__FitterBase.html:530,Availability,avail,available,530,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:1754,Availability,error,error,1754,"virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() con",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:1838,Availability,error,error,1838,"ons() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash(",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:385,Integrability,interface,interface,385,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:7043,Integrability,interface,interface,7043,"le::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:7143,Integrability,interface,interface,7143,"le::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
https://root.cern/root/html530/TMVA__FitterBase.html:7300,Security,access,accessor,7300,"le::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 39395 2011-05-26 10:05:54Z moneta $ » Last generated: 2011-07-04 15:34; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html530/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html530/TMVA__FitterBase.html
