id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/issues/2215:563,Integrability,message,message,563,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:826,Performance,concurren,concurrent,826,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:901,Performance,concurren,concurrent,901,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:976,Performance,concurren,concurrent,976,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:1431,Performance,concurren,concurrent,1431,"y helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Metadata (``api/workflows/v2/c43e7d14-36a1-4b0b-95bf-cc381db48b5b/metadata?expandSubWorkflows=false``):. (attached); [cromwell_jes_error_April272017.txt](https://github.com/broadinstitute/cromwell/files/962915/cromwell_jes_error_April272017.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:1752,Performance,concurren,concurrent,1752,"y helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Metadata (``api/workflows/v2/c43e7d14-36a1-4b0b-95bf-cc381db48b5b/metadata?expandSubWorkflows=false``):. (attached); [cromwell_jes_error_April272017.txt](https://github.com/broadinstitute/cromwell/files/962915/cromwell_jes_error_April272017.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:1825,Performance,concurren,concurrent,1825,"y helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Metadata (``api/workflows/v2/c43e7d14-36a1-4b0b-95bf-cc381db48b5b/metadata?expandSubWorkflows=false``):. (attached); [cromwell_jes_error_April272017.txt](https://github.com/broadinstitute/cromwell/files/962915/cromwell_jes_error_April272017.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:1910,Performance,concurren,concurrent,1910,"y helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Metadata (``api/workflows/v2/c43e7d14-36a1-4b0b-95bf-cc381db48b5b/metadata?expandSubWorkflows=false``):. (attached); [cromwell_jes_error_April272017.txt](https://github.com/broadinstitute/cromwell/files/962915/cromwell_jes_error_April272017.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:1987,Performance,concurren,concurrent,1987,"y helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Metadata (``api/workflows/v2/c43e7d14-36a1-4b0b-95bf-cc381db48b5b/metadata?expandSubWorkflows=false``):. (attached); [cromwell_jes_error_April272017.txt](https://github.com/broadinstitute/cromwell/files/962915/cromwell_jes_error_April272017.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:853,Safety,recover,recoverWith,853,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2215:928,Safety,recover,recoverWith,928,"- cromwell 26; - JES backend; - call caching on local mysql instance; - server mode. Ran a bunch of the initial jobs, but once it really started fan out (thousands of jobs), I got this error message. Trying to replicate now, but not sure if I can. Might be transient. . Regardless, error message is not particularly helpful. Any ideas? . ```; cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageException: 410 Gone; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. at cromwell.core.CromwellFatalException$.apply(core.scala:17); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:37); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:36); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.for",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2215
https://github.com/broadinstitute/cromwell/issues/2216:277,Availability,error,error,277,"- cromwell 26; - call caching is on (local mysql); - server mode, but only running one workflow; - lots of subworkflows; - JES backend. This workflow has > 20k tasks. Most of the questions are in the title. I ran a lot of tasks and the workflow eventually failed with the same error as reported in issue #2215 . Therefore, I am not sure whether this is a side effect of the failure. This could also just be an issue with the timing diagram. Regardless, see attached image. . Suggestion (which you probably thought, already): Do not investigate until after #2215 is remedied. . Once I run with a fix for #2215 , I'll check to see if this is still an issue. . Is there a parameter that would let me increase the dispatch rate? Would that alleviate this issue?. ![queuedincromwellissue](https://cloud.githubusercontent.com/assets/2152339/25530922/f9208b78-2bf5-11e7-9553-5a7f69a79dc4.png)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2216
https://github.com/broadinstitute/cromwell/issues/2216:374,Availability,failure,failure,374,"- cromwell 26; - call caching is on (local mysql); - server mode, but only running one workflow; - lots of subworkflows; - JES backend. This workflow has > 20k tasks. Most of the questions are in the title. I ran a lot of tasks and the workflow eventually failed with the same error as reported in issue #2215 . Therefore, I am not sure whether this is a side effect of the failure. This could also just be an issue with the timing diagram. Regardless, see attached image. . Suggestion (which you probably thought, already): Do not investigate until after #2215 is remedied. . Once I run with a fix for #2215 , I'll check to see if this is still an issue. . Is there a parameter that would let me increase the dispatch rate? Would that alleviate this issue?. ![queuedincromwellissue](https://cloud.githubusercontent.com/assets/2152339/25530922/f9208b78-2bf5-11e7-9553-5a7f69a79dc4.png)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2216
https://github.com/broadinstitute/cromwell/issues/2216:761,Performance,queue,queuedincromwellissue,761,"- cromwell 26; - call caching is on (local mysql); - server mode, but only running one workflow; - lots of subworkflows; - JES backend. This workflow has > 20k tasks. Most of the questions are in the title. I ran a lot of tasks and the workflow eventually failed with the same error as reported in issue #2215 . Therefore, I am not sure whether this is a side effect of the failure. This could also just be an issue with the timing diagram. Regardless, see attached image. . Suggestion (which you probably thought, already): Do not investigate until after #2215 is remedied. . Once I run with a fix for #2215 , I'll check to see if this is still an issue. . Is there a parameter that would let me increase the dispatch rate? Would that alleviate this issue?. ![queuedincromwellissue](https://cloud.githubusercontent.com/assets/2152339/25530922/f9208b78-2bf5-11e7-9553-5a7f69a79dc4.png)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2216
https://github.com/broadinstitute/cromwell/issues/2217:201,Availability,error,error,201,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:237,Availability,error,error,237,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:394,Availability,error,error,394,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:443,Availability,error,error,443,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:595,Deployability,configurat,configuration,595,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:207,Integrability,message,message,207,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:243,Integrability,message,message,243,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:400,Integrability,message,message,400,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:540,Integrability,MESSAGE,MESSAGE,540,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:595,Modifiability,config,configuration,595,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:874,Modifiability,rewrite,rewriteBatchedStatements,874,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:1381,Modifiability,rewrite,rewriteBatchedStatements,1381,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:921,Security,password,password,921,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/issues/2217:1428,Security,password,password,1428,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217
https://github.com/broadinstitute/cromwell/pull/2218:169,Availability,error,errors,169,"It turns out that ""Complete Success"" just wasn't quite right for Cromwell. EDIT: the actual motivation for this is that this was the cause for some of our `dead letter` errors appearing at the end of `cromwell run` commands.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2218
https://github.com/broadinstitute/cromwell/issues/2219:221,Availability,failure,failures,221,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:534,Availability,failure,failure,534,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:274,Integrability,message,message,274,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:508,Integrability,message,message,508,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:162,Performance,concurren,concurrent,162,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:453,Performance,queue,queued,453,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2219:711,Performance,queue,queued,711,"- cromwell-27-c89c83f-SNAP; - server mode; - JES backend; - call caching on localhost mysql server. Is this a matter of hitting some sort of ceiling in number of concurrent jobs? Can I increase this?. ```; ....snip....; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ""message"": ""JobStore write failure: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@122f57e rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@35ca91f1[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 2293]""; }; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2219
https://github.com/broadinstitute/cromwell/issues/2222:66,Availability,error,error,66,When I use cromwell with mysql database I often get the following error:; ```; Caused by: java.sql.SQLException: Can't get stat of './cromwell/DATABASECHANGELOGLOCK.TRG' (Errcode: 13 - Permission denied); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:963); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3966); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3902); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2526); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2673); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2545); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2503); 	at com.mysql.jdbc.StatementImpl.executeInternal(StatementImpl.java:839); 	at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:739); 	at com.zaxxer.hikari.proxy.StatementProxy.execute(StatementProxy.java:83); ```. What is interesting is that ./cromwell does not exist at all. In my case I use official latest docker mysql container for mysql (where I manually create cromwell database),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2222
https://github.com/broadinstitute/cromwell/issues/2223:3,Deployability,pipeline,pipelines,3,As pipelines often deal with very large files (including intermediate files) and writing a good pipeline implies many runs it will be useful to have a clean rest API call to clean up previous executions to save some hard disk space.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2223
https://github.com/broadinstitute/cromwell/issues/2223:96,Deployability,pipeline,pipeline,96,As pipelines often deal with very large files (including intermediate files) and writing a good pipeline implies many runs it will be useful to have a clean rest API call to clean up previous executions to save some hard disk space.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2223
https://github.com/broadinstitute/cromwell/pull/2224:133,Modifiability,refactor,refactor,133,"Makes a common `BatchingDbWriter` object to hold types for batched writers. For the time being at least I've refrained from a deeper refactor to pull commonality up to an abstract parent FSM, though that does mean a fair amount of repetition in the implementation classes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2224
https://github.com/broadinstitute/cromwell/issues/2225:309,Deployability,release,release,309,"The WDL4S version used in Cromwell 26 is 0.11 ([proof](https://github.com/broadinstitute/cromwell/blob/26/project/Dependencies.scala#L5)). . The develop `git.baseVersion`in WDL4S remains 0.11 (at least until https://github.com/broadinstitute/wdl4s/pull/104 merges). Quoth @Horneth and @mcovarr: ; > our magic release stuff doesn't do this?; > Yeah that's weird, it should do it if it doesn't it's a bug",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2225
https://github.com/broadinstitute/cromwell/issues/2225:114,Integrability,Depend,Dependencies,114,"The WDL4S version used in Cromwell 26 is 0.11 ([proof](https://github.com/broadinstitute/cromwell/blob/26/project/Dependencies.scala#L5)). . The develop `git.baseVersion`in WDL4S remains 0.11 (at least until https://github.com/broadinstitute/wdl4s/pull/104 merges). Quoth @Horneth and @mcovarr: ; > our magic release stuff doesn't do this?; > Yeah that's weird, it should do it if it doesn't it's a bug",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2225
https://github.com/broadinstitute/cromwell/issues/2226:32,Modifiability,variab,variable,32,"The following wdl has the wrong variable name in the output section of the task:. ```; workflow GenotypeGVCFsComparison {; File combined_gvcf_input = ""gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz"". call IndexVCF{; input:; combined_gvcf = combined_gvcf_input,; disk_size = 200; }; }. task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${gvcf}""; File gvcf_index = ""${gvcf}.tbi""; }; }; ```. In Version 24 of Cromwell this WDL breaks the whole cromwell server. In Version 25 the only the workflow breaks which is a big improvement, however it runs the task to completion before breaking. It would be nice to validate the WDL before running the task to make sure the variables are named correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226
https://github.com/broadinstitute/cromwell/issues/2226:1002,Modifiability,variab,variables,1002,"The following wdl has the wrong variable name in the output section of the task:. ```; workflow GenotypeGVCFsComparison {; File combined_gvcf_input = ""gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz"". call IndexVCF{; input:; combined_gvcf = combined_gvcf_input,; disk_size = 200; }; }. task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${gvcf}""; File gvcf_index = ""${gvcf}.tbi""; }; }; ```. In Version 24 of Cromwell this WDL breaks the whole cromwell server. In Version 25 the only the workflow breaks which is a big improvement, however it runs the task to completion before breaking. It would be nice to validate the WDL before running the task to make sure the variables are named correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226
https://github.com/broadinstitute/cromwell/issues/2226:944,Security,validat,validate,944,"The following wdl has the wrong variable name in the output section of the task:. ```; workflow GenotypeGVCFsComparison {; File combined_gvcf_input = ""gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz"". call IndexVCF{; input:; combined_gvcf = combined_gvcf_input,; disk_size = 200; }; }. task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${gvcf}""; File gvcf_index = ""${gvcf}.tbi""; }; }; ```. In Version 24 of Cromwell this WDL breaks the whole cromwell server. In Version 25 the only the workflow breaks which is a big improvement, however it runs the task to completion before breaking. It would be nice to validate the WDL before running the task to make sure the variables are named correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226
https://github.com/broadinstitute/cromwell/issues/2228:255,Availability,error,error,255,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:522,Availability,error,error,522,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:640,Availability,ERROR,ERROR,640,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2291,Availability,ERROR,ERROR,2291,"ingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n; File \""/usr/local/share/google/google-cloud-sdk/bin/bootstr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2592,Availability,error,error,2592,"(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n; File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.; py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrappin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:9151,Availability,error,error,9151,"timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; java.lang.Exception: Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", l",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16319,Availability,recover,recoverWith,16319,"ne 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16394,Availability,recover,recoverWith,16394,"usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:261,Integrability,message,message,261,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:528,Integrability,message,messages,528,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2606,Integrability,Message,Message,2606,"ontext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n; File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.; py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205,; in GetActiveProjectAndAccount\n project_name = properties.VALUES.cor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:9165,Integrability,Message,Message,9165,"in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; java.lang.Exception: Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:106,Performance,queue,queue,106,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:442,Performance,cache,cache,442,"- JES backend; - cromwell server; - localhost mysql; - cromwell-27-c89c83f-SNAP.jar; - I set the database queue size to 3000.; - I have *not* changed the metadata batch size. *Should I attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:1179,Performance,concurren,concurrent,1179," attempt to restart this workflow?* This took over 4 hours to get this error message and I do not want to incur the cost if it will fail the same way again. Side issues:; - My workflow failed and yet cromwell is still *mauling* the mysql server.; - The call cache lookups are taking >1 hour per task. Main issue:. I do not understand the error messages, but my workflow has entered a Failed state and I am not sure why. First, I see a bunch of NPE:; ```; [ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:1634,Performance,concurren,concurrent,1634,[ERROR] [05/01/2017 17:36:00.055] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor.receiver(CallCacheWriteActor.scala:17); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize fil,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:1955,Performance,concurren,concurrent,1955,"n.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa91",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2028,Performance,concurren,concurrent,2028,"ala:21); at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-H",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2113,Performance,concurren,concurrent,2113,"tor$$anonfun$1.apply(CallCacheWriteActor.scala:19); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:2190,Performance,concurren,concurrent,2190,"CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16292,Performance,concurren,concurrent,16292,"n2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16367,Performance,concurren,concurrent,16367,"d_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at sca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16442,Performance,concurren,concurrent,16442,"tus\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16897,Performance,concurren,concurrent,16897,"readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:17218,Performance,concurren,concurrent,17218,"readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:17291,Performance,concurren,concurrent,17291,"readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:17376,Performance,concurren,concurrent,17376,"readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:17453,Performance,concurren,concurrent,17453,"readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:4952,Safety,timeout,timeout,4952,"etProperty\n value = _GetPropertyWithoutD; efault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n; File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/googl; e/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/g; ooglecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.p; y\"", line 41, in _ReadNoProxyWithCleanFailures\n return gce_read.ReadNoProxy(uri)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce_read.py\"", li; ne 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/py; thon2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib; 2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True); \n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self; ._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data; = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n); gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:5877,Safety,timeout,timeout,5877,"n ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/py; thon2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib; 2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True); \n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self; ._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data; = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n); gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/loc; al-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga; /STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam,; command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/s; hare/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:8155,Safety,timeout,timeout,8155,"501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoProxyWithCleanFailures\n return gce_read.ReadNoProxy(uri)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce_read.py\"", line 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; java.lang.Exception: Task m2.Mutect2.M2:1:1 failed. J",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:9071,Safety,timeout,timeout,9071,"dk/core/credentials/gce_read.py\"", line 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; java.lang.Exception: Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:11488,Safety,timeout,timeout,11488,"501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoProxyWithCleanFailures\n return gce_read.ReadNoProxy(uri)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce_read.py\"", line 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n); gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DN",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:12404,Safety,timeout,timeout,12404,"ine 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n); gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n Fil",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:14675,Safety,timeout,timeout,14675,"501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoProxyWithCleanFailures\n return gce_read.ReadNoProxy(uri)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce_read.py\"", line 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:15591,Safety,timeout,timeout,15591,"ore/credentials/gce_read.py\"", line 50, in ReadNoProxy\n request, timeout=timeout_property).read()\n File \""/usr/lib/python2.7/urllib2.py\"", line 401, in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.Batch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16319,Safety,recover,recoverWith,16319,"ne 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:16394,Safety,recover,recoverWith,16394,"usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$.StandardException(JesAsyncBackendJobExecutionActor.scala:63); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:411); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:666); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$1.applyOrElse(StandardAsyncExecutionActor.scala:663); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:3697,Security,validat,validate,3697,"/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n; File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.; py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205,; in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py; \"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutD; efault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n; File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/googl; e/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/g; ooglecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.p; y\"", line 41, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:6913,Security,validat,validate,6913,"I/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/loc; al-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga; /STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam,; command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/s; hare/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:10246,Security,validat,validate,10246,"A/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2228:13433,Security,validat,validate,13433,"A/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228
https://github.com/broadinstitute/cromwell/issues/2229:81,Availability,error,error,81,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:168,Availability,ERROR,ERROR,168,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:955,Availability,Failure,Failure,955,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:963,Availability,recover,recoverWith,963,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:4296,Integrability,protocol,protocol,4296,.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.stora,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:4390,Integrability,protocol,protocol,4390,hod); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.DefaultStorageRpc.rewrite(DefaultStorageRpc.java:590); 	at com.google.cloud.storage.spi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:4559,Integrability,protocol,protocol,4559,eam.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.DefaultStorageRpc.rewrite(DefaultStorageRpc.java:590); 	at com.google.cloud.storage.spi.DefaultStorageRpc.openRewrite(DefaultStorageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageI,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:5326,Modifiability,rewrite,rewrite,5326,eam0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.DefaultStorageRpc.rewrite(DefaultStorageRpc.java:590); 	at com.google.cloud.storage.spi.DefaultStorageRpc.openRewrite(DefaultStorageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:416); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.copy(StorageImpl.java:416); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.copy(CloudStorageFileSystemProvider.java:493); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:646); 	at cromwell.core.path.BetterFileMethods$class.copyTo(BetterFileMethods.scala:415); 	at cromwell.filesystems.gcs.GcsPath.copyTo(GcsPathBuilder.scala:116); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply$mcV$sp(PathCopier.scala:45); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at cr,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:225,Performance,cache,cache,225,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:299,Performance,cache,cache,299,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:1195,Performance,Cache,CacheHitDuplicating,1195,"opying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.sta",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:1247,Performance,Cache,CacheHitDuplicating,1247,"eGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:1311,Performance,Cache,CacheHitDuplicating,1311,Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.Ba,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:1363,Performance,Cache,CacheHitDuplicating,1363,apshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$r,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2014,Performance,Cache,CacheHitDuplicating,2014,opy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2055,Performance,Cache,CacheHitDuplicating,2055,cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2119,Performance,Cache,CacheHitDuplicating,2119,cheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concur,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2163,Performance,Cache,CacheHitDuplicating,2163,t cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2627,Performance,concurren,concurrent,2627,at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2718,Performance,concurren,concurrent,2718,rableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:50,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:2966,Performance,concurren,concurrent,2966,ala:104); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copySimpletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3040,Performance,concurren,concurrent,3040,impletons(CacheHitDuplicating.scala:62); 	at cromwell.backend.callcaching.CacheHitDuplicating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3126,Performance,concurren,concurrent,3126,icating$class.copyCachedOutputs(CacheHitDuplicating.scala:92); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStre,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3204,Performance,concurren,concurrent,3204,ckend.standard.StandardCacheHitCopyingActor.copyCachedOutputs(StandardCacheHitCopyingActor.scala:33); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at cromwell.backend.BackendCacheHitCopyingActor$$anonfun$receive$1$$anonfun$applyOrElse$2$$anonfun$apply$1.apply(BackendCacheHitCopyingActor.scala:22); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:6683,Performance,cache,cache,6683,"torageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:416); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.copy(StorageImpl.java:416); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.copy(CloudStorageFileSystemProvider.java:493); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:646); 	at cromwell.core.path.BetterFileMethods$class.copyTo(BetterFileMethods.scala:415); 	at cromwell.filesystems.gcs.GcsPath.copyTo(GcsPathBuilder.scala:116); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply$mcV$sp(PathCopier.scala:45); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:44); 	... 24 common frames omitted; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-1373] INFO c.e.w.l.e.EngineJobExecutionActor - Could not find another cache hit, falling back to running job: GenotypeGVCFsComparison.IndexVCF:-1:1; ```. It seems that the file can't be copied so it invalidates the cache. The wdl task is as follows:. ```; task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${combined_gvcf}""; File gvcf_index = ""${combined_gvcf}.tbi""; }; }; ```. I'm going to try running this same task in V24 without the docker hash (to see if it's something to do with the file) and in V26 to see if the issue is resolved there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:6828,Performance,cache,cache,6828,"torageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:416); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.copy(StorageImpl.java:416); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.copy(CloudStorageFileSystemProvider.java:493); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:646); 	at cromwell.core.path.BetterFileMethods$class.copyTo(BetterFileMethods.scala:415); 	at cromwell.filesystems.gcs.GcsPath.copyTo(GcsPathBuilder.scala:116); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply$mcV$sp(PathCopier.scala:45); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:44); 	... 24 common frames omitted; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-1373] INFO c.e.w.l.e.EngineJobExecutionActor - Could not find another cache hit, falling back to running job: GenotypeGVCFsComparison.IndexVCF:-1:1; ```. It seems that the file can't be copied so it invalidates the cache. The wdl task is as follows:. ```; task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${combined_gvcf}""; File gvcf_index = ""${combined_gvcf}.tbi""; }; }; ```. I'm going to try running this same task in V24 without the docker hash (to see if it's something to do with the file) and in V26 to see if the issue is resolved there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:963,Safety,recover,recoverWith,963,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:20,Security,hash,hash,20,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3609,Security,secur,security,3609,2); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(H,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3675,Security,secur,security,3675,tedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.ja,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3736,Security,secur,security,3736,$PromiseCompletingRunnable.run(Future.scala:24); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at co,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3807,Security,secur,security,3807,Invocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:3882,Security,secur,security,3882,utorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.ja,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2229:7333,Security,hash,hash,7333,"torageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:416); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.copy(StorageImpl.java:416); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.copy(CloudStorageFileSystemProvider.java:493); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:646); 	at cromwell.core.path.BetterFileMethods$class.copyTo(BetterFileMethods.scala:415); 	at cromwell.filesystems.gcs.GcsPath.copyTo(GcsPathBuilder.scala:116); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply$mcV$sp(PathCopier.scala:45); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at cromwell.core.path.PathCopier$$anonfun$copy$1.apply(PathCopier.scala:44); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:44); 	... 24 common frames omitted; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-1373] INFO c.e.w.l.e.EngineJobExecutionActor - Could not find another cache hit, falling back to running job: GenotypeGVCFsComparison.IndexVCF:-1:1; ```. It seems that the file can't be copied so it invalidates the cache. The wdl task is as follows:. ```; task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${combined_gvcf}""; File gvcf_index = ""${combined_gvcf}.tbi""; }; }; ```. I'm going to try running this same task in V24 without the docker hash (to see if it's something to do with the file) and in V26 to see if the issue is resolved there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229
https://github.com/broadinstitute/cromwell/issues/2232:21,Security,validat,validation,21,"This wdl should fail validation because `Array[String]fq_set_out` is declared in both conditional blocks. ```; scatter(sample in read_tsv(samples_file)) {; call MakeDirs {; input:; output_dir = output_dir,; sample_name = sample[0]; }; if (length(sample) == 2) {; call SamToFastq {; input:; picard_path = picard_path,; read_data = sample[1],; sample_name = sample[0],; sample_dir = MakeDirs.sample_dir; }; Array[String]fq_set_out = SamToFastq.fq_set; }; if (length(sample) == 3) {; call CopyFastq {; input:; fq1 = sample[1],; fq2 = sample[2],; sample_name = sample[0],; sample_dir = MakeDirs.sample_dir; }; Array[String]fq_set_out = CopyFastq.fq_set; }; call AlignBAM {; input:; new_ref = IndexReference.gatk_ref,; sample_dir = MakeDirs.sample_dir,; sample_name = sample[0],; fq_set = fq_set_out; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2232
https://github.com/broadinstitute/cromwell/issues/2233:218,Integrability,message,message,218,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:689,Security,Access,AccessDeniedException,689,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:764,Security,access,access,764,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:898,Security,access,access,898,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:960,Security,Access,AccessDeniedException,960,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:1031,Security,access,access,1031,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:17,Testability,test,testing,17,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:264,Testability,log,logs,264,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:489,Testability,log,log,489,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2233:511,Testability,log,log,511,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233
https://github.com/broadinstitute/cromwell/issues/2234:36,Security,access,access,36,This way a server that doesn't have access to certain docker-hub repos could still run an individual workflow that used those images since that workflow would have different credentials than the server as a whole. This is especially helpful in situations where you share a server with many people who may not all have the same permissions.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2234
https://github.com/broadinstitute/cromwell/issues/2236:721,Availability,error,error,721,"The following task delocalizes the output file: . ```; task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf_index = ""${combined_gvcf).tbi""; }; }; ```. In V25 the output file delocalizes correctly, but if you try to use this output file as input to a future task, it doesn't get the full google bucket path, it just has the string interpolation of the path that was on the VM in the IndexVCF task. . Instead the file shouldn't delocalize and a helpful error message should be provided that indicates that a File input shouldn't be interpreted as a String in the output section because it's using that local VM's relative path at that point (rather than the full google bucket path).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2236
https://github.com/broadinstitute/cromwell/issues/2236:727,Integrability,message,message,727,"The following task delocalizes the output file: . ```; task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf_index = ""${combined_gvcf).tbi""; }; }; ```. In V25 the output file delocalizes correctly, but if you try to use this output file as input to a future task, it doesn't get the full google bucket path, it just has the string interpolation of the path that was on the VM in the IndexVCF task. . Instead the file shouldn't delocalize and a helpful error message should be provided that indicates that a File input shouldn't be interpreted as a String in the output section because it's using that local VM's relative path at that point (rather than the full google bucket path).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2236
https://github.com/broadinstitute/cromwell/issues/2238:873,Availability,avail,available,873,"**NB** - we're happy to have more than one person working on this as long as it's temporally close. If you find this interesting and there's already someone assigned speak up. Also we're happy to have people doing this in spare cycles unofficially (as long as there's at least one official person), so if that's you also speak up. Timeboxed to 1 week. Take a deep dive into CWL in whatever form you think will be the most effective for you. The output of this should be some form of show & tell to the group, whatever you think will be most effective for how you did this. To give a little bit of guidance: Imagine a spectrum between becoming a generalized CWL expert on one side or having a perfect proof of concept of how we could implement one specific thing. The desired outcome would be to trend towards the former. Our goal here is to have a goto person (or persons) available when we start putting shovels to the ground.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2238
https://github.com/broadinstitute/cromwell/issues/2238:597,Usability,guid,guidance,597,"**NB** - we're happy to have more than one person working on this as long as it's temporally close. If you find this interesting and there's already someone assigned speak up. Also we're happy to have people doing this in spare cycles unofficially (as long as there's at least one official person), so if that's you also speak up. Timeboxed to 1 week. Take a deep dive into CWL in whatever form you think will be the most effective for you. The output of this should be some form of show & tell to the group, whatever you think will be most effective for how you did this. To give a little bit of guidance: Imagine a spectrum between becoming a generalized CWL expert on one side or having a perfect proof of concept of how we could implement one specific thing. The desired outcome would be to trend towards the former. Our goal here is to have a goto person (or persons) available when we start putting shovels to the ground.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2238
https://github.com/broadinstitute/cromwell/pull/2239:23,Availability,failure,failure,23,This would work if the failure mode is passed through workflow options but not if it's set in the config.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2239
https://github.com/broadinstitute/cromwell/pull/2239:98,Modifiability,config,config,98,This would work if the failure mode is passed through workflow options but not if it's set in the config.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2239
https://github.com/broadinstitute/cromwell/pull/2242:50,Availability,recover,recovered,50,…lues which caused the jobs to fail once cromwell recovered after a migration. For Develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2242
https://github.com/broadinstitute/cromwell/pull/2242:50,Safety,recover,recovered,50,…lues which caused the jobs to fail once cromwell recovered after a migration. For Develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2242
https://github.com/broadinstitute/cromwell/issues/2246:58,Availability,error,errors,58,As you see on the screenshot all pairs are highlighted as errors in Intellij while wdltool validates everything without an issue.; ![pair_highlightning_error](https://cloud.githubusercontent.com/assets/842436/25742086/783c9136-3196-11e7-8649-9fd5e1403b70.png),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2246
https://github.com/broadinstitute/cromwell/issues/2246:91,Security,validat,validates,91,As you see on the screenshot all pairs are highlighted as errors in Intellij while wdltool validates everything without an issue.; ![pair_highlightning_error](https://cloud.githubusercontent.com/assets/842436/25742086/783c9136-3196-11e7-8649-9fd5e1403b70.png),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2246
https://github.com/broadinstitute/cromwell/issues/2248:176,Availability,failure,failures,176,When we're determining call cache hits we have an issue where we need to pull hashes and compare them to potential hits in our database. Many of these lookups are likely to be failures. It seems like a bloom filter could be a good optimization here (provided the memory tradeoff is worth the time benefit) by filtering out obvious negative results prior to hitting the database.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248
https://github.com/broadinstitute/cromwell/issues/2248:28,Performance,cache,cache,28,When we're determining call cache hits we have an issue where we need to pull hashes and compare them to potential hits in our database. Many of these lookups are likely to be failures. It seems like a bloom filter could be a good optimization here (provided the memory tradeoff is worth the time benefit) by filtering out obvious negative results prior to hitting the database.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248
https://github.com/broadinstitute/cromwell/issues/2248:231,Performance,optimiz,optimization,231,When we're determining call cache hits we have an issue where we need to pull hashes and compare them to potential hits in our database. Many of these lookups are likely to be failures. It seems like a bloom filter could be a good optimization here (provided the memory tradeoff is worth the time benefit) by filtering out obvious negative results prior to hitting the database.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248
https://github.com/broadinstitute/cromwell/issues/2248:78,Security,hash,hashes,78,When we're determining call cache hits we have an issue where we need to pull hashes and compare them to potential hits in our database. Many of these lookups are likely to be failures. It seems like a bloom filter could be a good optimization here (provided the memory tradeoff is worth the time benefit) by filtering out obvious negative results prior to hitting the database.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248
https://github.com/broadinstitute/cromwell/pull/2251:20,Availability,failure,failures,20,JesApi run creation failures were being caught by the JesApi status handler and not getting handled correctly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2251
https://github.com/broadinstitute/cromwell/issues/2252:179,Deployability,release,release,179,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252
https://github.com/broadinstitute/cromwell/issues/2252:207,Integrability,message,message,207,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252
https://github.com/broadinstitute/cromwell/issues/2252:119,Security,hash,hash,119,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252
https://github.com/broadinstitute/cromwell/issues/2252:265,Security,hash,hash,265,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252
https://github.com/broadinstitute/cromwell/issues/2252:396,Security,hash,hashes,396,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252
https://github.com/broadinstitute/cromwell/pull/2253:6,Deployability,Update,Update,6,- [x] Update Swagger; - [x] Centaur tests; - [x] Update readme; - [x] Update changelog,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2253
https://github.com/broadinstitute/cromwell/pull/2253:49,Deployability,Update,Update,49,- [x] Update Swagger; - [x] Centaur tests; - [x] Update readme; - [x] Update changelog,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2253
https://github.com/broadinstitute/cromwell/pull/2253:70,Deployability,Update,Update,70,- [x] Update Swagger; - [x] Centaur tests; - [x] Update readme; - [x] Update changelog,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2253
https://github.com/broadinstitute/cromwell/pull/2253:36,Testability,test,tests,36,- [x] Update Swagger; - [x] Centaur tests; - [x] Update readme; - [x] Update changelog,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2253
https://github.com/broadinstitute/cromwell/issues/2254:26,Availability,failure,failures,26,"Quite often I get ; ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Docker image quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b has an invalid syntax.""; }; ],; ```; Here is example of the task that caused this error. What is interested is that cromwell even did not start this task, so I suspect there is something wrong with docker parsing (I have this issue for this container both in develop and latest release of cromwell). ```; task star {. Int numberOfThreads = 8; File file; File genomeDir. command {; STAR --runThreadN ${numberOfThreads} --genomeDir ${genomeDir} --readFilesCommand gunzip -c --readFilesIn ${file}; }. runtime {; docker: ""quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; String result = ""STAR WORKS!""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2254
https://github.com/broadinstitute/cromwell/issues/2254:276,Availability,error,error,276,"Quite often I get ; ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Docker image quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b has an invalid syntax.""; }; ],; ```; Here is example of the task that caused this error. What is interested is that cromwell even did not start this task, so I suspect there is something wrong with docker parsing (I have this issue for this container both in develop and latest release of cromwell). ```; task star {. Int numberOfThreads = 8; File file; File genomeDir. command {; STAR --runThreadN ${numberOfThreads} --genomeDir ${genomeDir} --readFilesCommand gunzip -c --readFilesIn ${file}; }. runtime {; docker: ""quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; String result = ""STAR WORKS!""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2254
https://github.com/broadinstitute/cromwell/issues/2254:472,Deployability,release,release,472,"Quite often I get ; ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Docker image quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b has an invalid syntax.""; }; ],; ```; Here is example of the task that caused this error. What is interested is that cromwell even did not start this task, so I suspect there is something wrong with docker parsing (I have this issue for this container both in develop and latest release of cromwell). ```; task star {. Int numberOfThreads = 8; File file; File genomeDir. command {; STAR --runThreadN ${numberOfThreads} --genomeDir ${genomeDir} --readFilesCommand gunzip -c --readFilesIn ${file}; }. runtime {; docker: ""quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; String result = ""STAR WORKS!""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2254
https://github.com/broadinstitute/cromwell/issues/2254:61,Integrability,message,message,61,"Quite often I get ; ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Docker image quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b has an invalid syntax.""; }; ],; ```; Here is example of the task that caused this error. What is interested is that cromwell even did not start this task, so I suspect there is something wrong with docker parsing (I have this issue for this container both in develop and latest release of cromwell). ```; task star {. Int numberOfThreads = 8; File file; File genomeDir. command {; STAR --runThreadN ${numberOfThreads} --genomeDir ${genomeDir} --readFilesCommand gunzip -c --readFilesIn ${file}; }. runtime {; docker: ""quay.io/biocontainers/star:2.5.3a--0@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; String result = ""STAR WORKS!""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2254
https://github.com/broadinstitute/cromwell/issues/2256:253,Deployability,release,release,253,"I noticed that if I give cromwell a container with existing entry-point (like quay.io/ucsc_cgl/fastqc@sha256:86d82e95a8e1bff48d95daf94ad1190d9c38283c8c5ad848b4a498f19ca94bfa , for instance) and give a file as an input it (both develop branch and latest release) fails to run the entry point properly. Here is an example of task; ```; task report {. String fileName; File file. command {; ${file}; }. runtime {; docker: ""quay.io/ucsc_cgl/fastqc@sha256:86d82e95a8e1bff48d95daf94ad1190d9c38283c8c5ad848b4a498f19ca94bfa""; #docker: ""quay.io/biocontainers/fastqc@sha256:bb57a4deeec90633e746afbc38c36fdb202599fe71f9557b94652e9c8f3c1a02""; }. output {; #File out = sub(file, ""\\.fastq.gz"", ""_fastqc.gz""); File out = ""${fileName}.fastqc.gz""; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2256
https://github.com/broadinstitute/cromwell/issues/2258:286,Deployability,update,update,286,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258
https://github.com/broadinstitute/cromwell/issues/2258:355,Deployability,release,releases,355,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258
https://github.com/broadinstitute/cromwell/issues/2258:629,Deployability,deploy,deploy,629,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258
https://github.com/broadinstitute/cromwell/issues/2258:710,Deployability,deploy,deployment,710,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258
https://github.com/broadinstitute/cromwell/issues/2258:247,Security,hash,hash,247,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258
https://github.com/broadinstitute/cromwell/issues/2260:155,Availability,echo,echoPair,155,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:193,Availability,echo,echoPair,193,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:240,Availability,echo,echo,240,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:49,Testability,Test,Test,49,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:54,Testability,test,testMe,54,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:113,Testability,Test,Test,113,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:142,Testability,test,testMe,142,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2260:176,Testability,test,testMe,176,"AC:; Something like this should run:. JSON:; {; ""Test.testMe"":{""left"":""Left"",""right"":""Right""}; }. WDL:; workflow Test {; 	Pair[String,String] testMe; call echoPair{input: pair=testMe}; }. task echoPair{; Pair[String,String] pair; command{; echo (${pair.left}, ${pair.right); }; output {; String out = read_string(stdout()); }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2260
https://github.com/broadinstitute/cromwell/issues/2262:348,Availability,error,error,348,"- develop; - server mode. ```; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(cche.HASH_VALUE)) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. yields a value of 1440. Yet, even when I set ``group_concat_max_len`` to 30000, I get the error message that the migration cannot be completed successfully.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2262
https://github.com/broadinstitute/cromwell/issues/2262:354,Integrability,message,message,354,"- develop; - server mode. ```; SELECT MAX(aggregated) as group_concat_max_len FROM; (; SELECT cche.CALL_CACHING_ENTRY_ID, SUM(LENGTH(cche.HASH_VALUE)) AS aggregated; FROM CALL_CACHING_HASH_ENTRY cche; GROUP BY cche.CALL_CACHING_ENTRY_ID; ) aggregation; ```. yields a value of 1440. Yet, even when I set ``group_concat_max_len`` to 30000, I get the error message that the migration cannot be completed successfully.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2262
https://github.com/broadinstitute/cromwell/issues/2264:109,Deployability,pipeline,pipelines,109,"Extracting name of the file (usually - in order to save it with another extension or suffix) is so common in pipelines, that I think it should be part of wdl standard functions",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2264
https://github.com/broadinstitute/cromwell/issues/2265:116,Deployability,pipeline,pipelines,116,"When I run scatter I get ""shard-n"". It would be nice to have an option to define shards names, for instance in some pipelines I would be happy to use sample names instead of shard-n to be able to easily detect what sample was processed in a wrong way.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2265
https://github.com/broadinstitute/cromwell/issues/2265:203,Safety,detect,detect,203,"When I run scatter I get ""shard-n"". It would be nice to have an option to define shards names, for instance in some pipelines I would be happy to use sample names instead of shard-n to be able to easily detect what sample was processed in a wrong way.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2265
https://github.com/broadinstitute/cromwell/issues/2266:259,Security,hash,hash,259,"Make sure to also follow up on linked RFEs from Mike Noble. ----. I have in my WDL output a glob of an array of files like this : . ```; 	Array[File] ais=glob(""*.png""); ```. Then in my output (in the bucket) I see a list file and a ""directory"" (both having a hash) listing and containing files picked up from the glob. ```; gsutil cat gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4.list; THCA-BJ-A0Z2-TP-NB.maf.mutation_CCG_histogram.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_coverage.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_histogram.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_orientation_alt_counts.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_orientation_weighted_mutations.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_AF.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_counts.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_normalized.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_samples_1-1.png; ```. (here are the PNGs). ```; wm8b1-75c:lp_glob esalinas$ gsutil ls gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4/THCA-BJ-A0Z2-TP-NB.maf.mutation_CCG_histogram.png; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4/THCA-BJ-A0Z2-TP-NB.maf.mutation_coverage.png; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plot",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2266
https://github.com/broadinstitute/cromwell/issues/2267:397,Modifiability,config,configurable,397,"WDL tasks localize during JES runs using WDL like so:. ```; task myTask {; File myFileToLocalize; Array[File] otherFilesToLocalize. ...; command <<<; #process ${myFileToLocalize} .... #process ${otherFilesToLocalize sep=""somesep""} ... >>>; ... ```. also, WDL tasks can specify disk size for attached disk to help ensure that there is sufficient disk-space for files like so (in the example a user-configurable setting):. ```; task diskTask {. 	Int diskGB. ..... runtime {; disks: ""local-disk ${diskGB} HDD"". ... ```. It would seem like a good idea to have a special variable to automatic allocation of disk size of localized files. For example instead of the call being like. ```; call diskTask {; input:; ...; diskGB=100; }; ```. or. ```; call diskTask {; input:; ...; diskGB=prepTask.calcDisk; }; ```. or. ```; call diskTask {; input:; ...; diskGB=size(someInputFile); }. ```. that maybe the variable could be like :. ```; call bigTask {; inputs:; fileOne=someFileOfUnknownSize,; fileTwo=anotherFileOfUnknownSize,; diskGB=autoSize()+autoSize()*0.2; }. ```. where ""autoSize"" automatically calculates sizes for files localized and adds them and I did some ""+*"" to add some factor from that (to have space for output files from the run) (in this case 20% of the disk for the output). I wonder about people's thoughts on this?. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9346/idea-for-enhancment-autosize/p1. ---. @lbergelson commented on [Wed Apr 05 2017](https://github.com/broadinstitute/dsde-docs/issues/1928#issuecomment-291881558). 👍 It would be nice to be able to specify memory requirements as a function of input filesize as well... It would be nice to have fine grained access to each input size as well as just the total.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2267
https://github.com/broadinstitute/cromwell/issues/2267:566,Modifiability,variab,variable,566,"WDL tasks localize during JES runs using WDL like so:. ```; task myTask {; File myFileToLocalize; Array[File] otherFilesToLocalize. ...; command <<<; #process ${myFileToLocalize} .... #process ${otherFilesToLocalize sep=""somesep""} ... >>>; ... ```. also, WDL tasks can specify disk size for attached disk to help ensure that there is sufficient disk-space for files like so (in the example a user-configurable setting):. ```; task diskTask {. 	Int diskGB. ..... runtime {; disks: ""local-disk ${diskGB} HDD"". ... ```. It would seem like a good idea to have a special variable to automatic allocation of disk size of localized files. For example instead of the call being like. ```; call diskTask {; input:; ...; diskGB=100; }; ```. or. ```; call diskTask {; input:; ...; diskGB=prepTask.calcDisk; }; ```. or. ```; call diskTask {; input:; ...; diskGB=size(someInputFile); }. ```. that maybe the variable could be like :. ```; call bigTask {; inputs:; fileOne=someFileOfUnknownSize,; fileTwo=anotherFileOfUnknownSize,; diskGB=autoSize()+autoSize()*0.2; }. ```. where ""autoSize"" automatically calculates sizes for files localized and adds them and I did some ""+*"" to add some factor from that (to have space for output files from the run) (in this case 20% of the disk for the output). I wonder about people's thoughts on this?. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9346/idea-for-enhancment-autosize/p1. ---. @lbergelson commented on [Wed Apr 05 2017](https://github.com/broadinstitute/dsde-docs/issues/1928#issuecomment-291881558). 👍 It would be nice to be able to specify memory requirements as a function of input filesize as well... It would be nice to have fine grained access to each input size as well as just the total.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2267
https://github.com/broadinstitute/cromwell/issues/2267:894,Modifiability,variab,variable,894,"WDL tasks localize during JES runs using WDL like so:. ```; task myTask {; File myFileToLocalize; Array[File] otherFilesToLocalize. ...; command <<<; #process ${myFileToLocalize} .... #process ${otherFilesToLocalize sep=""somesep""} ... >>>; ... ```. also, WDL tasks can specify disk size for attached disk to help ensure that there is sufficient disk-space for files like so (in the example a user-configurable setting):. ```; task diskTask {. 	Int diskGB. ..... runtime {; disks: ""local-disk ${diskGB} HDD"". ... ```. It would seem like a good idea to have a special variable to automatic allocation of disk size of localized files. For example instead of the call being like. ```; call diskTask {; input:; ...; diskGB=100; }; ```. or. ```; call diskTask {; input:; ...; diskGB=prepTask.calcDisk; }; ```. or. ```; call diskTask {; input:; ...; diskGB=size(someInputFile); }. ```. that maybe the variable could be like :. ```; call bigTask {; inputs:; fileOne=someFileOfUnknownSize,; fileTwo=anotherFileOfUnknownSize,; diskGB=autoSize()+autoSize()*0.2; }. ```. where ""autoSize"" automatically calculates sizes for files localized and adds them and I did some ""+*"" to add some factor from that (to have space for output files from the run) (in this case 20% of the disk for the output). I wonder about people's thoughts on this?. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9346/idea-for-enhancment-autosize/p1. ---. @lbergelson commented on [Wed Apr 05 2017](https://github.com/broadinstitute/dsde-docs/issues/1928#issuecomment-291881558). 👍 It would be nice to be able to specify memory requirements as a function of input filesize as well... It would be nice to have fine grained access to each input size as well as just the total.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2267
https://github.com/broadinstitute/cromwell/issues/2267:1749,Security,access,access,1749,"WDL tasks localize during JES runs using WDL like so:. ```; task myTask {; File myFileToLocalize; Array[File] otherFilesToLocalize. ...; command <<<; #process ${myFileToLocalize} .... #process ${otherFilesToLocalize sep=""somesep""} ... >>>; ... ```. also, WDL tasks can specify disk size for attached disk to help ensure that there is sufficient disk-space for files like so (in the example a user-configurable setting):. ```; task diskTask {. 	Int diskGB. ..... runtime {; disks: ""local-disk ${diskGB} HDD"". ... ```. It would seem like a good idea to have a special variable to automatic allocation of disk size of localized files. For example instead of the call being like. ```; call diskTask {; input:; ...; diskGB=100; }; ```. or. ```; call diskTask {; input:; ...; diskGB=prepTask.calcDisk; }; ```. or. ```; call diskTask {; input:; ...; diskGB=size(someInputFile); }. ```. that maybe the variable could be like :. ```; call bigTask {; inputs:; fileOne=someFileOfUnknownSize,; fileTwo=anotherFileOfUnknownSize,; diskGB=autoSize()+autoSize()*0.2; }. ```. where ""autoSize"" automatically calculates sizes for files localized and adds them and I did some ""+*"" to add some factor from that (to have space for output files from the run) (in this case 20% of the disk for the output). I wonder about people's thoughts on this?. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9346/idea-for-enhancment-autosize/p1. ---. @lbergelson commented on [Wed Apr 05 2017](https://github.com/broadinstitute/dsde-docs/issues/1928#issuecomment-291881558). 👍 It would be nice to be able to specify memory requirements as a function of input filesize as well... It would be nice to have fine grained access to each input size as well as just the total.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2267
https://github.com/broadinstitute/cromwell/issues/2268:295,Deployability,configurat,configuration,295,"@vdauwera commented on [Wed Apr 12 2017](https://github.com/broadinstitute/dsde-docs/issues/1963). This needs to be discussed further with both workbench and cromwell peeps/POs. ----. This may have been asked before, but I can't find the relevant thread...; It looks like any change to a method configuration automatically triggers a version increase. It would be very useful to be able to control this. For example, changing a memory parameter should be possible without changing the version. In Firehose this was/is possible with the 'Outdate task' option. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9388/versioning-of-method-configuration/p1. ---. @vdauwera commented on [Tue Apr 18 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295047979). @knoblett @katevoss This is a total can of worms that should probably be discussed with POs across teams. ---. @knoblett commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295445174). Is this a Red Team request or a FireCloud request? Seems more like the latter, but just want to clarify. ---. @vdauwera commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295453435). I think it cuts across both. There are Cromwell-level implications in terms of call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268
https://github.com/broadinstitute/cromwell/issues/2268:699,Deployability,configurat,configuration,699,"@vdauwera commented on [Wed Apr 12 2017](https://github.com/broadinstitute/dsde-docs/issues/1963). This needs to be discussed further with both workbench and cromwell peeps/POs. ----. This may have been asked before, but I can't find the relevant thread...; It looks like any change to a method configuration automatically triggers a version increase. It would be very useful to be able to control this. For example, changing a memory parameter should be possible without changing the version. In Firehose this was/is possible with the 'Outdate task' option. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9388/versioning-of-method-configuration/p1. ---. @vdauwera commented on [Tue Apr 18 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295047979). @knoblett @katevoss This is a total can of worms that should probably be discussed with POs across teams. ---. @knoblett commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295445174). Is this a Red Team request or a FireCloud request? Seems more like the latter, but just want to clarify. ---. @vdauwera commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295453435). I think it cuts across both. There are Cromwell-level implications in terms of call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268
https://github.com/broadinstitute/cromwell/issues/2268:295,Modifiability,config,configuration,295,"@vdauwera commented on [Wed Apr 12 2017](https://github.com/broadinstitute/dsde-docs/issues/1963). This needs to be discussed further with both workbench and cromwell peeps/POs. ----. This may have been asked before, but I can't find the relevant thread...; It looks like any change to a method configuration automatically triggers a version increase. It would be very useful to be able to control this. For example, changing a memory parameter should be possible without changing the version. In Firehose this was/is possible with the 'Outdate task' option. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9388/versioning-of-method-configuration/p1. ---. @vdauwera commented on [Tue Apr 18 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295047979). @knoblett @katevoss This is a total can of worms that should probably be discussed with POs across teams. ---. @knoblett commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295445174). Is this a Red Team request or a FireCloud request? Seems more like the latter, but just want to clarify. ---. @vdauwera commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295453435). I think it cuts across both. There are Cromwell-level implications in terms of call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268
https://github.com/broadinstitute/cromwell/issues/2268:699,Modifiability,config,configuration,699,"@vdauwera commented on [Wed Apr 12 2017](https://github.com/broadinstitute/dsde-docs/issues/1963). This needs to be discussed further with both workbench and cromwell peeps/POs. ----. This may have been asked before, but I can't find the relevant thread...; It looks like any change to a method configuration automatically triggers a version increase. It would be very useful to be able to control this. For example, changing a memory parameter should be possible without changing the version. In Firehose this was/is possible with the 'Outdate task' option. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9388/versioning-of-method-configuration/p1. ---. @vdauwera commented on [Tue Apr 18 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295047979). @knoblett @katevoss This is a total can of worms that should probably be discussed with POs across teams. ---. @knoblett commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295445174). Is this a Red Team request or a FireCloud request? Seems more like the latter, but just want to clarify. ---. @vdauwera commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295453435). I think it cuts across both. There are Cromwell-level implications in terms of call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268
https://github.com/broadinstitute/cromwell/issues/2269:2121,Integrability,depend,depending,2121,"-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is the recommended way to deal with these cases in WDL? I'll have to re-engineer bcbio to be able to represent and pass these and wanted to do so in a way that was forward compatible with WDL's thoughts and plans. I've seen recommendations on current hacks like explicitly declaring the indexes as separate files, or tarring up a directory of files and passing that as input. I'm not clear enough on staging files from WDL/Cromwell to understand if these are guaranteed to always go in the right place (bai next to bam, all indexes in the same directory). Thanks for any thoughts/suggestions/tips. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/wdl/discussion/9299/secondary-index-files-and-directories-in-wdl/p1. ---. @vdauwera commented on [Thu May 04 2017](https://github.com/broadinstitute/dsde-docs/issues/1996#issuecomment-299359050). @katevoss this is a very common request from the Cromwel",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:599,Modifiability,config,configurable,599,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:775,Modifiability,config,config,775,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:827,Modifiability,config,config,827,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:2105,Modifiability,variab,variable,2105,"-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is the recommended way to deal with these cases in WDL? I'll have to re-engineer bcbio to be able to represent and pass these and wanted to do so in a way that was forward compatible with WDL's thoughts and plans. I've seen recommendations on current hacks like explicitly declaring the indexes as separate files, or tarring up a directory of files and passing that as input. I'm not clear enough on staging files from WDL/Cromwell to understand if these are guaranteed to always go in the right place (bai next to bam, all indexes in the same directory). Thanks for any thoughts/suggestions/tips. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/wdl/discussion/9299/secondary-index-files-and-directories-in-wdl/p1. ---. @vdauwera commented on [Thu May 04 2017](https://github.com/broadinstitute/dsde-docs/issues/1996#issuecomment-299359050). @katevoss this is a very common request from the Cromwel",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:208,Security,access,accessory,208,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:467,Security,access,accessory,467,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:696,Security,access,accessory,696,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:1067,Security,access,access-and-secondary-index-files,1067,"adinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trick",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:1193,Security,validat,validation,1193,"have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:1321,Testability,test,testing,1321,"ook for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is the recommended way to deal with these cases in WDL? I'll have to re-engineer bcbio to be able to represent and pass these and wanted to do so in a way that wa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2269:2534,Usability,clear,clear,2534,"to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is the recommended way to deal with these cases in WDL? I'll have to re-engineer bcbio to be able to represent and pass these and wanted to do so in a way that was forward compatible with WDL's thoughts and plans. I've seen recommendations on current hacks like explicitly declaring the indexes as separate files, or tarring up a directory of files and passing that as input. I'm not clear enough on staging files from WDL/Cromwell to understand if these are guaranteed to always go in the right place (bai next to bam, all indexes in the same directory). Thanks for any thoughts/suggestions/tips. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/wdl/discussion/9299/secondary-index-files-and-directories-in-wdl/p1. ---. @vdauwera commented on [Thu May 04 2017](https://github.com/broadinstitute/dsde-docs/issues/1996#issuecomment-299359050). @katevoss this is a very common request from the Cromwell user community",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269
https://github.com/broadinstitute/cromwell/issues/2270:114,Availability,error,error,114,"- cromwell-27-aab4763-SNAP.jar; - JES backend ; - localhost MySQL with call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:229,Availability,ERROR,ERROR,229,"- cromwell-27-aab4763-SNAP.jar; - JES backend ; - localhost MySQL with call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:985,Availability,Fault,FaultHandling,985,"- cromwell-27-aab4763-SNAP.jar; - JES backend ; - localhost MySQL with call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1033,Availability,Fault,FaultHandling,1033,"nd ; - localhost MySQL with call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.valida",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1067,Availability,Fault,FaultHandling,1067,"ith call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthM",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1851,Availability,Error,Error,1851,"ExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1862,Availability,error,error,1862,"ExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:4120,Availability,robust,robustExecuteOrRecover,4120,tandardCachingActorHelper.scala:64); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.jobPaths$lzycompute(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.jobPaths(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardCachingActorHelper$class.startMetadataKeyValues(StandardCachingActorHelper.scala:76); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(JesAsyncBackendJobExecutionActor.scala:339); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.startMetadataKeyValues(JesAsyncBackendJobExecutionActor.scala:339); at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:516); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.executeOrRecover(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.core.retry.Retry$.withRetry(Retry.scala:36); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.withRetry(AsyncBackendJobExecutionActor.scala:50); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:77); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:4311,Availability,robust,robustExecuteOrRecover,4311,.JesAsyncBackendJobExecutionActor.jobPaths(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.standard.StandardCachingActorHelper$class.startMetadataKeyValues(StandardCachingActorHelper.scala:76); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(JesAsyncBackendJobExecutionActor.scala:339); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.startMetadataKeyValues(JesAsyncBackendJobExecutionActor.scala:339); at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:516); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.executeOrRecover(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.core.retry.Retry$.withRetry(Retry.scala:36); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.withRetry(AsyncBackendJobExecutionActor.scala:50); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:77); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunct,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:4669,Availability,robust,robustExecuteOrRecover,4669,kendJobExecutionActor.startMetadataKeyValues(JesAsyncBackendJobExecutionActor.scala:339); at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:516); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.executeOrRecover(JesAsyncBackendJobExecutionActor.scala:67); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:54); at cromwell.core.retry.Retry$.withRetry(Retry.scala:36); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.withRetry(AsyncBackendJobExecutionActor.scala:50); at cromwell.backend.async.AsyncBackendJobExecutionActor$class.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:54); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:77); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutio,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6003,Availability,Error,Error,6003,"t scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a te",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6014,Availability,error,error,6014,"t scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a te",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1448,Performance,concurren,concurrent,1448,"ailed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1521,Performance,concurren,concurrent,1521,"ailed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1606,Performance,concurren,concurrent,1606,"ExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.bac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1683,Performance,concurren,concurrent,1683,"andard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:1948,Security,validat,validate,1948,"orStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:36); at cromwell.backend.impl.jes.Je",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:2037,Security,validat,validateCredential,2037,"andleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:36); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.standard.StandardCac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:2132,Security,validat,validateCredential,2132,"4); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:36); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.standard.StandardCachingActorHelper$class.jobPaths(StandardCachingActorHelper.scala:64); at cromwell.backend.impl.j",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6346,Security,validat,validateCredential,6346,"Function.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6463,Security,validat,validateCredential,6463,"lFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor All workflows finished; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6573,Security,validat,validateCredential,6573,"lFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor All workflows finished; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:6721,Security,validat,validate,6721,"lFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor All workflows finished; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2270:213,Usability,responsiv,responsive,213,"- cromwell-27-aab4763-SNAP.jar; - JES backend ; - localhost MySQL with call caching enabled.; - server mode. This error is above my ability to debug. Cromwell failed after that. It did not exit, but was no longer responsive. ```[ERROR] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 6c383c35-d791-4971-aecd-0723726c8a7b failed (during ExecutingWorkflowState): JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; java.lang.RuntimeException: JesAsyncBackendJobExecutionActor failed and didn't catch its exception.; at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:147); at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:144); at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270
https://github.com/broadinstitute/cromwell/issues/2276:119,Availability,error,error,119,"I do not really know how to give you more relevant information, but IntelliJ is complaining that the WDL plugin has an error ... ```; Cyclic TextAttributesKey dependency found: BAD_CHARACTER->BAD_CHARACTER; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2276
https://github.com/broadinstitute/cromwell/issues/2276:159,Integrability,depend,dependency,159,"I do not really know how to give you more relevant information, but IntelliJ is complaining that the WDL plugin has an error ... ```; Cyclic TextAttributesKey dependency found: BAD_CHARACTER->BAD_CHARACTER; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2276
https://github.com/broadinstitute/cromwell/issues/2276:105,Modifiability,plugin,plugin,105,"I do not really know how to give you more relevant information, but IntelliJ is complaining that the WDL plugin has an error ... ```; Cyclic TextAttributesKey dependency found: BAD_CHARACTER->BAD_CHARACTER; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2276
https://github.com/broadinstitute/cromwell/pull/2277:2,Deployability,Upgrade,Upgrade,2,"- Upgrade google store nio library; - While testing this I found myself in the situation where the workflow initialization would fail, in which case we still do finalization (which is fine), but as part of this finalization we stand up a `CopyWorkflowOutputs` actor, which was failing and making my workflow hang. This fixes the hanging and fails the workflow + don't even run CopyWorkflowOutputs if we failed at Initialization stage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2277
https://github.com/broadinstitute/cromwell/pull/2277:44,Testability,test,testing,44,"- Upgrade google store nio library; - While testing this I found myself in the situation where the workflow initialization would fail, in which case we still do finalization (which is fine), but as part of this finalization we stand up a `CopyWorkflowOutputs` actor, which was failing and making my workflow hang. This fixes the hanging and fails the workflow + don't even run CopyWorkflowOutputs if we failed at Initialization stage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2277
https://github.com/broadinstitute/cromwell/issues/2278:129,Availability,echo,echo,129,"Seen on Cromwell 26-c14e64d. Reported to us as GAWB-1867. Here's a WDL:. ```; task HelloTask; 	{; 	File InFile; 	command; 		{; 		echo ""A file is here !"" ;; 		echo ""Here is the ls"" ;; 		ls -alh * ; 		ls -alht ${InFile} ; 		head ${InFile}; 		}; 	output; 		{; 		}; 	meta {author : ""Eddie Salinas""}; 	runtime { docker: ""eddiebroad/public_test_dsdeepb_2332"" }; 	}; 	; workflow HelloWorkflow; 	{; 	File InFile; 	call HelloTask; 		 {; 		input:InFile=InFile; 		}; 	}; ```. If I accidentally pass an empty string to the input, the job stays running indefinitely:. ```; {; ""workflowName"": ""HelloWorkflow"",; ""submittedFiles"": {; ""inputs"": ""{\""HelloWorkflow.InFile\"":\""\""}"",; ""workflow"": ""task HelloTask\n\t{\n\tFile InFile\n\tcommand\n\t\t{\n\t\techo \""A file is here !\"" ;\n\t\techo \""Here is the ls\"" ;\n\t\tls -alh * \n\t\tls -alht ${InFile} \n\t\thead ${InFile}\n\t\t}\n\toutput\n\t\t{\n\t\t}\n \tmeta {author : \""Eddie Salinas\""}\n\truntime { docker: \""eddiebroad/public_test_dsdeepb_2332\"" }\n\t}\n\t\nworkflow HelloWorkflow\n\t{\n\tFile InFile\n\tcall HelloTask\n\t\t {\n\t\tinput:InFile=InFile\n\t\t}\n\t}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:158,Availability,echo,echo,158,"Seen on Cromwell 26-c14e64d. Reported to us as GAWB-1867. Here's a WDL:. ```; task HelloTask; 	{; 	File InFile; 	command; 		{; 		echo ""A file is here !"" ;; 		echo ""Here is the ls"" ;; 		ls -alh * ; 		ls -alht ${InFile} ; 		head ${InFile}; 		}; 	output; 		{; 		}; 	meta {author : ""Eddie Salinas""}; 	runtime { docker: ""eddiebroad/public_test_dsdeepb_2332"" }; 	}; 	; workflow HelloWorkflow; 	{; 	File InFile; 	call HelloTask; 		 {; 		input:InFile=InFile; 		}; 	}; ```. If I accidentally pass an empty string to the input, the job stays running indefinitely:. ```; {; ""workflowName"": ""HelloWorkflow"",; ""submittedFiles"": {; ""inputs"": ""{\""HelloWorkflow.InFile\"":\""\""}"",; ""workflow"": ""task HelloTask\n\t{\n\tFile InFile\n\tcommand\n\t\t{\n\t\techo \""A file is here !\"" ;\n\t\techo \""Here is the ls\"" ;\n\t\tls -alh * \n\t\tls -alht ${InFile} \n\t\thead ${InFile}\n\t\t}\n\toutput\n\t\t{\n\t\t}\n \tmeta {author : \""Eddie Salinas\""}\n\truntime { docker: \""eddiebroad/public_test_dsdeepb_2332\"" }\n\t}\n\t\nworkflow HelloWorkflow\n\t{\n\tFile InFile\n\tcall HelloTask\n\t\t {\n\t\tinput:InFile=InFile\n\t\t}\n\t}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:2632,Performance,Cache,Cache,2632,"fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""googleProject"": ""broad-dsde-dev""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-f"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""result"": ""Cache Miss: You are using a floating docker tag in this task. Cromwell does not consider tasks with floating tags to be eligible for call caching.\nIf you want this task to be eligible for call caching in the future, use a docker runtime attribute with a digest instead.\nThis is the exact docker image that was used for this job: eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa\nYou can replace the docker runtime attribute in your task with the above value to make this task eligible for call caching."",; ""hit"": false; },; ""inputs"": {; ""InFile"": """"; },; ""backend"": ""JES"",; ""stderr"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:1477,Testability,log,logs,1477,"ing to the input, the job stays running indefinitely:. ```; {; ""workflowName"": ""HelloWorkflow"",; ""submittedFiles"": {; ""inputs"": ""{\""HelloWorkflow.InFile\"":\""\""}"",; ""workflow"": ""task HelloTask\n\t{\n\tFile InFile\n\tcommand\n\t\t{\n\t\techo \""A file is here !\"" ;\n\t\techo \""Here is the ls\"" ;\n\t\tls -alh * \n\t\tls -alht ${InFile} \n\t\thead ${InFile}\n\t\t}\n\toutput\n\t\t{\n\t\t}\n \tmeta {author : \""Eddie Salinas\""}\n\truntime { docker: \""eddiebroad/public_test_dsdeepb_2332\"" }\n\t}\n\t\nworkflow HelloWorkflow\n\t{\n\tFile InFile\n\tcall HelloTask\n\t\t {\n\t\tinput:InFile=InFile\n\t\t}\n\t}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""googleProject"": ""broad-dsde-dev""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:1948,Testability,log,log,1948,"rkflow\n\t{\n\tFile InFile\n\tcall HelloTask\n\t\t {\n\t\tinput:InFile=InFile\n\t\t}\n\t}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""googleProject"": ""broad-dsde-dev""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-f"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""result"": ""Cache Miss: You are using a floating docker tag in this task. Cromwell does not consider tasks with floating tags to be eligible for call caching.\nIf you want this task to be eligible for call caching in the future, use a docker runtime attribute with a digest instead.\nThis is the exact docker image that was used for this job: eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d57",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:3443,Testability,log,log,3443," ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-f"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""result"": ""Cache Miss: You are using a floating docker tag in this task. Cromwell does not consider tasks with floating tags to be eligible for call caching.\nIf you want this task to be eligible for call caching in the future, use a docker runtime attribute with a digest instead.\nThis is the exact docker image that was used for this job: eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa\nYou can replace the docker runtime attribute in your task with the above value to make this task eligible for call caching."",; ""hit"": false; },; ""inputs"": {; ""InFile"": """"; },; ""backend"": ""JES"",; ""stderr"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stderr.log"",; ""callRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask.log""; },; ""start"": ""2017-05-17T18:00:17.932Z""; }]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/"",; ""id"": ""f5c59dc3-fb98-42d9-9dbf-e9305d8e8793"",; ""inputs"": {; ""HelloWorkflow.InFile"": """"; },; ""submission"": ""2017-05-17T18:00:00.844Z"",; ""status"": ""Running"",; ""start"": ""2017-05-17T18:00:15.104Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:3648,Testability,log,log,3648," ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-f"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""result"": ""Cache Miss: You are using a floating docker tag in this task. Cromwell does not consider tasks with floating tags to be eligible for call caching.\nIf you want this task to be eligible for call caching in the future, use a docker runtime attribute with a digest instead.\nThis is the exact docker image that was used for this job: eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa\nYou can replace the docker runtime attribute in your task with the above value to make this task eligible for call caching."",; ""hit"": false; },; ""inputs"": {; ""InFile"": """"; },; ""backend"": ""JES"",; ""stderr"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stderr.log"",; ""callRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask.log""; },; ""start"": ""2017-05-17T18:00:17.932Z""; }]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/"",; ""id"": ""f5c59dc3-fb98-42d9-9dbf-e9305d8e8793"",; ""inputs"": {; ""HelloWorkflow.InFile"": """"; },; ""submission"": ""2017-05-17T18:00:00.844Z"",; ""status"": ""Running"",; ""start"": ""2017-05-17T18:00:15.104Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:3813,Testability,log,log,3813," ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa"",; ""cpu"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b,us-central1-c,us-central1-f"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""result"": ""Cache Miss: You are using a floating docker tag in this task. Cromwell does not consider tasks with floating tags to be eligible for call caching.\nIf you want this task to be eligible for call caching in the future, use a docker runtime attribute with a digest instead.\nThis is the exact docker image that was used for this job: eddiebroad/public_test_dsdeepb_2332@sha256:7ce5d574aa6a54318e75fc7adbaeda03ff60bc110464525540a751dd99e241fa\nYou can replace the docker runtime attribute in your task with the above value to make this task eligible for call caching."",; ""hit"": false; },; ""inputs"": {; ""InFile"": """"; },; ""backend"": ""JES"",; ""stderr"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stderr.log"",; ""callRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask.log""; },; ""start"": ""2017-05-17T18:00:17.932Z""; }]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/"",; ""id"": ""f5c59dc3-fb98-42d9-9dbf-e9305d8e8793"",; ""inputs"": {; ""HelloWorkflow.InFile"": """"; },; ""submission"": ""2017-05-17T18:00:00.844Z"",; ""status"": ""Running"",; ""start"": ""2017-05-17T18:00:15.104Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2278:1343,Usability,clear,cleared,1343,"e's a WDL:. ```; task HelloTask; 	{; 	File InFile; 	command; 		{; 		echo ""A file is here !"" ;; 		echo ""Here is the ls"" ;; 		ls -alh * ; 		ls -alht ${InFile} ; 		head ${InFile}; 		}; 	output; 		{; 		}; 	meta {author : ""Eddie Salinas""}; 	runtime { docker: ""eddiebroad/public_test_dsdeepb_2332"" }; 	}; 	; workflow HelloWorkflow; 	{; 	File InFile; 	call HelloTask; 		 {; 		input:InFile=InFile; 		}; 	}; ```. If I accidentally pass an empty string to the input, the job stays running indefinitely:. ```; {; ""workflowName"": ""HelloWorkflow"",; ""submittedFiles"": {; ""inputs"": ""{\""HelloWorkflow.InFile\"":\""\""}"",; ""workflow"": ""task HelloTask\n\t{\n\tFile InFile\n\tcommand\n\t\t{\n\t\techo \""A file is here !\"" ;\n\t\techo \""Here is the ls\"" ;\n\t\tls -alh * \n\t\tls -alht ${InFile} \n\t\thead ${InFile}\n\t\t}\n\toutput\n\t\t{\n\t\t}\n \tmeta {author : \""Eddie Salinas\""}\n\truntime { docker: \""eddiebroad/public_test_dsdeepb_2332\"" }\n\t}\n\t\nworkflow HelloWorkflow\n\t{\n\tFile InFile\n\tcall HelloTask\n\t\t {\n\t\tinput:InFile=InFile\n\t\t}\n\t}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/workflow.logs\"",\n \""account_name\"": \""obamacloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c\"",\n \""read_from_cache\"": true\n}""; },; ""calls"": {; ""HelloWorkflow.HelloTask"": [{; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://fc-463a83e5-a9b2-49bc-b9d2-0024e9b1afe6/bb61413a-3e29-44d1-beaa-5bbdd8cc711c/HelloWorkflow/f5c59dc3-fb98-42d9-9dbf-e9305d8e8793/call-HelloTask/HelloTask-stdout.log"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""endpointUrl"": ""h",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2278
https://github.com/broadinstitute/cromwell/issues/2279:140,Availability,Echo,Echo,140,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:206,Availability,Echo,Echo,206,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:270,Availability,Echo,Echo,270,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:308,Availability,echo,echo,308,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:582,Availability,Echo,Echo,582,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:676,Availability,Echo,Echo,676,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:744,Availability,Echo,Echo,744,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:782,Availability,echo,echo,782,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2279:18,Security,validat,validates,18,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279
https://github.com/broadinstitute/cromwell/issues/2281:261,Availability,failure,failures-based-on-check-alive,261,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:424,Availability,alive,alive,424,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:441,Availability,failure,failure,441,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:517,Availability,alive,alive,517,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:370,Modifiability,config,configure,370,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:152,Safety,detect,detects,152,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2281:249,Safety,detect,detect-task-failures-based-on-check-alive,249,"When running jobs on backends with job runtime limits such as LSF or SLURM, jobs reaching the runtime limits are killed by the backend. [Cromwell never detects that this occurs](http://gatkforums.broadinstitute.org/wdl/discussion/9542/does-cromwell-detect-task-failures-based-on-check-alive), and will wait forever for a job that is already dead. It would be helpful to configure periodic checks for whether tasks are still alive, and enter failure modes for non-zero return codes when unfinished tasks are no longer alive.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2281
https://github.com/broadinstitute/cromwell/issues/2283:448,Availability,failure,failure,448,"@geoffjentry commented on [Fri May 05 2017](https://github.com/broadinstitute/wdl/issues/109). **Needs Refinement**. We want to be able to define types for the values of objects. One suggestion was something like the following (note `struct` is using as a possible replacement for `object`, see below):. struct MyType {; o_f: File; x: Array[String]; }. MyType foo = read_object(...). It will coerce to the types it expects and if it can't that's a failure. Open questions:. - Do we make a new construct (e.g. `struct` above), or replace objects; - If replace, who (if anyone) is currently using `object`; - What's the right syntax, regardless of the name of the construct. This needs focus grouping.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2283
https://github.com/broadinstitute/cromwell/issues/2284:313,Availability,ERROR,ERROR,313,"I am constantly having issues when I run docker-compose of cromwell (I use https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql where I provide my configutation). Even though I do not have docker-user in my application.conf file when I run my pipelines, I get:; ```; cromwell_1 | [ERROR] [05/20/2017 12:57:46.015] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/WorkflowInitializationActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/Local] Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:592,Availability,Error,Error,592,"I am constantly having issues when I run docker-compose of cromwell (I use https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql where I provide my configutation). Even though I do not have docker-user in my application.conf file when I run my pipelines, I get:; ```; cromwell_1 | [ERROR] [05/20/2017 12:57:46.015] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/WorkflowInitializationActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/Local] Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:1638,Availability,Error,Error,1638,"ring out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigIniti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5847,Availability,ERROR,ERROR,5847,"tionActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:683); cromwell_1 | 	at scala.collection.immutable.List.foreach(List.scala:381); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:682); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19.apply(WdlNamespace.scala:403); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19.apply(WdlNamespace.scala:402); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Trave",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:275,Deployability,pipeline,pipelines,275,"I am constantly having issues when I run docker-compose of cromwell (I use https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql where I provide my configutation). Even though I do not have docker-user in my application.conf file when I run my pipelines, I get:; ```; cromwell_1 | [ERROR] [05/20/2017 12:57:46.015] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/WorkflowInitializationActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/Local] Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:179,Modifiability,config,configutation,179,"I am constantly having issues when I run docker-compose of cromwell (I use https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql where I provide my configutation). Even though I do not have docker-user in my application.conf file when I run my pipelines, I get:; ```; cromwell_1 | [ERROR] [05/20/2017 12:57:46.015] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/WorkflowInitializationActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/Local] Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2686,Modifiability,config,config,2686,"mit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2693,Modifiability,Config,ConfigWdlNamespace,2693,"ll_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(Standar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2719,Modifiability,Config,ConfigWdlNamespace,2719,"tring job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2792,Modifiability,config,config,2792,"romwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializati",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2799,Modifiability,Config,ConfigInitializationActor,2799,"g out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.va",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2825,Modifiability,config,configWdlNamespace,2825,"1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2855,Modifiability,Config,ConfigInitializationActor,2855,"1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2935,Modifiability,config,config,2935,"mand {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitial",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2942,Modifiability,Config,ConfigInitializationActor,2942,"1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$cla",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2968,Modifiability,config,configWdlNamespace,2968," | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowIniti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:2987,Modifiability,Config,ConfigInitializationActor,2987," | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowIniti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3067,Modifiability,config,config,3067,"ker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3074,Modifiability,Config,ConfigInitializationActor,3074," | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3134,Modifiability,Config,ConfigInitializationActor,3134," | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3214,Modifiability,config,config,3214,"ng err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3221,Modifiability,Config,ConfigInitializationActor,3221,"1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anon",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3270,Modifiability,Config,ConfigInitializationActor,3270,"mwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3350,Modifiability,config,config,3350,"mwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3357,Modifiability,Config,ConfigInitializationActor,3357," {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationAc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3419,Modifiability,Config,ConfigInitializationActor,3419,"; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3499,Modifiability,config,config,3499,ypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3506,Modifiability,Config,ConfigInitializationActor,3506,\; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycle,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3557,Modifiability,Config,ConfigInitializationActor,3557,} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(Ba,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5854,Modifiability,Variab,Variable,5854,"tionActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:683); cromwell_1 | 	at scala.collection.immutable.List.foreach(List.scala:381); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:682); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19.apply(WdlNamespace.scala:403); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19.apply(WdlNamespace.scala:402); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Trave",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8972,Modifiability,config,config,8972,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8979,Modifiability,Config,ConfigWdlNamespace,8979,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:9005,Modifiability,Config,ConfigWdlNamespace,9005,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:4531,Performance,perform,performActionThenRespond,4531,er(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$Wo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:4660,Performance,perform,performActionThenRespond,4660,ttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5433,Performance,concurren,concurrent,5433,"nitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5520,Performance,concurren,concurrent,5520,"class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:683); cromwell_1 | 	at scala.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5619,Performance,concurren,concurrent,5619,"tandard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:683); cromwell_1 | 	at scala.collection.immutable.List.foreach(List.scala:381); cromwell_1 | 	at scala.collection.TraversableLike",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:5710,Performance,concurren,concurrent,5710,"ala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:42); cromwell_1 | 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); cromwell_1 | 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); cromwell_1 | 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | Caused by: wdl4s.parser.WdlParser$SyntaxError: ERROR: Variable docker_user does not reference any declaration in the task (line 31, col 25):; cromwell_1 | ; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | Task defined here (line 16, col 6):; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ^; cromwell_1 | ; cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:405); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42$$anonfun$apply$19$$anonfun$apply$22.apply(WdlNamespace.scala:403); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:683); cromwell_1 | 	at scala.collection.immutable.List.foreach(List.scala:381); cromwell_1 | 	at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:682); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8568,Performance,load,load,8568,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8671,Performance,load,load,8671,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8821,Performance,load,load,8821,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:8888,Performance,load,loadUsingSource,8888,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2284:3810,Security,validat,validateRuntimeAttributes,3810,ace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowIn,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284
https://github.com/broadinstitute/cromwell/issues/2285:20,Testability,log,logs,20,Seems that the call logs are not being copied to the final directory when run on the TES backend. This test is failing: https://github.com/broadinstitute/centaur/blob/develop/src/test/scala/centaur/FinalDirsSpec.scala#L64. using these parameters:; https://github.com/broadinstitute/centaur/blob/develop/src/main/resources/finalCopy/final_call_logs_dir_tes.test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2285
https://github.com/broadinstitute/cromwell/issues/2285:103,Testability,test,test,103,Seems that the call logs are not being copied to the final directory when run on the TES backend. This test is failing: https://github.com/broadinstitute/centaur/blob/develop/src/test/scala/centaur/FinalDirsSpec.scala#L64. using these parameters:; https://github.com/broadinstitute/centaur/blob/develop/src/main/resources/finalCopy/final_call_logs_dir_tes.test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2285
https://github.com/broadinstitute/cromwell/issues/2285:179,Testability,test,test,179,Seems that the call logs are not being copied to the final directory when run on the TES backend. This test is failing: https://github.com/broadinstitute/centaur/blob/develop/src/test/scala/centaur/FinalDirsSpec.scala#L64. using these parameters:; https://github.com/broadinstitute/centaur/blob/develop/src/main/resources/finalCopy/final_call_logs_dir_tes.test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2285
https://github.com/broadinstitute/cromwell/issues/2285:356,Testability,test,test,356,Seems that the call logs are not being copied to the final directory when run on the TES backend. This test is failing: https://github.com/broadinstitute/centaur/blob/develop/src/test/scala/centaur/FinalDirsSpec.scala#L64. using these parameters:; https://github.com/broadinstitute/centaur/blob/develop/src/main/resources/finalCopy/final_call_logs_dir_tes.test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2285
https://github.com/broadinstitute/cromwell/issues/2286:19,Availability,error,error,19,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:147,Availability,failure,failure,147,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:229,Availability,ERROR,ERROR,229,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:651,Performance,concurren,concurrent,651,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:1111,Performance,concurren,concurrent,1111,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:1436,Performance,concurren,concurrent,1436,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:1510,Performance,concurren,concurrent,1510,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:1596,Performance,concurren,concurrent,1596,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/issues/2286:1674,Performance,concurren,concurrent,1674,"I encountered this error in Cromwell v26, while running a large workflow that appears to have failed. I am not sure whether it is the cause of the failure; I have not yet been able to locate what job this corresponds to. ; ```; [ERROR] [05/22/2017 00:14:05.821] [cromwell-system-akka.dispatchers.engine-dispatcher-38] [akka.dispatch.Dispatcher] null; java.lang.NullPointerException; 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:22); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheWriteActor$$anonfun$1.apply(CallCacheWriteActor.scala:19); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2286
https://github.com/broadinstitute/cromwell/pull/2287:461,Availability,avail,available,461,"This fixes the docker deadlock by doing 2 things:. - makes sure that all `HttpResponse`s are either consumed or discarded to avoid https://github.com/akka/akka/issues/19538; - removes the decoupling between the `tokenFlow` and the `manifestFlow`; This is believed to be the main cause of the problem. Decoupling the token request from the manifest request can create a situation where all the connections are being used for token requests, and no connection is available to make a manifest request which makes the stream freeze.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2287
https://github.com/broadinstitute/cromwell/pull/2287:125,Safety,avoid,avoid,125,"This fixes the docker deadlock by doing 2 things:. - makes sure that all `HttpResponse`s are either consumed or discarded to avoid https://github.com/akka/akka/issues/19538; - removes the decoupling between the `tokenFlow` and the `manifestFlow`; This is believed to be the main cause of the problem. Decoupling the token request from the manifest request can create a situation where all the connections are being used for token requests, and no connection is available to make a manifest request which makes the stream freeze.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2287
https://github.com/broadinstitute/cromwell/pull/2293:2,Deployability,Update,Updated,2,"* Updated to reflect the current status of the [TES schema](https://github.com/ga4gh/task-execution-schemas); * Adds gcsPathBuilder; * Removed cpu, ram, and disk default values so that the TES implementation can handle defaults",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2293
https://github.com/broadinstitute/cromwell/issues/2296:331,Availability,error,error,331,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:574,Availability,error,error,574,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:777,Availability,ERROR,ERROR,777,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:1002,Availability,ERROR,ERROR,1002,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:3370,Deployability,configurat,configuration,3370,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:2957,Integrability,Message,Message,2957,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:3370,Modifiability,config,configuration,3370,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:747,Performance,load,load,747,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:972,Performance,load,load,972,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:2461,Performance,concurren,concurrent,2461,"vent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [201",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:2535,Performance,concurren,concurrent,2535,"kflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished wi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:2621,Performance,concurren,concurrent,2621,"riptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to sta",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:2699,Performance,concurren,concurrent,2699,":799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:1572,Testability,Log,LoggingFSM,1572,or Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.j,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:1665,Testability,Log,LoggingFSM,1665,ingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:3327,Testability,log,logging,3327,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:3399,Testability,log,log-dead-letters,3399,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:3427,Testability,log,log-dead-letters-during-shutdown,3427,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2296:104,Usability,simpl,simple-multi-step-workflow,104,"Trying to follow example here: http://gatkforums.broadinstitute.org/wdl/discussion/7221/2-howto-write-a-simple-multi-step-workflow. I editted the json file (simpleVariantSelection_inputs.json) with the full paths on my local machine and replacing the ""File"" and ""String"" placeholders. However when I run I am getting the following error:. [2017-05-25 12:18:24,85] [info] WorkflowManagerActor Successfully started WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c; [2017-05-25 12:18:24,85] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-05-25 12:18:24,93] [error] WorkflowManagerActor Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Finished parsing without consuming all tokens. {; ^. 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:137); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:129); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296
https://github.com/broadinstitute/cromwell/issues/2297:53,Deployability,update,update,53,"Workflows can stay in ""Running"" mode forever. I will update this ticket with a WDL to reproduce it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2297
https://github.com/broadinstitute/cromwell/issues/2300:115,Availability,error,error,115,"Pair accessing was never added properly to the docs.; When a pair is accessed incorrectly, it'd be nice to have an error along the lines of `use pair.left and pair.right to access Pair members`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300
https://github.com/broadinstitute/cromwell/issues/2300:5,Security,access,accessing,5,"Pair accessing was never added properly to the docs.; When a pair is accessed incorrectly, it'd be nice to have an error along the lines of `use pair.left and pair.right to access Pair members`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300
https://github.com/broadinstitute/cromwell/issues/2300:69,Security,access,accessed,69,"Pair accessing was never added properly to the docs.; When a pair is accessed incorrectly, it'd be nice to have an error along the lines of `use pair.left and pair.right to access Pair members`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300
https://github.com/broadinstitute/cromwell/issues/2300:173,Security,access,access,173,"Pair accessing was never added properly to the docs.; When a pair is accessed incorrectly, it'd be nice to have an error along the lines of `use pair.left and pair.right to access Pair members`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300
https://github.com/broadinstitute/cromwell/issues/2301:21,Deployability,upgrade,upgrade,21,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2301:83,Deployability,integrat,integration,83,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2301:67,Energy Efficiency,Green,Green,67,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2301:83,Integrability,integrat,integration,83,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2301:0,Testability,Test,Test,0,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2301:95,Testability,test,testing,95,"Test the Cromwell 27 upgrade for GOTC. Also, let's talk about what Green needs for integration testing in general, and what they need.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2301
https://github.com/broadinstitute/cromwell/issues/2303:161,Usability,guid,guide,161,Cromwell Workflow Object Model (CromWOM) will be a subset of WDL4S and ultimately a superset of WDL and CWL. Look at converting CWL files to the WDL4S format to guide the design of CromWOM. The general approach is in increasing order of complexity:; 1st-tool.cwl; 1st-workflow.cwl; env.cwl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2303
https://github.com/broadinstitute/cromwell/issues/2308:90,Integrability,depend,dependency,90,This is a much bigger split than separating the packages but will allow us to enforce the dependency direction:; - `wdl` depends on `wom`; - `wom` **must not** depend on `wdl`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2308
https://github.com/broadinstitute/cromwell/issues/2308:121,Integrability,depend,depends,121,This is a much bigger split than separating the packages but will allow us to enforce the dependency direction:; - `wdl` depends on `wom`; - `wom` **must not** depend on `wdl`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2308
https://github.com/broadinstitute/cromwell/issues/2308:160,Integrability,depend,depend,160,This is a much bigger split than separating the packages but will allow us to enforce the dependency direction:; - `wdl` depends on `wom`; - `wom` **must not** depend on `wdl`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2308
https://github.com/broadinstitute/cromwell/issues/2309:202,Availability,down,downstream,202,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:224,Availability,down,downstream,224,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:551,Availability,down,downstream,551,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:736,Availability,down,down,736,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:749,Integrability,depend,depending,749,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:256,Performance,cache,cache,256,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/issues/2309:442,Performance,cache,cache,442,"As a user, I have a workflow that runs a scatter over 10 shards with a task that produce a file, then uses writelines to write out the gathered array of files (the fofn), which is used as an input to a downstream step. That downstream step will never call cache because the fofn is different every time because the file in it, while each having the same md5, produce a different fofn because call caching copies the data to new paths on each cache hit. This is painful because I love call caching, and now I have to recompute this step (and all steps downstream of it) every time. @cjllanwarne @jmthibault79 any more details or ideas for addressing this; @katevoss this is the issue we talked about on the phone yesterday. It's slowing down JG, but depending on how hard it is to fix may be too late for this use case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309
https://github.com/broadinstitute/cromwell/pull/2314:48,Security,validat,validation,48,"Specifically to ""refresh token"" mode credential validation.; Other modes should only be validated once at Cromwell startup, since they don't change for every workflow.; Only ""refresh token mode"" generates different credentials for every workflow (with the refresh token passed in), that need to be validated. Retrying this asynchronously means turning into `Future`s a bunch of methods that were previously synchronous.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2314
https://github.com/broadinstitute/cromwell/pull/2314:88,Security,validat,validated,88,"Specifically to ""refresh token"" mode credential validation.; Other modes should only be validated once at Cromwell startup, since they don't change for every workflow.; Only ""refresh token mode"" generates different credentials for every workflow (with the refresh token passed in), that need to be validated. Retrying this asynchronously means turning into `Future`s a bunch of methods that were previously synchronous.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2314
https://github.com/broadinstitute/cromwell/pull/2314:298,Security,validat,validated,298,"Specifically to ""refresh token"" mode credential validation.; Other modes should only be validated once at Cromwell startup, since they don't change for every workflow.; Only ""refresh token mode"" generates different credentials for every workflow (with the refresh token passed in), that need to be validated. Retrying this asynchronously means turning into `Future`s a bunch of methods that were previously synchronous.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2314
https://github.com/broadinstitute/cromwell/issues/2315:159,Availability,alive,alive,159,"Some SFS backends can kill jobs outside of Cromwell, leaving us waiting forever for an rc file that will never be created. . Idea: occasionally run the `check-alive` command to verify that long-running jobs are indeed still alive outside of restarting Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2315
https://github.com/broadinstitute/cromwell/issues/2315:224,Availability,alive,alive,224,"Some SFS backends can kill jobs outside of Cromwell, leaving us waiting forever for an rc file that will never be created. . Idea: occasionally run the `check-alive` command to verify that long-running jobs are indeed still alive outside of restarting Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2315
https://github.com/broadinstitute/cromwell/issues/2318:26,Safety,abort,abort,26,I noticed that in swagger abort is marked as POST request despite it contains only two parameters: version and id. I suggest to make it a get request,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2318
https://github.com/broadinstitute/cromwell/issues/2323:64,Deployability,deploy,deploy,64,We want to ctmpl'ize the cromwell conf we will be using when we deploy cromwell. This involves removing any environment specific things (making them variable) as well as any secrets. Any secrets removed should be put into vault.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2323
https://github.com/broadinstitute/cromwell/issues/2323:149,Modifiability,variab,variable,149,We want to ctmpl'ize the cromwell conf we will be using when we deploy cromwell. This involves removing any environment specific things (making them variable) as well as any secrets. Any secrets removed should be put into vault.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2323
https://github.com/broadinstitute/cromwell/issues/2324:63,Deployability,deploy,deploy,63,We want to ctmpl'ize the cromiam conf we will be using when we deploy cromiam. This involves removing any environment specific things (making them variable) as well as any secrets. Any secrets removed should be put into vault.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2324
https://github.com/broadinstitute/cromwell/issues/2324:147,Modifiability,variab,variable,147,We want to ctmpl'ize the cromiam conf we will be using when we deploy cromiam. This involves removing any environment specific things (making them variable) as well as any secrets. Any secrets removed should be put into vault.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2324
https://github.com/broadinstitute/cromwell/issues/2325:152,Usability,guid,guide,152,"Create the docker-compose ctmpl that will bring all the pieces together (cromwell, cromiam, eva, other devops tools, etc etc). @jacmrob will be able to guide us once we get here.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2325
https://github.com/broadinstitute/cromwell/issues/2327:382,Modifiability,extend,extending,382,"As an outside developer who would like to develop new functionality for Cromwell, I would like to have a developers guide that can get me going. The developer's guide can assume a high level of technical proficiency, but I need help in understand the architecture and concepts that are relevant. The areas that are important to me (in rough order) are:; - creating a new backend; - extending an existing backend; - replacing ""pluggable"" components with new implementations (e.g. the Metadata Store)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2327
https://github.com/broadinstitute/cromwell/issues/2327:116,Usability,guid,guide,116,"As an outside developer who would like to develop new functionality for Cromwell, I would like to have a developers guide that can get me going. The developer's guide can assume a high level of technical proficiency, but I need help in understand the architecture and concepts that are relevant. The areas that are important to me (in rough order) are:; - creating a new backend; - extending an existing backend; - replacing ""pluggable"" components with new implementations (e.g. the Metadata Store)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2327
https://github.com/broadinstitute/cromwell/issues/2327:161,Usability,guid,guide,161,"As an outside developer who would like to develop new functionality for Cromwell, I would like to have a developers guide that can get me going. The developer's guide can assume a high level of technical proficiency, but I need help in understand the architecture and concepts that are relevant. The areas that are important to me (in rough order) are:; - creating a new backend; - extending an existing backend; - replacing ""pluggable"" components with new implementations (e.g. the Metadata Store)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2327
https://github.com/broadinstitute/cromwell/issues/2330:178,Modifiability,config,config,178,"With the SFS backend, when call caching files can be copied, sym linked or hard linked. With JES we only support copying the file. Provide a mechanism for the JES backend in the config file to either copy the files or leave them in place and access them that way.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330
https://github.com/broadinstitute/cromwell/issues/2330:242,Security,access,access,242,"With the SFS backend, when call caching files can be copied, sym linked or hard linked. With JES we only support copying the file. Provide a mechanism for the JES backend in the config file to either copy the files or leave them in place and access them that way.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330
https://github.com/broadinstitute/cromwell/issues/2332:58,Deployability,update,update,58,"@ruchim here are the two use cases:; As a user, I want to update an existing label after submission.; As a user, I want to remove an existing label after submission. This is outside of JES, no increase or decrease of ""JESification"" for now.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2332
https://github.com/broadinstitute/cromwell/issues/2333:31,Safety,abort,abort,31,"@ruchim ; As a user, I want to abort a series of workflows by their label. Does not involve JESification at this time.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2333
https://github.com/broadinstitute/cromwell/issues/2334:194,Availability,error,error,194,"I have a scatter block in a WDL (see below). I had one task that called a subworkflow and it was fine (m2.Mutect2). So I decided to add another task to the scatter block and now I get a parsing error. I'm really trying to find the issue here, but can't. Basically, p.left.left works for earlier calls in the same scatter block but not the later ones. ```. import ""dl_ob_training_m2.wdl"" as dl_ob_training_m2; import ""mutect2.wdl"" as m2. workflow dl_testing_m2 {; File tumor_bam_file_list; Array[File] tumor_bam_files = read_lines(tumor_bam_file_list). File tumor_bam_file_index_list; Array[File] tumor_bam_indices = read_lines(tumor_bam_file_index_list). File normal_bam_file_list; Array[File] normal_bam_files = read_lines(normal_bam_file_list). File normal_bam_file_index_list; Array[File] normal_bam_indices = read_lines(normal_bam_file_index_list). # pair.left and pair.right; Array[Pair[File, File]] tumor_bam_pair = zip(tumor_bam_files, tumor_bam_indices); Array[Pair[File, File]] normal_bam_pair = zip(normal_bam_files, normal_bam_indices). Array[Pair[Pair[File, File], Pair[File, File]]] tumor_normal_pairs = zip(tumor_bam_pair, normal_bam_pair). # ...........<snip>......... scatter (p in tumor_normal_pairs) {; # This call works fine; call m2.Mutect2 as m2_tn {; input:; gatk4_jar = ""/root/gatk-protected.jar"",; intervals = mutectIntervals,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fai,; ref_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/ga",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:2383,Availability,error,error,2383,".<snip>......... scatter (p in tumor_normal_pairs) {; # This call works fine; call m2.Mutect2 as m2_tn {; input:; gatk4_jar = ""/root/gatk-protected.jar"",; intervals = mutectIntervals,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fai,; ref_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:2815,Availability,error,error,2815,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:2884,Availability,ERROR,ERROR,2884,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:3140,Availability,error,error,3140,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:3250,Availability,error,error,3250,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:3400,Availability,error,error,3400,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2334:2821,Integrability,message,message,2821,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334
https://github.com/broadinstitute/cromwell/issues/2336:44,Availability,down,down,44,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. First try will be with using Travis and probably moving to Jenkins if it can't be done. This test could be run nightly/weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2336
https://github.com/broadinstitute/cromwell/issues/2336:15,Energy Efficiency,green,green,15,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. First try will be with using Travis and probably moving to Jenkins if it can't be done. This test could be run nightly/weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2336
https://github.com/broadinstitute/cromwell/issues/2336:237,Testability,test,test,237,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. First try will be with using Travis and probably moving to Jenkins if it can't be done. This test could be run nightly/weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2336
https://github.com/broadinstitute/cromwell/issues/2337:44,Availability,down,down,44,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. The easiest first step would be to make this a part of the Tyburn daily test we already have on Jenkins. This test should probably run weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2337
https://github.com/broadinstitute/cromwell/issues/2337:15,Energy Efficiency,green,green,15,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. The easiest first step would be to make this a part of the Tyburn daily test we already have on Jenkins. This test should probably run weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2337
https://github.com/broadinstitute/cromwell/issues/2337:216,Testability,test,test,216,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. The easiest first step would be to make this a part of the Tyburn daily test we already have on Jenkins. This test should probably run weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2337
https://github.com/broadinstitute/cromwell/issues/2337:254,Testability,test,test,254,"We want to run green workflows with slimmed down inputs to make sure we haven't broken any of the features they currently use with our changes. The easiest first step would be to make this a part of the Tyburn daily test we already have on Jenkins. This test should probably run weekly, discuss with the team once things are set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2337
https://github.com/broadinstitute/cromwell/issues/2338:327,Availability,avail,available,327,Currently the only trace of a call end status after the workflow has completed is in the metadata.; This makes it impossible for other endpoints (e.g: call caching diff endpoint) to relay this information without reading from metadata. We might want to investigate storing this information somewhere permanent: it is currently available in the jobstore but only for the duration of the workflow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2338
https://github.com/broadinstitute/cromwell/issues/2340:263,Availability,error,error,263,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:284,Availability,down,down,284,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:335,Availability,error,error,335,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:366,Availability,error,error,366,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:546,Availability,ERROR,ERROR,546,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:700,Availability,error,error,700,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2340:184,Testability,log,log,184,"There's an Akka Streams AbruptTerminationException being thrown by some process being shutdown unexpectedly. It's not causing any actual issues for users, however it's presence in the log is distracting. We should make sure that whatever process is throwing this error should be shut down more gracefully. ```[2017-06-05 16:56:14,16] [error] Outgoing request stream error; akka.stream.AbruptTerminationException: Processor actor [Actor[akka://cromwell-system/user/StreamSupervisor-1/flow-6-0-unknown-operation#-1334744097]] terminated abruptly; [ERROR] [06/05/2017 16:56:14.156] [cromwell-system-akka.actor.default-dispatcher-37] [akka.actor.ActorSystemImpl(cromwell-system)] Outgoing request stream error (akka.stream.AbruptTerminationException)```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2340
https://github.com/broadinstitute/cromwell/issues/2346:82,Deployability,configurat,configuration,82,"Seems like this would currently look something like PBE, with probably a lot less configuration. In the KISS spirit, perhaps only a list of supported `workflowType` + `workflowTypeVersion`s for each language processor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2346
https://github.com/broadinstitute/cromwell/issues/2346:82,Modifiability,config,configuration,82,"Seems like this would currently look something like PBE, with probably a lot less configuration. In the KISS spirit, perhaps only a list of supported `workflowType` + `workflowTypeVersion`s for each language processor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2346
https://github.com/broadinstitute/cromwell/issues/2350:21,Modifiability,config,configured,21,"Currently Centaur is configured with a URL for a live Cromwell server. Leave this capability but also allow for Centaur to manage its own Cromwell such that it can start/stop it at will. Note that there's currently a bash script that does a lot of this, that script should be refactored as necessary once the functionality is in Centaur proper.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2350
https://github.com/broadinstitute/cromwell/issues/2350:276,Modifiability,refactor,refactored,276,"Currently Centaur is configured with a URL for a live Cromwell server. Leave this capability but also allow for Centaur to manage its own Cromwell such that it can start/stop it at will. Note that there's currently a bash script that does a lot of this, that script should be refactored as necessary once the functionality is in Centaur proper.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2350
https://github.com/broadinstitute/cromwell/issues/2351:31,Testability,test,test,31,Add a directive in the Centaur test file to restart the underlying Cromwell server after the Nth call. If Centaur is in JAR mode (see #2350) it will honor this request. If Centaur is *not* in JAR mode this test will be skipped.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2351
https://github.com/broadinstitute/cromwell/issues/2351:206,Testability,test,test,206,Add a directive in the Centaur test file to restart the underlying Cromwell server after the Nth call. If Centaur is in JAR mode (see #2350) it will honor this request. If Centaur is *not* in JAR mode this test will be skipped.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2351
https://github.com/broadinstitute/cromwell/issues/2352:121,Testability,test,tests,121,"This might be a noop but once the restarting Cromwell functionality is in place in Centaur, make sure that all the other tests don't fall over whilst Cromwell is off.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2352
https://github.com/broadinstitute/cromwell/issues/2353:233,Availability,down,down,233,Add a workflow with at least 3 calls. For the call which triggers the Cromwell restart make sure that it involves a long sleep or something like that so that we know the job is still considered to be running by Cromwell when we shut down the server.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2353
https://github.com/broadinstitute/cromwell/issues/2354:20,Testability,test,test,20,Create an automated test framework for workflow restarts in Cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2354
https://github.com/broadinstitute/cromwell/issues/2356:263,Energy Efficiency,reduce,reduce,263,Whilst looking into non-MySQL based solutions for CQRS read stores I saw what I thought was a neat idea. By tagging each event with a version it is possible to not do bulk migrations when one needs to modify event entity structure (aside: we need to find ways to reduce that) but rather to migrate them the first time they're accessed.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2356
https://github.com/broadinstitute/cromwell/issues/2356:326,Security,access,accessed,326,Whilst looking into non-MySQL based solutions for CQRS read stores I saw what I thought was a neat idea. By tagging each event with a version it is possible to not do bulk migrations when one needs to modify event entity structure (aside: we need to find ways to reduce that) but rather to migrate them the first time they're accessed.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2356
https://github.com/broadinstitute/cromwell/pull/2357:168,Deployability,Update,Update,168,What to expect:; - Add labels through a new endpoint; - stop storing jes labels in metadata/custom_labels table; - stop publishing custom labels to jes metadata. - [x] Update Swagger; - [x] Update Readme; - [x] Update Changelog; - [x] More tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2357
https://github.com/broadinstitute/cromwell/pull/2357:190,Deployability,Update,Update,190,What to expect:; - Add labels through a new endpoint; - stop storing jes labels in metadata/custom_labels table; - stop publishing custom labels to jes metadata. - [x] Update Swagger; - [x] Update Readme; - [x] Update Changelog; - [x] More tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2357
https://github.com/broadinstitute/cromwell/pull/2357:211,Deployability,Update,Update,211,What to expect:; - Add labels through a new endpoint; - stop storing jes labels in metadata/custom_labels table; - stop publishing custom labels to jes metadata. - [x] Update Swagger; - [x] Update Readme; - [x] Update Changelog; - [x] More tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2357
https://github.com/broadinstitute/cromwell/pull/2357:240,Testability,test,tests,240,What to expect:; - Add labels through a new endpoint; - stop storing jes labels in metadata/custom_labels table; - stop publishing custom labels to jes metadata. - [x] Update Swagger; - [x] Update Readme; - [x] Update Changelog; - [x] More tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2357
https://github.com/broadinstitute/cromwell/issues/2359:25,Security,hash,hash,25,"When the WDL specified a hash, we used to not do anything and keep the user-specified value as the string to md5.; We now use the full name of the parsed docker value.; They might be different in a case where the docker is for example ; `ubuntu@sha256:ea1d854d38be82f54d39efe2c67000bed1b03348bcc2f3dc094f260855dff368`. 26 will use this as is where 27 will use ; `library/ubuntu@sha256:ea1d854d38be82f54d39efe2c67000bed1b03348bcc2f3dc094f260855dff368`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2359
https://github.com/broadinstitute/cromwell/pull/2360:149,Testability,test,test,149,"Specifically, don't force on a `library/` prefix where none was explicitly specified. This looks ok in the debugger but I haven't figured out a good test for it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2360
https://github.com/broadinstitute/cromwell/pull/2361:88,Performance,cache,caches,88,Don't implicitly add a library/ repo prefix to Docker images as that breaks 26-era call caches.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2361
https://github.com/broadinstitute/cromwell/pull/2362:17,Testability,test,test,17,"That Centaur JES test is broken for realz, let me figure that out before reviewing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2362
https://github.com/broadinstitute/cromwell/pull/2363:222,Modifiability,layers,layers,222,"Second PR for call caching diff endpoint, it's a lot but most of it was actually already reviewed in the first one.; New things are CallCacheDiffActor, CallCacheDiffActorSpec and things touching to MetadataQuery in the DB layers to be able to query a specific call using include/exclude key filters",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2363
https://github.com/broadinstitute/cromwell/issues/2365:254,Availability,avail,available,254,"I am running on a local backend (laptop) and have noticed that the number of tasks running simultaneously appears to be unlimited? If this is the case, would it be possible to add config parameters to local backends to limit cpu and memory usage to that available?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2365
https://github.com/broadinstitute/cromwell/issues/2365:180,Modifiability,config,config,180,"I am running on a local backend (laptop) and have noticed that the number of tasks running simultaneously appears to be unlimited? If this is the case, would it be possible to add config parameters to local backends to limit cpu and memory usage to that available?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2365
https://github.com/broadinstitute/cromwell/pull/2366:45,Deployability,update,updates-,45,https://blog.travis-ci.com/2017-06-19-trusty-updates-2017-Q2,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2366
https://github.com/broadinstitute/cromwell/issues/2367:42,Availability,failure,failure,42,"This workflow run on JES will cause a JES failure with `the local copy message must have path set`. This is because the value for `a` is passed to JES as an input but because it's empty the submission fails. We should catch this before it gets to JES and fail with a better error message. ```; task t {; File a; command {; cat ${a}; }; output {; String out = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow w {; call t; }; ```. ```; {; ""w.t.a"": """"; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2367
https://github.com/broadinstitute/cromwell/issues/2367:274,Availability,error,error,274,"This workflow run on JES will cause a JES failure with `the local copy message must have path set`. This is because the value for `a` is passed to JES as an input but because it's empty the submission fails. We should catch this before it gets to JES and fail with a better error message. ```; task t {; File a; command {; cat ${a}; }; output {; String out = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow w {; call t; }; ```. ```; {; ""w.t.a"": """"; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2367
https://github.com/broadinstitute/cromwell/issues/2367:71,Integrability,message,message,71,"This workflow run on JES will cause a JES failure with `the local copy message must have path set`. This is because the value for `a` is passed to JES as an input but because it's empty the submission fails. We should catch this before it gets to JES and fail with a better error message. ```; task t {; File a; command {; cat ${a}; }; output {; String out = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow w {; call t; }; ```. ```; {; ""w.t.a"": """"; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2367
https://github.com/broadinstitute/cromwell/issues/2367:280,Integrability,message,message,280,"This workflow run on JES will cause a JES failure with `the local copy message must have path set`. This is because the value for `a` is passed to JES as an input but because it's empty the submission fails. We should catch this before it gets to JES and fail with a better error message. ```; task t {; File a; command {; cat ${a}; }; output {; String out = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow w {; call t; }; ```. ```; {; ""w.t.a"": """"; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2367
https://github.com/broadinstitute/cromwell/pull/2370:24,Availability,failure,failures,24,"...because we're seeing failures with gsutil with the newest image. Need to fix that for sure, but this is more like a temporary patch.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2370
https://github.com/broadinstitute/cromwell/pull/2370:129,Deployability,patch,patch,129,"...because we're seeing failures with gsutil with the newest image. Need to fix that for sure, but this is more like a temporary patch.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2370
https://github.com/broadinstitute/cromwell/pull/2372:540,Deployability,Update,Update,540,"- There's no migration to move hashes from previous workflows to metadata. Which means the Call Caching Diff endpoint won't work for those. Instead of returning an empty diff which could be mistaken for ""those calls are identical"", return 404.; @katevoss @bradtaylor If that's a behavior we want to change please say so (cf email sent earlier this week). - Reverts the code that was persisting failed jobs hashes to the hash table. We don't need it anymore because it's in the metadata and that's what the Call Caching endpoint is using. - Update changelog / README",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2372
https://github.com/broadinstitute/cromwell/pull/2372:31,Security,hash,hashes,31,"- There's no migration to move hashes from previous workflows to metadata. Which means the Call Caching Diff endpoint won't work for those. Instead of returning an empty diff which could be mistaken for ""those calls are identical"", return 404.; @katevoss @bradtaylor If that's a behavior we want to change please say so (cf email sent earlier this week). - Reverts the code that was persisting failed jobs hashes to the hash table. We don't need it anymore because it's in the metadata and that's what the Call Caching endpoint is using. - Update changelog / README",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2372
https://github.com/broadinstitute/cromwell/pull/2372:406,Security,hash,hashes,406,"- There's no migration to move hashes from previous workflows to metadata. Which means the Call Caching Diff endpoint won't work for those. Instead of returning an empty diff which could be mistaken for ""those calls are identical"", return 404.; @katevoss @bradtaylor If that's a behavior we want to change please say so (cf email sent earlier this week). - Reverts the code that was persisting failed jobs hashes to the hash table. We don't need it anymore because it's in the metadata and that's what the Call Caching endpoint is using. - Update changelog / README",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2372
https://github.com/broadinstitute/cromwell/pull/2372:420,Security,hash,hash,420,"- There's no migration to move hashes from previous workflows to metadata. Which means the Call Caching Diff endpoint won't work for those. Instead of returning an empty diff which could be mistaken for ""those calls are identical"", return 404.; @katevoss @bradtaylor If that's a behavior we want to change please say so (cf email sent earlier this week). - Reverts the code that was persisting failed jobs hashes to the hash table. We don't need it anymore because it's in the metadata and that's what the Call Caching endpoint is using. - Update changelog / README",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2372
https://github.com/broadinstitute/cromwell/issues/2373:119,Performance,queue,queued,119,"It would be nice to have a way to shutdown a Cromwell server gracefully.; By that I mean give it time to clear up any ""queued work"", mostly for actors talking to the database.; This would ensure that nothing is left un-persisted and generally allow for cleaner restarts.; This is probably a significant amount work but just wanted to get it out there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2373
https://github.com/broadinstitute/cromwell/issues/2373:105,Usability,clear,clear,105,"It would be nice to have a way to shutdown a Cromwell server gracefully.; By that I mean give it time to clear up any ""queued work"", mostly for actors talking to the database.; This would ensure that nothing is left un-persisted and generally allow for cleaner restarts.; This is probably a significant amount work but just wanted to get it out there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2373
https://github.com/broadinstitute/cromwell/issues/2378:253,Availability,error,error,253,"As mentioned in [this forum post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/39791), there appears to be a race between cromwell checking stderr and it actually being written/flushed to disk. > WDL seemed to fail with a file not found error always in regard to the stderr file, but when I look up the file manually the file was always there, and the specific task also finished with rc=0, but the main cromwell process failed with return code of 1 already due to the file not found error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2378
https://github.com/broadinstitute/cromwell/issues/2378:500,Availability,error,error,500,"As mentioned in [this forum post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/39791), there appears to be a race between cromwell checking stderr and it actually being written/flushed to disk. > WDL seemed to fail with a file not found error always in regard to the stderr file, but when I look up the file manually the file was always there, and the specific task also finished with rc=0, but the main cromwell process failed with return code of 1 already due to the file not found error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2378
https://github.com/broadinstitute/cromwell/pull/2379:11,Modifiability,config,config,11,"A proposed config scheme to support multiple language frontends to Cromwell. Basically a simplified version of the backend scheme, this is just a strawman for discussion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2379
https://github.com/broadinstitute/cromwell/pull/2379:89,Usability,simpl,simplified,89,"A proposed config scheme to support multiple language frontends to Cromwell. Basically a simplified version of the backend scheme, this is just a strawman for discussion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2379
https://github.com/broadinstitute/cromwell/pull/2380:560,Usability,pause,pauses,560,"- Despite what it might seem, I tried to leave as much as possible the way I found it. I've got a big list of followup issues to file - both pre-existing conditions (provided we get this in before the ACA gets passed) and some things which are now hokier than I'd like due to the changes but would cause some serious spidering going on; - I did move some stuff around, e.g. PartialWorkflowSources, so many things look by diff to be changed a lot more than they really were; - The work for this has been spread across the better part of a year, often with long pauses in between. I did my best to spot inconsistencies and such but I'm sure they're still out there",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2380
https://github.com/broadinstitute/cromwell/issues/2381:93,Availability,failure,failure-messages,93,"See [this forum post](http://gatkforums.broadinstitute.org/firecloud/discussion/9851/cryptic-failure-messages). >message: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@1fc7758d rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@39871354[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 1543924]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2381
https://github.com/broadinstitute/cromwell/issues/2381:101,Integrability,message,messages,101,"See [this forum post](http://gatkforums.broadinstitute.org/firecloud/discussion/9851/cryptic-failure-messages). >message: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@1fc7758d rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@39871354[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 1543924]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2381
https://github.com/broadinstitute/cromwell/issues/2381:113,Integrability,message,message,113,"See [this forum post](http://gatkforums.broadinstitute.org/firecloud/discussion/9851/cryptic-failure-messages). >message: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@1fc7758d rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@39871354[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 1543924]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2381
https://github.com/broadinstitute/cromwell/issues/2381:293,Performance,queue,queued,293,"See [this forum post](http://gatkforums.broadinstitute.org/firecloud/discussion/9851/cryptic-failure-messages). >message: Task slick.basic.BasicBackend$DatabaseDef$$anon$2@1fc7758d rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@39871354[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 1543924]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2381
https://github.com/broadinstitute/cromwell/pull/2393:20,Deployability,release,release,20,Hopefully fixes the release of wdltool as part of the release process,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2393
https://github.com/broadinstitute/cromwell/pull/2393:54,Deployability,release,release,54,Hopefully fixes the release of wdltool as part of the release process,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2393
https://github.com/broadinstitute/cromwell/issues/2394:198,Availability,echo,echo,198,"This WDL validates and even executes ""successfully"" but it shouldn't:. ```; task hello {; command {; #nothing; }; output {; String out = ""out""; }; }. task bye {; String instring = ""bye""; command {; echo ${instring}; }; output {; String out = read_string(stdout()); }; }. workflow w {; call hello; call bye { input: instring = hello }; }; ```. `call bye { input: instring = hello }` is invalid",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2394
https://github.com/broadinstitute/cromwell/issues/2394:9,Security,validat,validates,9,"This WDL validates and even executes ""successfully"" but it shouldn't:. ```; task hello {; command {; #nothing; }; output {; String out = ""out""; }; }. task bye {; String instring = ""bye""; command {; echo ${instring}; }; output {; String out = read_string(stdout()); }; }. workflow w {; call hello; call bye { input: instring = hello }; }; ```. `call bye { input: instring = hello }` is invalid",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2394
https://github.com/broadinstitute/cromwell/pull/2395:0,Integrability,Wrap,Wrap,0,Wrap test in eventually to make sure metadata of workflow is flushed before we ask for it. This changed a bit when we set the default batch size from 1 -> 200,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2395
https://github.com/broadinstitute/cromwell/pull/2395:5,Testability,test,test,5,Wrap test in eventually to make sure metadata of workflow is flushed before we ask for it. This changed a bit when we set the default batch size from 1 -> 200,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2395
https://github.com/broadinstitute/cromwell/issues/2405:20,Availability,failure,failure,20,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:197,Availability,error,error,197,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:249,Availability,down,download,249,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:211,Integrability,Message,Message,211,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:241,Modifiability,config,config,241,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:230,Performance,load,load,230,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:75,Testability,test,testing,75,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:872,Testability,test,test,872,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:878,Testability,log,logs,878,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/issues/2405:1022,Testability,log,logs,1022,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405
https://github.com/broadinstitute/cromwell/pull/2406:11,Availability,error,error,11,Adjust the error message for the Call Caching diff endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2406
https://github.com/broadinstitute/cromwell/pull/2406:17,Integrability,message,message,17,Adjust the error message for the Call Caching diff endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2406
https://github.com/broadinstitute/cromwell/issues/2410:149,Deployability,pipeline,pipelines,149,"It is very inconvenient to provide a lot of separate files via cromwell REST or console and it often leads to many mistakes when one has to run many pipelines.; It would be much better to be able just zip whole folder with cromwell project and give one json config file that gives all pathes inside zip (where is subworkflows folder, where are options and where is the main workflow).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2410
https://github.com/broadinstitute/cromwell/issues/2410:258,Modifiability,config,config,258,"It is very inconvenient to provide a lot of separate files via cromwell REST or console and it often leads to many mistakes when one has to run many pipelines.; It would be much better to be able just zip whole folder with cromwell project and give one json config file that gives all pathes inside zip (where is subworkflows folder, where are options and where is the main workflow).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2410
https://github.com/broadinstitute/cromwell/issues/2411:4,Deployability,integrat,integration,4,Our integration testing environments always stand up a Cromwell server. We need something to provide some testing for single workflow mode.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2411
https://github.com/broadinstitute/cromwell/issues/2411:4,Integrability,integrat,integration,4,Our integration testing environments always stand up a Cromwell server. We need something to provide some testing for single workflow mode.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2411
https://github.com/broadinstitute/cromwell/issues/2411:16,Testability,test,testing,16,Our integration testing environments always stand up a Cromwell server. We need something to provide some testing for single workflow mode.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2411
https://github.com/broadinstitute/cromwell/issues/2411:106,Testability,test,testing,106,Our integration testing environments always stand up a Cromwell server. We need something to provide some testing for single workflow mode.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2411
https://github.com/broadinstitute/cromwell/issues/2413:160,Availability,error,error,160,"When I try to refer condition[0] in the following example I get weird ; ```; Can't index Success(WdlString(GSM1696299)) with index Success(WdlInteger(0)); ```; error. As an input here I give a row from tsv file, like; ```tsv; Transgenic_Control_L4	GSM1696283	GSM1696284; ```; I use if(sample != condition[0]) check because I cannot get array.tail in wdl (I opened a https://github.com/broadinstitute/cromwell/issues/2414 issue on this) and have to skip the first element somehow. Looks like it does not evaluate condition[0] as array here.; Here is the code sample that raises this error. It is one of subworkflows.; ```wdl; workflow cleanup {. Array[String] condition. scatter (sample in condition) {; #first sample is not a sample but name of the condition; if(sample != condition[0]) {; call get_sample {input: condition = sample[0], sample = sample }; }; }. output {; String out = ""WORKS!""; }. }. task get_sample {. String condition; String sample. # read the following explanations for parameters; # https://edwards.sdsu.edu/research/fastq-dump/. #command {; # fastq-dump --skip-technical --gzip --readids --read-filter pass --dumpbase --split-files --clip ${file}; #}. #quay.io/comp-bio-aging/geoparse --location /data --filetype sra --keep_sra true GSM1696283 GSM1696284; command {; --filetype fastq --keep_sra false ${sample}; }. runtime {; docker: ""quay.io/comp-bio-aging/geoparse@sha256:bdf03cda576e24985060a795bede5b50eca89c9053a0fe179b8f9bc282e4db00""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2413
https://github.com/broadinstitute/cromwell/issues/2413:582,Availability,error,error,582,"When I try to refer condition[0] in the following example I get weird ; ```; Can't index Success(WdlString(GSM1696299)) with index Success(WdlInteger(0)); ```; error. As an input here I give a row from tsv file, like; ```tsv; Transgenic_Control_L4	GSM1696283	GSM1696284; ```; I use if(sample != condition[0]) check because I cannot get array.tail in wdl (I opened a https://github.com/broadinstitute/cromwell/issues/2414 issue on this) and have to skip the first element somehow. Looks like it does not evaluate condition[0] as array here.; Here is the code sample that raises this error. It is one of subworkflows.; ```wdl; workflow cleanup {. Array[String] condition. scatter (sample in condition) {; #first sample is not a sample but name of the condition; if(sample != condition[0]) {; call get_sample {input: condition = sample[0], sample = sample }; }; }. output {; String out = ""WORKS!""; }. }. task get_sample {. String condition; String sample. # read the following explanations for parameters; # https://edwards.sdsu.edu/research/fastq-dump/. #command {; # fastq-dump --skip-technical --gzip --readids --read-filter pass --dumpbase --split-files --clip ${file}; #}. #quay.io/comp-bio-aging/geoparse --location /data --filetype sra --keep_sra true GSM1696283 GSM1696284; command {; --filetype fastq --keep_sra false ${sample}; }. runtime {; docker: ""quay.io/comp-bio-aging/geoparse@sha256:bdf03cda576e24985060a795bede5b50eca89c9053a0fe179b8f9bc282e4db00""; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2413
https://github.com/broadinstitute/cromwell/issues/2414:153,Security,access,accession,153,Having a tail function in the array is very useful as it is quite common to read tsv files where first column is name of condition and others are sample accession numbers. I also opened a forum question on this http://gatkforums.broadinstitute.org/wdl/discussion/9893/getting-tail-of-the-array/p1?new=1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2414
https://github.com/broadinstitute/cromwell/issues/2417:149,Energy Efficiency,reduce,reduceLeft,149,"I think this should be fine, but @Horneth brought it up during an unrelated code review. . Determine if we desire determinism here, and fix it (via `reduceLeft`?) if appropriate",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2417
https://github.com/broadinstitute/cromwell/issues/2419:335,Availability,down,downside,335,"A while back we changed things to return gzipped content in the metadata endpoint by default, despite what the client says it can handle. generally the client should be telling the server what it can expect and the server either handles it appropriately or returns a 415. I think that we should switch this to encoding on request. The downside is that there might be users who would be much better off getting a gzipped response but not realizing they have to do something extra (depending on their client).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2419
https://github.com/broadinstitute/cromwell/issues/2419:480,Integrability,depend,depending,480,"A while back we changed things to return gzipped content in the metadata endpoint by default, despite what the client says it can handle. generally the client should be telling the server what it can expect and the server either handles it appropriately or returns a 415. I think that we should switch this to encoding on request. The downside is that there might be users who would be much better off getting a gzipped response but not realizing they have to do something extra (depending on their client).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2419
https://github.com/broadinstitute/cromwell/issues/2421:105,Availability,down,downstream,105,"We are investigating ways we can store additional information with a cromwell run that is useful for our downstream applications. The two ways to pass associated metadata with a workflow are the Labels attribute through the runtimeOptions, or the `meta` object within cromwell itself. Exposing either of these as parsable json in the metadata objet would achieve what we are looking for; ; ## Meta; If I Have a workflow with a meta object:. ```; workflow a {; call b. meta {; some_key: ""some_value""; }; }; ```; The only way to retrieve the meta values from the /metadata endpoint would be to re-parse the workflow string contained in metadata object ; ```; ""workflow"": "" .....""; ```; Since they are simple KV pairs it would be nice to have an output that looks like the following, embedded in the `metadata` object:; ```; {; ""meta"": {; ""key"":""value"",; ""key2"":""value2""; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2421
https://github.com/broadinstitute/cromwell/issues/2421:699,Usability,simpl,simple,699,"We are investigating ways we can store additional information with a cromwell run that is useful for our downstream applications. The two ways to pass associated metadata with a workflow are the Labels attribute through the runtimeOptions, or the `meta` object within cromwell itself. Exposing either of these as parsable json in the metadata objet would achieve what we are looking for; ; ## Meta; If I Have a workflow with a meta object:. ```; workflow a {; call b. meta {; some_key: ""some_value""; }; }; ```; The only way to retrieve the meta values from the /metadata endpoint would be to re-parse the workflow string contained in metadata object ; ```; ""workflow"": "" .....""; ```; Since they are simple KV pairs it would be nice to have an output that looks like the following, embedded in the `metadata` object:; ```; {; ""meta"": {; ""key"":""value"",; ""key2"":""value2""; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2421
https://github.com/broadinstitute/cromwell/issues/2424:120,Security,expose,expose,120,"In the near future PAPI will support the ability to pass a boolean argument called `restrictMetadataAccess`. We want to expose this both via workflow option as well as the ability to set the default value to `true` (although normally the default value should be `false`). The mechanism to specify this to PAPI is still TBD, so hit me up for more details when you get to that point.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2424
https://github.com/broadinstitute/cromwell/issues/2426:259,Integrability,message,message,259,"Ideally cromwell should report that it has hit a number of retries, and should report that no more attempts will be made. Currently, when cromwell hits a limit on Google, it reports that it will retry the operation. In fact, it retries once, reports the same message, then does _not_ retry. I.e. the metadata reports; >""events"": [{ ""description"": ""Warning: Creating VM and disk(s) would exceed \""CPUS\"" in region us-central1, will try again"", ""startTime"": ""2017-06-29T20:08:56.443727575Z"" }, ; >{ ""description"": ""Warning: Creating VM and disk(s) would exceed \""CPUS\"" in region us-central1, will try again"", ""startTime"": ""2017-06-29T20:35:58.853234031Z"" }],. But then cromwell does not try again. Inspired by [this forum post](http://gatkforums.broadinstitute.org/firecloud/discussion/9889/warning-creating-vm-and-disk-s-would-exceed-cpus-in-region-us-central1-will-try-again)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2426
https://github.com/broadinstitute/cromwell/issues/2429:299,Availability,error,error,299,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2429:305,Integrability,message,message,305,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2429:148,Modifiability,config,config,148,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2429:79,Safety,detect,detect,79,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2429:179,Safety,safe,safe,179,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2429:427,Testability,test,testing,427,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429
https://github.com/broadinstitute/cromwell/issues/2432:515,Energy Efficiency,monitor,monitor,515,"Cromwell will need to provide an endpoint called status which will return a 200 with other information on subsystems. For examples of how this was implemented in Rawls, see their [StatusService](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/status/StatusService.scala) and [HealthMonitor](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/monitor/HealthMonitor.scala). Subsystems to monitor include the CloudSQL database, Dockerhub, GCS and PAPI. If you can think of something else which seems useful feel free to add it in. This endpoint should also be exposed via CromIAM w/o needing authZ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2432
https://github.com/broadinstitute/cromwell/issues/2432:559,Energy Efficiency,monitor,monitor,559,"Cromwell will need to provide an endpoint called status which will return a 200 with other information on subsystems. For examples of how this was implemented in Rawls, see their [StatusService](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/status/StatusService.scala) and [HealthMonitor](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/monitor/HealthMonitor.scala). Subsystems to monitor include the CloudSQL database, Dockerhub, GCS and PAPI. If you can think of something else which seems useful feel free to add it in. This endpoint should also be exposed via CromIAM w/o needing authZ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2432
https://github.com/broadinstitute/cromwell/issues/2432:730,Security,expose,exposed,730,"Cromwell will need to provide an endpoint called status which will return a 200 with other information on subsystems. For examples of how this was implemented in Rawls, see their [StatusService](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/status/StatusService.scala) and [HealthMonitor](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/monitor/HealthMonitor.scala). Subsystems to monitor include the CloudSQL database, Dockerhub, GCS and PAPI. If you can think of something else which seems useful feel free to add it in. This endpoint should also be exposed via CromIAM w/o needing authZ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2432
https://github.com/broadinstitute/cromwell/pull/2433:15,Modifiability,variab,variables,15,Simple pattern variables compiler flag cleanup.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2433
https://github.com/broadinstitute/cromwell/pull/2433:0,Usability,Simpl,Simple,0,Simple pattern variables compiler flag cleanup.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2433
https://github.com/broadinstitute/cromwell/issues/2434:374,Availability,down,down,374,"A while back we had a fairly serious performance bug due to the usage of `mapValues`. It'd gone away for a while but it seems to be used somewhat frequently again. Currently 22 times in Cromwell. A quick skim of them made at least a few of them look to be pretty suspicious looking. Remove these, or at least prove that any remaining invocation can't possibly be a big deal down the road.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2434
https://github.com/broadinstitute/cromwell/issues/2434:37,Performance,perform,performance,37,"A while back we had a fairly serious performance bug due to the usage of `mapValues`. It'd gone away for a while but it seems to be used somewhat frequently again. Currently 22 times in Cromwell. A quick skim of them made at least a few of them look to be pretty suspicious looking. Remove these, or at least prove that any remaining invocation can't possibly be a big deal down the road.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2434
https://github.com/broadinstitute/cromwell/issues/2436:207,Modifiability,enhance,enhance,207,"A user today requested an `else` statement be added, in the conventional sense below:. ```; if (myBool) {; #do something; }; else {; #do something else; }; ```. I agree that adding something like this would enhance the readability we advertise for WDL, though I understand that this isn't completely pressing as there is currently a workaround (`if(!myBool)`). I leave this to your team to prioritize/discuss further as needed. You can find the original user question [here](http://gatkforums.broadinstitute.org/firecloud/discussion/9929/is-there-a-null-value-that-can-be-used-in-wdl-could-else-statements-be-added-to-conditionals).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2436
https://github.com/broadinstitute/cromwell/pull/2437:108,Usability,usab,usable,108,"Effectively removes `console`-killing compiler options when invoking the `console` target, making `console` usable again.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2437
https://github.com/broadinstitute/cromwell/issues/2438:10598,Availability,ERROR,ERROR,10598,"a.MetadataComponent$$anon$1.combine(MetadataComponent.scala:15); #011at cats.kernel.instances.MapMonoid.combine(map.scala:26); #011at cats.kernel.instances.MapMonoid.combine(map.scala:36); #011at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); #011at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); #011at scala.collection.immutable.Map$Map1.foreach(Map.scala:116); #011at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); #011at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); #011at cats.kernel.instances.MapMonoid$$anonfun$combine$2.apply(map.scala:36); #011at cats.kernel.instances.MapMonoid$$anonfun$combine$2.apply(map.scala:37); #011at cats.kernel.SemigroupFunctions.maybeCombine(Semigroup.scala:50); #011at cromwell.webservice.metadata.MetadataComponent$$anon$1.combine(MetadataComponent.scala:9); #011at cromwell.webservice.metadata.MetadataComponent$$anon$1.combine(MetadataComponent.scala:18); #011at scala.math.Ordering$$anon$9.max(Ordering.scala:199); #011at scala.math.Ordering$class.max(Ordering.scala:103); #011at scala.math.Ordering$$anon$9.gteq(Ordering.scala:204); #011at scala.math.Ordering$$anonfun$by$1.apply(Ordering.scala:219); #011at scala.math.Ordering$$anonfun$by$1.apply(Ordering.scala:219); #011at cromwell.webservice.metadata.MetadataPrimitive$$anonfun$2.apply(MetadataComponent.scala:42); #011at cromwell.webservice.metadata.MetadataPrimitive$$anonfun$2.apply(MetadataComponent.scala:43); #011at scala.Enumeration.withName(Enumeration.scala:124); java.util.NoSuchElementException: No value found for 'Preempted'. 2017-07-12 17:53:26,768 cromwell-system-akka.dispatchers.api-dispatcher-201 ERROR - Error during processing of request HttpRequest(GET,http://app:8000/api/workflows/v1/ce7b5164-8a0c-4386-a993-d4a522460df7/metadata,List(blah blah headers,Empty,HTTP/1.1); ```. This results in FC not displaying workflow details, which annoys users.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:10606,Availability,Error,Error,10606,"a.MetadataComponent$$anon$1.combine(MetadataComponent.scala:15); #011at cats.kernel.instances.MapMonoid.combine(map.scala:26); #011at cats.kernel.instances.MapMonoid.combine(map.scala:36); #011at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); #011at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); #011at scala.collection.immutable.Map$Map1.foreach(Map.scala:116); #011at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); #011at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); #011at cats.kernel.instances.MapMonoid$$anonfun$combine$2.apply(map.scala:36); #011at cats.kernel.instances.MapMonoid$$anonfun$combine$2.apply(map.scala:37); #011at cats.kernel.SemigroupFunctions.maybeCombine(Semigroup.scala:50); #011at cromwell.webservice.metadata.MetadataComponent$$anon$1.combine(MetadataComponent.scala:9); #011at cromwell.webservice.metadata.MetadataComponent$$anon$1.combine(MetadataComponent.scala:18); #011at scala.math.Ordering$$anon$9.max(Ordering.scala:199); #011at scala.math.Ordering$class.max(Ordering.scala:103); #011at scala.math.Ordering$$anon$9.gteq(Ordering.scala:204); #011at scala.math.Ordering$$anonfun$by$1.apply(Ordering.scala:219); #011at scala.math.Ordering$$anonfun$by$1.apply(Ordering.scala:219); #011at cromwell.webservice.metadata.MetadataPrimitive$$anonfun$2.apply(MetadataComponent.scala:42); #011at cromwell.webservice.metadata.MetadataPrimitive$$anonfun$2.apply(MetadataComponent.scala:43); #011at scala.Enumeration.withName(Enumeration.scala:124); java.util.NoSuchElementException: No value found for 'Preempted'. 2017-07-12 17:53:26,768 cromwell-system-akka.dispatchers.api-dispatcher-201 ERROR - Error during processing of request HttpRequest(GET,http://app:8000/api/workflows/v1/ce7b5164-8a0c-4386-a993-d4a522460df7/metadata,List(blah blah headers,Empty,HTTP/1.1); ```. This results in FC not displaying workflow details, which annoys users.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:1086,Integrability,rout,routing,1086,l:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$1.apply(Marshaller.scala:58); #011at spray.httpx.marshalling.Marsha,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:112,Performance,concurren,concurrent,112,Happens on a small set of workflows but not others. From the logs of the offending Cromwell:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDele,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:202,Performance,concurren,concurrent,202,Happens on a small set of workflows but not others. From the logs of the offending Cromwell:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDele,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:283,Performance,concurren,concurrent,283,Happens on a small set of workflows but not others. From the logs of the offending Cromwell:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDele,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:372,Performance,concurren,concurrent,372,Happens on a small set of workflows but not others. From the logs of the offending Cromwell:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDele,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:3201,Security,Hash,HashMap,3201,JsonMarshaller$1.apply(SprayJsonSupport.scala:42); #011at spray.httpx.SprayJsonSupport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(Traversa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:3209,Security,Hash,HashTrieMap,3209,JsonMarshaller$1.apply(SprayJsonSupport.scala:42); #011at spray.httpx.SprayJsonSupport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(Traversa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:3229,Security,Hash,HashMap,3229,pply(SprayJsonSupport.scala:42); #011at spray.httpx.SprayJsonSupport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:3283,Security,Hash,HashMap,3283,upport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:3308,Security,Hash,HashMap,3308,prayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2438:61,Testability,log,logs,61,Happens on a small set of workflows but not others. From the logs of the offending Cromwell:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDele,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438
https://github.com/broadinstitute/cromwell/issues/2442:129,Deployability,configurat,configuration,129,"There are a few development activities that are blocked by needing Jeff's computer. It has something to with the encryption of a configuration something something... more to be filled in by Jeff. . @geoffjentry I would really like you to work on unblocking this when you have your work computer back. If there's anything across other teams or BITs etc that you need, just say the word.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2442
https://github.com/broadinstitute/cromwell/issues/2442:129,Modifiability,config,configuration,129,"There are a few development activities that are blocked by needing Jeff's computer. It has something to with the encryption of a configuration something something... more to be filled in by Jeff. . @geoffjentry I would really like you to work on unblocking this when you have your work computer back. If there's anything across other teams or BITs etc that you need, just say the word.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2442
https://github.com/broadinstitute/cromwell/issues/2442:113,Security,encrypt,encryption,113,"There are a few development activities that are blocked by needing Jeff's computer. It has something to with the encryption of a configuration something something... more to be filled in by Jeff. . @geoffjentry I would really like you to work on unblocking this when you have your work computer back. If there's anything across other teams or BITs etc that you need, just say the word.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2442
https://github.com/broadinstitute/cromwell/issues/2445:176,Testability,log,log,176,"Try it yourself, if you think you're fast enough (you probably are):. - Run a simple workflow with a few small tasks; - Watch like a hawk for a ""workflow done"" in the Cromwell log; - Quickly stop the server; - On restart, presto chango, the `executionStatus` remains `Running` forever!; - ...; - Weep?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2445
https://github.com/broadinstitute/cromwell/issues/2445:78,Usability,simpl,simple,78,"Try it yourself, if you think you're fast enough (you probably are):. - Run a simple workflow with a few small tasks; - Watch like a hawk for a ""workflow done"" in the Cromwell log; - Quickly stop the server; - On restart, presto chango, the `executionStatus` remains `Running` forever!; - ...; - Weep?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2445
https://github.com/broadinstitute/cromwell/pull/2447:19,Deployability,integrat,integrate,19,"There is a need to integrate query API with some of the components I'm developing and while I was testing with different versions of Cromwell (0.24, 0.28 and 0.29) I found out the following:; - 0.24/0.28: when Cromwell is under load and trying to query +100 workflows, Cromwell (Slick) throws stack overflow exception.; - 0.29: seems to work fine but I found that query POST API was returning everything since query params where empty and request body was parsed. This is the fix that worked for me.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2447
https://github.com/broadinstitute/cromwell/pull/2447:19,Integrability,integrat,integrate,19,"There is a need to integrate query API with some of the components I'm developing and while I was testing with different versions of Cromwell (0.24, 0.28 and 0.29) I found out the following:; - 0.24/0.28: when Cromwell is under load and trying to query +100 workflows, Cromwell (Slick) throws stack overflow exception.; - 0.29: seems to work fine but I found that query POST API was returning everything since query params where empty and request body was parsed. This is the fix that worked for me.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2447
https://github.com/broadinstitute/cromwell/pull/2447:228,Performance,load,load,228,"There is a need to integrate query API with some of the components I'm developing and while I was testing with different versions of Cromwell (0.24, 0.28 and 0.29) I found out the following:; - 0.24/0.28: when Cromwell is under load and trying to query +100 workflows, Cromwell (Slick) throws stack overflow exception.; - 0.29: seems to work fine but I found that query POST API was returning everything since query params where empty and request body was parsed. This is the fix that worked for me.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2447
https://github.com/broadinstitute/cromwell/pull/2447:98,Testability,test,testing,98,"There is a need to integrate query API with some of the components I'm developing and while I was testing with different versions of Cromwell (0.24, 0.28 and 0.29) I found out the following:; - 0.24/0.28: when Cromwell is under load and trying to query +100 workflows, Cromwell (Slick) throws stack overflow exception.; - 0.29: seems to work fine but I found that query POST API was returning everything since query params where empty and request body was parsed. This is the fix that worked for me.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2447
https://github.com/broadinstitute/cromwell/pull/2448:157,Deployability,update,updates,157,"DO NOT MERGE - the dependent wdl4s version is not on develop or even cromwomification yet. A serious contender for the most boring PR ever, this is just the updates to point to a subprojectified, cromwommy version of wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2448
https://github.com/broadinstitute/cromwell/pull/2448:19,Integrability,depend,dependent,19,"DO NOT MERGE - the dependent wdl4s version is not on develop or even cromwomification yet. A serious contender for the most boring PR ever, this is just the updates to point to a subprojectified, cromwommy version of wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2448
https://github.com/broadinstitute/cromwell/issues/2450:183,Availability,error,error,183,"@francares reports the following. He said that it disappeared in 29 but it's concerning that it just disappeared without (I think) intentionally being fixed. Reproduce and track this error down in 28 and then demonstrate that a) this *is* actually resolved in 29 and b) it didn't get ""resolved"" via another bug. ```; Uncaught error from thread [cromwell-system-akka.dispatchers.api-dispatcher-57] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.StackOverflowError; 	at scala.collection.immutable.Set$EmptySet$.seq(Set.scala:68); 	at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141); 	at scala.collection.AbstractSet.$plus$plus(Set.scala:47); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:27); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	...; ```; It's easy to reproduce, just run +100 hello world workflows and then query for all those workflows ids using query POST API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2450
https://github.com/broadinstitute/cromwell/issues/2450:189,Availability,down,down,189,"@francares reports the following. He said that it disappeared in 29 but it's concerning that it just disappeared without (I think) intentionally being fixed. Reproduce and track this error down in 28 and then demonstrate that a) this *is* actually resolved in 29 and b) it didn't get ""resolved"" via another bug. ```; Uncaught error from thread [cromwell-system-akka.dispatchers.api-dispatcher-57] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.StackOverflowError; 	at scala.collection.immutable.Set$EmptySet$.seq(Set.scala:68); 	at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141); 	at scala.collection.AbstractSet.$plus$plus(Set.scala:47); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:27); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	...; ```; It's easy to reproduce, just run +100 hello world workflows and then query for all those workflows ids using query POST API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2450
https://github.com/broadinstitute/cromwell/issues/2450:326,Availability,error,error,326,"@francares reports the following. He said that it disappeared in 29 but it's concerning that it just disappeared without (I think) intentionally being fixed. Reproduce and track this error down in 28 and then demonstrate that a) this *is* actually resolved in 29 and b) it didn't get ""resolved"" via another bug. ```; Uncaught error from thread [cromwell-system-akka.dispatchers.api-dispatcher-57] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.StackOverflowError; 	at scala.collection.immutable.Set$EmptySet$.seq(Set.scala:68); 	at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141); 	at scala.collection.AbstractSet.$plus$plus(Set.scala:47); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:27); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	...; ```; It's easy to reproduce, just run +100 hello world workflows and then query for all those workflows ids using query POST API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2450
https://github.com/broadinstitute/cromwell/issues/2450:406,Availability,down,down,406,"@francares reports the following. He said that it disappeared in 29 but it's concerning that it just disappeared without (I think) intentionally being fixed. Reproduce and track this error down in 28 and then demonstrate that a) this *is* actually resolved in 29 and b) it didn't get ""resolved"" via another bug. ```; Uncaught error from thread [cromwell-system-akka.dispatchers.api-dispatcher-57] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.StackOverflowError; 	at scala.collection.immutable.Set$EmptySet$.seq(Set.scala:68); 	at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141); 	at scala.collection.AbstractSet.$plus$plus(Set.scala:47); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:27); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	...; ```; It's easy to reproduce, just run +100 hello world workflows and then query for all those workflows ids using query POST API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2450
https://github.com/broadinstitute/cromwell/issues/2450:445,Availability,error,error,445,"@francares reports the following. He said that it disappeared in 29 but it's concerning that it just disappeared without (I think) intentionally being fixed. Reproduce and track this error down in 28 and then demonstrate that a) this *is* actually resolved in 29 and b) it didn't get ""resolved"" via another bug. ```; Uncaught error from thread [cromwell-system-akka.dispatchers.api-dispatcher-57] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.StackOverflowError; 	at scala.collection.immutable.Set$EmptySet$.seq(Set.scala:68); 	at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141); 	at scala.collection.AbstractSet.$plus$plus(Set.scala:47); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:27); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	at slick.compiler.ExpandSums.slick$compiler$ExpandSums$$tr$1(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.compiler.ExpandSums$$anonfun$7.apply(ExpandSums.scala:32); 	at slick.util.ConstArray.endoMap(ConstArray.scala:122); 	at slick.ast.Node$class.mapChildren(Node.scala:51); 	at slick.ast.Apply.mapChildren(Node.scala:547); 	...; ```; It's easy to reproduce, just run +100 hello world workflows and then query for all those workflows ids using query POST API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2450
https://github.com/broadinstitute/cromwell/issues/2451:236,Performance,cache,cache,236,Cromwell currently allows overrides of initialized task declarations. Confirm that call caching properly takes this into account. ```; task foo {; Int i = 3; command {}; output {; Int o = 4; }; }. workflow bar {; call foo; # should not cache to the above; call foo as foo4 { input: i = foo.o }; }; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2451
https://github.com/broadinstitute/cromwell/issues/2452:625,Availability,ERROR,ERROR,625,"Just wanted to report a behavior I saw while trying to scale Cromwell horizontally. I haven't had time to take a look to it but is related to metadata and the way that is written in the database. How to reproduce:; 1. Deploy:; 1 VM with Nginx to act as the load balancer; 2 VMs with Cromwell 29; 1 VM with MySQL 5.6.36. 2. Submit Hello World workflow 10000 times. 3. Try to get status for some/all workflows while workflows are being processed. 4. These issues are manifested:. Duplicated entry exception (this one happens repeatedly) =>; ``` ; 2017-07-13 22:07:39,149 cromwell-system-akka.dispatchers.service-dispatcher-243 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2490); 	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedSta",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3612,Availability,ERROR,ERROR,3612,"ent$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:26",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3620,Availability,Error,Error,3620,"ent$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:26",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:6638,Availability,ERROR,ERROR,6638,"c.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. A deadlock in the DB =>; ```; 2017-07-13 22:14:36,622 cromwell-system-akka.dispatchers.service-dispatcher-549 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9811,Availability,ERROR,ERROR,9811,".jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:24",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9819,Availability,Error,Error,9819,".jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:24",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:218,Deployability,Deploy,Deploy,218,"Just wanted to report a behavior I saw while trying to scale Cromwell horizontally. I haven't had time to take a look to it but is related to metadata and the way that is written in the database. How to reproduce:; 1. Deploy:; 1 VM with Nginx to act as the load balancer; 2 VMs with Cromwell 29; 1 VM with MySQL 5.6.36. 2. Submit Hello World workflow 10000 times. 3. Try to get status for some/all workflows while workflows are being processed. 4. These issues are manifested:. Duplicated entry exception (this one happens repeatedly) =>; ``` ; 2017-07-13 22:07:39,149 cromwell-system-akka.dispatchers.service-dispatcher-243 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2490); 	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedSta",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:257,Performance,load,load,257,"Just wanted to report a behavior I saw while trying to scale Cromwell horizontally. I haven't had time to take a look to it but is related to metadata and the way that is written in the database. How to reproduce:; 1. Deploy:; 1 VM with Nginx to act as the load balancer; 2 VMs with Cromwell 29; 1 VM with MySQL 5.6.36. 2. Submit Hello World workflow 10000 times. 3. Try to get status for some/all workflows while workflows are being processed. 4. These issues are manifested:. Duplicated entry exception (this one happens repeatedly) =>; ``` ; 2017-07-13 22:07:39,149 cromwell-system-akka.dispatchers.service-dispatcher-243 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2490); 	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedSta",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3339,Performance,concurren,concurrent,3339," slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createS",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3424,Performance,concurren,concurrent,3424,"run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:935); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.j",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:6324,Performance,concurren,concurrent,6324," slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. A deadlock in the DB =>; ```; 2017-07-13 22:14:36,622 cromwell-system-akka.dispatchers.service-dispatcher-549 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:6409,Performance,concurren,concurrent,6409,"run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. A deadlock in the DB =>; ```; 2017-07-13 22:14:36,622 cromwell-system-akka.dispatchers.service-dispatcher-549 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.j",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9538,Performance,concurren,concurrent,9538,"ionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkError",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9623,Performance,concurren,concurrent,9623,"d$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:951); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:12709,Performance,concurren,concurrent,12709, com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:12794,Performance,concurren,concurrent,12794, com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3006,Usability,Simpl,SimpleJdbcProfileAction,3006,"executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccess",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:3100,Usability,Simpl,SimpleJdbcProfileAction,3100,"pdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:07:39,149 cromwell-system-akka.actor.default-dispatcher-230 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'cromwell-workflow-id-cromwell-6d021019-ac3f-4a28-b034-d58fb92022' for key 'UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConst",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:5991,Usability,Simpl,SimpleJdbcProfileAction,5991,"executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. A deadlock in the DB =>; ```; 2017-07-13 22:14:36,622 cromwell-system-akka.dispatchers.service-dispatcher-549 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:6085,Usability,Simpl,SimpleJdbcProfileAction,6085,"pdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.$anonfun$run$11(JdbcActionComponent.scala:511); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$SingleInsertAction.run(JdbcActionComponent.scala:508); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. A deadlock in the DB =>; ```; 2017-07-13 22:14:36,622 cromwell-system-akka.dispatchers.service-dispatcher-549 ERROR - Failed to summarize metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9205,Usability,Simpl,SimpleJdbcProfileAction,9205,"ikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.ne",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:9299,Usability,Simpl,SimpleJdbcProfileAction,9299,"dbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); 2017-07-13 22:14:36,622 cromwell-system-akka.actor.default-dispatcher-552 ERROR - Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newIns",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:12376,Usability,Simpl,SimpleJdbcProfileAction,12376, com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2452:12470,Usability,Simpl,SimpleJdbcProfileAction,12470, com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079); 	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013); 	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104); 	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998); 	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.$anonfun$nativeUpsert$1(JdbcActionComponent.scala:564); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement(JdbcBackend.scala:379); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedInsertStatement$(JdbcBackend.scala:376); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedInsertStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:640); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.nativeUpsert(JdbcActionComponent.scala:561); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.f$1(JdbcActionComponent.scala:544); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$InsertOrUpdateAction.run(JdbcActionComponent.scala:557); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:31); 	at slick.jdbc.JdbcActionComponent$SimpleJdbcProfileAction.run(JdbcActionComponent.scala:28); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:240); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:240); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2452
https://github.com/broadinstitute/cromwell/issues/2453:2154,Performance,concurren,concurrent,2154,kflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:2223,Performance,concurren,concurrent,2223,kflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:2304,Performance,concurren,concurrent,2304,kflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:2377,Performance,concurren,concurrent,2377,kflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:1208,Testability,Log,LoggingFSM,1208,at java.lang.Long.parseLong(Long.java:578); 	at java.lang.Long.valueOf(Long.java:776); 	at java.lang.Long.decode(Long.java:928); 	at java.util.UUID.fromString(UUID.java:198); 	at cromwell.core.WorkflowId$.fromString(WorkflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concu,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:1284,Testability,Log,LoggingFSM,1284,.valueOf(Long.java:776); 	at java.lang.Long.decode(Long.java:928); 	at java.util.UUID.fromString(UUID.java:198); 	at cromwell.core.WorkflowId$.fromString(WorkflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/issues/2453:1339,Testability,Log,LoggingFSM,1339,.java:928); 	at java.util.UUID.fromString(UUID.java:198); 	at cromwell.core.WorkflowId$.fromString(WorkflowId.scala:11); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.cromwell$engine$workflow$lifecycle$execution$callcaching$CallCacheDiffActor$$makeMetadataQuery(CallCacheDiffActor.scala:298); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:59); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor$$anonfun$1.applyOrElse(CallCacheDiffActor.scala:56); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:663); 	at akka.actor.FSM.processEvent$(FSM.scala:660); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.akka$actor$LoggingFSM$$super$processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:799); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.processEvent(CallCacheDiffActor.scala:53); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor.aroundReceive(Actor.scala:502); 	at akka.actor.Actor.aroundReceive$(Actor.scala:500); 	at cromwell.engine.workflow.lifecycle.execution.callcaching.CallCacheDiffActor.aroundReceive(CallCacheDiffActor.scala:53); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2453
https://github.com/broadinstitute/cromwell/pull/2457:28,Testability,log,logic,28,I tried to step through the logic of the terminal-related code and this looks right to me. Granted I'm not a human formal verification tool. 👍,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2457
https://github.com/broadinstitute/cromwell/issues/2463:58,Availability,down,download,58,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2463:475,Availability,down,downloading,475,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2463:49,Deployability,release,releases,49,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2463:345,Deployability,upgrade,upgraded,345,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2463:267,Security,checksum,checksum,267,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2463:514,Security,checksum,checksum,514,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463
https://github.com/broadinstitute/cromwell/issues/2464:200,Availability,reliab,reliable,200,"- cromwell v27; - SGE backend; - server mode. Cromwell timing diagram displays SGE queued (qw) status as Running. This increases difficulty of debugging (or evaluating) a tool, since we do not have a reliable and easy(!) way to look at timing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2464
https://github.com/broadinstitute/cromwell/issues/2464:83,Performance,queue,queued,83,"- cromwell v27; - SGE backend; - server mode. Cromwell timing diagram displays SGE queued (qw) status as Running. This increases difficulty of debugging (or evaluating) a tool, since we do not have a reliable and easy(!) way to look at timing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2464
https://github.com/broadinstitute/cromwell/issues/2466:27,Availability,error,errors,27,"At the moment we see slick errors from excessive database activity. This is working as intended on the part of slick, so now we need to gracefully handle this. There are temporary measures people can enact, but this ticket is about rewiring things to be brave in the face of danger. I see this as requiring heavy tech talk/design discussion prior to being shovel ready. . Some initial thoughts:. - My assumption is via a backpressure mechanism but I don't want to mandate this. But it seems natural to me that the answer to ""it hurts when I do this"" is ""stop doing that for a while"". ; - One area where this gets tricky is the metadata service. The solution should not overfit to the default (currently only) metadata service implementation (i.e. MySQL tied to the same database connection as the rest of the system).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2466
https://github.com/broadinstitute/cromwell/issues/2467:31,Integrability,message,messages,31,"Enable Cromwell to emit statsd messages to a configurable host. It'd be awesome if this whole thing could be configurable on/off but if that's a pain it's not a big deal. The default host could be a non-existent UDP thing or something. The main key for this is the infrastructure, but some initial things to instrument. Things with lifetime counts are for creating a time series, e.g. ""how many of X happened in the last N time units"". - Lifetime count of submitted workflows; - Lifetime count of completed workflows; - Lifetime count of aborted workflows; - Current count of both pending & running workflows; - Lifetime count of retry events, e.g. GCS & PAPI; - Probably best broken up so GCS & PAPI separate if possible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2467
https://github.com/broadinstitute/cromwell/issues/2467:45,Modifiability,config,configurable,45,"Enable Cromwell to emit statsd messages to a configurable host. It'd be awesome if this whole thing could be configurable on/off but if that's a pain it's not a big deal. The default host could be a non-existent UDP thing or something. The main key for this is the infrastructure, but some initial things to instrument. Things with lifetime counts are for creating a time series, e.g. ""how many of X happened in the last N time units"". - Lifetime count of submitted workflows; - Lifetime count of completed workflows; - Lifetime count of aborted workflows; - Current count of both pending & running workflows; - Lifetime count of retry events, e.g. GCS & PAPI; - Probably best broken up so GCS & PAPI separate if possible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2467
https://github.com/broadinstitute/cromwell/issues/2467:109,Modifiability,config,configurable,109,"Enable Cromwell to emit statsd messages to a configurable host. It'd be awesome if this whole thing could be configurable on/off but if that's a pain it's not a big deal. The default host could be a non-existent UDP thing or something. The main key for this is the infrastructure, but some initial things to instrument. Things with lifetime counts are for creating a time series, e.g. ""how many of X happened in the last N time units"". - Lifetime count of submitted workflows; - Lifetime count of completed workflows; - Lifetime count of aborted workflows; - Current count of both pending & running workflows; - Lifetime count of retry events, e.g. GCS & PAPI; - Probably best broken up so GCS & PAPI separate if possible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2467
https://github.com/broadinstitute/cromwell/issues/2467:538,Safety,abort,aborted,538,"Enable Cromwell to emit statsd messages to a configurable host. It'd be awesome if this whole thing could be configurable on/off but if that's a pain it's not a big deal. The default host could be a non-existent UDP thing or something. The main key for this is the infrastructure, but some initial things to instrument. Things with lifetime counts are for creating a time series, e.g. ""how many of X happened in the last N time units"". - Lifetime count of submitted workflows; - Lifetime count of completed workflows; - Lifetime count of aborted workflows; - Current count of both pending & running workflows; - Lifetime count of retry events, e.g. GCS & PAPI; - Probably best broken up so GCS & PAPI separate if possible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2467
https://github.com/broadinstitute/cromwell/issues/2469:1324,Availability,Failure,Failure,1324,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:378,Integrability,message,message,378,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:917,Integrability,interface,interface,917,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:959,Integrability,message,messages,959,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:988,Modifiability,parameteriz,parameterized,988,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:1261,Modifiability,parameteriz,parameterized,1261,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/issues/2469:18,Security,access,accessible,18,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469
https://github.com/broadinstitute/cromwell/pull/2471:19,Security,hash,hashDifferential,19,"Previously:; ```; ""hashDifferential"": [; { ""output expression:String hi”: ; {; ""callA"": ""935C6E7EB2068B83C40B788575747EFB”, ; ""callB"": “0183144CF6617D5341681C6B2F756046""; }; },; …; ]; ```. This PR :; ```; ""hashDifferential"": [; ""hashKey"": ""output expression:String hi"",; ""callA"": ""935C6E7EB2068B83C40B788575747EFB"",; ""callB"": ""0183144CF6617D5341681C6B2F756046""; },; ...; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471
https://github.com/broadinstitute/cromwell/pull/2471:206,Security,hash,hashDifferential,206,"Previously:; ```; ""hashDifferential"": [; { ""output expression:String hi”: ; {; ""callA"": ""935C6E7EB2068B83C40B788575747EFB”, ; ""callB"": “0183144CF6617D5341681C6B2F756046""; }; },; …; ]; ```. This PR :; ```; ""hashDifferential"": [; ""hashKey"": ""output expression:String hi"",; ""callA"": ""935C6E7EB2068B83C40B788575747EFB"",; ""callB"": ""0183144CF6617D5341681C6B2F756046""; },; ...; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471
https://github.com/broadinstitute/cromwell/pull/2471:229,Security,hash,hashKey,229,"Previously:; ```; ""hashDifferential"": [; { ""output expression:String hi”: ; {; ""callA"": ""935C6E7EB2068B83C40B788575747EFB”, ; ""callB"": “0183144CF6617D5341681C6B2F756046""; }; },; …; ]; ```. This PR :; ```; ""hashDifferential"": [; ""hashKey"": ""output expression:String hi"",; ""callA"": ""935C6E7EB2068B83C40B788575747EFB"",; ""callB"": ""0183144CF6617D5341681C6B2F756046""; },; ...; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471
https://github.com/broadinstitute/cromwell/pull/2474:53,Performance,cache,cache,53,Adds endpoint support for; - logs; - outputs; - call cache diffs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2474
https://github.com/broadinstitute/cromwell/pull/2474:29,Testability,log,logs,29,Adds endpoint support for; - logs; - outputs; - call cache diffs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2474
https://github.com/broadinstitute/cromwell/issues/2475:184,Modifiability,config,config,184,"When using the workflow option key ""google_project"", one can direct their workflow to be run in a google project that is different from the default project declared in the Jes backend config. When utilizing this option, the jobs of the workflow are run in the expected google project. However, when looking at the call metadata in Cromwell, it says they were run in the default configured google project -- which is wrong and needs to be adjusted to reflect the google project where the jobs are actually run.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2475
https://github.com/broadinstitute/cromwell/issues/2475:378,Modifiability,config,configured,378,"When using the workflow option key ""google_project"", one can direct their workflow to be run in a google project that is different from the default project declared in the Jes backend config. When utilizing this option, the jobs of the workflow are run in the expected google project. However, when looking at the call metadata in Cromwell, it says they were run in the default configured google project -- which is wrong and needs to be adjusted to reflect the google project where the jobs are actually run.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2475
https://github.com/broadinstitute/cromwell/issues/2476:220,Availability,down,down,220,"When running firecloud in a box, the services start with an empty database and initialize them with liquibase. Sometimes the cromwell service can't connect to port 8000 right away and when this happens the service shuts down and restarts. Typically, the shutdown happens during the liquibase initialization and this leave a lock in the DB. On restart, cromwell can connect to port 8000, but can't complete the DB initialization because of the lock left during shutdown. The cromwell system should either complete the DB initialization before shutting down if it can't connect to the port or it should handle an interrupted DB initialization on restart. [cromwell-app.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166281/cromwell-app.rtf.txt); [cromwell-proxy.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166282/cromwell-proxy.rtf.txt); [cromwell-mysql.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166280/cromwell-mysql.rtf.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2476
https://github.com/broadinstitute/cromwell/issues/2476:551,Availability,down,down,551,"When running firecloud in a box, the services start with an empty database and initialize them with liquibase. Sometimes the cromwell service can't connect to port 8000 right away and when this happens the service shuts down and restarts. Typically, the shutdown happens during the liquibase initialization and this leave a lock in the DB. On restart, cromwell can connect to port 8000, but can't complete the DB initialization because of the lock left during shutdown. The cromwell system should either complete the DB initialization before shutting down if it can't connect to the port or it should handle an interrupted DB initialization on restart. [cromwell-app.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166281/cromwell-app.rtf.txt); [cromwell-proxy.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166282/cromwell-proxy.rtf.txt); [cromwell-mysql.rtf.txt](https://github.com/broadinstitute/cromwell/files/1166280/cromwell-mysql.rtf.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2476
https://github.com/broadinstitute/cromwell/issues/2479:175,Safety,safe,safe,175,"This will enable us to protect from inadvertendyl putting secrets in code:. See: https://cloudplatform.googleblog.com/2017/07/help-keep-your-Google-Cloud-service-account-keys-safe.html with this section:; ""prevent committing keys to external source code repositories""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2479
https://github.com/broadinstitute/cromwell/issues/2480:74,Availability,down,download,74,"you recently released version ""28"", then found a bug, and changed the JAR download, but still called it ""28"". This has caused problems for brew, conda etc who package releases and use SHA256 to verify. It would have been better if you made it a ""29"" release, and delete the ""28"" release. Thank you for considering this opinion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2480
https://github.com/broadinstitute/cromwell/issues/2480:13,Deployability,release,released,13,"you recently released version ""28"", then found a bug, and changed the JAR download, but still called it ""28"". This has caused problems for brew, conda etc who package releases and use SHA256 to verify. It would have been better if you made it a ""29"" release, and delete the ""28"" release. Thank you for considering this opinion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2480
https://github.com/broadinstitute/cromwell/issues/2480:167,Deployability,release,releases,167,"you recently released version ""28"", then found a bug, and changed the JAR download, but still called it ""28"". This has caused problems for brew, conda etc who package releases and use SHA256 to verify. It would have been better if you made it a ""29"" release, and delete the ""28"" release. Thank you for considering this opinion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2480
https://github.com/broadinstitute/cromwell/issues/2480:250,Deployability,release,release,250,"you recently released version ""28"", then found a bug, and changed the JAR download, but still called it ""28"". This has caused problems for brew, conda etc who package releases and use SHA256 to verify. It would have been better if you made it a ""29"" release, and delete the ""28"" release. Thank you for considering this opinion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2480
https://github.com/broadinstitute/cromwell/issues/2480:279,Deployability,release,release,279,"you recently released version ""28"", then found a bug, and changed the JAR download, but still called it ""28"". This has caused problems for brew, conda etc who package releases and use SHA256 to verify. It would have been better if you made it a ""29"" release, and delete the ""28"" release. Thank you for considering this opinion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2480
https://github.com/broadinstitute/cromwell/pull/2490:167,Testability,Test,Test,167,- [x] Add more docs; Reviwers please take a look at https://github.com/broadinstitute/cromwell/wiki and https://github.com/broadinstitute/cromwell/wiki/DevZone; - [x] Test at high scale (Tested at centaur scale),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2490
https://github.com/broadinstitute/cromwell/pull/2490:187,Testability,Test,Tested,187,- [x] Add more docs; Reviwers please take a look at https://github.com/broadinstitute/cromwell/wiki and https://github.com/broadinstitute/cromwell/wiki/DevZone; - [x] Test at high scale (Tested at centaur scale),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2490
https://github.com/broadinstitute/cromwell/issues/2492:68,Integrability,message,message,68,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:649,Integrability,message,messages,649,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:529,Performance,race condition,race condition,529,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:4,Safety,abort,abort-all-workflows-on-terminate,4,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:143,Safety,abort,aborted,143,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:250,Safety,abort,aborted,250,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:349,Safety,abort,abort,349,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2492:425,Safety,abort,abort,425,"If `abort-all-workflows-on-terminate` is true, Cromwell will send a message directly to the WorkflowManagerActor which will trigger jobs to be aborted on the backend side but the workflow store is not made aware of that. Which means on restart, all ""aborted"" workflows will be restarted. Possible fix: instead of going to the WMA directly, send the abort command to the WorkflowStore first like it's done for single workflow abort, and have the WorkflowStore notify the WMA when all workflows have been removed. There might be a race condition between workflow submission and workflow deletion from the store so it might need some carefully ordered messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2492
https://github.com/broadinstitute/cromwell/issues/2495:100,Availability,error,errors,100,"Hi Cromwell team,. I've heard rumors that lately you've been plagued with the same intermittent 503 errors using the GCS NIO library that have plagued the GATK. We have what we believe is a definitive fix for this issue up at https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281. To take advantage of the fix, client code needs to set the library-level retry/reopen settings to be sufficiently aggressive. The settings GATK uses (which have cleared up our 503 issues at scale completely) can be seen in the `setGlobalNIODefaultOptions()` method in this class:. https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java. Mentioning @LeeTL1220 on this ticket by request",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2495
https://github.com/broadinstitute/cromwell/issues/2495:455,Usability,clear,cleared,455,"Hi Cromwell team,. I've heard rumors that lately you've been plagued with the same intermittent 503 errors using the GCS NIO library that have plagued the GATK. We have what we believe is a definitive fix for this issue up at https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281. To take advantage of the fix, client code needs to set the library-level retry/reopen settings to be sufficiently aggressive. The settings GATK uses (which have cleared up our 503 issues at scale completely) can be seen in the `setGlobalNIODefaultOptions()` method in this class:. https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java. Mentioning @LeeTL1220 on this ticket by request",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2495
https://github.com/broadinstitute/cromwell/issues/2496:55,Availability,error,error,55,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:82,Availability,failure,failure,82,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:229,Availability,error,error,229,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:410,Availability,error,error,410,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:990,Availability,ERROR,ERROR,990,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:1150,Availability,failure,failure,1150,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:61,Integrability,message,message,61,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:253,Integrability,message,message,253,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:797,Integrability,message,message,797,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:806,Safety,Abort,AbortedResponse,806,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/issues/2496:512,Testability,log,logs,512,"We have a cromwell task that failed with the unhelpful error message: `Unexpected failure in EJEA (root cause not captured).` After investigation we found that the task was being killed by the google cloud compute system:; ```; ""error"": {; ""code"": 1,; ""message"": ""Operation canceled at 2017-07-23T01:01:39-07:00 because it is older than 6 days""; },; ```; It would be better if cromwell was able to report this error directly, so we don't have to look at the gcloud operations properties. Looking at the cromwell logs I see this sequence:; ```; 2017-07-23 08:09:42 [cromwell-system-akka.actor.default-dispatcher-3449] WARN c.e.w.l.e.WorkflowExecutionActor - WorkflowExecutionActor-f15009ab-b5bc-47ac-b832-3d0ae2f15888 [UUID(f15009ab)]: WorkflowExecutionActor [UUID(f15009ab)] received an unhandled message: AbortedResponse(PairedEndSingleSampleWorkflow.MarkDuplicates:-1:1) in state: WorkflowExecutionInProgressState; 2017-07-23 08:09:47 [cromwell-system-akka.actor.default-dispatcher-3375] ERROR c.e.workflow.WorkflowManagerActor - WorkflowManagerActor Workflow f15009ab-b5bc-47ac-b832-3d0ae2f15888 failed (during ExecutingWorkflowState): Unexpected failure in EJEA (root cause not captured).; ```. In this case the google operations ID is `EOjNtPvUKxiOgeqc763--TEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU`. I can provide more operations IDs if necessary.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2496
https://github.com/broadinstitute/cromwell/pull/2502:31,Deployability,release,releases,31,https://github.com/scala/scala/releases/tag/v2.12.3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2502
https://github.com/broadinstitute/cromwell/pull/2503:114,Availability,resilien,resilient,114,Because sometimes things other than cromwell can cancel jobs. Also might make restarts after aborts a little more resilient in case of unexpected race conditions (not a guarantee TM),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2503
https://github.com/broadinstitute/cromwell/pull/2503:146,Performance,race condition,race conditions,146,Because sometimes things other than cromwell can cancel jobs. Also might make restarts after aborts a little more resilient in case of unexpected race conditions (not a guarantee TM),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2503
https://github.com/broadinstitute/cromwell/pull/2503:93,Safety,abort,aborts,93,Because sometimes things other than cromwell can cancel jobs. Also might make restarts after aborts a little more resilient in case of unexpected race conditions (not a guarantee TM),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2503
https://github.com/broadinstitute/cromwell/issues/2504:133,Availability,error,errors,133,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:157,Availability,ERROR,ERROR,157,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:481,Deployability,release,release,481,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:558,Deployability,release,releaseURL,558,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:784,Deployability,release,releaseURL,784,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:831,Deployability,release,releaseURL,831,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:882,Deployability,release,releaseURL,882,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:79,Modifiability,variab,variables,79,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:164,Modifiability,Variab,Variable,164,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2504:122,Security,validat,validation,122,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504
https://github.com/broadinstitute/cromwell/issues/2505:19,Modifiability,variab,variables,19,"What I expect from variables inside the tasks is that they will be initialized when the task is executed.; So, for instance, if I have a task like this:; ```; task my_task {; String a; Strinb b = a + ""/"" + ""annotation.fa"". command { something ${b} }; }; ```; and call it like this; ```; call my_stak {; input: a = ""my_path""; }; ```; I expect b to be ""my_path/genome"" cause it is reasonable. But looks like it is not the case with cromwell as cromwell initializes b before the task my_task is called.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2505
https://github.com/broadinstitute/cromwell/issues/2506:109,Availability,down,downstream,109,"A user has a workflow where the output of a task is localized to a path ""/some/path/./blah/blah.txt"". A task downstream that goes to utilize that file path as input fails silently because it's trying at some point to convert that path to a RealPath (http://googlecloudplatform.github.io/google-cloud-java/0.7.0/apidocs/com/google/cloud/storage/contrib/nio/CloudStoragePath.html method:`toRealPath`) and it fails to do so as dot-dirs are not allowed. Something throws an exception `IllegalArgumentException - if path contains extra slashes or dot-dirs when permitEmptyPathComponents is false, or if the resulting path is empty.` and it's present in the server logs only and the workflow remains running and the task hangs in notstarted state. It would be great if dot-dirs were handled or atleast reported back as not-supported and fail the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2506
https://github.com/broadinstitute/cromwell/issues/2506:659,Testability,log,logs,659,"A user has a workflow where the output of a task is localized to a path ""/some/path/./blah/blah.txt"". A task downstream that goes to utilize that file path as input fails silently because it's trying at some point to convert that path to a RealPath (http://googlecloudplatform.github.io/google-cloud-java/0.7.0/apidocs/com/google/cloud/storage/contrib/nio/CloudStoragePath.html method:`toRealPath`) and it fails to do so as dot-dirs are not allowed. Something throws an exception `IllegalArgumentException - if path contains extra slashes or dot-dirs when permitEmptyPathComponents is false, or if the resulting path is empty.` and it's present in the server logs only and the workflow remains running and the task hangs in notstarted state. It would be great if dot-dirs were handled or atleast reported back as not-supported and fail the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2506
https://github.com/broadinstitute/cromwell/issues/2507:721,Availability,echo,echo,721,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:762,Availability,echo,echo,762,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:803,Availability,echo,echo,803,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:844,Availability,echo,echo,844,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:878,Availability,echo,echo,878,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:900,Availability,echo,echo,900,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:963,Availability,echo,echo,963,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1037,Availability,echo,echo,1037,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1044,Availability,echo,echo,1044,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1104,Availability,echo,echo,1104,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1120,Availability,echo,echo,1120,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1208,Availability,echo,echo,1208,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:1298,Availability,echo,echo,1298,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/issues/2507:779,Energy Efficiency,MONITOR,MONITORING,779,"There have been many requests over time to provide data on CPU, memory, and disk usage. . In an ideal world this would be a rich time series of data, in a less ideal world this would be max with a couple of periodic data points, and in a much more practical world it'd just be max usage. The last one is the definition of done here but if one wants to get ambitious ....... The PAPI backend already allows for a custom script to be attached, we should be putting in something on our own for any backend which runs things via unix command lines (ie spark jobs and such likely don't make sense). At least one group is using the following in production, this is likely a good start if not completely AOK. ``````#!/bin/bash; echo ==================================; echo =========== MONITORING ===========; echo ==================================; echo --- General Information ---; echo \#CPU: $(nproc); echo Total Memory: $(free -h | grep Mem | awk '{ print $2 }'); echo Total Disk space: $(df -h | grep cromwell_root | awk '{ print $2}'); echo ; echo --- Runtime Information ---. function runtimeInfo() {; echo [$(date)]; echo \* CPU usage: $(top -bn 2 -d 0.01 | grep '^%Cpu' | tail -n 1 | awk '{print $2}')%; echo \* Memory usage: $(free -m | grep Mem | awk '{ OFMT=""%.0f""; print ($3/$2)*100; }')%; echo \* Disk usage: $(df | grep cromwell_root | awk '{ print $5 }'); }. while true; do runtimeInfo; sleep 300; done```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2507
https://github.com/broadinstitute/cromwell/pull/2512:120,Availability,failure,failure,120,"Ensure GCS file systems use custom configuration.; When an exception/timeout occurs during asyncHashing, report it as a failure.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2512
https://github.com/broadinstitute/cromwell/pull/2512:35,Deployability,configurat,configuration,35,"Ensure GCS file systems use custom configuration.; When an exception/timeout occurs during asyncHashing, report it as a failure.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2512
https://github.com/broadinstitute/cromwell/pull/2512:35,Modifiability,config,configuration,35,"Ensure GCS file systems use custom configuration.; When an exception/timeout occurs during asyncHashing, report it as a failure.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2512
https://github.com/broadinstitute/cromwell/pull/2512:69,Safety,timeout,timeout,69,"Ensure GCS file systems use custom configuration.; When an exception/timeout occurs during asyncHashing, report it as a failure.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2512
https://github.com/broadinstitute/cromwell/issues/2513:101,Availability,error,error,101,"If you use a java or scala client (e.g. CromIAM...) to connect to Cromwell over HTTPS, you'll get an error like:; ```; javax.net.ssl.SSLProtocolException: handshake alert: unrecognized_name; ```; cf. Google, this can be ignored client-side by adding:; ```; System.setProperty(""jsse.enableSNIExtension"", ""false""); ```; However, it would probably be nicer if Cromwell addressed this by adding an appropriate name when running in HTTPS mode. Since CromIAM is happy talking to Sam over HTTPS, they probably know how to do this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2513
https://github.com/broadinstitute/cromwell/pull/2516:17,Testability,test,tested,17,Still provides a tested utility function for replacing json values.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2516
https://github.com/broadinstitute/cromwell/issues/2518:331,Availability,echo,echo,331,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:563,Availability,error,error,563,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:776,Availability,error,error,776,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:569,Integrability,message,message,569,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:408,Testability,test,test,408,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:463,Testability,test,test,463,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2518:680,Testability,test,test,680,"I have an similar issue to this [https://github.com/broadinstitute/cromwell/issues/1306](https://github.com/broadinstitute/cromwell/issues/1306), but I don't think OP's solution fits whats going in my case since input files are not part of the issue. Using the hello-world example:. ```{wdl}; task hello {; String name. command {; echo 'Hello ${name}!'; }; output {; File response = stdout(); }; }. workflow test {; call hello; }; ```. with input; ```{json}; {; ""test.hello.name"": ""World""; }; ```; I run `$ cromwell run hello.wdl hello.json hello.out`. I get the error message:. > /Users/jasonweirather/Dropbox (Partners HealthCare)/projects/2017_08_FIRECLOUD/cromwell-executions/test/12ed39b6-cf8f-4ea1-a965-193cd89f99e9/call-hello/execution/stderr.background; -bash: syntax error near unexpected token `('. Seems it may be having troubles being run from a working directory with a space and parentheses. This was done on Mac OS X 10.12.6 in the bash terminal.; Version of cromwell is `cromwell: 28-5fd2237-SNAP`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2518
https://github.com/broadinstitute/cromwell/issues/2521:10,Integrability,interface,interface,10,Define an interface in WOM that contains a minimal set of methods such that. - Cromwell can supply an implementation of them at runtime; - It meets the I/O needs of both CWL and WDL so that they can evaluate expressions using this interface for I/O related work. It might be interesting to think about whether or not this interface should be made asynchronous.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2521
https://github.com/broadinstitute/cromwell/issues/2521:231,Integrability,interface,interface,231,Define an interface in WOM that contains a minimal set of methods such that. - Cromwell can supply an implementation of them at runtime; - It meets the I/O needs of both CWL and WDL so that they can evaluate expressions using this interface for I/O related work. It might be interesting to think about whether or not this interface should be made asynchronous.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2521
https://github.com/broadinstitute/cromwell/issues/2521:322,Integrability,interface,interface,322,Define an interface in WOM that contains a minimal set of methods such that. - Cromwell can supply an implementation of them at runtime; - It meets the I/O needs of both CWL and WDL so that they can evaluate expressions using this interface for I/O related work. It might be interesting to think about whether or not this interface should be made asynchronous.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2521
https://github.com/broadinstitute/cromwell/issues/2522:149,Modifiability,variab,variable,149,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522
https://github.com/broadinstitute/cromwell/issues/2522:193,Modifiability,variab,variable,193,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522
https://github.com/broadinstitute/cromwell/issues/2522:432,Modifiability,variab,variables,432,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522
https://github.com/broadinstitute/cromwell/issues/2522:416,Security,expose,expose,416,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522
https://github.com/broadinstitute/cromwell/issues/2523:137,Modifiability,variab,variable,137,Wdl4s should be able to build an instance of WdlStandardLibraryFunctions using an instance of WOM I/O Functions.; It might also need the variable context for things like `stdout` / `stderr`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2523
https://github.com/broadinstitute/cromwell/issues/2524:93,Integrability,interface,interface,93,The CWL bindings should provide a way to evaluate CWL expressions that is compliant with WOM interface. CWL has a concept of `Parameter References` similar to WDL lookup that does not require Javascript. And the concept of expression that does. Here are some links that could help:. - [Parameter References](http://www.commonwl.org/v1.0/CommandLineTool.html#Parameter_references); - [Expressions](http://www.commonwl.org/v1.0/CommandLineTool.html#Expressions); - [CWLTool](https://github.com/common-workflow-language/cwltool/blob/master/cwltool/expression.py); - [Bunny](https://github.com/rabix/bunny/tree/master/rabix-bindings-cwl/src/main/java/org/rabix/bindings/cwl/expression); - [Nashorn](https://docs.oracle.com/javase/8/docs/technotes/guides/scripting/nashorn/),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2524
https://github.com/broadinstitute/cromwell/issues/2524:743,Usability,guid,guides,743,The CWL bindings should provide a way to evaluate CWL expressions that is compliant with WOM interface. CWL has a concept of `Parameter References` similar to WDL lookup that does not require Javascript. And the concept of expression that does. Here are some links that could help:. - [Parameter References](http://www.commonwl.org/v1.0/CommandLineTool.html#Parameter_references); - [Expressions](http://www.commonwl.org/v1.0/CommandLineTool.html#Expressions); - [CWLTool](https://github.com/common-workflow-language/cwltool/blob/master/cwltool/expression.py); - [Bunny](https://github.com/rabix/bunny/tree/master/rabix-bindings-cwl/src/main/java/org/rabix/bindings/cwl/expression); - [Nashorn](https://docs.oracle.com/javase/8/docs/technotes/guides/scripting/nashorn/),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2524
https://github.com/broadinstitute/cromwell/issues/2526:203,Availability,error,error,203,"- v28; - JES backend; - continue while possible is true. I would expect the below workflow to have failed. However, cromwell listed many tasks as running that had failed (quickly) with an out-of-storage error. Metadata is attached. ; [lee_metadata_bd884082.json.txt](https://github.com/broadinstitute/cromwell/files/1205626/lee_metadata_bd884082.json.txt). Remaining running tasks look like this one (as near as I can tell):. ```; ....snip....; 2017/08/07 17:03:25 E: command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/08/07 17:03:27 W: cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam, command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; ...snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2526
https://github.com/broadinstitute/cromwell/issues/2526:804,Availability,down,downloaded,804,"- v28; - JES backend; - continue while possible is true. I would expect the below workflow to have failed. However, cromwell listed many tasks as running that had failed (quickly) with an out-of-storage error. Metadata is attached. ; [lee_metadata_bd884082.json.txt](https://github.com/broadinstitute/cromwell/files/1205626/lee_metadata_bd884082.json.txt). Remaining running tasks look like this one (as near as I can tell):. ```; ....snip....; 2017/08/07 17:03:25 E: command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/08/07 17:03:27 W: cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam, command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; ...snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2526
https://github.com/broadinstitute/cromwell/issues/2526:847,Availability,down,download,847,"- v28; - JES backend; - continue while possible is true. I would expect the below workflow to have failed. However, cromwell listed many tasks as running that had failed (quickly) with an out-of-storage error. Metadata is attached. ; [lee_metadata_bd884082.json.txt](https://github.com/broadinstitute/cromwell/files/1205626/lee_metadata_bd884082.json.txt). Remaining running tasks look like this one (as near as I can tell):. ```; ....snip....; 2017/08/07 17:03:25 E: command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/08/07 17:03:27 W: cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam, command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; ...snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2526
https://github.com/broadinstitute/cromwell/issues/2526:1570,Availability,down,downloaded,1570,"- v28; - JES backend; - continue while possible is true. I would expect the below workflow to have failed. However, cromwell listed many tasks as running that had failed (quickly) with an out-of-storage error. Metadata is attached. ; [lee_metadata_bd884082.json.txt](https://github.com/broadinstitute/cromwell/files/1205626/lee_metadata_bd884082.json.txt). Remaining running tasks look like this one (as near as I can tell):. ```; ....snip....; 2017/08/07 17:03:25 E: command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/08/07 17:03:27 W: cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam, command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; ...snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2526
https://github.com/broadinstitute/cromwell/issues/2526:1613,Availability,down,download,1613,"- v28; - JES backend; - continue while possible is true. I would expect the below workflow to have failed. However, cromwell listed many tasks as running that had failed (quickly) with an out-of-storage error. Metadata is attached. ; [lee_metadata_bd884082.json.txt](https://github.com/broadinstitute/cromwell/files/1205626/lee_metadata_bd884082.json.txt). Remaining running tasks look like this one (as near as I can tell):. ```; ....snip....; 2017/08/07 17:03:25 E: command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/08/07 17:03:27 W: cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam, command failed: [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; [Errno 28] No space left on device; CommandException: Some components of /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/KIRP/DNA/WGS/BCM/ILLUMINA/TCGA-A4-A48D-10A-01D-A25F-10_wgs_Illumina.bam were not downloaded successfully. Please retry this download.; CommandException: 1 file/object could not be transferred.; ...snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2526
https://github.com/broadinstitute/cromwell/issues/2527:405,Deployability,configurat,configuration,405,"- v28; - JES backend. With the below changes to a reference.conf, I would expect my jobs to be distributed between us-central1-f and -c, but when I check the VM instances, they are all still going to us-central1-b, the cromwell default. . Do I have the default-zones in the correct location in the hierarchy? This was taken from reference.conf, but might have gotten stale in v28. Here is a snippet of my configuration:. ```; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; 	 .... snip...; 	 genomics {; 			....snip.... 			 # Specifies the zone(s) to use for JES jobs unless overridden by a task's runtime attributes; 			 default-zones = [""us-central1-f"", ""us-central1-c""]; 		....snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2527
https://github.com/broadinstitute/cromwell/issues/2527:405,Modifiability,config,configuration,405,"- v28; - JES backend. With the below changes to a reference.conf, I would expect my jobs to be distributed between us-central1-f and -c, but when I check the VM instances, they are all still going to us-central1-b, the cromwell default. . Do I have the default-zones in the correct location in the hierarchy? This was taken from reference.conf, but might have gotten stale in v28. Here is a snippet of my configuration:. ```; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; 	 .... snip...; 	 genomics {; 			....snip.... 			 # Specifies the zone(s) to use for JES jobs unless overridden by a task's runtime attributes; 			 default-zones = [""us-central1-f"", ""us-central1-c""]; 		....snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2527
https://github.com/broadinstitute/cromwell/issues/2528:119,Modifiability,config,configured,119,"Onprem and restricted environments can be really cagey about what Dockers are being run. Cromwell should be able to be configured (maybe in conf file? Maybe something more dynamic?) to restrict what Dockers are being run. Both the NIH and Broad Internal have mentioned the fact that unrestricted Dockers being run is something they're a bit cagey about. This would help them feel good, even if it eventually goes unused.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2528
https://github.com/broadinstitute/cromwell/pull/2529:2,Energy Efficiency,monitor,monitoring,2,- monitoring logs now delocalize; - publish monitoring script used as well as the monitoring logs to call-level metadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2529
https://github.com/broadinstitute/cromwell/pull/2529:44,Energy Efficiency,monitor,monitoring,44,- monitoring logs now delocalize; - publish monitoring script used as well as the monitoring logs to call-level metadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2529
https://github.com/broadinstitute/cromwell/pull/2529:82,Energy Efficiency,monitor,monitoring,82,- monitoring logs now delocalize; - publish monitoring script used as well as the monitoring logs to call-level metadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2529
https://github.com/broadinstitute/cromwell/pull/2529:13,Testability,log,logs,13,- monitoring logs now delocalize; - publish monitoring script used as well as the monitoring logs to call-level metadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2529
https://github.com/broadinstitute/cromwell/pull/2529:93,Testability,log,logs,93,- monitoring logs now delocalize; - publish monitoring script used as well as the monitoring logs to call-level metadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2529
https://github.com/broadinstitute/cromwell/issues/2530:16,Deployability,release,release,16,The Cromwell 29 release notes will be in both Github on the Changelog page as well as on the WDL/Cromwell blog.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2530
https://github.com/broadinstitute/cromwell/issues/2534:73,Testability,test,tests,73,So that we can have a more interesting set of examples for WomExpression tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2534
https://github.com/broadinstitute/cromwell/issues/2535:43,Availability,error,error,43,FC user have seen their job fail with this error message: https://gatkforums.broadinstitute.org/firecloud/discussion/comment/41300. Could be transient in which case retrying it could be the way to go,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535
https://github.com/broadinstitute/cromwell/issues/2535:49,Integrability,message,message,49,FC user have seen their job fail with this error message: https://gatkforums.broadinstitute.org/firecloud/discussion/comment/41300. Could be transient in which case retrying it could be the way to go,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535
https://github.com/broadinstitute/cromwell/issues/2538:46,Availability,failure,failure,46,"When I see the below message, I think it is a failure, when in reality it just means that it could not find the docker image on docker hub, but found it when it checked the local docker instance. ```; [2017-08-10 20:51:05,54] [warn] BackendPreparationActor_for_bb616a1f:CNVSomaticPanelWorkflow.AnnotateTargets:-1:1 [bb616a1f]: Docker lookup failed:. java.lang.Exception: Docker image broadinstitute/gatk:2c8bf87cf523f25443f6eb7ddbe83efb0e03a69c not found; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538
https://github.com/broadinstitute/cromwell/issues/2538:21,Integrability,message,message,21,"When I see the below message, I think it is a failure, when in reality it just means that it could not find the docker image on docker hub, but found it when it checked the local docker instance. ```; [2017-08-10 20:51:05,54] [warn] BackendPreparationActor_for_bb616a1f:CNVSomaticPanelWorkflow.AnnotateTargets:-1:1 [bb616a1f]: Docker lookup failed:. java.lang.Exception: Docker image broadinstitute/gatk:2c8bf87cf523f25443f6eb7ddbe83efb0e03a69c not found; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538
https://github.com/broadinstitute/cromwell/pull/2542:577,Availability,down,downstream,577,"Thanks to @mcovarr we *think* we figured out the cause of the memory leak.; The `WorkflowExecutionActor` was sending ""snapshots"" of its current internal data (including execution store and output store) to the `EJEA`and `SWEA` so they could pass it on to the JobPreparationActor (resp. `SubWorkflowPreparationActor`) so they could evaluate inputs using the OutputStore.; This PR rewires things so that the WEA data does not escape the WEA. Instead actors needing the OutputStore for input evaluation request it at the right time and it gets sent across but never stored in the downstream actors, therefore not holding references and allowing for proper GC.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2542
https://github.com/broadinstitute/cromwell/pull/2543:234,Performance,queue,queue,234,"Note that there is already `debug` level logging for the actual flush events, which might be a good idea to turn on to see if the settings we've chosen are reasonable or whether we're just flushing constantly and blowing up the Slick queue.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2543
https://github.com/broadinstitute/cromwell/pull/2543:41,Testability,log,logging,41,"Note that there is already `debug` level logging for the actual flush events, which might be a good idea to turn on to see if the settings we've chosen are reasonable or whether we're just flushing constantly and blowing up the Slick queue.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2543
https://github.com/broadinstitute/cromwell/issues/2544:123,Deployability,release,releases,123,"Currently each of cromwell, wdl4s, wdltool etc. each handle their versioning independently. . It would be easier to script releases if they used a standardized approach, be it version.sbt or project/Version.scala.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2544
https://github.com/broadinstitute/cromwell/issues/2545:171,Performance,queue,queue,171,"Placeholder as I don't know if this is a good idea or not. I think it might be useful to have us prioritize our communication w/ GCP instead of putting things into a pure queue. Example to illustrate: I could imagine us wanting to make sure job cancel requests go through rapidly, and if we're backed up for 15 minutes due to status requests a user might get annoyed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2545
https://github.com/broadinstitute/cromwell/pull/2547:16,Testability,Test,TestBackendLifecycleActorFactory,16,Removed unused `TestBackendLifecycleActorFactory`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2547
https://github.com/broadinstitute/cromwell/issues/2548:66,Performance,concurren,concurrently,66,"#2540 enables backends to specify a limited number of jobs to run concurrently. If this ticket is implemented, instead of defaulting to an infinite number of tokens, backends would default to some other value. The actual default needs to be defined before this ticket may be implemented.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2548
https://github.com/broadinstitute/cromwell/pull/2554:67,Availability,error,error,67,"This is a proposal on how to solve the ""insufficient data written"" error that is due to the batch request doing PAPI job creation / polling being too large. The actual limit number is unknown yet (ticket is open with google).; Depending on their answer the solution might look different but this would be one way to fix it.; I tested it with @ruchim's WDL that reproduces this problem and didn't see it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2554
https://github.com/broadinstitute/cromwell/pull/2554:227,Integrability,Depend,Depending,227,"This is a proposal on how to solve the ""insufficient data written"" error that is due to the batch request doing PAPI job creation / polling being too large. The actual limit number is unknown yet (ticket is open with google).; Depending on their answer the solution might look different but this would be one way to fix it.; I tested it with @ruchim's WDL that reproduces this problem and didn't see it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2554
https://github.com/broadinstitute/cromwell/pull/2554:327,Testability,test,tested,327,"This is a proposal on how to solve the ""insufficient data written"" error that is due to the batch request doing PAPI job creation / polling being too large. The actual limit number is unknown yet (ticket is open with google).; Depending on their answer the solution might look different but this would be one way to fix it.; I tested it with @ruchim's WDL that reproduces this problem and didn't see it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2554
https://github.com/broadinstitute/cromwell/issues/2556:299,Testability,test,tests,299,"I'm going to merge https://github.com/broadinstitute/wdl4s/pull/175 in case people are waiting for it, but I still need to ungrossify some of the CWL stuff. I think that's going to be better addressed in a later PR so it gets the attention it will need in PR. Specifically:; - [x] Uncomment the two tests in `CWLWorkflowWomSpec.scala`; - [ ] Remove the `.getOrElse(???)` in `WorkflowStep.scala`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2556
https://github.com/broadinstitute/cromwell/issues/2562:14,Availability,down,down,14,Graceful shut down is expecting a `Ctrl-C` or SIGINT (possibly SIGKILL too?). Docker stop just turns off the lights. We should document how to stop a container in order to take advantage of the graceful shutdown process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2562
https://github.com/broadinstitute/cromwell/issues/2565:658,Modifiability,variab,variable,658,"I think this is what most people mean when they write declarations in WDL. Some are a bit different from how they're currently interpreted but I think it should make things easier and safer (eg. if it's an optional that has a default, don't force a `select_first`...). ## Example; ```; workflow foo {; Int a ; Int b = 5 ; Int c = b ; Int? d ; Int? e = 6; Int? f = d ; }; ```. |Declaration | Type | *Must* be supplied | **Can** be supplied | Notes | ; |-------|-----------|-------|-|-|; | `Int a` | Int | Yes | Yes | |; | `Int b = 5` | Int | No | Yes | |; | `Int c = b` | Int | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |; | `Int? d` | Int? | No | Yes | |; | `Int? e = 5` | ~~Int?~~ **Int** | No | Yes | Can be treated as an `Int` because it has a default |; | `Int? f = d` | Int? | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565
https://github.com/broadinstitute/cromwell/issues/2565:923,Modifiability,variab,variable,923,"I think this is what most people mean when they write declarations in WDL. Some are a bit different from how they're currently interpreted but I think it should make things easier and safer (eg. if it's an optional that has a default, don't force a `select_first`...). ## Example; ```; workflow foo {; Int a ; Int b = 5 ; Int c = b ; Int? d ; Int? e = 6; Int? f = d ; }; ```. |Declaration | Type | *Must* be supplied | **Can** be supplied | Notes | ; |-------|-----------|-------|-|-|; | `Int a` | Int | Yes | Yes | |; | `Int b = 5` | Int | No | Yes | |; | `Int c = b` | Int | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |; | `Int? d` | Int? | No | Yes | |; | `Int? e = 5` | ~~Int?~~ **Int** | No | Yes | Can be treated as an `Int` because it has a default |; | `Int? f = d` | Int? | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565
https://github.com/broadinstitute/cromwell/issues/2565:184,Safety,safe,safer,184,"I think this is what most people mean when they write declarations in WDL. Some are a bit different from how they're currently interpreted but I think it should make things easier and safer (eg. if it's an optional that has a default, don't force a `select_first`...). ## Example; ```; workflow foo {; Int a ; Int b = 5 ; Int c = b ; Int? d ; Int? e = 6; Int? f = d ; }; ```. |Declaration | Type | *Must* be supplied | **Can** be supplied | Notes | ; |-------|-----------|-------|-|-|; | `Int a` | Int | Yes | Yes | |; | `Int b = 5` | Int | No | Yes | |; | `Int c = b` | Int | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |; | `Int? d` | Int? | No | Yes | |; | `Int? e = 5` | ~~Int?~~ **Int** | No | Yes | Can be treated as an `Int` because it has a default |; | `Int? f = d` | Int? | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565
https://github.com/broadinstitute/cromwell/pull/2566:73,Testability,test,testing,73,"What it would look like if #1149 were satisfied. We do have real restart testing now, and the rest is all call caching tests; I'm looking over what we for that over in Centaur-land.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566
https://github.com/broadinstitute/cromwell/pull/2566:119,Testability,test,tests,119,"What it would look like if #1149 were satisfied. We do have real restart testing now, and the rest is all call caching tests; I'm looking over what we for that over in Centaur-land.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566
https://github.com/broadinstitute/cromwell/issues/2568:82,Usability,simpl,simple,82,"Now that we have real expressions, demonstrate converting a workflow containing a simple scatter block in WDL into a WOM graph",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2568
https://github.com/broadinstitute/cromwell/issues/2569:90,Integrability,depend,dependent,90,"Right now, the Wom `TaskDefinition` just uses a copy of the WDL `commandTemplate`. That's dependent on WDL functionality and probably won't fly for CWL. Like with the `WomExpressions`, we probably want a core concept of a ""thing that can build a command line"" and leave the implementation details up to the language bindings.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2569
https://github.com/broadinstitute/cromwell/issues/2570:36,Integrability,rout,route,36,"- Break as many eggs as you want en route.; - Need to make any assumptions to simplify things? Make them!; - We don't necessarily need to merge the result into develop if it's hideous, we just want to find out how close/far we are from making this happen.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2570
https://github.com/broadinstitute/cromwell/issues/2570:78,Usability,simpl,simplify,78,"- Break as many eggs as you want en route.; - Need to make any assumptions to simplify things? Make them!; - We don't necessarily need to merge the result into develop if it's hideous, we just want to find out how close/far we are from making this happen.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2570
https://github.com/broadinstitute/cromwell/issues/2571:754,Integrability,depend,depend,754,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571
https://github.com/broadinstitute/cromwell/issues/2571:113,Performance,perform,performance,113,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571
https://github.com/broadinstitute/cromwell/issues/2571:577,Performance,perform,performance,577,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571
https://github.com/broadinstitute/cromwell/issues/2571:609,Security,hash,hash,609,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571
https://github.com/broadinstitute/cromwell/issues/2571:511,Testability,benchmark,benchmarking,511,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571
https://github.com/broadinstitute/cromwell/pull/2572:141,Modifiability,config,configured,141,"Renamed the singleton services store to the engine services store.; Added metadata services store to the system startup.; Metadata liquibase configured via a new set of xml, with the same tables.; Added jitter to MetadataServiceActorSpec to ensure order is constistent.; Removed unused SqlDatabase from WorkflowStoreActor/WorkflowStoreEngineActor.; Fixed filename of CustomLabelEntry.scala.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572
https://github.com/broadinstitute/cromwell/issues/2573:8,Availability,error,error,8,"If some error occurs during release, it'd be nice to kick off the whole job again and have the process adjust accordingly. ## Should we release this project?; Would need to consult that these are correct and current:. * git tags; * release on github; * jar in JFrog; * brew Pr exists (for cromwell). This decision will determine version number for downstream projects.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2573
https://github.com/broadinstitute/cromwell/issues/2573:348,Availability,down,downstream,348,"If some error occurs during release, it'd be nice to kick off the whole job again and have the process adjust accordingly. ## Should we release this project?; Would need to consult that these are correct and current:. * git tags; * release on github; * jar in JFrog; * brew Pr exists (for cromwell). This decision will determine version number for downstream projects.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2573
https://github.com/broadinstitute/cromwell/issues/2573:28,Deployability,release,release,28,"If some error occurs during release, it'd be nice to kick off the whole job again and have the process adjust accordingly. ## Should we release this project?; Would need to consult that these are correct and current:. * git tags; * release on github; * jar in JFrog; * brew Pr exists (for cromwell). This decision will determine version number for downstream projects.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2573
https://github.com/broadinstitute/cromwell/issues/2573:136,Deployability,release,release,136,"If some error occurs during release, it'd be nice to kick off the whole job again and have the process adjust accordingly. ## Should we release this project?; Would need to consult that these are correct and current:. * git tags; * release on github; * jar in JFrog; * brew Pr exists (for cromwell). This decision will determine version number for downstream projects.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2573
https://github.com/broadinstitute/cromwell/issues/2573:232,Deployability,release,release,232,"If some error occurs during release, it'd be nice to kick off the whole job again and have the process adjust accordingly. ## Should we release this project?; Would need to consult that these are correct and current:. * git tags; * release on github; * jar in JFrog; * brew Pr exists (for cromwell). This decision will determine version number for downstream projects.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2573
https://github.com/broadinstitute/cromwell/issues/2574:14,Deployability,release,release,14,Currently our release to the `brew` package management system is manual. It should be scripted and included in the release process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2574
https://github.com/broadinstitute/cromwell/issues/2574:115,Deployability,release,release,115,Currently our release to the `brew` package management system is manual. It should be scripted and included in the release process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2574
https://github.com/broadinstitute/cromwell/issues/2575:223,Availability,down,downing,223,"The ServiceRegistry requires all services sitting behind it to at least be aware of the graceful shutdown infrastructure, e.g. handling a `ShutdownCommand` even if the service doesn't need to be graceful about its shutting downing. It'd be nicer if this could be made to not be the case",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2575
https://github.com/broadinstitute/cromwell/issues/2576:390,Availability,ERROR,ERROR,390,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:941,Availability,Failure,Failure,941,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:949,Availability,recover,recoverWith,949,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:8899,Availability,outage,outage,8899,"nknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpression.scala:172); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); 	... 34 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 80 more; ```. If this was due to an extended GCS service outage, a workflow failure is expected. But if cromwell didn't retry at all after a single cloud hiccup, that should be fixed as cloud hiccups are expected.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:8918,Availability,failure,failure,8918,"nknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpression.scala:172); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); 	... 34 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 80 more; ```. If this was due to an extended GCS service outage, a workflow failure is expected. But if cromwell didn't retry at all after a single cloud hiccup, that should be fixed as cloud hiccups are expected.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:1188,Energy Efficiency,adapt,adapted,1188,"omwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionAct",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:4964,Energy Efficiency,adapt,adapted,4964,.google.cloud.storage.StorageException: 503 Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:579); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.size(Files.java:2332); 	at better.files.File.$anonfun$size$1(File.scala:502); 	at better.files.File.$anonfun$size$1$adapted(File.scala:502); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:448); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1417); 	at scala.collection.TraversableOnce.sum(TraversableOnce.scala:216); 	at scala.collection.TraversableOnce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFu,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:1188,Modifiability,adapt,adapted,1188,"omwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionAct",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:4964,Modifiability,adapt,adapted,4964,.google.cloud.storage.StorageException: 503 Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:579); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.size(Files.java:2332); 	at better.files.File.$anonfun$size$1(File.scala:502); 	at better.files.File.$anonfun$size$1$adapted(File.scala:502); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:448); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1417); 	at scala.collection.TraversableOnce.sum(TraversableOnce.scala:216); 	at scala.collection.TraversableOnce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFu,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:8878,Modifiability,extend,extended,8878,"nknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpression.scala:172); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); 	... 34 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 80 more; ```. If this was due to an extended GCS service outage, a workflow failure is expected. But if cromwell didn't retry at all after a single cloud hiccup, that should be fixed as cloud hiccups are expected.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:2842,Performance,concurren,concurrent,2842,WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.evaluateOutputs(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionSuccess(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinP,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:2908,Performance,concurren,concurrent,2908,dl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.evaluateOutputs(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionSuccess(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.ru,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:2986,Performance,concurren,concurrent,2986,ckend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); 	at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.evaluateOutputs(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionSuccess(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.google.cloud.storage.StorageE,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:3311,Performance,concurren,concurrent,3311,.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); 	at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); 	at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionSuccess(JesAsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.google.cloud.storage.StorageException: 503 Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(Sto,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:949,Safety,recover,recoverWith,949,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:6282,Security,validat,validateFileSizeIsWithinLimits,6282,scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1417); 	at scala.collection.TraversableOnce.sum(TraversableOnce.scala:216); 	at scala.collection.TraversableOnce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:6434,Security,validat,validateFileSizeIsWithinLimits,6434, 	at scala.collection.TraversableOnce.sum(TraversableOnce.scala:216); 	at scala.collection.TraversableOnce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:6537,Security,validat,validateFileSizeIsWithinLimits,6537,ce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpress,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:6656,Security,validat,validateFileSizeIsWithinLimits,6656,ize(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpression.scala:172); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); 	... 34 more; Caused by: com.google.api,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:115,Testability,log,log,115,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2576:295,Testability,log,logs,295,"A 503 StorageException seems to have failed one of the centaur JES jobs, and hence the workflow. Via the [cromwell.log](https://console.cloud.google.com/storage/browser/cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/0310fa51-e985-4c54-8cdb-5058155f452e/call-centaur/cromwell_root/logs/). ```java; 2017-08-25 05:43:25,399 cromwell-system-akka.dispatchers.engine-dispatcher-51 ERROR - WorkflowManagerActor Workflow dabddbe7-a385-4df4-be97-c1ef7b884823 failed (during ExecutingWorkflowState): Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); java.lang.RuntimeException: Could not evaluate composeEngineFunctions.y = read_int(stderr()) + x + read_string(blah); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:190); 	at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:189); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); 	at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:182); 	at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); 	at cromwell.backend.stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576
https://github.com/broadinstitute/cromwell/issues/2579:239,Availability,error,error,239,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:717,Availability,error,error,717,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:867,Availability,down,down,867,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:906,Availability,error,error,906,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:2599,Deployability,release,released,2599,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1267,Integrability,depend,depends,1267," incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1372,Integrability,depend,dependencyTree,1372,"kka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1756,Integrability,depend,dependency,1756,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1872,Integrability,Depend,Dependencies,1872,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1901,Integrability,Depend,Dependencies,1901,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:1968,Integrability,Depend,Dependencies,1968,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:2002,Integrability,Depend,Dependencies,2002,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:2049,Integrability,Depend,Dependencies,2049,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:586,Modifiability,plugin,plugins,586,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:202,Safety,Detect,Detected,202,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:22,Testability,test,test,22,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:119,Testability,test,test,119,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/issues/2579:2369,Testability,Test,Test,2369,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579
https://github.com/broadinstitute/cromwell/pull/2580:60,Deployability,release,released,60,"as per http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes, to use akka-actor and akka-http together; #2579",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2580
https://github.com/broadinstitute/cromwell/pull/2581:161,Safety,abort,abort,161,A different approach to #1126 from that proposed in the ticket. This records the container ID at `docker run` time and uses that to `docker kill` the process on abort.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2581
https://github.com/broadinstitute/cromwell/pull/2582:102,Energy Efficiency,monitor,monitor,102,Note that there's no documentation nor testing for this atm. Yes I'm aware of that :). Initial health monitor support; o Provide health monitor infrastructure to provide ability to attach checks for underlying subsystems; o Provide status endpoint which will query current contents of health monitor implementation; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2582
https://github.com/broadinstitute/cromwell/pull/2582:136,Energy Efficiency,monitor,monitor,136,Note that there's no documentation nor testing for this atm. Yes I'm aware of that :). Initial health monitor support; o Provide health monitor infrastructure to provide ability to attach checks for underlying subsystems; o Provide status endpoint which will query current contents of health monitor implementation; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2582
https://github.com/broadinstitute/cromwell/pull/2582:292,Energy Efficiency,monitor,monitor,292,Note that there's no documentation nor testing for this atm. Yes I'm aware of that :). Initial health monitor support; o Provide health monitor infrastructure to provide ability to attach checks for underlying subsystems; o Provide status endpoint which will query current contents of health monitor implementation; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2582
https://github.com/broadinstitute/cromwell/pull/2582:39,Testability,test,testing,39,Note that there's no documentation nor testing for this atm. Yes I'm aware of that :). Initial health monitor support; o Provide health monitor infrastructure to provide ability to attach checks for underlying subsystems; o Provide status endpoint which will query current contents of health monitor implementation; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2582
https://github.com/broadinstitute/cromwell/issues/2584:362,Availability,error,error,362,"In a Cromwell configured with multiple backends, be able to dynamically determine which backend to send a job based on where the input files live. . 1. If there are no files, use the default backend; 2. If all of the files are on the same filesystem, use the backend associated w/ that filesystem (see below); 3. If the files are not all on the same filesystem, error. This will require moving backend determination (at least for many tasks) out of materialization and closer to the runtime dispatch. Note that the 2nd stage really only works right now because there's (mostly) a 1-1 mapping of backend to filesystem. If you can find a way to do this slickly in a world where a backend might support multiple filesystems, so much the better. Note also that this relates to #1312 (ideally this is done after that, but shouldn't matter too much either way). The workflow option should always override dynamic dispatch determination.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2584
https://github.com/broadinstitute/cromwell/issues/2584:14,Modifiability,config,configured,14,"In a Cromwell configured with multiple backends, be able to dynamically determine which backend to send a job based on where the input files live. . 1. If there are no files, use the default backend; 2. If all of the files are on the same filesystem, use the backend associated w/ that filesystem (see below); 3. If the files are not all on the same filesystem, error. This will require moving backend determination (at least for many tasks) out of materialization and closer to the runtime dispatch. Note that the 2nd stage really only works right now because there's (mostly) a 1-1 mapping of backend to filesystem. If you can find a way to do this slickly in a world where a backend might support multiple filesystems, so much the better. Note also that this relates to #1312 (ideally this is done after that, but shouldn't matter too much either way). The workflow option should always override dynamic dispatch determination.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2584
https://github.com/broadinstitute/cromwell/pull/2587:162,Integrability,message,messages,162,"Add a base infrastructure to support StatsD (or other) instrumentation.; The actual implementation sits behind the service registry. Cromwell components can send messages to this service to report information about their behavior and what they're doing.; Default implementation is NooP.; Second implementation is a StatsD client based on what Workbench is doing. It makes the metrics look a bit funky on the StatsD side and needs some tweaking but is simpler than re-implementing a fully scalable client (which I've started doing but backpedaled from as it seemed like too much code to maintain, at least for now). The result can easily be visualized by firing up this docker https://github.com/kamon-io/docker-grafana-graphite, starting a Cromwell server and playing with the dashboards. I started documenting the metrics more in details but it seems like the kind of thing that is likely to change based on what we need / want so I just listed high level categories. Please opine if this is not enough. They're auto-discovered by StatsD anyway so you don't need to know what they are to find them. I also punted on the dependency issue as I don't know where we stand regarding services using specific libraries (@geoffjentry ?) For now they're in core.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2587
https://github.com/broadinstitute/cromwell/pull/2587:1121,Integrability,depend,dependency,1121,"Add a base infrastructure to support StatsD (or other) instrumentation.; The actual implementation sits behind the service registry. Cromwell components can send messages to this service to report information about their behavior and what they're doing.; Default implementation is NooP.; Second implementation is a StatsD client based on what Workbench is doing. It makes the metrics look a bit funky on the StatsD side and needs some tweaking but is simpler than re-implementing a fully scalable client (which I've started doing but backpedaled from as it seemed like too much code to maintain, at least for now). The result can easily be visualized by firing up this docker https://github.com/kamon-io/docker-grafana-graphite, starting a Cromwell server and playing with the dashboards. I started documenting the metrics more in details but it seems like the kind of thing that is likely to change based on what we need / want so I just listed high level categories. Please opine if this is not enough. They're auto-discovered by StatsD anyway so you don't need to know what they are to find them. I also punted on the dependency issue as I don't know where we stand regarding services using specific libraries (@geoffjentry ?) For now they're in core.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2587
https://github.com/broadinstitute/cromwell/pull/2587:488,Performance,scalab,scalable,488,"Add a base infrastructure to support StatsD (or other) instrumentation.; The actual implementation sits behind the service registry. Cromwell components can send messages to this service to report information about their behavior and what they're doing.; Default implementation is NooP.; Second implementation is a StatsD client based on what Workbench is doing. It makes the metrics look a bit funky on the StatsD side and needs some tweaking but is simpler than re-implementing a fully scalable client (which I've started doing but backpedaled from as it seemed like too much code to maintain, at least for now). The result can easily be visualized by firing up this docker https://github.com/kamon-io/docker-grafana-graphite, starting a Cromwell server and playing with the dashboards. I started documenting the metrics more in details but it seems like the kind of thing that is likely to change based on what we need / want so I just listed high level categories. Please opine if this is not enough. They're auto-discovered by StatsD anyway so you don't need to know what they are to find them. I also punted on the dependency issue as I don't know where we stand regarding services using specific libraries (@geoffjentry ?) For now they're in core.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2587
https://github.com/broadinstitute/cromwell/pull/2587:451,Usability,simpl,simpler,451,"Add a base infrastructure to support StatsD (or other) instrumentation.; The actual implementation sits behind the service registry. Cromwell components can send messages to this service to report information about their behavior and what they're doing.; Default implementation is NooP.; Second implementation is a StatsD client based on what Workbench is doing. It makes the metrics look a bit funky on the StatsD side and needs some tweaking but is simpler than re-implementing a fully scalable client (which I've started doing but backpedaled from as it seemed like too much code to maintain, at least for now). The result can easily be visualized by firing up this docker https://github.com/kamon-io/docker-grafana-graphite, starting a Cromwell server and playing with the dashboards. I started documenting the metrics more in details but it seems like the kind of thing that is likely to change based on what we need / want so I just listed high level categories. Please opine if this is not enough. They're auto-discovered by StatsD anyway so you don't need to know what they are to find them. I also punted on the dependency issue as I don't know where we stand regarding services using specific libraries (@geoffjentry ?) For now they're in core.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2587
https://github.com/broadinstitute/cromwell/issues/2589:111,Availability,error,error,111,"I'm trying to use `quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0`, but I'm getting the following error:. ```; [ERROR] [08/31/2017 20:01:21.193] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManage; rActor] WorkflowManagerActor Workflow 73494fe9-ef7b-45e0-b982-b50baf3281d7 failed (during ExecutingWorkflowState): Docker image quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0 has an invalid syntax.; java.lang.IllegalArgumentException: Docker image quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0 has an invalid syntax.; at cromwell.docker.DockerImageIdentifier$.fromString(DockerImageIdentifier.scala:60); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.handleDockerValue$1(JobPreparationActor.scala:112); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.cromwell$engine$workflow$lifecycle$execution$preparation$JobPreparatio; nActor$$fetchDockerHashesIfNecessary(JobPreparationActor.scala:129); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActor.scala:57); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActor.scala:54); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.processEvent(JobPreparationActor.scala:33); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.aroundReceive(JobPreparationActor.scala:33); at akka.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2589
https://github.com/broadinstitute/cromwell/issues/2589:125,Availability,ERROR,ERROR,125,"I'm trying to use `quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0`, but I'm getting the following error:. ```; [ERROR] [08/31/2017 20:01:21.193] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManage; rActor] WorkflowManagerActor Workflow 73494fe9-ef7b-45e0-b982-b50baf3281d7 failed (during ExecutingWorkflowState): Docker image quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0 has an invalid syntax.; java.lang.IllegalArgumentException: Docker image quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.5_0 has an invalid syntax.; at cromwell.docker.DockerImageIdentifier$.fromString(DockerImageIdentifier.scala:60); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.handleDockerValue$1(JobPreparationActor.scala:112); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.cromwell$engine$workflow$lifecycle$execution$preparation$JobPreparatio; nActor$$fetchDockerHashesIfNecessary(JobPreparationActor.scala:129); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActor.scala:57); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActor.scala:54); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.processEvent(JobPreparationActor.scala:33); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.execution.preparation.JobPreparationActor.aroundReceive(JobPreparationActor.scala:33); at akka.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2589
https://github.com/broadinstitute/cromwell/issues/2590:227,Energy Efficiency,green,green,227,Running locally: https://github.com/common-workflow-language/common-workflow-language/blob/master/CONFORMANCE_TESTS.md. Then get it on their master one: http://ci.commonwl.org/. Don't wire it into our travis yet as we won't be green for a while.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2590
https://github.com/broadinstitute/cromwell/issues/2594:158,Availability,error,error,158,"The specification according to the documentation is `${true=""--enabled"", false=""--disabled"" boolean_var}`, and the false tag is optional. However, I get this error when attempting this syntax:. ```. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Both 'true' and 'false' attributes must be specified if either is specified:. --tumorBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2594:353,Availability,ERROR,ERROR,353,"The specification according to the documentation is `${true=""--enabled"", false=""--disabled"" boolean_var}`, and the false tag is optional. However, I get this error when attempting this syntax:. ```. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Both 'true' and 'false' attributes must be specified if either is specified:. --tumorBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2594:323,Performance,load,load,323,"The specification according to the documentation is `${true=""--enabled"", false=""--disabled"" boolean_var}`, and the false tag is optional. However, I get this error when attempting this syntax:. ```. cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Both 'true' and 'false' attributes must be specified if either is specified:. --tumorBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2594:1291,Testability,Log,LoggingFSM,1291,e to load namespace from workflow: ERROR: Both 'true' and 'false' attributes must be specified if either is specified:. --tumorBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2594:1383,Testability,Log,LoggingFSM,1383,ibutes must be specified if either is specified:. --tumorBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2594:1437,Testability,Log,LoggingFSM,1437,morBam=${tumor_bam} --normalBam=${normal_bam} ${true='--targeted' targeted} \; ^. at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:186); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:156); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:151); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:663); at akka.actor.FSM.processEvent$(FSM.scala:660); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.LoggingFSM.processEvent(FSM.scala:799); at akka.actor.LoggingFSM.processEvent$(FSM.scala:781); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor.aroundReceive(Actor.scala:513); at akka.actor.Actor.aroundReceive$(Actor.scala:511); at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:114); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.run,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2594
https://github.com/broadinstitute/cromwell/issues/2595:296,Energy Efficiency,monitor,monitor,296,"It would be nice to have a rest Endpoint which would cause Cromwell to stop launching any new Jobs, wait for a terminal state in all of the current jobs, then gracefully shutdown after a set delay. The use case for this is an attempt to scale cromwell. We run a large number of workflows are and monitor the number of workflows per machine, sometimes we need to increase the number of cromwells to accomodate the load, but then want to shut them off later",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2595
https://github.com/broadinstitute/cromwell/issues/2595:413,Performance,load,load,413,"It would be nice to have a rest Endpoint which would cause Cromwell to stop launching any new Jobs, wait for a terminal state in all of the current jobs, then gracefully shutdown after a set delay. The use case for this is an attempt to scale cromwell. We run a large number of workflows are and monitor the number of workflows per machine, sometimes we need to increase the number of cromwells to accomodate the load, but then want to shut them off later",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2595
https://github.com/broadinstitute/cromwell/issues/2597:93,Performance,cache,cached-execution-directory,93,"https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory#latest. Even though the call-caching mode is set to copy, the outputs have been copied and unexpectedly -- a placeholder has also been written to the call directory. I'm not sure of the frequency of this event as I'm not sure how many people are checking call directories for jobs they expect to have cached. Ideally we'd never see this placeholder file in the case of the `copy` duplication-strategy for call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2597
https://github.com/broadinstitute/cromwell/issues/2597:421,Performance,cache,cached,421,"https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory#latest. Even though the call-caching mode is set to copy, the outputs have been copied and unexpectedly -- a placeholder has also been written to the call directory. I'm not sure of the frequency of this event as I'm not sure how many people are checking call directories for jobs they expect to have cached. Ideally we'd never see this placeholder file in the case of the `copy` duplication-strategy for call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2597
https://github.com/broadinstitute/cromwell/issues/2598:204,Performance,Perform,Perform,204,"From both swagger & purely from command line verify that the following workflow (pardon the pun) works. If it does not, file tickets here or with Sam as appropriate. Create a doc detailing the outcome. - Perform OAuth authentication (via clicky buttons in swagger, gcloud on CLI); - Register user in Sam; - Submit workflow to Cromwell; - Get final results from Cromwell for that workflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2598
https://github.com/broadinstitute/cromwell/issues/2598:218,Security,authenticat,authentication,218,"From both swagger & purely from command line verify that the following workflow (pardon the pun) works. If it does not, file tickets here or with Sam as appropriate. Create a doc detailing the outcome. - Perform OAuth authentication (via clicky buttons in swagger, gcloud on CLI); - Register user in Sam; - Submit workflow to Cromwell; - Get final results from Cromwell for that workflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2598
https://github.com/broadinstitute/cromwell/issues/2599:380,Availability,echo,echo,380,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599
https://github.com/broadinstitute/cromwell/issues/2599:495,Availability,error,error,495,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599
https://github.com/broadinstitute/cromwell/issues/2599:671,Availability,ERROR,ERROR,671,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599
https://github.com/broadinstitute/cromwell/issues/2599:641,Performance,load,load,641,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599
https://github.com/broadinstitute/cromwell/issues/2599:73,Security,access,accesses,73,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599
https://github.com/broadinstitute/cromwell/issues/2600:60,Security,hash,hash,60,"Per the linked forum post, add an option to turn off Docker hash lookups with the understanding that this would not be compatible with call caching. https://gatkforums.broadinstitute.org/wdl/discussion/10279/problem-with-docker-images-pulled-self-hosted-registries",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2600
https://github.com/broadinstitute/cromwell/pull/2601:74,Performance,cache,cache,74,"Issue: Currently, regardless of the duplication strategy in JES, the call cache placeholder file is created in case of cache hits. . Fix: Added a statement that confirms the caching strategy is set to reference in order to upload the call_caching_placeholder.txt.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2601
https://github.com/broadinstitute/cromwell/pull/2601:119,Performance,cache,cache,119,"Issue: Currently, regardless of the duplication strategy in JES, the call cache placeholder file is created in case of cache hits. . Fix: Added a statement that confirms the caching strategy is set to reference in order to upload the call_caching_placeholder.txt.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2601
https://github.com/broadinstitute/cromwell/issues/2604:115,Performance,cache,cache,115,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604
https://github.com/broadinstitute/cromwell/issues/2604:690,Performance,cache,cache,690,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604
https://github.com/broadinstitute/cromwell/issues/2604:198,Safety,Risk,Risk,198,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604
https://github.com/broadinstitute/cromwell/issues/2604:75,Security,hash,hashing,75,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604
https://github.com/broadinstitute/cromwell/issues/2604:248,Security,hash,hashing,248,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604
https://github.com/broadinstitute/cromwell/issues/2606:25,Modifiability,config,configured,25,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606
https://github.com/broadinstitute/cromwell/issues/2606:131,Modifiability,extend,extends,131,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606
https://github.com/broadinstitute/cromwell/issues/2606:260,Modifiability,extend,extend,260,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606
https://github.com/broadinstitute/cromwell/issues/2606:308,Security,validat,validation,308,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606
https://github.com/broadinstitute/cromwell/issues/2608:270,Deployability,configurat,configuration,270,WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2608
https://github.com/broadinstitute/cromwell/issues/2608:227,Integrability,depend,depending,227,WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2608
https://github.com/broadinstitute/cromwell/issues/2608:270,Modifiability,config,configuration,270,WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2608
https://github.com/broadinstitute/cromwell/issues/2611:52,Deployability,configurat,configuration,52,Design a way for Cromwell to pass language specific configuration to the various bindings.; The use case for this is read_*** bytes limitation that are different for different WDL functions which Cromwell has no knowledge of anymore.; CWL also requires the same type of limitation.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2611
https://github.com/broadinstitute/cromwell/issues/2611:52,Modifiability,config,configuration,52,Design a way for Cromwell to pass language specific configuration to the various bindings.; The use case for this is read_*** bytes limitation that are different for different WDL functions which Cromwell has no knowledge of anymore.; CWL also requires the same type of limitation.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2611
https://github.com/broadinstitute/cromwell/pull/2613:97,Testability,test,testing,97,"Breaks a LOT of things. If we merge this Cromwell will be unusable from this point.; In terms of testing do we want to `ignore` failing unit tests (with a ~~PostMVP~~ PostWom tag ?); Leave them failing ?; Should centaur tests be ignored too (at this point it'd pretty much be all of them except hello world maybe..) ?. The only significant code changes are in the CallPreparation Actor, the MetarializeWD Actor and to some lower degree the WorkflowExecutionActor, ExecutionStore and OutputStore (which I cloned with a WOM version for now only for dev purposes until the WOM version replaces the old one). The rest is mostly going from Wdl node types to Wom node types and associated equivalent. There's also code commented that was not necessary to run 3step and that needs attention in order to work in WOM world.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613
https://github.com/broadinstitute/cromwell/pull/2613:141,Testability,test,tests,141,"Breaks a LOT of things. If we merge this Cromwell will be unusable from this point.; In terms of testing do we want to `ignore` failing unit tests (with a ~~PostMVP~~ PostWom tag ?); Leave them failing ?; Should centaur tests be ignored too (at this point it'd pretty much be all of them except hello world maybe..) ?. The only significant code changes are in the CallPreparation Actor, the MetarializeWD Actor and to some lower degree the WorkflowExecutionActor, ExecutionStore and OutputStore (which I cloned with a WOM version for now only for dev purposes until the WOM version replaces the old one). The rest is mostly going from Wdl node types to Wom node types and associated equivalent. There's also code commented that was not necessary to run 3step and that needs attention in order to work in WOM world.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613
https://github.com/broadinstitute/cromwell/pull/2613:220,Testability,test,tests,220,"Breaks a LOT of things. If we merge this Cromwell will be unusable from this point.; In terms of testing do we want to `ignore` failing unit tests (with a ~~PostMVP~~ PostWom tag ?); Leave them failing ?; Should centaur tests be ignored too (at this point it'd pretty much be all of them except hello world maybe..) ?. The only significant code changes are in the CallPreparation Actor, the MetarializeWD Actor and to some lower degree the WorkflowExecutionActor, ExecutionStore and OutputStore (which I cloned with a WOM version for now only for dev purposes until the WOM version replaces the old one). The rest is mostly going from Wdl node types to Wom node types and associated equivalent. There's also code commented that was not necessary to run 3step and that needs attention in order to work in WOM world.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613
https://github.com/broadinstitute/cromwell/issues/2615:23,Testability,test,tests,23,Then reinstate centaur tests:; - [ ] `sub_workflow_interactions_scatter`; - [ ] `sub_workflow_hello_world`; - [ ] `conditionals.lots_of_testing`; - [ ] `conditionals.subworkflows_in_ifs`; - [ ] `recursive_imports`; - [ ] `missing_import_failure`; - [ ] `sub_workflow_interactions`; - [ ] `public_http_import`; - [ ] `aliased_subworkflows` (addition: make sure WF inputs direct from `input.json` to the aliased subworkflows works); - [ ] `sub_workflow_var_refs`; - [ ] `refresh_token_sub_workflow`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2615
https://github.com/broadinstitute/cromwell/issues/2620:1514,Performance,perform,performance,1514,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2620:751,Security,threat,threat,751,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2620:866,Security,access,access,866,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2620:901,Security,threat,threat,901,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2620:1215,Security,access,access,1215,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2620:1400,Security,access,access,1400,"- Cromwell does not support soft links for dockerized jobs by [design](https://github.com/broadinstitute/cromwell/blob/29_hotfix/supportedBackends/sfs/src/main/scala/cromwell/backend/sfs/SharedFileSystem.scala#L112); - I guess that's because symlinks are a big challenge with Docker. They do not work inside Docker container unless both the directories are mounted (dir with symlink - Cromwell's tmp execution dir and original dir where input files are present), plus, mounts inside the container should have the same name/path as that of the host file system. Since Cromwell has information about original input files, they can be mounted along with the tmp execution dir (where symlinks will be created), to the Docker container; - This possesses a threat (of being modified inside a Docker container), to input files, which can be circumvented by using read only access to the input files (similar threat is also applicable to hard linked input files, in case of current behavior); - Also given the nature of hard-links, they can be completely eliminated . Benefits of using symlinks over hard-links:; - Hard links can't cross file systems; soft links can; - OS user which runs Cromwell requires to have a write access to input files in order for hard-links to work, this is not a requirement for soft links; - When hard-links do not work in case of Docker jobs (when necessary conditions - write access, same device requirement, aren't satisfied), Cromwell falls back to copy option, which takes a significant performance hit as the input files could be huge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620
https://github.com/broadinstitute/cromwell/issues/2621:233,Performance,cache,cache,233,"A very common way of producing a side .md5 file is to use something like. `md5 -q dbsnp_138.vcf > dbsnp_138.vcf.md5`. Which produces a trailing newline character, which cromwell reads and interprets as part of the hash, thus causing cache misses against files that (a) were hashed by cromwell or (b) don't have a newline. Not only isn't this the desired behavior... it's very confusing because it appears that sometimes call caching works and other times it does not. Cromwell should strip out all trailing whitespace (e.g. \n, \r\n) from the data read in the .md5 file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2621
https://github.com/broadinstitute/cromwell/issues/2621:214,Security,hash,hash,214,"A very common way of producing a side .md5 file is to use something like. `md5 -q dbsnp_138.vcf > dbsnp_138.vcf.md5`. Which produces a trailing newline character, which cromwell reads and interprets as part of the hash, thus causing cache misses against files that (a) were hashed by cromwell or (b) don't have a newline. Not only isn't this the desired behavior... it's very confusing because it appears that sometimes call caching works and other times it does not. Cromwell should strip out all trailing whitespace (e.g. \n, \r\n) from the data read in the .md5 file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2621
https://github.com/broadinstitute/cromwell/issues/2621:274,Security,hash,hashed,274,"A very common way of producing a side .md5 file is to use something like. `md5 -q dbsnp_138.vcf > dbsnp_138.vcf.md5`. Which produces a trailing newline character, which cromwell reads and interprets as part of the hash, thus causing cache misses against files that (a) were hashed by cromwell or (b) don't have a newline. Not only isn't this the desired behavior... it's very confusing because it appears that sometimes call caching works and other times it does not. Cromwell should strip out all trailing whitespace (e.g. \n, \r\n) from the data read in the .md5 file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2621
https://github.com/broadinstitute/cromwell/issues/2623:203,Availability,echo,echo,203,It would be really handy to have a `cromwell.server` script that would make starting and stopping a server cromwell easy. ```; $ cromwell.server start; ... Started!. $ cromwell.server status; running. $ echo $?; 0. $ cromwell.server stop; ... Stopped!. $ cromwell.server status; stopped. $ echo $?; 1; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2623
https://github.com/broadinstitute/cromwell/issues/2623:290,Availability,echo,echo,290,It would be really handy to have a `cromwell.server` script that would make starting and stopping a server cromwell easy. ```; $ cromwell.server start; ... Started!. $ cromwell.server status; running. $ echo $?; 0. $ cromwell.server stop; ... Stopped!. $ cromwell.server status; stopped. $ echo $?; 1; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2623
https://github.com/broadinstitute/cromwell/issues/2624:151,Deployability,Install,Installing,151,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2624:765,Deployability,configurat,configuration,765,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2624:765,Modifiability,config,configuration,765,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2624:424,Performance,cache,cache,424,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2624:514,Safety,detect,detected,514,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2624:618,Security,password,password,618,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624
https://github.com/broadinstitute/cromwell/issues/2625:28,Security,validat,validateDeclarations,28,"In the MaterializeWDA, the `validateDeclarations` method now uses `NoFunctions` which prevents evaluation of workflow level declaration with `read_string` etc...; The way of achieving this may be different in WOM-world but this functionality must remain.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2625
https://github.com/broadinstitute/cromwell/pull/2628:34,Testability,Test,Tests,34,"First pass at Womifying Cromwell; Tests that couldn't be fixed were tageed with `PostWomTest` and ignored; The code contains a lot of `TODO WOM`. I know everyone has an opinion on TODOs, I don't really like them myself but in this case it's mostly used to annotate code with contextual information about what needs to be fixed or how or why etc...; They're ALL expected to be removed by the end of this milestone.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2628
https://github.com/broadinstitute/cromwell/issues/2629:144,Deployability,update,updated,144,Doug will soon be changing the SAM resource type for workflows from `workflow` to something like `workflow-collection`. CromIAM will need to be updated [here](https://github.com/broadinstitute/CromIAM/blob/a65b4569c40b10bd3477e0394f2c55dd1ddd234a/src/main/scala/cromiam/sam/SamClient.scala#L47). This change must be synchronized with the change to SAM in the dev environments. NOTE: Doug has also mentioned that the existing workflow resources will not be migrated in SAM during this change.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2629
https://github.com/broadinstitute/cromwell/issues/2629:316,Integrability,synchroniz,synchronized,316,Doug will soon be changing the SAM resource type for workflows from `workflow` to something like `workflow-collection`. CromIAM will need to be updated [here](https://github.com/broadinstitute/CromIAM/blob/a65b4569c40b10bd3477e0394f2c55dd1ddd234a/src/main/scala/cromiam/sam/SamClient.scala#L47). This change must be synchronized with the change to SAM in the dev environments. NOTE: Doug has also mentioned that the existing workflow resources will not be migrated in SAM during this change.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2629
https://github.com/broadinstitute/cromwell/issues/2632:332,Availability,error,error,332,"- SGE backend (though I bet backend does not matter); - server mode; - cromwell 29. WDL takes in a list of filenames and scatters over a read_lines call. Each line is a file.; If the list file has DOS line endings, read_lines preserves the `\r` character in the file name. After running dos2unix, the issue disappeared. Here is the error message and you can even see the appended `\r`... ```; Could not localize /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r:\n\t/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r doesn't exists\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r""; ```. Hash error:; ```; ""Cannot hash file /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r because it can't be found"". ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632
https://github.com/broadinstitute/cromwell/issues/2632:1213,Availability,error,error,1213,"- SGE backend (though I bet backend does not matter); - server mode; - cromwell 29. WDL takes in a list of filenames and scatters over a read_lines call. Each line is a file.; If the list file has DOS line endings, read_lines preserves the `\r` character in the file name. After running dos2unix, the issue disappeared. Here is the error message and you can even see the appended `\r`... ```; Could not localize /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r:\n\t/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r doesn't exists\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r""; ```. Hash error:; ```; ""Cannot hash file /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r because it can't be found"". ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632
https://github.com/broadinstitute/cromwell/issues/2632:338,Integrability,message,message,338,"- SGE backend (though I bet backend does not matter); - server mode; - cromwell 29. WDL takes in a list of filenames and scatters over a read_lines call. Each line is a file.; If the list file has DOS line endings, read_lines preserves the `\r` character in the file name. After running dos2unix, the issue disappeared. Here is the error message and you can even see the appended `\r`... ```; Could not localize /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r:\n\t/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r doesn't exists\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r""; ```. Hash error:; ```; ""Cannot hash file /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r because it can't be found"". ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632
https://github.com/broadinstitute/cromwell/issues/2632:1208,Security,Hash,Hash,1208,"- SGE backend (though I bet backend does not matter); - server mode; - cromwell 29. WDL takes in a list of filenames and scatters over a read_lines call. Each line is a file.; If the list file has DOS line endings, read_lines preserves the `\r` character in the file name. After running dos2unix, the issue disappeared. Here is the error message and you can even see the appended `\r`... ```; Could not localize /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r:\n\t/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r doesn't exists\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r""; ```. Hash error:; ```; ""Cannot hash file /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r because it can't be found"". ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632
https://github.com/broadinstitute/cromwell/issues/2632:1234,Security,hash,hash,1234,"- SGE backend (though I bet backend does not matter); - server mode; - cromwell 29. WDL takes in a list of filenames and scatters over a read_lines call. Each line is a file.; If the list file has DOS line endings, read_lines preserves the `\r` character in the file name. After running dos2unix, the issue disappeared. Here is the error message and you can even see the appended `\r`... ```; Could not localize /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r:\n\t/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r doesn't exists\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /dsde/working/lichtens/sge_cromwell/cromwell-executions/m2_validation/3055776a-c32a-4309-a426-87f5730454b4/call-m1_basic_validator/shard-1/inputs/seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r -> /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r\n\tFile not found /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r""; ```. Hash error:; ```; ""Cannot hash file /seq/picard_aggregation/G20440/HSCX1989N/v2/HSCX1989N.bai\r because it can't be found"". ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632
https://github.com/broadinstitute/cromwell/pull/2635:292,Availability,echo,echo,292,- Starter-for-10 PR.; - Lets us start up Cromwell with a simple; ```; # cromwell.server start; ```; - Lets us stop Cromwell with a simple; ```; # cromwell.server stop; ```; - Lets us see whether Cromwell is already running with a simple; ```; # cromwell.server status; Cromwell is stopped. # echo $?; 1; ```; - My ultimate dream is to make this part of the [cromwell quickstart process](https://github.com/broadinstitute/cromwell/issues/2624) to get people up and ready for server mode in just a few simple commands.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2635
https://github.com/broadinstitute/cromwell/pull/2635:57,Usability,simpl,simple,57,- Starter-for-10 PR.; - Lets us start up Cromwell with a simple; ```; # cromwell.server start; ```; - Lets us stop Cromwell with a simple; ```; # cromwell.server stop; ```; - Lets us see whether Cromwell is already running with a simple; ```; # cromwell.server status; Cromwell is stopped. # echo $?; 1; ```; - My ultimate dream is to make this part of the [cromwell quickstart process](https://github.com/broadinstitute/cromwell/issues/2624) to get people up and ready for server mode in just a few simple commands.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2635
https://github.com/broadinstitute/cromwell/pull/2635:131,Usability,simpl,simple,131,- Starter-for-10 PR.; - Lets us start up Cromwell with a simple; ```; # cromwell.server start; ```; - Lets us stop Cromwell with a simple; ```; # cromwell.server stop; ```; - Lets us see whether Cromwell is already running with a simple; ```; # cromwell.server status; Cromwell is stopped. # echo $?; 1; ```; - My ultimate dream is to make this part of the [cromwell quickstart process](https://github.com/broadinstitute/cromwell/issues/2624) to get people up and ready for server mode in just a few simple commands.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2635
https://github.com/broadinstitute/cromwell/pull/2635:230,Usability,simpl,simple,230,- Starter-for-10 PR.; - Lets us start up Cromwell with a simple; ```; # cromwell.server start; ```; - Lets us stop Cromwell with a simple; ```; # cromwell.server stop; ```; - Lets us see whether Cromwell is already running with a simple; ```; # cromwell.server status; Cromwell is stopped. # echo $?; 1; ```; - My ultimate dream is to make this part of the [cromwell quickstart process](https://github.com/broadinstitute/cromwell/issues/2624) to get people up and ready for server mode in just a few simple commands.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2635
https://github.com/broadinstitute/cromwell/pull/2635:500,Usability,simpl,simple,500,- Starter-for-10 PR.; - Lets us start up Cromwell with a simple; ```; # cromwell.server start; ```; - Lets us stop Cromwell with a simple; ```; # cromwell.server stop; ```; - Lets us see whether Cromwell is already running with a simple; ```; # cromwell.server status; Cromwell is stopped. # echo $?; 1; ```; - My ultimate dream is to make this part of the [cromwell quickstart process](https://github.com/broadinstitute/cromwell/issues/2624) to get people up and ready for server mode in just a few simple commands.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2635
https://github.com/broadinstitute/cromwell/issues/2636:45,Availability,echo,echo,45,"eg; ```; task foo {; String? bar; command {; echo ""result: ${default=""d"" bar}""; }; output {; String out = read_string(stdout()); }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2636
https://github.com/broadinstitute/cromwell/issues/2637:73,Modifiability,config,configurable,73,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637
https://github.com/broadinstitute/cromwell/issues/2637:325,Security,access,access,325,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637
https://github.com/broadinstitute/cromwell/issues/2637:339,Security,firewall,firewall,339,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637
https://github.com/broadinstitute/cromwell/issues/2637:401,Security,secur,secure,401,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637
https://github.com/broadinstitute/cromwell/issues/2642:154,Deployability,pipeline,pipelines,154,"Currently, monitoring only functions on google VMs and not on local cromwell runs (the documentation is not clear on that). . The mint team is developing pipelines where we would like to use a monitoring script to judge ram and disk usage to better estimate runtime specifications. It would be helpful if it could be enabled for local use as well as VM usage (I hear this isn't hard). . Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2642
https://github.com/broadinstitute/cromwell/issues/2642:11,Energy Efficiency,monitor,monitoring,11,"Currently, monitoring only functions on google VMs and not on local cromwell runs (the documentation is not clear on that). . The mint team is developing pipelines where we would like to use a monitoring script to judge ram and disk usage to better estimate runtime specifications. It would be helpful if it could be enabled for local use as well as VM usage (I hear this isn't hard). . Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2642
https://github.com/broadinstitute/cromwell/issues/2642:193,Energy Efficiency,monitor,monitoring,193,"Currently, monitoring only functions on google VMs and not on local cromwell runs (the documentation is not clear on that). . The mint team is developing pipelines where we would like to use a monitoring script to judge ram and disk usage to better estimate runtime specifications. It would be helpful if it could be enabled for local use as well as VM usage (I hear this isn't hard). . Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2642
https://github.com/broadinstitute/cromwell/issues/2642:108,Usability,clear,clear,108,"Currently, monitoring only functions on google VMs and not on local cromwell runs (the documentation is not clear on that). . The mint team is developing pipelines where we would like to use a monitoring script to judge ram and disk usage to better estimate runtime specifications. It would be helpful if it could be enabled for local use as well as VM usage (I hear this isn't hard). . Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2642
https://github.com/broadinstitute/cromwell/issues/2643:313,Availability,error,error,313,"- SGE backend; - cromwell v29. The following WDL works:; ```; # Runtime parameters; Int? mem; String gatk_docker; Int? preemptible_attempts; Int? disk_space_gb. Int final_mem=select_first([mem, 3]); ... snip....; runtime {; memory: select_first([mem, 3]) + "" GB""; ....snip....; ```. BUT the below WDL gives me an error that the + operator is not supported for optional variables, please use select_first. However, the variable final_mem is not optional:. ```; ....; # Everything is the same as the working WDL, except:; runtime {; memory: final_mem + "" GB""; ....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2643
https://github.com/broadinstitute/cromwell/issues/2643:369,Modifiability,variab,variables,369,"- SGE backend; - cromwell v29. The following WDL works:; ```; # Runtime parameters; Int? mem; String gatk_docker; Int? preemptible_attempts; Int? disk_space_gb. Int final_mem=select_first([mem, 3]); ... snip....; runtime {; memory: select_first([mem, 3]) + "" GB""; ....snip....; ```. BUT the below WDL gives me an error that the + operator is not supported for optional variables, please use select_first. However, the variable final_mem is not optional:. ```; ....; # Everything is the same as the working WDL, except:; runtime {; memory: final_mem + "" GB""; ....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2643
https://github.com/broadinstitute/cromwell/issues/2643:418,Modifiability,variab,variable,418,"- SGE backend; - cromwell v29. The following WDL works:; ```; # Runtime parameters; Int? mem; String gatk_docker; Int? preemptible_attempts; Int? disk_space_gb. Int final_mem=select_first([mem, 3]); ... snip....; runtime {; memory: select_first([mem, 3]) + "" GB""; ....snip....; ```. BUT the below WDL gives me an error that the + operator is not supported for optional variables, please use select_first. However, the variable final_mem is not optional:. ```; ....; # Everything is the same as the working WDL, except:; runtime {; memory: final_mem + "" GB""; ....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2643
https://github.com/broadinstitute/cromwell/issues/2645:56,Availability,down,down,56,"If cromwell can't bind to it's tcp port, it should shut down, not continue running in zombie mode.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2645
https://github.com/broadinstitute/cromwell/issues/2651:118,Safety,avoid,avoid,118,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool inputs` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2651
https://github.com/broadinstitute/cromwell/issues/2651:66,Security,access,access,66,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool inputs` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2651
https://github.com/broadinstitute/cromwell/issues/2651:163,Security,access,access,163,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool inputs` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2651
https://github.com/broadinstitute/cromwell/issues/2652:120,Safety,avoid,avoid,120,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool validate` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality. . This issue is a companion to #2651.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652
https://github.com/broadinstitute/cromwell/issues/2652:66,Security,access,access,66,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool validate` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality. . This issue is a companion to #2651.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652
https://github.com/broadinstitute/cromwell/issues/2652:85,Security,validat,validate,85,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool validate` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality. . This issue is a companion to #2651.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652
https://github.com/broadinstitute/cromwell/issues/2652:165,Security,access,access,165,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool validate` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality. . This issue is a companion to #2651.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652
https://github.com/broadinstitute/cromwell/pull/2653:17,Energy Efficiency,monitor,monitor,17,o Provide health monitor infrastructure to know status of underlying systems; o Provide status endpoint which will query current contents of health monitor; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2653
https://github.com/broadinstitute/cromwell/pull/2653:148,Energy Efficiency,monitor,monitor,148,o Provide health monitor infrastructure to know status of underlying systems; o Provide status endpoint which will query current contents of health monitor; o Moved some google code to a new cloudSupport project; o Moved some general docker code to core from the dockerHashing project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2653
https://github.com/broadinstitute/cromwell/pull/2654:17,Energy Efficiency,monitor,monitor,17,o Provide health monitor infrastructure to know status of underlying systems; o Provide status endpoint which will query current contents of health monitor; o Provide health monitor implementations for typical and workbench usages; o Moved some google code to a new cloudSupport project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2654
https://github.com/broadinstitute/cromwell/pull/2654:148,Energy Efficiency,monitor,monitor,148,o Provide health monitor infrastructure to know status of underlying systems; o Provide status endpoint which will query current contents of health monitor; o Provide health monitor implementations for typical and workbench usages; o Moved some google code to a new cloudSupport project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2654
https://github.com/broadinstitute/cromwell/pull/2654:174,Energy Efficiency,monitor,monitor,174,o Provide health monitor infrastructure to know status of underlying systems; o Provide status endpoint which will query current contents of health monitor; o Provide health monitor implementations for typical and workbench usages; o Moved some google code to a new cloudSupport project,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2654
https://github.com/broadinstitute/cromwell/issues/2655:14,Deployability,release,releases,14,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:900,Deployability,deploy,deployed,900,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:1021,Deployability,deploy,deploy,1021,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:53,Modifiability,variab,variable,53,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:664,Modifiability,variab,variable,664,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:728,Modifiability,variab,variable,728,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:950,Modifiability,variab,variable,950,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:959,Modifiability,config,configurable,959,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/issues/2655:465,Performance,perform,perform,465,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655
https://github.com/broadinstitute/cromwell/pull/2656:53,Availability,Error,ErrorOr,53,Most of this code is just propagating the IOFunction ErrorOr to the edges. `GlobFunctions` used some existing logic to re-create globbing function.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2656
https://github.com/broadinstitute/cromwell/pull/2656:110,Testability,log,logic,110,Most of this code is just propagating the IOFunction ErrorOr to the edges. `GlobFunctions` used some existing logic to re-create globbing function.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2656
https://github.com/broadinstitute/cromwell/issues/2658:1508,Availability,avail,available,1508,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/issues/2658:388,Integrability,depend,depending,388,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/issues/2658:1467,Modifiability,variab,variable,1467,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/issues/2658:825,Security,access,access,825,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/issues/2658:1008,Security,access,access,1008,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/issues/2658:1573,Security,secur,secure,1573,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658
https://github.com/broadinstitute/cromwell/pull/2659:99,Integrability,message,message,99,"Implements the solution suggested in #2658 . I just noticed I forgot the escape $EUID in my commit message, apologies.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2659
https://github.com/broadinstitute/cromwell/pull/2664:67,Energy Efficiency,green,green,67,I'm not actually going to wait for :+1: but will wait for it to go green. My claim will be out of safety but really it's because I'm lazy and will do it later.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2664
https://github.com/broadinstitute/cromwell/pull/2664:98,Safety,safe,safety,98,I'm not actually going to wait for :+1: but will wait for it to go green. My claim will be out of safety but really it's because I'm lazy and will do it later.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2664
https://github.com/broadinstitute/cromwell/issues/2669:45,Security,encrypt,encrypted,45,"For now treat this like refresh tokens, e.g. encrypted, deleted afterwards, etc. user provides json key via workflow options.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2669
https://github.com/broadinstitute/cromwell/issues/2671:1206,Availability,avail,available,1206,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:479,Integrability,message,message,479,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:327,Performance,load,load,327,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:857,Performance,load,load,857,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:164,Usability,simpl,simple,164,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:242,Usability,simpl,simple,242,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:272,Usability,simpl,simple,272,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:640,Usability,simpl,simple,640,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:772,Usability,simpl,simple,772,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2671:802,Usability,simpl,simple,802,"Hi there,. There is an issue posting a cromwell job, getting the id from the response, and then trying to run a GET call too soon after the initial post. Here is a simple example. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The get response was. `{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: 054f9462-3775-4745-8ca6-5a63c9c4492f""; }` . Even though the 054f9462 ID was gotten directly from the original response. The simple solution is to add a sleep statement between the post and get. `curl -v ""localhost:8000/api/workflows/v1"" -F workflowSource=@simple.wdl -F workflowInputs=@simple.json | python -c 'import json,sys,time;obj=json.load(sys.stdin);time.sleep(10);print obj[""id""];' | xargs -I {} curl ""http://localhost:8000/api/workflows/v1/{}/status""`. The response was . `{""status"":""Submitted"",""id"":""897e2f30-2e4d-4cf0-9bb3-d926ec42dc6a""}`. Is there a way to know for sure the job is ready for a GET post? Or is this a bug, and the response JSON should be returned after GETs are available?. Thanks for your time!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671
https://github.com/broadinstitute/cromwell/issues/2673:196,Availability,error,error,196,"Dear cromwell team,. We are trying to setup a test environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:5569,Availability,error,error,5569,"entos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/inputs/home/centos/storage/WDLdata/bams/mother.bam \; -o NA12878.raw.indels.snps.vcf; [2017-10-04 06:06:58,15] [info] BackgroundConfigAsyncJobExecutionActor [bf90a37bhelloHaplotypeCaller.haplotypeCaller:NA:1]: executing: /bin/bash /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/script; [2017-10-04 06:06:58,21] [info] BackgroundConfigAsyncJobExecutionActor [bf90a37bhelloHaplotypeCaller.haplotypeCaller:NA:1]: job id: 13026; [2017-10-04 06:06:58,21] [info] BackgroundConfigAsyncJobExecutionActor [bf90a37bhelloHaplotypeCaller.haplotypeCaller:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-10-04 06:07:31,28] [info] BackgroundConfigAsyncJobExecutionActor [bf90a37bhelloHaplotypeCaller.haplotypeCaller:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-10-04 06:07:31,37] [error] WorkflowManagerActor Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6634,Deployability,configurat,configuration,6634,"-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:12092,Deployability,Update,UpdateVCFSequenceDictionary,12092,"lotypeCaller ^[[31m(BETA Tool) ^[[36mCall germline SNPs and indels via local re-assembly of haplotypes^[[0m; ^[[32m IndexFeatureFile ^[[36mCreates indices for Feature-containing files (eg VCF and BED files)^[[0m; ^[[32m LiftOverVcf ^[[36mLifts a VCF between genome builds^[[0m; ^[[32m MakeSitesOnlyVcf ^[[36mCreates a VCF bereft of genotype information from an input VCF^[[0m; ^[[32m MergeVcfs ^[[36mMerges multiple VCF files into one VCF file^[[0m; ^[[32m Mutect2 ^[[31m(BETA Tool) ^[[36mCall somatic SNVs and indels via local assembly of haplotypes^[[0m; ^[[32m RemoveNearbyIndels ^[[36m(Internal) Remove indels that are close to each other from a vcf^[[0m; ^[[32m RenameSampleInVcf ^[[36mRename a sample within a VCF^[[0m; ^[[32m SelectVariants ^[[36mSelect a subset of variants from a VCF file^[[0m; ^[[32m SortVcf ^[[36mSorts one or more VCF files^[[0m; ^[[32m SplitIntervals ^[[36mSplit intervals into sub-interval files.^[[0m; ^[[32m SplitVcfs ^[[36mSplits an input VCF file into two VCF files^[[0m; ^[[32m UpdateVCFSequenceDictionary ^[[36mUpdates the sequence dictionary in a variant file.^[[0m; ^[[32m ValidateVariants ^[[36mValidate VCF^[[0m; ^[[32m VariantFiltration ^[[36mFilter variant calls based on INFO and FORMAT annotations^[[0m; ^[[32m VariantRecalibrator ^[[36mBuild a recalibration model to score variant quality for filtering purposes^[[0m; ^[[32m VariantsToTable ^[[36mExtract specific fields from a VCF file to a tab-delimited table^[[0m; ^[[32m VcfToIntervalList ^[[36mConverts a VCF file to a Picard Interval List^[[0m. ^[[37m--------------------------------------------------------------------------------------; ^[[0m; Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: '-T' is not a valid command. at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:291); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Any advise?. Thank you very much",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6347,Integrability,Message,Message,6347," WaitingForReturnCodeFile; [2017-10-04 06:07:31,28] [info] BackgroundConfigAsyncJobExecutionActor [bf90a37bhelloHaplotypeCaller.haplotypeCaller:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-10-04 06:07:31,37] [error] WorkflowManagerActor Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionBy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:899,Modifiability,config,configured,899,"Dear cromwell team,. We are trying to setup a test environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:1034,Modifiability,config,configured,1034,"est environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 [bf90a37b]: Starting ca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6634,Modifiability,config,configuration,6634,"-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:9877,Security,validat,validated,9877,,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:12190,Security,Validat,ValidateVariants,12190,"lotypeCaller ^[[31m(BETA Tool) ^[[36mCall germline SNPs and indels via local re-assembly of haplotypes^[[0m; ^[[32m IndexFeatureFile ^[[36mCreates indices for Feature-containing files (eg VCF and BED files)^[[0m; ^[[32m LiftOverVcf ^[[36mLifts a VCF between genome builds^[[0m; ^[[32m MakeSitesOnlyVcf ^[[36mCreates a VCF bereft of genotype information from an input VCF^[[0m; ^[[32m MergeVcfs ^[[36mMerges multiple VCF files into one VCF file^[[0m; ^[[32m Mutect2 ^[[31m(BETA Tool) ^[[36mCall somatic SNVs and indels via local assembly of haplotypes^[[0m; ^[[32m RemoveNearbyIndels ^[[36m(Internal) Remove indels that are close to each other from a vcf^[[0m; ^[[32m RenameSampleInVcf ^[[36mRename a sample within a VCF^[[0m; ^[[32m SelectVariants ^[[36mSelect a subset of variants from a VCF file^[[0m; ^[[32m SortVcf ^[[36mSorts one or more VCF files^[[0m; ^[[32m SplitIntervals ^[[36mSplit intervals into sub-interval files.^[[0m; ^[[32m SplitVcfs ^[[36mSplits an input VCF file into two VCF files^[[0m; ^[[32m UpdateVCFSequenceDictionary ^[[36mUpdates the sequence dictionary in a variant file.^[[0m; ^[[32m ValidateVariants ^[[36mValidate VCF^[[0m; ^[[32m VariantFiltration ^[[36mFilter variant calls based on INFO and FORMAT annotations^[[0m; ^[[32m VariantRecalibrator ^[[36mBuild a recalibration model to score variant quality for filtering purposes^[[0m; ^[[32m VariantsToTable ^[[36mExtract specific fields from a VCF file to a tab-delimited table^[[0m; ^[[32m VcfToIntervalList ^[[36mConverts a VCF file to a Picard Interval List^[[0m. ^[[37m--------------------------------------------------------------------------------------; ^[[0m; Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: '-T' is not a valid command. at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:291); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Any advise?. Thank you very much",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:46,Testability,test,test,46,"Dear cromwell team,. We are trying to setup a test environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:110,Testability,test,tested,110,"Dear cromwell team,. We are trying to setup a test environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6591,Testability,log,logging,6591,"-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6663,Testability,log,log-dead-letters,6663,"ate): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRAM file^[[0m; ^[[32m CollectQualityYieldMetricsSpark ^",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/issues/2673:6691,Testability,log,log-dead-letters-during-shutdown,6691,"haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRAM file^[[0m; ^[[32m CollectQualityYieldMetricsSpark ^[[31m(BETA Tool) ^[[36mCollectQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673
https://github.com/broadinstitute/cromwell/pull/2676:99,Testability,test,testing,99,"Opened a [Centaur ticket](https://github.com/broadinstitute/centaur/issues/234) to provide centaur testing for this, but since this won't be used in anger for a while punting for now.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2676
https://github.com/broadinstitute/cromwell/pull/2680:209,Availability,failure,failures,209,"Updates Cromwell with the latest changes from wdl4s; I was able to unignore half of the unit tests that were previously ignored, and re-enable 60 centaur tests (on local and TES).; I haven't looked at the JES failures yet, so this is not be merged until they're fixed, but I though I would make a PR a bit early as this re-wires a decent amount of stuff that was broken due to missing FQNs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680
https://github.com/broadinstitute/cromwell/pull/2680:0,Deployability,Update,Updates,0,"Updates Cromwell with the latest changes from wdl4s; I was able to unignore half of the unit tests that were previously ignored, and re-enable 60 centaur tests (on local and TES).; I haven't looked at the JES failures yet, so this is not be merged until they're fixed, but I though I would make a PR a bit early as this re-wires a decent amount of stuff that was broken due to missing FQNs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680
https://github.com/broadinstitute/cromwell/pull/2680:93,Testability,test,tests,93,"Updates Cromwell with the latest changes from wdl4s; I was able to unignore half of the unit tests that were previously ignored, and re-enable 60 centaur tests (on local and TES).; I haven't looked at the JES failures yet, so this is not be merged until they're fixed, but I though I would make a PR a bit early as this re-wires a decent amount of stuff that was broken due to missing FQNs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680
https://github.com/broadinstitute/cromwell/pull/2680:154,Testability,test,tests,154,"Updates Cromwell with the latest changes from wdl4s; I was able to unignore half of the unit tests that were previously ignored, and re-enable 60 centaur tests (on local and TES).; I haven't looked at the JES failures yet, so this is not be merged until they're fixed, but I though I would make a PR a bit early as this re-wires a decent amount of stuff that was broken due to missing FQNs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680
https://github.com/broadinstitute/cromwell/issues/2681:101,Performance,cache,cache-hit,101,"I have a workflow where one of the inputs was created by a brand-new version of a tool, but it had a cache-hit for a run from 2 months ago. I can only assume that this is because the new input file had the exact same hash as the old input file, but because the google bucket the old input file was in is gone, I have no way to confirm this. It seems like it would be fairly trivial, and extremely helpful, for this information to be contained in the call_caching_placeholder.txt, or some equivalent file when outputs are copied. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681
https://github.com/broadinstitute/cromwell/issues/2681:217,Security,hash,hash,217,"I have a workflow where one of the inputs was created by a brand-new version of a tool, but it had a cache-hit for a run from 2 months ago. I can only assume that this is because the new input file had the exact same hash as the old input file, but because the google bucket the old input file was in is gone, I have no way to confirm this. It seems like it would be fairly trivial, and extremely helpful, for this information to be contained in the call_caching_placeholder.txt, or some equivalent file when outputs are copied. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681
https://github.com/broadinstitute/cromwell/issues/2692:246,Availability,error,error,246,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:789,Availability,echo,echo,789,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:1770,Availability,error,error,1770,"""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/br",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:2446,Availability,echo,echo,2446,"e output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to be working! Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:2460,Availability,echo,echo,2460,"e output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to be working! Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:3125,Availability,error,error,3125,"e output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to be working! Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:252,Integrability,message,message,252,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:1776,Integrability,message,message,1776,"""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/br",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:323,Modifiability,Variab,VariableNotFoundException,323,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:350,Modifiability,Variab,Variable,350,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:2359,Modifiability,variab,variable,2359,"then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:2947,Modifiability,variab,variable,2947,"e output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to be working! Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2692:3179,Performance,load,load,3179,"e output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095284). I think `Pair`s are declared with parenthesis and not brackets. Does . ```; output {; Pair[File, Array[File]] p = (unmapped_bam, fastqs); }; ```. work ?. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261096132). Also, as long as you don't declared the zip as a workflow variable you should be fine. For example, this should work:. ```; task t {; command {; echo ""hello""; echo ""world""; }; output {; Array[String] o = read_lines(stdout()); }; }. task t2 {; Array[Pair[String, String]] p; command {; #do something; }; output {; Array[Pair[String, String]] o = p; }; }. workflow w {; call t; call t as u; call t2 { input: zip(t.o, u.o) }; }; ```. ---. @meganshand commented on [Thu Nov 17 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261247751). Pair with ( ) worked perfectly with the workaround tasks. I tried to not declare a workflow variable, but since I need to scatter over the zipped array I did the following:. `scatter(unmapped_pair in zip(QuerySortSam.sorted_bam, SamToFastq.fastqs)){`. Which gave me the error:. `Workflow input processing failed.; Unable to load namespace from workflow: Unrecognized token on line 282, column 55:`. Regardless, for my current use case I'm happy with my workaround, and using Pair seems to be working! Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692
https://github.com/broadinstitute/cromwell/issues/2693:667,Deployability,patch,patches,667,"@antonkulaga commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86). If there will be ScalaJS support, then it will be possible to do things like validation of wdl4s directly in the browser. ---. @geoffjentry commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86#issuecomment-280335418). that's an interesting point. My take is that I have nothing against doing it, for me personally it'd likely involve flipping the switch and if it Just Works great and if not (IIRC scala.js isn't 100% source compatible?) I'm not going to go much further. . I mean this in a non-snarky way but this is really going to be in a ""patches welcome"" territory as I doubt it'll be officially prioritized and while I just added it to my ""it'd be a good thing to do"" mental todo list it's not the top item and I don't pop things off that list as frequently as I'd prefer.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2693
https://github.com/broadinstitute/cromwell/issues/2693:173,Security,validat,validation,173,"@antonkulaga commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86). If there will be ScalaJS support, then it will be possible to do things like validation of wdl4s directly in the browser. ---. @geoffjentry commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86#issuecomment-280335418). that's an interesting point. My take is that I have nothing against doing it, for me personally it'd likely involve flipping the switch and if it Just Works great and if not (IIRC scala.js isn't 100% source compatible?) I'm not going to go much further. . I mean this in a non-snarky way but this is really going to be in a ""patches welcome"" territory as I doubt it'll be officially prioritized and while I just added it to my ""it'd be a good thing to do"" mental todo list it's not the top item and I don't pop things off that list as frequently as I'd prefer.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2693
https://github.com/broadinstitute/cromwell/issues/2694:2546,Availability,down,down,2546,"er (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:2956,Availability,down,down,2956,"17](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diab",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:3024,Availability,down,down,3024,"27). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:3251,Availability,down,down,3251,"mponent-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is ge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:571,Deployability,pipeline,pipelines,571,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:4247,Energy Efficiency,efficient,efficient,4247,"w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is getting our own development of this as efficient as possible, not supporting users trying to make use of it. ---. @cjllanwarne commented on [Wed Oct 11 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-335851314). Resolved in person but will be done in the new composite cromwell repo. ---. @katevoss commented on [Wed Oct 11 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-335852862). This PR will be in Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:2528,Performance,perform,performance,2528,"er (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:2930,Performance,perform,performance,2930,"17](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diab",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:3233,Performance,perform,performance,3233,"mponent-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is ge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:180,Security,hash,hashCode,180,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:523,Security,hash,hashCode,523,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:590,Security,hash,hashCode,590,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1609,Security,hash,hashCode,1609,"led for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1696,Security,hash,hashCode,1696,"ally with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as w",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1713,Security,hash,hashCode,1713," for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1735,Security,hash,hashCode,1735,"n branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the fi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1817,Security,hash,hashCode,1817,"t 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli comment",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1834,Security,hash,hashCode,1834,"/github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1852,Security,hash,hashCode,1852,"tute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1878,Security,hash,hashCode,1878,"ecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2694:1119,Testability,test,test,1119," GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694
https://github.com/broadinstitute/cromwell/issues/2695:2546,Availability,down,down,2546,"er (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:2956,Availability,down,down,2956,"17](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diab",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:3024,Availability,down,down,3024,"27). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:3251,Availability,down,down,3251,"mponent-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is ge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:571,Deployability,pipeline,pipelines,571,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:4247,Energy Efficiency,efficient,efficient,4247,"w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is getting our own development of this as efficient as possible, not supporting users trying to make use of it. ---. @cjllanwarne commented on [Wed Oct 11 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-335851314). Resolved in person but will be done in the new composite cromwell repo. ---. @katevoss commented on [Wed Oct 11 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-335852862). This PR will be in Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:2528,Performance,perform,performance,2528,"er (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:2930,Performance,perform,performance,2930,"17](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diab",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:3233,Performance,perform,performance,3233,"mponent-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577609). The performance issues aren't down the road. When I try to build a WOM; graph right now, it slows down after the first 100 nodes and never finishes. On Thu, Oct 5, 2017 at 4:01 PM, Dan Billings <notifications@github.com>; wrote:. > I suggest we leave this as-is with the understanding that it could be a; > performance issue down the road.; >; > rework the whole thing later; > This is a specific anti-goal.; >; > As I suggested, I would like to discuss w/ Chris when he gets back next; > week as we introduced the reference equality in the first place and I'm not; > aware of his motivation to do so.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aJnzYP8ru5JvHrjbR5jwKwO9Brncks5spTV8gaJpZM4PttJd>; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>. ---. @geoffjentry commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334577969). +1 on waiting for chris. @curoli- at the moment our priority is ge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:180,Security,hash,hashCode,180,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:523,Security,hash,hashCode,523,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:590,Security,hash,hashCode,590,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1609,Security,hash,hashCode,1609,"led for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1696,Security,hash,hashCode,1696,"ally with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as w",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1713,Security,hash,hashCode,1713," for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1735,Security,hash,hashCode,1735,"n branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the fi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1817,Security,hash,hashCode,1817,"t 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli comment",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1834,Security,hash,hashCode,1834,"/github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1852,Security,hash,hashCode,1852,"tute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1878,Security,hash,hashCode,1878,"ecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2695:1119,Testability,test,test,1119," GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2695
https://github.com/broadinstitute/cromwell/issues/2696:137,Testability,test,test,137,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[a]`; - `{""a"": glob(""globFile.txt""}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2696
https://github.com/broadinstitute/cromwell/issues/2696:207,Testability,test,test,207,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[a]`; - `{""a"": glob(""globFile.txt""}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2696
https://github.com/broadinstitute/cromwell/issues/2697:137,Testability,test,test,137,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[a]`; - `{""a"": glob(""globFile.txt""}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2697
https://github.com/broadinstitute/cromwell/issues/2697:207,Testability,test,test,207,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[a]`; - `{""a"": glob(""globFile.txt""}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2697
https://github.com/broadinstitute/cromwell/issues/2698:137,Testability,test,test,137,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[""a""]`; - `{""a"": glob(""globFile.txt"")}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698
https://github.com/broadinstitute/cromwell/issues/2698:207,Testability,test,test,207,"@kshakir commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90). The `FileEvaluatorSpec` contains a number of test expressions to search for files-to-localize. This includes a new test for [indexing a glob](https://github.com/broadinstitute/cromwell/issues/1980), i.e. `glob(""*.txt"")[0]`. Ideally, the following additions to the above spec would all generate the correct list of files to delocalize:. - `glob(""globFile.txt"")[read_int(""intFile.txt"")]`; - ~~`{""a"": glob(""globFile.txt"")}`~~ Works; - `{""a"": glob(""globFile.txt"")}[""a""]`; - `{""a"": glob(""globFile.txt"")}[read_string(""aFile.txt"")]`. Currently, either the above fail to parse in `WdlExpression.parseString`, -or- the returned AST doesn't contain the information required for the `FileEvaluator` to retrieve the file names. EDIT: Fixed typos above. ---. @cjllanwarne commented on [Fri Feb 24 2017](https://github.com/broadinstitute/wdl4s/issues/90#issuecomment-282393959). The most surprising of these are 2 and 3, but those also contain typos, I think they should be:; ```; {""a"": glob(""globFile.txt"")}; {""a"": glob(""globFile.txt"")}[""a""]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698
https://github.com/broadinstitute/cromwell/issues/2699:144,Availability,error,error,144,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/92). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; workflow undeclared_scatter_variable {; scatter (i in undeclared) {}; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2699
https://github.com/broadinstitute/cromwell/issues/2699:168,Availability,error,error,168,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/92). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; workflow undeclared_scatter_variable {; scatter (i in undeclared) {}; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2699
https://github.com/broadinstitute/cromwell/issues/2699:359,Deployability,patch,patches,359,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/92). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; workflow undeclared_scatter_variable {; scatter (i in undeclared) {}; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2699
https://github.com/broadinstitute/cromwell/issues/2699:406,Deployability,update,updated,406,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/92). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; workflow undeclared_scatter_variable {; scatter (i in undeclared) {}; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2699
https://github.com/broadinstitute/cromwell/issues/2699:388,Testability,test,test,388,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/92). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; workflow undeclared_scatter_variable {; scatter (i in undeclared) {}; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2699
https://github.com/broadinstitute/cromwell/issues/2700:144,Availability,error,error,144,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2700:168,Availability,error,error,168,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2700:223,Availability,echo,echo,223,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2700:657,Deployability,patch,patches,657,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2700:704,Deployability,update,updated,704,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2700:686,Testability,test,test,686,"@kshakir commented on [Mon Feb 27 2017](https://github.com/broadinstitute/wdl4s/issues/93). The following wdl currently parses in wdl4s without error, later causing an error within cromwell. ```; task x {; Int i; command { echo $i }; runtime { docker: ""ubuntu"" }; output {; Int out_but_intentionally_misnamed = i; Boolean validOutput = i % 2 == 0; }; }. workflow missing_optional_output {; Array[Int] arr = [0,1,2,3]; scatter (i in arr) {; call x { input: i = i }; if (x.validOutput) {; Int x_out = x.out_except_undeclared; }; }. Array[Int?] x_out_maybes = x_out; }; ```. See https://github.com/broadinstitute/cromwell/issues/2020 for more info of cromwell patches, including a centaur test, that may be updated or removed if this is fixed in wdl4s.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700
https://github.com/broadinstitute/cromwell/issues/2701:992,Availability,error,error,992,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2701:1654,Modifiability,enhance,enhancement,1654,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2701:99,Performance,load,loading,99,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2701:154,Performance,load,load,154,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2701:1097,Performance,load,load,1097,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2701:1406,Performance,load,loading,1406,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701
https://github.com/broadinstitute/cromwell/issues/2703:178,Availability,error,error,178,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703
https://github.com/broadinstitute/cromwell/issues/2703:1093,Energy Efficiency,adapt,adapted,1093,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703
https://github.com/broadinstitute/cromwell/issues/2703:1093,Modifiability,adapt,adapted,1093,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703
https://github.com/broadinstitute/cromwell/issues/2703:301,Security,validat,validate,301,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703
https://github.com/broadinstitute/cromwell/issues/2703:364,Security,validat,validate,364,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703
https://github.com/broadinstitute/cromwell/issues/2712:1354,Integrability,depend,depends,1354,"@mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156). It appears that some relatively recent changes have greatly extended compile times into multiple minutes, probably due to Circe decoding and encoding. Investigate and see if there's anything that can be done to lessen the pain. ---. @geoffjentry commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094471). @mcovarr ""anything that can be done"". Remove Circe autoencoding? :). On a serious note, wdl4s still needs to be bumped up to 2.12.3 which should help a bit. In fact I'll do that now. ---. @mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094942). We tried 2.12.3 locally and whatever improvement there was didn't rock our worlds. ---. @kshakir commented on [Wed Sep 13 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-329144787). Some things to also try:. [![Generic Derivation: The Hard Parts—Travis Brown](http://img.youtube.com/vi/80h3hZidSeE/0.jpg)](https://youtu.be/80h3hZidSeE?t=34m7s ""Generic Derivation: The Hard Parts—Travis Brown""). ---. @danbills commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-330304677). I propose we move everything JSON-related into a subproject that depends on the object model. . This would allow rapid development and testing of CWL -> WOM. . Json stuff is pretty small and contained so it wouldn't be too spaghetti-y.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2712
https://github.com/broadinstitute/cromwell/issues/2712:153,Modifiability,extend,extended,153,"@mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156). It appears that some relatively recent changes have greatly extended compile times into multiple minutes, probably due to Circe decoding and encoding. Investigate and see if there's anything that can be done to lessen the pain. ---. @geoffjentry commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094471). @mcovarr ""anything that can be done"". Remove Circe autoencoding? :). On a serious note, wdl4s still needs to be bumped up to 2.12.3 which should help a bit. In fact I'll do that now. ---. @mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094942). We tried 2.12.3 locally and whatever improvement there was didn't rock our worlds. ---. @kshakir commented on [Wed Sep 13 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-329144787). Some things to also try:. [![Generic Derivation: The Hard Parts—Travis Brown](http://img.youtube.com/vi/80h3hZidSeE/0.jpg)](https://youtu.be/80h3hZidSeE?t=34m7s ""Generic Derivation: The Hard Parts—Travis Brown""). ---. @danbills commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-330304677). I propose we move everything JSON-related into a subproject that depends on the object model. . This would allow rapid development and testing of CWL -> WOM. . Json stuff is pretty small and contained so it wouldn't be too spaghetti-y.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2712
https://github.com/broadinstitute/cromwell/issues/2712:1424,Testability,test,testing,1424,"@mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156). It appears that some relatively recent changes have greatly extended compile times into multiple minutes, probably due to Circe decoding and encoding. Investigate and see if there's anything that can be done to lessen the pain. ---. @geoffjentry commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094471). @mcovarr ""anything that can be done"". Remove Circe autoencoding? :). On a serious note, wdl4s still needs to be bumped up to 2.12.3 which should help a bit. In fact I'll do that now. ---. @mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094942). We tried 2.12.3 locally and whatever improvement there was didn't rock our worlds. ---. @kshakir commented on [Wed Sep 13 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-329144787). Some things to also try:. [![Generic Derivation: The Hard Parts—Travis Brown](http://img.youtube.com/vi/80h3hZidSeE/0.jpg)](https://youtu.be/80h3hZidSeE?t=34m7s ""Generic Derivation: The Hard Parts—Travis Brown""). ---. @danbills commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-330304677). I propose we move everything JSON-related into a subproject that depends on the object model. . This would allow rapid development and testing of CWL -> WOM. . Json stuff is pretty small and contained so it wouldn't be too spaghetti-y.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2712
https://github.com/broadinstitute/cromwell/issues/2713:242,Security,validat,validation,242,"@ruchim commented on [Fri Aug 11 2017](https://github.com/broadinstitute/wdl4s/issues/168). The wdl docs say that when using the true/false syntax in the command block, one can get away with declaring just one of the 2, however the WDL fails validation and fails to create a namespace and therefore never gets run. . AC:; Actually allow being able to declare True or False and statements OR Keep enforcing that both the behavior for true/false need to be defined, and adjust that expectation in the docs accordingly. https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#true-and-false",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2713
https://github.com/broadinstitute/cromwell/issues/2715:104,Availability,avail,available,104,@danbills commented on [Thu Aug 17 2017](https://github.com/broadinstitute/wdl4s/issues/177). Once it's available it would be nice to have scaladocs published for CWL as they are for WDL,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2715
https://github.com/broadinstitute/cromwell/issues/2717:363,Deployability,configurat,configuration,363,@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/195). WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2717
https://github.com/broadinstitute/cromwell/issues/2717:320,Integrability,depend,depending,320,@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/195). WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2717
https://github.com/broadinstitute/cromwell/issues/2717:363,Modifiability,config,configuration,363,@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/195). WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2717
https://github.com/broadinstitute/cromwell/issues/2724:663,Availability,error,error,663,"@cjllanwarne commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/217). EG this can be converted from WDL to WOM:; ```; import ""import_me.wdl"" as import_me. workflow outer {; ; Array[Int] xs; scatter (x in xs) {; 	Boolean b; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. But if we move the `b` outside the scatter:; ```; import ""import_me.wdl"" as import_me. workflow outer {; Boolean b; Array[Int] xs; scatter (x in xs) {; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. Then we get an error:; ```; Exception in thread ""main"" java.lang.Exception: Can't build WOM executable from WDL namespace:; No input b found evaluating inputs for expression b; key not found: b; ```. ---. @Horneth commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-330214878). This has implications in Cromwell. Namely if `b` was a Call instead of being a boolean, and `import_me.inner` depended on an output of `b`, when we evaluate the inputs of `import_me.inner` it will make a difference whether or not `b` is a sibling of `import_me.inner`. If it is we want to get the output with the same shard number from the output store, otherwise the output with no index (if we rule out nested scatters). We could simplify and say ""always look for the same index and if it's not there take the output with no index"" but it would be better to know for sure which one we need. ---. @mcovarr commented on [Fri Sep 22 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-331568932). Sorry if this is a dumb question, but do you understand what's going wrong here? It's obvious looking at this statically what `b` is supposed to be whether it's inside or outside the scatter. Also it seems a little weird to me that `b` can even be a `GraphInputNode` inside the scatter...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2724
https://github.com/broadinstitute/cromwell/issues/2724:1079,Integrability,depend,depended,1079,"@cjllanwarne commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/217). EG this can be converted from WDL to WOM:; ```; import ""import_me.wdl"" as import_me. workflow outer {; ; Array[Int] xs; scatter (x in xs) {; 	Boolean b; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. But if we move the `b` outside the scatter:; ```; import ""import_me.wdl"" as import_me. workflow outer {; Boolean b; Array[Int] xs; scatter (x in xs) {; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. Then we get an error:; ```; Exception in thread ""main"" java.lang.Exception: Can't build WOM executable from WDL namespace:; No input b found evaluating inputs for expression b; key not found: b; ```. ---. @Horneth commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-330214878). This has implications in Cromwell. Namely if `b` was a Call instead of being a boolean, and `import_me.inner` depended on an output of `b`, when we evaluate the inputs of `import_me.inner` it will make a difference whether or not `b` is a sibling of `import_me.inner`. If it is we want to get the output with the same shard number from the output store, otherwise the output with no index (if we rule out nested scatters). We could simplify and say ""always look for the same index and if it's not there take the output with no index"" but it would be better to know for sure which one we need. ---. @mcovarr commented on [Fri Sep 22 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-331568932). Sorry if this is a dumb question, but do you understand what's going wrong here? It's obvious looking at this statically what `b` is supposed to be whether it's inside or outside the scatter. Also it seems a little weird to me that `b` can even be a `GraphInputNode` inside the scatter...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2724
https://github.com/broadinstitute/cromwell/issues/2724:1401,Usability,simpl,simplify,1401,"@cjllanwarne commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/217). EG this can be converted from WDL to WOM:; ```; import ""import_me.wdl"" as import_me. workflow outer {; ; Array[Int] xs; scatter (x in xs) {; 	Boolean b; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. But if we move the `b` outside the scatter:; ```; import ""import_me.wdl"" as import_me. workflow outer {; Boolean b; Array[Int] xs; scatter (x in xs) {; if (b) {; call import_me.inner as inner { input: i = x }; }; }; output {; Array[String?] outer_out = inner.out; }; }; ```. Then we get an error:; ```; Exception in thread ""main"" java.lang.Exception: Can't build WOM executable from WDL namespace:; No input b found evaluating inputs for expression b; key not found: b; ```. ---. @Horneth commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-330214878). This has implications in Cromwell. Namely if `b` was a Call instead of being a boolean, and `import_me.inner` depended on an output of `b`, when we evaluate the inputs of `import_me.inner` it will make a difference whether or not `b` is a sibling of `import_me.inner`. If it is we want to get the output with the same shard number from the output store, otherwise the output with no index (if we rule out nested scatters). We could simplify and say ""always look for the same index and if it's not there take the output with no index"" but it would be better to know for sure which one we need. ---. @mcovarr commented on [Fri Sep 22 2017](https://github.com/broadinstitute/wdl4s/issues/217#issuecomment-331568932). Sorry if this is a dumb question, but do you understand what's going wrong here? It's obvious looking at this statically what `b` is supposed to be whether it's inside or outside the scatter. Also it seems a little weird to me that `b` can even be a `GraphInputNode` inside the scatter...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2724
https://github.com/broadinstitute/cromwell/issues/2725:316,Deployability,update,updates,316,"@danbills commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/216). We have existing tests (in ExportCwlSamplesSpec) that are testing output as previously implemented, yet library collisions forced us to remove that capability. If and when [circe-yaml](https://github.com/circe/circe-yaml) updates their cats dependency we could use that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2725
https://github.com/broadinstitute/cromwell/issues/2725:335,Integrability,depend,dependency,335,"@danbills commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/216). We have existing tests (in ExportCwlSamplesSpec) that are testing output as previously implemented, yet library collisions forced us to remove that capability. If and when [circe-yaml](https://github.com/circe/circe-yaml) updates their cats dependency we could use that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2725
https://github.com/broadinstitute/cromwell/issues/2725:111,Testability,test,tests,111,"@danbills commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/216). We have existing tests (in ExportCwlSamplesSpec) that are testing output as previously implemented, yet library collisions forced us to remove that capability. If and when [circe-yaml](https://github.com/circe/circe-yaml) updates their cats dependency we could use that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2725
https://github.com/broadinstitute/cromwell/issues/2725:152,Testability,test,testing,152,"@danbills commented on [Fri Sep 15 2017](https://github.com/broadinstitute/wdl4s/issues/216). We have existing tests (in ExportCwlSamplesSpec) that are testing output as previously implemented, yet library collisions forced us to remove that capability. If and when [circe-yaml](https://github.com/circe/circe-yaml) updates their cats dependency we could use that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2725
https://github.com/broadinstitute/cromwell/issues/2726:149,Availability,avail,available,149,@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/204). CWL has a lot of meta information that is currently not available in WOM.; This could be part of a larger work and include re-work of WDL runtime attributes but those bits need to make it to Cromwell somehow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2726
https://github.com/broadinstitute/cromwell/issues/2728:644,Deployability,update,update,644,"@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/202). The CWL parser currently hardcode the same name for all workflows.; Find out if CWL has a way to specify a workflow name. If not use a hash ? A new endpoint parameter ?; @katevoss this could use PO input if it turns out CWL has no way to specify a workflow name. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894259). So it turns out that CWL v1.0.2 has an `id` field for Workflow, and cwltool gives us one for free:. http://www.commonwl.org/v1.0/Workflow.html#Workflow. so we should update the model to have a required `id: String` and this problem goes away. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894392). This also applies to `CommandLineTool`, cwltool pre-processing gives us one.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2728
https://github.com/broadinstitute/cromwell/issues/2728:228,Security,hash,hash,228,"@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/202). The CWL parser currently hardcode the same name for all workflows.; Find out if CWL has a way to specify a workflow name. If not use a hash ? A new endpoint parameter ?; @katevoss this could use PO input if it turns out CWL has no way to specify a workflow name. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894259). So it turns out that CWL v1.0.2 has an `id` field for Workflow, and cwltool gives us one for free:. http://www.commonwl.org/v1.0/Workflow.html#Workflow. so we should update the model to have a required `id: String` and this problem goes away. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894392). This also applies to `CommandLineTool`, cwltool pre-processing gives us one.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2728
https://github.com/broadinstitute/cromwell/issues/2733:124,Integrability,message,message,124,"Lenthall and wdl4s have been folded into the main Cromwell repo so the Lenthall and wdl4s repos should be deprecated. Add a message to the Readme, make it impossible for users to make new issues/PR's, etc. As a **user looking at the wdl4s or Lenthall repos**, I want **it to be obvious that they are deprecated, and to have useful information about where to find the artifacts within Cromwell**, so that **I am not tempted to develop against the deprecated repos**. - Effort: Small; - Risk: Small to Medium; - We'll have to keep an eye on the repos for a little while to make sure all interested parties got the message; - Business value: Small to Medium; - Having clear communication to users is important!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2733
https://github.com/broadinstitute/cromwell/issues/2733:612,Integrability,message,message,612,"Lenthall and wdl4s have been folded into the main Cromwell repo so the Lenthall and wdl4s repos should be deprecated. Add a message to the Readme, make it impossible for users to make new issues/PR's, etc. As a **user looking at the wdl4s or Lenthall repos**, I want **it to be obvious that they are deprecated, and to have useful information about where to find the artifacts within Cromwell**, so that **I am not tempted to develop against the deprecated repos**. - Effort: Small; - Risk: Small to Medium; - We'll have to keep an eye on the repos for a little while to make sure all interested parties got the message; - Business value: Small to Medium; - Having clear communication to users is important!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2733
https://github.com/broadinstitute/cromwell/issues/2733:485,Safety,Risk,Risk,485,"Lenthall and wdl4s have been folded into the main Cromwell repo so the Lenthall and wdl4s repos should be deprecated. Add a message to the Readme, make it impossible for users to make new issues/PR's, etc. As a **user looking at the wdl4s or Lenthall repos**, I want **it to be obvious that they are deprecated, and to have useful information about where to find the artifacts within Cromwell**, so that **I am not tempted to develop against the deprecated repos**. - Effort: Small; - Risk: Small to Medium; - We'll have to keep an eye on the repos for a little while to make sure all interested parties got the message; - Business value: Small to Medium; - Having clear communication to users is important!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2733
https://github.com/broadinstitute/cromwell/issues/2733:665,Usability,clear,clear,665,"Lenthall and wdl4s have been folded into the main Cromwell repo so the Lenthall and wdl4s repos should be deprecated. Add a message to the Readme, make it impossible for users to make new issues/PR's, etc. As a **user looking at the wdl4s or Lenthall repos**, I want **it to be obvious that they are deprecated, and to have useful information about where to find the artifacts within Cromwell**, so that **I am not tempted to develop against the deprecated repos**. - Effort: Small; - Risk: Small to Medium; - We'll have to keep an eye on the repos for a little while to make sure all interested parties got the message; - Business value: Small to Medium; - Having clear communication to users is important!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2733
https://github.com/broadinstitute/cromwell/pull/2734:17,Availability,failure,failures,17,"* disabled build failures due to deprecation warnings... it's a hotfix, deadend branch!; * support public http-based imports in cromwell; * fixed a few necessary classes due to newer cats being pulled in",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2734
https://github.com/broadinstitute/cromwell/pull/2734:64,Deployability,hotfix,hotfix,64,"* disabled build failures due to deprecation warnings... it's a hotfix, deadend branch!; * support public http-based imports in cromwell; * fixed a few necessary classes due to newer cats being pulled in",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2734
https://github.com/broadinstitute/cromwell/issues/2735:259,Availability,failure,failure,259,"It is very common to provide folders as inputs to different bioinformatic tools. For instance, STAR index is usually computed once per reference genome and then provided to each STAR-based RNA-Seq task as an input. However, when this is done a common caching failure is reported (because it is a folder):; ```; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Is a directory""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2735
https://github.com/broadinstitute/cromwell/issues/2735:351,Integrability,message,message,351,"It is very common to provide folders as inputs to different bioinformatic tools. For instance, STAR index is usually computed once per reference genome and then provided to each STAR-based RNA-Seq task as an input. However, when this is done a common caching failure is reported (because it is a folder):; ```; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Is a directory""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2735
https://github.com/broadinstitute/cromwell/issues/2735:312,Security,hash,hashFailures,312,"It is very common to provide folders as inputs to different bioinformatic tools. For instance, STAR index is usually computed once per reference genome and then provided to each STAR-based RNA-Seq task as an input. However, when this is done a common caching failure is reported (because it is a folder):; ```; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Is a directory""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2735
https://github.com/broadinstitute/cromwell/issues/2736:834,Availability,error,error,834,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2736:1009,Availability,error,error,1009,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2736:1043,Modifiability,config,configurable,1043,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2736:173,Performance,perform,perform,173,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2736:316,Performance,perform,performance,316,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2736:557,Performance,perform,performance,557,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736
https://github.com/broadinstitute/cromwell/issues/2738:267,Modifiability,variab,variable,267,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10272/workflow-function-sub-is-too-impatient-needs-to-wait-until-inputs-are-ready). They would like Cromwell to wait until after a task has run to try to resolve a workflow-level variable. Their specific use case is calling the `sub()` function inside the workflow, like so:. ```; workflow myWF {; call taskA; String myString = sub(taskA.out, ""_"", """"); }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2738
https://github.com/broadinstitute/cromwell/issues/2739:94,Availability,error,error-messages-should-include-the-problematic-input-whenever-possible-disk-strings,94,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:201,Availability,error,error,201,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:382,Availability,error,error,382,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:624,Availability,error,error,624,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:771,Availability,error,error,771,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:100,Integrability,message,messages-should-include-the-problematic-input-whenever-possible-disk-strings,100,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:207,Integrability,message,message,207,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:388,Integrability,message,message,388,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:630,Integrability,message,message,630,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2739:777,Integrability,message,message,777,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10273/error-messages-should-include-the-problematic-input-whenever-possible-disk-strings). This user ran into an error message which stated he had an improperly formatted disk string, but with no further information on how to find out which disk string was incorrect. It would be better if the error message specifically referenced which disk string was improperly formatted, either through a line number, or by showing the specific incorrect disk string referenced. In addition, his improper formatting was `local-disk 0 HDD`, but the error message stated that the format must be `local-disk SIZE TYPE`. If you could add that `SIZE` must be a non-zero value, that would improve the error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2739
https://github.com/broadinstitute/cromwell/issues/2740:104,Availability,error,error-message-when-task-fails-to-complete,104,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:182,Availability,error,error,182,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:366,Availability,error,error,366,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:423,Availability,failure,failure,423,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:509,Availability,failure,failure,509,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:110,Integrability,message,message-when-task-fails-to-complete,110,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:372,Integrability,message,message,372,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/issues/2740:386,Usability,clear,clearer,386,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10319/incorrect-error-message-when-task-fails-to-complete). . When a script fails to run, the error that is eventually returned is that Cromwell failed to delocalize the output file, due to the fact that the file is missing because the script failed to run. They would like the error message to be clearer as to the true reason of the failure, that it is due to an invalid return code from the script and (secondarily) a failure to delocalize the missing file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2740
https://github.com/broadinstitute/cromwell/pull/2741:98,Deployability,Update,Update,98,"Switching GraphNode.{equals, hashCode} from component-based to reference (object identity)-based. Update two unit tests to reflect the change.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2741
https://github.com/broadinstitute/cromwell/pull/2741:29,Security,hash,hashCode,29,"Switching GraphNode.{equals, hashCode} from component-based to reference (object identity)-based. Update two unit tests to reflect the change.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2741
https://github.com/broadinstitute/cromwell/pull/2741:114,Testability,test,tests,114,"Switching GraphNode.{equals, hashCode} from component-based to reference (object identity)-based. Update two unit tests to reflect the change.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2741
https://github.com/broadinstitute/cromwell/issues/2743:764,Availability,down,downloaded,764,"[unpredictable_time_example.json.txt](https://github.com/broadinstitute/cromwell/files/1380844/unpredictable_time_example.json.txt). In the attached metadata json file from a recent run (extension mangled with txt because github complains about json uploads) I'm seeing unpredictable datetime strings which, as a result, are difficult to parse. . 1. `2017-10-04T21:47:18.661720750Z` (the norm); 2. `2017-10-04T14:49:56.008-07:00` (`-07:00` suffix is also very common); 3. `2017-10-04T21:54Z` (`calls: count.align_reads_split: executionEvents: ""waiting for quota""). It doesn't seem to be restricted to start or end times. This metadata file was obtained from the swagger REST metadata endpoint from a local version of cromwell 29. I verified it in browser and also downloaded it directly from the endpoint with requests. request: `http://localhost:6361/api/workflows/v1/74e00c0a-ffb8-4e1a-94db-b0169ca7ed42/metadata`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2743
https://github.com/broadinstitute/cromwell/issues/2744:634,Availability,error,error,634,"For the following task ; ```; task star_index {. File genomeDir; File genomeFasta; Int threads; Int binBits; Int max_memory = 100000000000. command {; /usr/local/bin/STAR \; --runThreadN ${threads} \; --runMode genomeGenerate \; --genomeDir ${genomeDir} \; --genomeFastaFiles ${genomeFasta} \; --genomeChrBinNbits ${binBits} \; --limitGenomeGenerateRAM=${max_memory}; }. runtime {; docker: ""quay.io/biocontainers/star@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; File out = genomeDir; }. }; ```; I get ; ```; ""Unable to load namespace from workflow: For input string: \""100000000000\""""; ```; error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2744
https://github.com/broadinstitute/cromwell/issues/2744:562,Performance,load,load,562,"For the following task ; ```; task star_index {. File genomeDir; File genomeFasta; Int threads; Int binBits; Int max_memory = 100000000000. command {; /usr/local/bin/STAR \; --runThreadN ${threads} \; --runMode genomeGenerate \; --genomeDir ${genomeDir} \; --genomeFastaFiles ${genomeFasta} \; --genomeChrBinNbits ${binBits} \; --limitGenomeGenerateRAM=${max_memory}; }. runtime {; docker: ""quay.io/biocontainers/star@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b""; }. output {; File out = genomeDir; }. }; ```; I get ; ```; ""Unable to load namespace from workflow: For input string: \""100000000000\""""; ```; error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2744
https://github.com/broadinstitute/cromwell/pull/2745:191,Testability,test,tests,191,* Introduced `WorkflowStepInputExpression`.; * Standardized FullyQualifiedName to handle the separate cases in a more coherent way.; * Introduced `CwlExpressionCommandPart`. I've not written tests for these new expression as I was focused on getting 3step running. I am open to testing suggestions but request that we merge first and I pick that up when I'm back from vaca.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2745
https://github.com/broadinstitute/cromwell/pull/2745:278,Testability,test,testing,278,* Introduced `WorkflowStepInputExpression`.; * Standardized FullyQualifiedName to handle the separate cases in a more coherent way.; * Introduced `CwlExpressionCommandPart`. I've not written tests for these new expression as I was focused on getting 3step running. I am open to testing suggestions but request that we merge first and I pick that up when I'm back from vaca.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2745
https://github.com/broadinstitute/cromwell/pull/2749:93,Testability,test,test,93,"* if you happen to have a 3step.wdl[options or inputs] in your local working directory, this test fails because it expects NOT to find them there. This isn't so crazy since (a) 3step is real workflow name and (b) people might (as I did) run it to test out cromwell from their local working directory",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2749
https://github.com/broadinstitute/cromwell/pull/2749:247,Testability,test,test,247,"* if you happen to have a 3step.wdl[options or inputs] in your local working directory, this test fails because it expects NOT to find them there. This isn't so crazy since (a) 3step is real workflow name and (b) people might (as I did) run it to test out cromwell from their local working directory",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2749
https://github.com/broadinstitute/cromwell/issues/2753:821,Availability,echo,echo,821,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:890,Availability,error,errors,890,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:926,Integrability,message,message,926,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:992,Integrability,message,message,992,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:1063,Integrability,message,message,1063,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:1124,Integrability,message,message,1124,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/issues/2753:1179,Integrability,message,message,1179,"The following workflow and subworkflow wdls do not work in cromwell v29 hot fix (3be5b8c0537ef051dece9fbad63a154b72ad510d): . ```; import ""subworkflow.wdl"" as sub. workflow wf {; 	Array[Float] arr = [1.0,2.0,3.0]. 	call sub.subwf {; 		input:; 			input_array = arr; 	}; }; ```. ```; workflow subwf {; 	Array[Float] input_array. 	call SumFloats {; 		input:; 			sizes = input_array,; 			preemptible_tries = 0; 	}. 	String size = if SumFloats.total_size < 2.0 then ""Small"" else ""Big"". 	call print {; 		input: ; 			s = size; 	}; }. task SumFloats {; 	Array[Float] sizes; 	Int preemptible_tries. 	command <<<; 	python -c ""print ${sep=""+"" sizes}""; 	>>>; 	output {; 		Float total_size = read_float(stdout()); 	}; 	runtime {; 		docker: ""python:2.7""; 		preemptible: preemptible_tries; 	}; }. task print {; 	String s. 	command {; 		echo ${s}; 	}. 	runtime {; 		docker: ""python:2.7""; 	}; }; ```. I get errors such as the following:. ```; message: ""Could not find size in input section of call wf.subwf""; message: ""Could not find SumFloats in input section of call wf.subwf""; message: ""No declaration named SumFloats for call wf.subwf""; message: ""Input evaluation for Call wf.subwf failed.""; message: ""Couldn't resolve all inputs for wf.subwf at index None.""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753
https://github.com/broadinstitute/cromwell/pull/2754:183,Usability,simpl,simple,183,This gargantuosity pries apart WOM and WDL into separate packages. There's a lot of mechanical renaming stuff here but also some substantive changes required to actually separate the simple value-containing WOM stuff from actual WDL knowledge. This split isn't perfect yet but it's hopefully a step in the right direction. There will be a second PR that actually renames `WdlThing` to `WomThing` since that's going to be pure mechanical noise.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2754
https://github.com/broadinstitute/cromwell/pull/2755:234,Deployability,patch,patching,234,"This is the PR I threatened in #2754 that just renames all the `WdlStuff` to `WomStuff`. This shouldn't need a real review. This was 100% IDE driven except for fixing the aftereffects of what appears to have been an IDE bug, and also patching one goofy test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755
https://github.com/broadinstitute/cromwell/pull/2755:17,Security,threat,threatened,17,"This is the PR I threatened in #2754 that just renames all the `WdlStuff` to `WomStuff`. This shouldn't need a real review. This was 100% IDE driven except for fixing the aftereffects of what appears to have been an IDE bug, and also patching one goofy test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755
https://github.com/broadinstitute/cromwell/pull/2755:253,Testability,test,test,253,"This is the PR I threatened in #2754 that just renames all the `WdlStuff` to `WomStuff`. This shouldn't need a real review. This was 100% IDE driven except for fixing the aftereffects of what appears to have been an IDE bug, and also patching one goofy test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755
https://github.com/broadinstitute/cromwell/issues/2756:344,Availability,echo,echo,344,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:474,Availability,error,error,474,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:539,Availability,ERROR,ERROR,539,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:735,Availability,echo,echo,735,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:1417,Availability,error,error,1417,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:480,Integrability,message,messages,480,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:1423,Integrability,message,message,1423,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:430,Security,validat,validate,430,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:498,Security,validat,validate,498,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:884,Security,validat,validates,884,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2756:151,Usability,simpl,simple,151,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756
https://github.com/broadinstitute/cromwell/issues/2766:92,Security,authoriz,authorization,92,Currently the endpoints not off of `/api` (e.g. `/engine/Segment/version`) still require an authorization header. This should not be the case. These endpoints should be fully public.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2766
https://github.com/broadinstitute/cromwell/issues/2768:304,Availability,error,error,304,"Currently, this is set to default to 128000. This is too small for most practical use, especially given that gs URLs can get quite long. Can the new limit be much higher? We'll need 5GB (no joke!) for some our larger analyses. Or at least a workflow option to temporarily override?. Otherwise, we get an error such as:; ```""Workflow has invalid declarations: Could not evaluate workflow declarations:\nSingleSampleGenotyping.gvcfs_list:\n\tUse of WdlSingleFile(gs://broad-dsde-methods/gauthier/Finnish_FE_WGS.1000samples.gvcf_list) failed because the file was too big (174730 bytes when only files of up to 128000 bytes are permissible""```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768
https://github.com/broadinstitute/cromwell/issues/2773:118,Modifiability,config,configuring,118,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773
https://github.com/broadinstitute/cromwell/issues/2773:247,Safety,risk,risks,247,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773
https://github.com/broadinstitute/cromwell/issues/2773:275,Safety,Risk,Risk,275,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773
https://github.com/broadinstitute/cromwell/issues/2773:238,Security,secur,security,238,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773
https://github.com/broadinstitute/cromwell/issues/2774:521,Availability,error,error,521,"This may be a known issue, in which case feel free to link this to that. If not... I ran a workflow on the DSDE-Methods server, which is running on P.API, and it failed when a file didn't exist. I was running a CNV pipeline to create a Panel of Normals, and a few of the bams (and their bai's) in the list did not exist. From @LeeTL1220: Cromwell can't localize a file because the file does not exist. As a result, instead of saying it, it does not create workflow root directory, doesn't make any usable log files.; The error message is just the name of the file, rather than to say that this file is missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774
https://github.com/broadinstitute/cromwell/issues/2774:215,Deployability,pipeline,pipeline,215,"This may be a known issue, in which case feel free to link this to that. If not... I ran a workflow on the DSDE-Methods server, which is running on P.API, and it failed when a file didn't exist. I was running a CNV pipeline to create a Panel of Normals, and a few of the bams (and their bai's) in the list did not exist. From @LeeTL1220: Cromwell can't localize a file because the file does not exist. As a result, instead of saying it, it does not create workflow root directory, doesn't make any usable log files.; The error message is just the name of the file, rather than to say that this file is missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774
https://github.com/broadinstitute/cromwell/issues/2774:527,Integrability,message,message,527,"This may be a known issue, in which case feel free to link this to that. If not... I ran a workflow on the DSDE-Methods server, which is running on P.API, and it failed when a file didn't exist. I was running a CNV pipeline to create a Panel of Normals, and a few of the bams (and their bai's) in the list did not exist. From @LeeTL1220: Cromwell can't localize a file because the file does not exist. As a result, instead of saying it, it does not create workflow root directory, doesn't make any usable log files.; The error message is just the name of the file, rather than to say that this file is missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774
https://github.com/broadinstitute/cromwell/issues/2774:505,Testability,log,log,505,"This may be a known issue, in which case feel free to link this to that. If not... I ran a workflow on the DSDE-Methods server, which is running on P.API, and it failed when a file didn't exist. I was running a CNV pipeline to create a Panel of Normals, and a few of the bams (and their bai's) in the list did not exist. From @LeeTL1220: Cromwell can't localize a file because the file does not exist. As a result, instead of saying it, it does not create workflow root directory, doesn't make any usable log files.; The error message is just the name of the file, rather than to say that this file is missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774
https://github.com/broadinstitute/cromwell/issues/2774:498,Usability,usab,usable,498,"This may be a known issue, in which case feel free to link this to that. If not... I ran a workflow on the DSDE-Methods server, which is running on P.API, and it failed when a file didn't exist. I was running a CNV pipeline to create a Panel of Normals, and a few of the bams (and their bai's) in the list did not exist. From @LeeTL1220: Cromwell can't localize a file because the file does not exist. As a result, instead of saying it, it does not create workflow root directory, doesn't make any usable log files.; The error message is just the name of the file, rather than to say that this file is missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774
https://github.com/broadinstitute/cromwell/pull/2777:137,Modifiability,plugin,plugin,137,"I'm throwing in some nice-to-haves here:. * deleted unused ""mungeId"" artifact before FullyQualifiedName was born; * added ""sbt-pack"" SBT plugin which makes nice run scripts and doesn't assemble fat jar (slow)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2777
https://github.com/broadinstitute/cromwell/pull/2778:137,Modifiability,plugin,plugin,137,"I'm throwing in some nice-to-haves here:. * deleted unused ""mungeId"" artifact before FullyQualifiedName was born; * added ""sbt-pack"" SBT plugin which makes nice run scripts and doesn't assemble fat jar (slow)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2778
https://github.com/broadinstitute/cromwell/issues/2787:99,Availability,failure,failure,99,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:264,Availability,error,error,264,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:360,Availability,failure,failure,360,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:422,Availability,failure,failure,422,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:653,Availability,failure,failure,653,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:115,Performance,cache,cache,115,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:211,Performance,cache,cache,211,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:438,Performance,cache,cache,438,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:587,Performance,cache,cache,587,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:669,Performance,cache,cache,669,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2787:766,Performance,cache,cache,766,"For instance, someone used ""docker.io/<their image>"" path in their runtime block and this led to a failure to call cache since call caching doesn't support docker.io urls. . Right now, since this failed to call cache it reran the job, however this was due to user error and they assumed caching would work. Additionally, there are cases such as when there's a failure to communicate with dockerhub that would also lead to failure to call cache. This request is for a workflow option that worked in conjunction with read_from_cache that set this behavior more strictly - if there is call cache miss, then run a new job, but if there is any other type of failure to call cache (transient, bad url, etc) then fail the job for the reason that the user requested to call cache and call caching failed to determine caching correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2787
https://github.com/broadinstitute/cromwell/issues/2788:594,Availability,error,error,594,"Figure out how it is possible that travis can not compile the build but returns 0. Incident report:; [travis build](https://travis-ci.org/broadinstitute/cromwell/jobs/292596774); [raw log, excerpted below](https://s3.amazonaws.com/archive.travis-ci.org/jobs/292596774/log.txt?X-Amz-Expires=30&X-Amz-Date=20171025T234339Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20171025/us-east-1/s3/aws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=71b729c64e9fbce0fb7e520c77d2d3da8876b62e8e4f5f87b5084f594b439ee0). When compiling 2.11 `cwl` package, compilation reported an error, yet still returned 0:; ```; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/issues/2788:1683,Availability,error,errors,1683,"e/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mdoc[0m) Scaladoc generation failed[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mcompileIncremental[0m) Compilation failed[0m; [0m[[31merror[0m] [0mTotal time: 273 s, completed Oct 25, 2017 1:03:49 PM[0m. restoring stty: 500:5:bf:8a3b:3:1c:7f:15:4:0:1:0:11:13:1a:0:12:f:17:16:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0. travis_time:end:1f45f95e:start=1508935437087656153,finish=1508936629752201761,duration=1192664545608; [0Ktravis_fold:end:after_success; [0K[33;1mSkipping a deployment with the script provider because this is not a tagged commit[0m. Done. Your bu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/issues/2788:2057,Availability,error,errors,2057,"/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mdoc[0m) Scaladoc generation failed[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mcompileIncremental[0m) Compilation failed[0m; [0m[[31merror[0m] [0mTotal time: 273 s, completed Oct 25, 2017 1:03:49 PM[0m. restoring stty: 500:5:bf:8a3b:3:1c:7f:15:4:0:1:0:11:13:1a:0:12:f:17:16:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0. travis_time:end:1f45f95e:start=1508935437087656153,finish=1508936629752201761,duration=1192664545608; [0Ktravis_fold:end:after_success; [0K[33;1mSkipping a deployment with the script provider because this is not a tagged commit[0m. Done. Your build exited with 0.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/issues/2788:2596,Deployability,deploy,deployment,2596,"/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mdoc[0m) Scaladoc generation failed[0m; [0m[[31merror[0m] [0m(cwl/compile:[31mcompileIncremental[0m) Compilation failed[0m; [0m[[31merror[0m] [0mTotal time: 273 s, completed Oct 25, 2017 1:03:49 PM[0m. restoring stty: 500:5:bf:8a3b:3:1c:7f:15:4:0:1:0:11:13:1a:0:12:f:17:16:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0. travis_time:end:1f45f95e:start=1508935437087656153,finish=1508936629752201761,duration=1192664545608; [0Ktravis_fold:end:after_success; [0K[33;1mSkipping a deployment with the script provider because this is not a tagged commit[0m. Done. Your build exited with 0.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/issues/2788:184,Testability,log,log,184,"Figure out how it is possible that travis can not compile the build but returns 0. Incident report:; [travis build](https://travis-ci.org/broadinstitute/cromwell/jobs/292596774); [raw log, excerpted below](https://s3.amazonaws.com/archive.travis-ci.org/jobs/292596774/log.txt?X-Amz-Expires=30&X-Amz-Date=20171025T234339Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20171025/us-east-1/s3/aws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=71b729c64e9fbce0fb7e520c77d2d3da8876b62e8e4f5f87b5084f594b439ee0). When compiling 2.11 `cwl` package, compilation reported an error, yet still returned 0:; ```; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/issues/2788:268,Testability,log,log,268,"Figure out how it is possible that travis can not compile the build but returns 0. Incident report:; [travis build](https://travis-ci.org/broadinstitute/cromwell/jobs/292596774); [raw log, excerpted below](https://s3.amazonaws.com/archive.travis-ci.org/jobs/292596774/log.txt?X-Amz-Expires=30&X-Amz-Date=20171025T234339Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20171025/us-east-1/s3/aws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=71b729c64e9fbce0fb7e520c77d2d3da8876b62e8e4f5f87b5084f594b439ee0). When compiling 2.11 `cwl` package, compilation reported an error, yet still returned 0:; ```; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/CommandLineTool.scala:45: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(taskDefinition.validNelCheck, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[[31merror[0m] [0m ^[0m; [0m[[31merror[0m] [0mtwo errors found[0m; [0m[[31merror[0m] [0m/home/travis/build/broadinstitute/cromwell/cwl/src/main/scala/cwl/Workflow.scala:30: value buildWomExecutable is not a member of object cwl.CwlExecutableValidation[0m; [0m[[31merror[0m] [0m CwlExecutableValidation.buildWomExecutable(womDefinition, inputFile)[0m; [0m[",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788
https://github.com/broadinstitute/cromwell/pull/2789:126,Deployability,rolling,rolling,126,"This addresses two issues:. * Some issue w/ Liquibase, SBT 1.0, and metadata table XOR command. Not sure what is going on but rolling back fixed it.; * Typo in scala-2.11 was breaking compile, Travis did not seem to mind so #2788",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2789
https://github.com/broadinstitute/cromwell/issues/2791:1,Availability,failure,failures,1,"""failures"": [{""causedBy"": [{""causedBy"": [],""message"": ""the local copy message must have path set.""}],""message"": ""Unable to complete JES Api Request""}]. See workflow metadata at: https://cromwell-v29.dsde-methods.broadinstitute.org/api/workflows/v1/4ff9cb8a-cade-482a-8492-66ea3b7a2eaa/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791
https://github.com/broadinstitute/cromwell/issues/2791:44,Integrability,message,message,44,"""failures"": [{""causedBy"": [{""causedBy"": [],""message"": ""the local copy message must have path set.""}],""message"": ""Unable to complete JES Api Request""}]. See workflow metadata at: https://cromwell-v29.dsde-methods.broadinstitute.org/api/workflows/v1/4ff9cb8a-cade-482a-8492-66ea3b7a2eaa/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791
https://github.com/broadinstitute/cromwell/issues/2791:70,Integrability,message,message,70,"""failures"": [{""causedBy"": [{""causedBy"": [],""message"": ""the local copy message must have path set.""}],""message"": ""Unable to complete JES Api Request""}]. See workflow metadata at: https://cromwell-v29.dsde-methods.broadinstitute.org/api/workflows/v1/4ff9cb8a-cade-482a-8492-66ea3b7a2eaa/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791
https://github.com/broadinstitute/cromwell/issues/2791:102,Integrability,message,message,102,"""failures"": [{""causedBy"": [{""causedBy"": [],""message"": ""the local copy message must have path set.""}],""message"": ""Unable to complete JES Api Request""}]. See workflow metadata at: https://cromwell-v29.dsde-methods.broadinstitute.org/api/workflows/v1/4ff9cb8a-cade-482a-8492-66ea3b7a2eaa/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791
https://github.com/broadinstitute/cromwell/pull/2793:336,Availability,Error,ErrorOr,336,"This PR is a lot less scary than it looks. Most of the changed lines spring from two changes (and the changes are actually make everything a lot simpler!):. - `TaskDefinition` is split into two: `CallableTaskDefinition` which can be called, and `ExecutableTaskDefinition` which can be executed.; - `Callable` now doesn't have a `graph: ErrorOr[Graph]`. Instead the new, more specific `ExecutableCallable` has a `graph: Graph` method.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2793
https://github.com/broadinstitute/cromwell/pull/2793:145,Usability,simpl,simpler,145,"This PR is a lot less scary than it looks. Most of the changed lines spring from two changes (and the changes are actually make everything a lot simpler!):. - `TaskDefinition` is split into two: `CallableTaskDefinition` which can be called, and `ExecutableTaskDefinition` which can be executed.; - `Callable` now doesn't have a `graph: ErrorOr[Graph]`. Instead the new, more specific `ExecutableCallable` has a `graph: Graph` method.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2793
https://github.com/broadinstitute/cromwell/issues/2796:53,Modifiability,variab,variable,53,"Whether using `-DLOG_MODE=pretty`, or an environment variable, one should be able to force the mode pretty or standard. When working correctly the pretty should output ansi colors, and standard won't.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2796
https://github.com/broadinstitute/cromwell/pull/2802:973,Availability,echo,echo,973,"Still looking at a Centaur test for this but I thought I'd let the seafowl have at it. Metadata looks like:. ```; {; ""workflowName"": ""three_step"",; ""submittedFiles"": {; ""workflow"": ""import \""3step-tasks.wdl\"" as tasks\nimport \""https://raw.githubusercontent.com/broadinstitute/centaur/591beaf8422af7c3faf51e437a91d94d13b76eba/src/main/resources/standardTestCases/aliased_subworkflows/subworkflow.wdl\"" as subworkflow\n\n\nworkflow three_step {\n call tasks.ps as ps\n call tasks.cgrep as cgrep {\n input: in_file = ps.procs\n }\n call tasks.wc as wc {\n input: in_file = ps.procs\n }\n output {\n cgrep.*\n wc.*\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n\n}"",; ""inputs"": ""{\""three_step.cgrep.pattern\"":\""mcovarr\""}"",; ""labels"": ""{}"",; ""imports"": {; ""https://raw.githubusercontent.com/broadinstitute/centaur/591beaf8422af7c3faf51e437a91d94d13b76eba/src/main/resources/standardTestCases/aliased_subworkflows/subworkflow.wdl"": ""task increment {\n Int i\n command {\n echo $(( ${i} + 1 ))\n }\n output {\n Int j = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\nworkflow subwf {\n Array[Int] is\n scatter (i in is) {\n call increment { input: i = i }\n }\n output {\n Array[Int] js = increment.j\n }\n}\n"",; ""3step-tasks.wdl"": ""task ps {\n command {\n ps\n }\n output {\n File procs = stdout()\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\ntask cgrep {\n String pattern\n File in_file\n command {\n grep '${pattern}' ${in_file} | wc -l\n }\n output {\n Int count = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\ntask wc {\n File in_file\n command {\n cat ${in_file} | wc -l\n }\n output {\n Int count = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\n""; }; },; .; .; .; ```. So the http imports come in under ""submittedFiles"" which is maybe a little weird. But other options would have http imports either not being next to the file imports and/or having to change the metadata schema.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2802
https://github.com/broadinstitute/cromwell/pull/2802:27,Testability,test,test,27,"Still looking at a Centaur test for this but I thought I'd let the seafowl have at it. Metadata looks like:. ```; {; ""workflowName"": ""three_step"",; ""submittedFiles"": {; ""workflow"": ""import \""3step-tasks.wdl\"" as tasks\nimport \""https://raw.githubusercontent.com/broadinstitute/centaur/591beaf8422af7c3faf51e437a91d94d13b76eba/src/main/resources/standardTestCases/aliased_subworkflows/subworkflow.wdl\"" as subworkflow\n\n\nworkflow three_step {\n call tasks.ps as ps\n call tasks.cgrep as cgrep {\n input: in_file = ps.procs\n }\n call tasks.wc as wc {\n input: in_file = ps.procs\n }\n output {\n cgrep.*\n wc.*\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n\n}"",; ""inputs"": ""{\""three_step.cgrep.pattern\"":\""mcovarr\""}"",; ""labels"": ""{}"",; ""imports"": {; ""https://raw.githubusercontent.com/broadinstitute/centaur/591beaf8422af7c3faf51e437a91d94d13b76eba/src/main/resources/standardTestCases/aliased_subworkflows/subworkflow.wdl"": ""task increment {\n Int i\n command {\n echo $(( ${i} + 1 ))\n }\n output {\n Int j = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\nworkflow subwf {\n Array[Int] is\n scatter (i in is) {\n call increment { input: i = i }\n }\n output {\n Array[Int] js = increment.j\n }\n}\n"",; ""3step-tasks.wdl"": ""task ps {\n command {\n ps\n }\n output {\n File procs = stdout()\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\ntask cgrep {\n String pattern\n File in_file\n command {\n grep '${pattern}' ${in_file} | wc -l\n }\n output {\n Int count = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\ntask wc {\n File in_file\n command {\n cat ${in_file} | wc -l\n }\n output {\n Int count = read_int(stdout())\n }\n runtime {\n docker: \""ubuntu:latest\""\n }\n}\n\n""; }; },; .; .; .; ```. So the http imports come in under ""submittedFiles"" which is maybe a little weird. But other options would have http imports either not being next to the file imports and/or having to change the metadata schema.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2802
https://github.com/broadinstitute/cromwell/pull/2803:107,Availability,echo,echo,107,"Reinstates the ability to run at least the `simple_if` WDL from centaur:; ```wdl; task runMe {; command {; echo ""done""; }; output {; String s = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow simple_if {; if (true) {; call runMe as runMeTrue; }. if (false) {; call runMe as runMeFalse; }. output {; runMeTrue.s; runMeFalse.s; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2803
https://github.com/broadinstitute/cromwell/issues/2804:73,Availability,error,error,73,"In `CwlCodecs.decodeCwl` , our entry point for parsing CWL, we have poor error messaging. Currently if `Cwl` types fail to parse, the only output is a single `CNil` as it fails to parse either a `Workflow` or a `CommandLineTool` (the inhabitants of the coproduct type `Cwl`). I think we should parse the two types manually (ie. `decode[Workflow]` and `decode[CommandLineTool]`) and think of a nice way to report that neither one was successful. It'd be a nice bonus to figure out which one ""got farther"" before it failed so that it may be more relevant to the caller.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2804
https://github.com/broadinstitute/cromwell/pull/2807:1697,Availability,error,error,1697,"This is a port of the original pull [request](https://github.com/broadinstitute/wdl4s/pull/256) to the Cromwell tree. I hope this was done correctly, while addressing the review comments. Thanks for pointing out how to use `Try` and `should equal` in the testing framework. There are two outstanding comments, which I am answering here, since I am assuming you want to dismantle the old wdl4s git repository. . 1) TypeEvaluator.scala; *Q: Isn't the caller perhaps trying to ascertain if the expression actually can be coerced to the declared type?* ; A: That could be added as an assert. . 2) WdlSubworkflowWomSpec.scala; *Q: The magic conversion of a single Thing to an Array[Thing] was a feature someone explicitly asked for way back when. I never liked this feature but I'm sure there's WDL out there that expects this to work.*; A: I can see why a user might want that. A side effect is that Array[T] can automatically be coerced to Array[Array[T]]. I ran into a case where Array[String] was coerced into Array[Array[File]]. For example, the workflow below executes under Cromwell v0.29, involving the coercion of `Array[Int]` to `Array[Array[Int?]]`.; ; ```; # Trying out file copy operations; task Num {; Array[Array[Int?]] numbers; command {; }; output {; Array[Array[Int?]] result = numbers; }; }. workflow w {; Array[Int] primes = [2, 3, 5, 7, 11]; call Num { input: numbers = primes }; output {; Num.result; }; }; ```. This raises two issues in my mind: ; 1) There are many ways to convert a single dimensional array into a two dimensional array. Which one does the WDL language specify? ; 2) A user can mistakenly pass an incorrectly typed argument to a task without getting a compiler error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807
https://github.com/broadinstitute/cromwell/pull/2807:255,Testability,test,testing,255,"This is a port of the original pull [request](https://github.com/broadinstitute/wdl4s/pull/256) to the Cromwell tree. I hope this was done correctly, while addressing the review comments. Thanks for pointing out how to use `Try` and `should equal` in the testing framework. There are two outstanding comments, which I am answering here, since I am assuming you want to dismantle the old wdl4s git repository. . 1) TypeEvaluator.scala; *Q: Isn't the caller perhaps trying to ascertain if the expression actually can be coerced to the declared type?* ; A: That could be added as an assert. . 2) WdlSubworkflowWomSpec.scala; *Q: The magic conversion of a single Thing to an Array[Thing] was a feature someone explicitly asked for way back when. I never liked this feature but I'm sure there's WDL out there that expects this to work.*; A: I can see why a user might want that. A side effect is that Array[T] can automatically be coerced to Array[Array[T]]. I ran into a case where Array[String] was coerced into Array[Array[File]]. For example, the workflow below executes under Cromwell v0.29, involving the coercion of `Array[Int]` to `Array[Array[Int?]]`.; ; ```; # Trying out file copy operations; task Num {; Array[Array[Int?]] numbers; command {; }; output {; Array[Array[Int?]] result = numbers; }; }. workflow w {; Array[Int] primes = [2, 3, 5, 7, 11]; call Num { input: numbers = primes }; output {; Num.result; }; }; ```. This raises two issues in my mind: ; 1) There are many ways to convert a single dimensional array into a two dimensional array. Which one does the WDL language specify? ; 2) A user can mistakenly pass an incorrectly typed argument to a task without getting a compiler error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807
https://github.com/broadinstitute/cromwell/pull/2807:580,Testability,assert,assert,580,"This is a port of the original pull [request](https://github.com/broadinstitute/wdl4s/pull/256) to the Cromwell tree. I hope this was done correctly, while addressing the review comments. Thanks for pointing out how to use `Try` and `should equal` in the testing framework. There are two outstanding comments, which I am answering here, since I am assuming you want to dismantle the old wdl4s git repository. . 1) TypeEvaluator.scala; *Q: Isn't the caller perhaps trying to ascertain if the expression actually can be coerced to the declared type?* ; A: That could be added as an assert. . 2) WdlSubworkflowWomSpec.scala; *Q: The magic conversion of a single Thing to an Array[Thing] was a feature someone explicitly asked for way back when. I never liked this feature but I'm sure there's WDL out there that expects this to work.*; A: I can see why a user might want that. A side effect is that Array[T] can automatically be coerced to Array[Array[T]]. I ran into a case where Array[String] was coerced into Array[Array[File]]. For example, the workflow below executes under Cromwell v0.29, involving the coercion of `Array[Int]` to `Array[Array[Int?]]`.; ; ```; # Trying out file copy operations; task Num {; Array[Array[Int?]] numbers; command {; }; output {; Array[Array[Int?]] result = numbers; }; }. workflow w {; Array[Int] primes = [2, 3, 5, 7, 11]; call Num { input: numbers = primes }; output {; Num.result; }; }; ```. This raises two issues in my mind: ; 1) There are many ways to convert a single dimensional array into a two dimensional array. Which one does the WDL language specify? ; 2) A user can mistakenly pass an incorrectly typed argument to a task without getting a compiler error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807
https://github.com/broadinstitute/cromwell/pull/2810:777,Availability,down,down,777,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810
https://github.com/broadinstitute/cromwell/pull/2810:742,Integrability,depend,dependency,742,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810
https://github.com/broadinstitute/cromwell/pull/2810:122,Modifiability,variab,variable,122,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810
https://github.com/broadinstitute/cromwell/pull/2810:720,Modifiability,config,config,720,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810
https://github.com/broadinstitute/cromwell/pull/2810:560,Usability,clear,clear,560,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810
https://github.com/broadinstitute/cromwell/issues/2813:127,Availability,error,error,127,"In the `AsyncBackendJobExecutionActor`, the `isTransient` method is defined as `!isFatal(throwable)` which means any non fatal error will trigger infinite retries which is not great.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2813
https://github.com/broadinstitute/cromwell/issues/2816:215,Performance,race condition,race condition,215,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2816:118,Safety,timeout,timeout,118,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2816:161,Security,hash,hash,161,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2816:4,Testability,test,test,4,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2816:92,Testability,test,test,92,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2816:102,Testability,assert,asserts,102,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816
https://github.com/broadinstitute/cromwell/issues/2817:125,Modifiability,config,config,125,"The CWL expression evaluation needs to know minimum settings for cpu cores, memory size, etc. These should be specified in a config and passed in to the implementation. Currently they are hardcoded.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2817
https://github.com/broadinstitute/cromwell/pull/2819:147,Safety,abort,abort-on-terminate,147,"…nate is true. It doesn't matter in run mode since it apparently uses an in-memory workflow store, but in the unlikely case in which someone sets `abort-on-terminate` to `true` in server mode, we want to set the status of all running jobs in the workflow store to `Aborting` so that when we restart the server we don't keep running those jobs. It also fixes a bug which was preventing run mode to exit properly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2819
https://github.com/broadinstitute/cromwell/pull/2819:265,Safety,Abort,Aborting,265,"…nate is true. It doesn't matter in run mode since it apparently uses an in-memory workflow store, but in the unlikely case in which someone sets `abort-on-terminate` to `true` in server mode, we want to set the status of all running jobs in the workflow store to `Aborting` so that when we restart the server we don't keep running those jobs. It also fixes a bug which was preventing run mode to exit properly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2819
https://github.com/broadinstitute/cromwell/issues/2820:177,Integrability,message,message,177,"There's some flakiness in the abort tests right now, I believe the reason is we tend to abort too quickly when a workflow is being restarted (for example if we receive an abort message during materialization, we'll assume that it's fine to stop without going further, which is not the case if the workflow is being restarted as jobs might be running and need to be reconnected to)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820
https://github.com/broadinstitute/cromwell/issues/2820:30,Safety,abort,abort,30,"There's some flakiness in the abort tests right now, I believe the reason is we tend to abort too quickly when a workflow is being restarted (for example if we receive an abort message during materialization, we'll assume that it's fine to stop without going further, which is not the case if the workflow is being restarted as jobs might be running and need to be reconnected to)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820
https://github.com/broadinstitute/cromwell/issues/2820:88,Safety,abort,abort,88,"There's some flakiness in the abort tests right now, I believe the reason is we tend to abort too quickly when a workflow is being restarted (for example if we receive an abort message during materialization, we'll assume that it's fine to stop without going further, which is not the case if the workflow is being restarted as jobs might be running and need to be reconnected to)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820
https://github.com/broadinstitute/cromwell/issues/2820:171,Safety,abort,abort,171,"There's some flakiness in the abort tests right now, I believe the reason is we tend to abort too quickly when a workflow is being restarted (for example if we receive an abort message during materialization, we'll assume that it's fine to stop without going further, which is not the case if the workflow is being restarted as jobs might be running and need to be reconnected to)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820
https://github.com/broadinstitute/cromwell/issues/2820:36,Testability,test,tests,36,"There's some flakiness in the abort tests right now, I believe the reason is we tend to abort too quickly when a workflow is being restarted (for example if we receive an abort message during materialization, we'll assume that it's fine to stop without going further, which is not the case if the workflow is being restarted as jobs might be running and need to be reconnected to)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820
https://github.com/broadinstitute/cromwell/pull/2821:106,Deployability,update,update,106,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:304,Deployability,update,updates,304,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:495,Deployability,hotfix,hotfix,495,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:468,Integrability,depend,dependency,468,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:883,Integrability,inject,injected,883,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:15,Performance,concurren,concurrent,15,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:195,Safety,avoid,avoid,195,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:883,Security,inject,injected,883,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:608,Testability,test,test,608,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:671,Testability,test,test,671,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:759,Testability,Test,TestActorSystem,759,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:791,Testability,test,test,791,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/pull/2821:389,Usability,simpl,simplified,389,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821
https://github.com/broadinstitute/cromwell/issues/2823:215,Availability,error,error,215,"Observed in a run from Firecloud: an input File was specified as a string ""gs://....."" where a stray space was carelessly inserted into the name. Three days later (don't ask) when the workflow got to its end, a JES error was thrown on failure to localize the file. I believe we should check for valid file names at the outset of a workflow, and that would include looking for an illegal space character.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2823
https://github.com/broadinstitute/cromwell/issues/2823:235,Availability,failure,failure,235,"Observed in a run from Firecloud: an input File was specified as a string ""gs://....."" where a stray space was carelessly inserted into the name. Three days later (don't ask) when the workflow got to its end, a JES error was thrown on failure to localize the file. I believe we should check for valid file names at the outset of a workflow, and that would include looking for an illegal space character.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2823
https://github.com/broadinstitute/cromwell/issues/2824:31,Modifiability,config,configure,31,It will be great to be able to configure Access-Control-Allow-Origin * for cromwell to be able to call it via AJAX,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824
https://github.com/broadinstitute/cromwell/issues/2824:41,Security,Access,Access-Control-Allow-Origin,41,It will be great to be able to configure Access-Control-Allow-Origin * for cromwell to be able to call it via AJAX,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824
https://github.com/broadinstitute/cromwell/pull/2825:367,Availability,down,download,367,"Currently, there is no library function to flatten an array of array of files (`Array[Array[File]]`). A scatter, where each task call produces an array of files, is a natural way of ending up with such a structure. In order to flatten this array, you can write a task that takes the it as an argument, and manipulate it with python code. However, this task will also download all the files, taking significant time and disk space. To work around this, you can coerce the files into strings (their paths), and manipulate the paths. . You can see an example [here](https://github.com/HumanCellAtlas/skylab/blob/master/10x/count/count.wdl#L195). The `chunk_reads_join` task flattens the `fastq_chunks` file array, which is coerced into an `Array[Array[String]]`. In order to avoid this circuitous implementation, this pull requests implements a generic flatten operation for ragged array types.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2825
https://github.com/broadinstitute/cromwell/pull/2825:772,Safety,avoid,avoid,772,"Currently, there is no library function to flatten an array of array of files (`Array[Array[File]]`). A scatter, where each task call produces an array of files, is a natural way of ending up with such a structure. In order to flatten this array, you can write a task that takes the it as an argument, and manipulate it with python code. However, this task will also download all the files, taking significant time and disk space. To work around this, you can coerce the files into strings (their paths), and manipulate the paths. . You can see an example [here](https://github.com/HumanCellAtlas/skylab/blob/master/10x/count/count.wdl#L195). The `chunk_reads_join` task flattens the `fastq_chunks` file array, which is coerced into an `Array[Array[String]]`. In order to avoid this circuitous implementation, this pull requests implements a generic flatten operation for ragged array types.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2825
https://github.com/broadinstitute/cromwell/issues/2826:151,Availability,avail,available,151,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:542,Availability,avail,available,542,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:865,Availability,avail,available,865,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5238,Integrability,mediaT,mediaType,5238,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5321,Integrability,mediaT,mediaType,5321,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5505,Integrability,mediaT,mediaType,5505,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:2222,Modifiability,config,config,2222," 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""container\"":\""be8ce157bc5ce90906f21220f2fd1442baa95c7284eead432626d6f1b4ac182e\"",\""container_config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/sh\"",\""-c\"",\""#(nop) \"",\""CMD [\\\""/bin/bash\\\""]\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""created\"":\""2017-08-07T23:50:27.564116691Z\"",\""docker_version\"":\""17.03.1-ce\"",\""id\"":\""0a8d1e311b7797cd62611f599600a2e4633e4a7d1df9c1119141bd99c4842beb\"",\""os\"":\""linux\"",\""parent\"":\""63",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5308,Modifiability,config,config,5308,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5489,Modifiability,layers,layers,5489,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:29,Security,hash,hashing,29,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:146,Security,hash,hash,146,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:828,Security,hash,hash,828,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:932,Security,hash,hashes,932,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:1093,Security,hash,hash,1093," `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be9062961015212",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:1771,Security,XSS,XSS-Protection,1771,"ely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""S",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:2465,Security,Expose,ExposedPorts,2465," 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""container\"":\""be8ce157bc5ce90906f21220f2fd1442baa95c7284eead432626d6f1b4ac182e\"",\""container_config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/sh\"",\""-c\"",\""#(nop) \"",\""CMD [\\\""/bin/bash\\\""]\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""created\"":\""2017-08-07T23:50:27.564116691Z\"",\""docker_version\"":\""17.03.1-ce\"",\""id\"":\""0a8d1e311b7797cd62611f599600a2e4633e4a7d1df9c1119141bd99c4842beb\"",\""os\"":\""linux\"",\""parent\"":\""63",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:3194,Security,Expose,ExposedPorts,3194," 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""container\"":\""be8ce157bc5ce90906f21220f2fd1442baa95c7284eead432626d6f1b4ac182e\"",\""container_config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/sh\"",\""-c\"",\""#(nop) \"",\""CMD [\\\""/bin/bash\\\""]\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""created\"":\""2017-08-07T23:50:27.564116691Z\"",\""docker_version\"":\""17.03.1-ce\"",\""id\"":\""0a8d1e311b7797cd62611f599600a2e4633e4a7d1df9c1119141bd99c4842beb\"",\""os\"":\""linux\"",\""parent\"":\""63",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/issues/2826:5099,Security,XSS,XSS-Protection,5099,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826
https://github.com/broadinstitute/cromwell/pull/2828:189,Availability,down,down,189,"CWL was treating output glob strings as if they were filenames, and thus was not returning the filename that Cromwell expects, namely `glob-${md5(fileName)}.list`. The implementation boils down to `OutputEvaluator` trying to detect whether the output of the expression is a glob. If it is _is_ a glob, it changes the output to be the filename as listed above.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2828
https://github.com/broadinstitute/cromwell/pull/2828:225,Safety,detect,detect,225,"CWL was treating output glob strings as if they were filenames, and thus was not returning the filename that Cromwell expects, namely `glob-${md5(fileName)}.list`. The implementation boils down to `OutputEvaluator` trying to detect whether the output of the expression is a glob. If it is _is_ a glob, it changes the output to be the filename as listed above.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2828
https://github.com/broadinstitute/cromwell/pull/2829:326,Deployability,update,update,326,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2829:63,Safety,abort,abort,63,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2829:201,Safety,Abort,Aborted,201,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2829:312,Safety,abort,abort,312,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2829:438,Safety,abort,aborted,438,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2829:500,Safety,abort,abort,500,"In situations where a workflow is being restarted, receives an abort command but is only at materialization stage or initialization stage we currently assume it's ok to stop right here and declare it `Aborted`. This assumption is wrong as jobs are probably running and we need to re-connect to them so we can 1) abort them 2) update their status.; In the same vein, if a workflow is in the workflow store waiting to be restarted and gets aborted, we need to still pick it up and reconnect to jobs to abort them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829
https://github.com/broadinstitute/cromwell/pull/2830:0,Testability,Test,Tested,0,Tested this out on a fork over here: https://github.com/mcovarr/cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2830
https://github.com/broadinstitute/cromwell/issues/2831:88,Testability,test,tests,88,cromwell 30 will need this back. See `WdlFunctions` in the code. Then reinstate centaur tests:; - [x] `globbingscatter`; - [ ] `globbingindex`; - [x] `space`; - [x] `globbingBehavior`; - [x] `dontglobinputs`; - [x] `lots_of_inputs`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2831
https://github.com/broadinstitute/cromwell/pull/2832:198,Availability,error,error,198,"Accepts yaml input files during submission.; Whether the input is in yaml or json, it will be written in **json** in the database, as well as metadata.; Also `cats`ify things a little to get better error reporting on incorrect submit request.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2832
https://github.com/broadinstitute/cromwell/issues/2835:75,Safety,risk,risk,75,We currently do not have automated CWL testing in Centaur. this puts us at risk for regressions. Start w/ ; * 1st-workflow.cwl; * three_step.cwl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2835
https://github.com/broadinstitute/cromwell/issues/2835:39,Testability,test,testing,39,We currently do not have automated CWL testing in Centaur. this puts us at risk for regressions. Start w/ ; * 1st-workflow.cwl; * three_step.cwl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2835
https://github.com/broadinstitute/cromwell/issues/2837:335,Availability,error,error,335,"instead of registering the workflow id as the collection, as currently happens, register the collection name. if a collection was not specified (it's optional) create a collection name, `USERNAME_caas_collection`. . If the collection name specified already exists in sam and the user does not have write access to it it will return an error (or at least that's the belief of the author of this ticket). Make sure to detect that and return an appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2837
https://github.com/broadinstitute/cromwell/issues/2837:454,Availability,error,error,454,"instead of registering the workflow id as the collection, as currently happens, register the collection name. if a collection was not specified (it's optional) create a collection name, `USERNAME_caas_collection`. . If the collection name specified already exists in sam and the user does not have write access to it it will return an error (or at least that's the belief of the author of this ticket). Make sure to detect that and return an appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2837
https://github.com/broadinstitute/cromwell/issues/2837:416,Safety,detect,detect,416,"instead of registering the workflow id as the collection, as currently happens, register the collection name. if a collection was not specified (it's optional) create a collection name, `USERNAME_caas_collection`. . If the collection name specified already exists in sam and the user does not have write access to it it will return an error (or at least that's the belief of the author of this ticket). Make sure to detect that and return an appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2837
https://github.com/broadinstitute/cromwell/issues/2837:304,Security,access,access,304,"instead of registering the workflow id as the collection, as currently happens, register the collection name. if a collection was not specified (it's optional) create a collection name, `USERNAME_caas_collection`. . If the collection name specified already exists in sam and the user does not have write access to it it will return an error (or at least that's the belief of the author of this ticket). Make sure to detect that and return an appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2837
https://github.com/broadinstitute/cromwell/issues/2838:230,Availability,error,error,230,"When submitting the workflow to cromwell use the collection name in the workflow labels under the key `cromwell_collection_name`. . Further, users are **not** allowed to have used this label on their own, attempts to do so are an error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2838
https://github.com/broadinstitute/cromwell/issues/2839:284,Availability,error,error,284,Add a new API endpoint to CromIAM which will allow a user to update the collection name for one or more workflows in a one to many fashion - i.e. one collection name will be applied to 1+ workflows. If Sam says that the user does not have access to this collection name it will be an error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2839
https://github.com/broadinstitute/cromwell/issues/2839:61,Deployability,update,update,61,Add a new API endpoint to CromIAM which will allow a user to update the collection name for one or more workflows in a one to many fashion - i.e. one collection name will be applied to 1+ workflows. If Sam says that the user does not have access to this collection name it will be an error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2839
https://github.com/broadinstitute/cromwell/issues/2839:239,Security,access,access,239,Add a new API endpoint to CromIAM which will allow a user to update the collection name for one or more workflows in a one to many fashion - i.e. one collection name will be applied to 1+ workflows. If Sam says that the user does not have access to this collection name it will be an error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2839
https://github.com/broadinstitute/cromwell/issues/2840:19,Deployability,patch,patch,19,Intercept calls to patch the labels for workflows and disallow the updating of `caas_collection_name`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2840
https://github.com/broadinstitute/cromwell/pull/2841:46,Availability,down,down,46,Lets us trickle declarations and call outputs down into nested workflows. Eg this wdl:; ```wdl; workflow nested_lookups {; Int i = 27; if(true) {; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; }; ```. Gives us this womgraph:; ![test](https://user-images.githubusercontent.com/13006282/32580790-0eb26dc8-c4b5-11e7-8852-99d941823a2d.png),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2841
https://github.com/broadinstitute/cromwell/pull/2841:250,Testability,test,test,250,Lets us trickle declarations and call outputs down into nested workflows. Eg this wdl:; ```wdl; workflow nested_lookups {; Int i = 27; if(true) {; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; }; ```. Gives us this womgraph:; ![test](https://user-images.githubusercontent.com/13006282/32580790-0eb26dc8-c4b5-11e7-8852-99d941823a2d.png),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2841
https://github.com/broadinstitute/cromwell/pull/2842:50,Availability,error,errors,50,Missing *-version.conf files will no longer cause errors when running from IntelliJ.; Fixed projectName (ex: 'cromwell-engine') vs artifactName (ex: 'cromwell-engine.jar').; Also snuck in sbt 1.x syntax fix missed in a prior commit.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2842
https://github.com/broadinstitute/cromwell/pull/2843:71,Security,expose,exposed,71,This adds 3step to the list of tests run by centaur. Running this test exposed a regression that is fixed in this PR. Unfortunately 1st-workflow is not suitable as it expects a file input but is added here anyway with the potential of running a modified version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843
https://github.com/broadinstitute/cromwell/pull/2843:31,Testability,test,tests,31,This adds 3step to the list of tests run by centaur. Running this test exposed a regression that is fixed in this PR. Unfortunately 1st-workflow is not suitable as it expects a file input but is added here anyway with the potential of running a modified version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843
https://github.com/broadinstitute/cromwell/pull/2843:66,Testability,test,test,66,This adds 3step to the list of tests run by centaur. Running this test exposed a regression that is fixed in this PR. Unfortunately 1st-workflow is not suitable as it expects a file input but is added here anyway with the potential of running a modified version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843
https://github.com/broadinstitute/cromwell/issues/2844:332,Availability,down,downstream,332,"- JES/PAPI backend; - Cromwell v29. I have a task that dropped its outputs into ""./"", since output directory was a parameter and that is how it was set. So when cromwell/PAPI saw an output file `...././my_output.txt`, they created a bucket that actually contains the ""."" ... . The task was allowed to complete successfully and then downstream tasks failed. Proposed solutions:; - check the output location either when the first/upstream task completes (or, if possible, before it starts).; - Simple prune the ./ from the output path. ```; java.lang.IllegalArgumentException: I/O not allowed on dot-dirs or extra slashes when !permitEmptyPathComponents: /lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/25df0c1d-5a13; -4bc1-8712-0cf90a78dfda/call-cnvPair/CNVSomaticPairWorkflow/6fe3dc67-c5f0-4c61-8881-474ceac4c8d7/call-ModelSegmentsTumor/./G25783.TCGA-55-6986-01A-11D-1945-08.2.modelFinal.seg; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2844
https://github.com/broadinstitute/cromwell/issues/2844:683,Testability,test,test-dl-oxoq-full,683,"- JES/PAPI backend; - Cromwell v29. I have a task that dropped its outputs into ""./"", since output directory was a parameter and that is how it was set. So when cromwell/PAPI saw an output file `...././my_output.txt`, they created a bucket that actually contains the ""."" ... . The task was allowed to complete successfully and then downstream tasks failed. Proposed solutions:; - check the output location either when the first/upstream task completes (or, if possible, before it starts).; - Simple prune the ./ from the output path. ```; java.lang.IllegalArgumentException: I/O not allowed on dot-dirs or extra slashes when !permitEmptyPathComponents: /lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/25df0c1d-5a13; -4bc1-8712-0cf90a78dfda/call-cnvPair/CNVSomaticPairWorkflow/6fe3dc67-c5f0-4c61-8881-474ceac4c8d7/call-ModelSegmentsTumor/./G25783.TCGA-55-6986-01A-11D-1945-08.2.modelFinal.seg; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2844
https://github.com/broadinstitute/cromwell/issues/2844:492,Usability,Simpl,Simple,492,"- JES/PAPI backend; - Cromwell v29. I have a task that dropped its outputs into ""./"", since output directory was a parameter and that is how it was set. So when cromwell/PAPI saw an output file `...././my_output.txt`, they created a bucket that actually contains the ""."" ... . The task was allowed to complete successfully and then downstream tasks failed. Proposed solutions:; - check the output location either when the first/upstream task completes (or, if possible, before it starts).; - Simple prune the ./ from the output path. ```; java.lang.IllegalArgumentException: I/O not allowed on dot-dirs or extra slashes when !permitEmptyPathComponents: /lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/25df0c1d-5a13; -4bc1-8712-0cf90a78dfda/call-cnvPair/CNVSomaticPairWorkflow/6fe3dc67-c5f0-4c61-8881-474ceac4c8d7/call-ModelSegmentsTumor/./G25783.TCGA-55-6986-01A-11D-1945-08.2.modelFinal.seg; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2844
https://github.com/broadinstitute/cromwell/issues/2845:39,Availability,error,error,39,"- JES Backend; - v29. See #2844 . This error causes cromwell to enter a funny state when the error described in #2844 occurs in a subworkflow. Cromwell states that the workflow (and subworkflow) are running, though the server log shows the exception. Not only that, the backend status is `Success` for the task that generated the invalid filename, though the task status remains `Running`, just like the workflows. Without looking at the server logs, a user cannot determine what is going on, easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845
https://github.com/broadinstitute/cromwell/issues/2845:93,Availability,error,error,93,"- JES Backend; - v29. See #2844 . This error causes cromwell to enter a funny state when the error described in #2844 occurs in a subworkflow. Cromwell states that the workflow (and subworkflow) are running, though the server log shows the exception. Not only that, the backend status is `Success` for the task that generated the invalid filename, though the task status remains `Running`, just like the workflows. Without looking at the server logs, a user cannot determine what is going on, easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845
https://github.com/broadinstitute/cromwell/issues/2845:226,Testability,log,log,226,"- JES Backend; - v29. See #2844 . This error causes cromwell to enter a funny state when the error described in #2844 occurs in a subworkflow. Cromwell states that the workflow (and subworkflow) are running, though the server log shows the exception. Not only that, the backend status is `Success` for the task that generated the invalid filename, though the task status remains `Running`, just like the workflows. Without looking at the server logs, a user cannot determine what is going on, easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845
https://github.com/broadinstitute/cromwell/issues/2845:445,Testability,log,logs,445,"- JES Backend; - v29. See #2844 . This error causes cromwell to enter a funny state when the error described in #2844 occurs in a subworkflow. Cromwell states that the workflow (and subworkflow) are running, though the server log shows the exception. Not only that, the backend status is `Success` for the task that generated the invalid filename, though the task status remains `Running`, just like the workflows. Without looking at the server logs, a user cannot determine what is going on, easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845
https://github.com/broadinstitute/cromwell/issues/2846:376,Availability,robust,robust,376,"Provide a configurable knob which will limit the number of in flight calls per workflow. This includes scatters, e.g. if the limit is 5 and there's a 6-way scatter, at most 5 shards may be processed at once. This will likely be requested to be in place prior to or shortly after the GATK launch in early january. Edit: Some clarifications. As mentioned below this needs to be robust to the entirety of the root workflow, including all subworkflows. It also needs to be robust to restart, IOW on a restart of Cromwell if there were N jobs restarted the counter should start at MAX - N.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2846
https://github.com/broadinstitute/cromwell/issues/2846:469,Availability,robust,robust,469,"Provide a configurable knob which will limit the number of in flight calls per workflow. This includes scatters, e.g. if the limit is 5 and there's a 6-way scatter, at most 5 shards may be processed at once. This will likely be requested to be in place prior to or shortly after the GATK launch in early january. Edit: Some clarifications. As mentioned below this needs to be robust to the entirety of the root workflow, including all subworkflows. It also needs to be robust to restart, IOW on a restart of Cromwell if there were N jobs restarted the counter should start at MAX - N.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2846
https://github.com/broadinstitute/cromwell/issues/2846:10,Modifiability,config,configurable,10,"Provide a configurable knob which will limit the number of in flight calls per workflow. This includes scatters, e.g. if the limit is 5 and there's a 6-way scatter, at most 5 shards may be processed at once. This will likely be requested to be in place prior to or shortly after the GATK launch in early january. Edit: Some clarifications. As mentioned below this needs to be robust to the entirety of the root workflow, including all subworkflows. It also needs to be robust to restart, IOW on a restart of Cromwell if there were N jobs restarted the counter should start at MAX - N.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2846
https://github.com/broadinstitute/cromwell/issues/2850:14,Testability,test,tests,14,Uncomment the tests in `WdlNestedConditionalWomSpec` and remove the commented `throwaway` declarations in `nested_lookups.wdl`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2850
https://github.com/broadinstitute/cromwell/issues/2852:182,Availability,ping,pinging,182,"When Sam is no longer recording the workflow ID but the collection ID, for non-submission workflow based reqests we'll need to first look up the collection id from cromwell prior to pinging Sam",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2852
https://github.com/broadinstitute/cromwell/issues/2854:380,Integrability,depend,dependencies,380,"To recreate:; - Make a submission via swagger with a WDL and an `inputs.json`; - Look to the logs. Lo:; ```; The 'wdlDependencies' parameter name has been deprecated in favor of 'workflowDependencies'.; Support for 'wdlDependencies' will be removed from future versions of Cromwell.; Please switch to using 'workflowDependencies' in future submissions.; ```. I didn't specify any dependencies, and swagger shouldn't be submitting them as `wdlDependencies` anyway. Maybe our REST deprecation is triggering too eagerly?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2854
https://github.com/broadinstitute/cromwell/issues/2854:93,Testability,log,logs,93,"To recreate:; - Make a submission via swagger with a WDL and an `inputs.json`; - Look to the logs. Lo:; ```; The 'wdlDependencies' parameter name has been deprecated in favor of 'workflowDependencies'.; Support for 'wdlDependencies' will be removed from future versions of Cromwell.; Please switch to using 'workflowDependencies' in future submissions.; ```. I didn't specify any dependencies, and swagger shouldn't be submitting them as `wdlDependencies` anyway. Maybe our REST deprecation is triggering too eagerly?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2854
https://github.com/broadinstitute/cromwell/pull/2855:323,Availability,error,errors,323,"See below for motivating use case WDL (now a test). The throwaways need OGINs to reference the `i`, but we weren't recording the OGINs that they were making. The upshot was that multiple usages of the same variable in a nested scope was producing multiple OGINs for the same value, and that was causing the ""duplicate FQN"" errors to trigger. ```; workflow nested_lookups {; Int i = 27; if(true) {; Int? throwaway = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; Int? throwaway2 = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2855
https://github.com/broadinstitute/cromwell/pull/2855:206,Modifiability,variab,variable,206,"See below for motivating use case WDL (now a test). The throwaways need OGINs to reference the `i`, but we weren't recording the OGINs that they were making. The upshot was that multiple usages of the same variable in a nested scope was producing multiple OGINs for the same value, and that was causing the ""duplicate FQN"" errors to trigger. ```; workflow nested_lookups {; Int i = 27; if(true) {; Int? throwaway = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; Int? throwaway2 = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2855
https://github.com/broadinstitute/cromwell/pull/2855:45,Testability,test,test,45,"See below for motivating use case WDL (now a test). The throwaways need OGINs to reference the `i`, but we weren't recording the OGINs that they were making. The upshot was that multiple usages of the same variable in a nested scope was producing multiple OGINs for the same value, and that was causing the ""duplicate FQN"" errors to trigger. ```; workflow nested_lookups {; Int i = 27; if(true) {; Int? throwaway = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; Int? throwaway2 = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2855
https://github.com/broadinstitute/cromwell/issues/2856:26,Testability,test,tested,26,"From David Wine:. >I just tested out my latest question for which I could not find guidance in the docs; thus I had to bother a real live human. The question was; ""Is it true that a container image can be pulled from Google Container Registry, and how is it specified."". >If the answer is in the new docs I didn't find it. >I searched on container, and got lots of hits, though none I saw actually had the word ""container"".; I searched on dockerhub, ""docker="", ""docker:"", and browsed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2856
https://github.com/broadinstitute/cromwell/issues/2856:83,Usability,guid,guidance,83,"From David Wine:. >I just tested out my latest question for which I could not find guidance in the docs; thus I had to bother a real live human. The question was; ""Is it true that a container image can be pulled from Google Container Registry, and how is it specified."". >If the answer is in the new docs I didn't find it. >I searched on container, and got lots of hits, though none I saw actually had the word ""container"".; I searched on dockerhub, ""docker="", ""docker:"", and browsed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2856
https://github.com/broadinstitute/cromwell/pull/2859:6,Deployability,update,updates,6,Minor updates to YAML to fix capitalization.; Cleaned up sbt eviction warnings for both project and project/project.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2859
https://github.com/broadinstitute/cromwell/issues/2860:31,Testability,test,tests,31,And then re-enable the centaur tests; - [x] `optional_parameter`; - [x] `workflow_output_declarations`; - [x] `select_functions`; - [x] `if_then_else_expressions`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2860
https://github.com/broadinstitute/cromwell/issues/2861:508,Modifiability,enhance,enhanced,508,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2861:112,Security,access,accessing,112,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2861:165,Security,access,accessing,165,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2861:232,Security,access,access,232,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2861:349,Security,access,access,349,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2861:394,Testability,test,tests,394,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861
https://github.com/broadinstitute/cromwell/issues/2862:8,Testability,test,tests,8,Centaur tests:; - [x] `refresh_token_no_auth_bucket`; - [x] `refresh_token`; - [ ] ~`refresh_token_sub_workflow`~; - [x] `refresh_token_failure`. EDIT: Moved `refresh_token_sub_workflow` to #2615,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2862
https://github.com/broadinstitute/cromwell/issues/2863:479,Deployability,update,update,479,"- [x] overview of docs (goals, etc); - [x] link to label [needs docs](https://github.com/broadinstitute/cromwell/issues?q=is%3Aopen+is%3Aissue+label%3A%22needs+docs%22); - [x] formatting etc from [101 docs](https://docs.google.com/document/d/1-8fVXy9eHnheQz3IJiKGXjCZcNN8DPwywwqnOINB7l4/edit#); - [x] expand upon or figure out what to do with the [dev zone wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone) ; - [x] add sbt command for generating API markdown; - [x] update REST API docs to remove hidden sbt command",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2863
https://github.com/broadinstitute/cromwell/issues/2864:18,Testability,test,tests,18,Reinstate centaur tests:; - [x] `write_lines`; - [ ] `fofn_caching`; - [x] `array_io`; - [x] `write_lines_files`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2864
https://github.com/broadinstitute/cromwell/issues/2865:18,Testability,test,test,18,Reinstate centaur test:; - [ ] `no_new_calls`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2865
https://github.com/broadinstitute/cromwell/issues/2866:167,Testability,test,test,167,"This might be as simple as updating the ""waited for"" status from `Failed` to `Succeeded`, since we expect workflow success in the metadata. And then reinstate centaur test:; - [ ] `restart_jes_with_recover`; - [ ] `restart_local_with_recover`; - [ ] `restart_tes_without_recover`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2866
https://github.com/broadinstitute/cromwell/issues/2866:17,Usability,simpl,simple,17,"This might be as simple as updating the ""waited for"" status from `Failed` to `Succeeded`, since we expect workflow success in the metadata. And then reinstate centaur test:; - [ ] `restart_jes_with_recover`; - [ ] `restart_local_with_recover`; - [ ] `restart_tes_without_recover`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2866
https://github.com/broadinstitute/cromwell/issues/2867:311,Availability,avail,available,311,@mcovarr commented on [Tue Nov 14 2017](https://github.com/broadinstitute/wdltool/issues/51). This is for the benefit of womtool which is going to have to resort to forging inputs as a [stopgap measure](https://github.com/broadinstitute/cromwell/pull/2857). WdlNamespace should continue to make the current API available for production code.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2867
https://github.com/broadinstitute/cromwell/issues/2869:256,Availability,avail,available,256,"@mcovarr commented on [Thu Sep 07 2017](https://github.com/broadinstitute/wdltool/issues/48). Per the link below, enhance wdltool to be able to detect malformed expressions. Expressions that can't be evaluated are okay and expected due to values not being available, but malformed expressions are not okay. https://gatkforums.broadinstitute.org/wdl/discussion/10311/error-evaluating-output-files-that-serve-as-input-files-for-following-step#latest",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2869
https://github.com/broadinstitute/cromwell/issues/2869:366,Availability,error,error-evaluating-output-files-that-serve-as-input-files-for-following-step,366,"@mcovarr commented on [Thu Sep 07 2017](https://github.com/broadinstitute/wdltool/issues/48). Per the link below, enhance wdltool to be able to detect malformed expressions. Expressions that can't be evaluated are okay and expected due to values not being available, but malformed expressions are not okay. https://gatkforums.broadinstitute.org/wdl/discussion/10311/error-evaluating-output-files-that-serve-as-input-files-for-following-step#latest",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2869
https://github.com/broadinstitute/cromwell/issues/2869:114,Modifiability,enhance,enhance,114,"@mcovarr commented on [Thu Sep 07 2017](https://github.com/broadinstitute/wdltool/issues/48). Per the link below, enhance wdltool to be able to detect malformed expressions. Expressions that can't be evaluated are okay and expected due to values not being available, but malformed expressions are not okay. https://gatkforums.broadinstitute.org/wdl/discussion/10311/error-evaluating-output-files-that-serve-as-input-files-for-following-step#latest",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2869
https://github.com/broadinstitute/cromwell/issues/2869:144,Safety,detect,detect,144,"@mcovarr commented on [Thu Sep 07 2017](https://github.com/broadinstitute/wdltool/issues/48). Per the link below, enhance wdltool to be able to detect malformed expressions. Expressions that can't be evaluated are okay and expected due to values not being available, but malformed expressions are not okay. https://gatkforums.broadinstitute.org/wdl/discussion/10311/error-evaluating-output-files-that-serve-as-input-files-for-following-step#latest",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2869
https://github.com/broadinstitute/cromwell/issues/2870:214,Availability,Error,Error,214,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:285,Availability,error,error,285,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:364,Availability,echo,echo,364,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:428,Availability,error,error,428,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:455,Availability,echo,echo,455,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:541,Availability,error,error,541,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:630,Availability,ERROR,ERROR,630,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:723,Availability,error,error,723,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:763,Availability,echo,echo,763,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:792,Availability,error,errors,792,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:898,Availability,error,error,898,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:1403,Availability,echo,echo,1403,"s a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly, I have never written a parser before, so I don't know how feasible this is, but can you write the grammar/parser such that everything on a line after a `#` character is ignored?. The only edge cases I imagine are when the `#` character is in a quoted string. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343). @tmdefreitas Yes, that is ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:3006,Availability,error,error,3006,"613). Admittedly, I have never written a parser before, so I don't know how feasible this is, but can you write the grammar/parser such that everything on a line after a `#` character is ignored?. The only edge cases I imagine are when the `#` character is in a quoted string. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343). @tmdefreitas Yes, that is definitely possible. However, we try to not make assumptions about the type of characters that your script can have in it. I'm perhaps being a little overly cautious, but I'd hate for there to be a case where somebody wants to use a `#` in their command but it gets interpreted as a comment. That could lead to the same kind of confusion that we're seeing now. I vacillate on this because I also see the pragmatism in implementing your suggestion for the common case. In most cases I can think of, a `#` is a comment. Maybe some approach like Eddie's where I can have the parser give a better error message is the best solution. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200508578). Scott,. Not only can I imagine a command where # is used (and in a WDL no less),; but I have actually written such a command. In the merge step for mutect, I use ""#"" to select for header lines in; merging call_stats files and VCF files!. command <<<; #increase verbosity; set -x. #mutect1 call_stats merging; MUTECT1_CS=""MuTect1.call_stats.txt""; head --lines=2 ${mutect1_cs[0]} > $MUTECT1_CS; cat ${sep =' ' mutect1_cs} | grep -Pv '#'|grep -Pv '^contig' >> $MUTECT1_CS. #mutect2 call_stats merging; MUTECT2_CS=""MuTect2.call_stats.txt""; cat ${mutect2_cs[0]} |grep -P '^#' > $MUTECT2_CS ;; cat ${sep=' ' mutect2_cs} |grep -Pv '^#' >> $MUTECT2_CS ;; -eddie. On Wed, Mar 23, 2016 at 3:25 PM, Scott Frazer notifications@github.com; wrote:. > @tmdefreitas https://github.com/tmdefreitas Yes, that is definitely; > possible.; >",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:4593,Availability,error,error,4593,"} > $MUTECT1_CS; cat ${sep =' ' mutect1_cs} | grep -Pv '#'|grep -Pv '^contig' >> $MUTECT1_CS. #mutect2 call_stats merging; MUTECT2_CS=""MuTect2.call_stats.txt""; cat ${mutect2_cs[0]} |grep -P '^#' > $MUTECT2_CS ;; cat ${sep=' ' mutect2_cs} |grep -Pv '^#' >> $MUTECT2_CS ;; -eddie. On Wed, Mar 23, 2016 at 3:25 PM, Scott Frazer notifications@github.com; wrote:. > @tmdefreitas https://github.com/tmdefreitas Yes, that is definitely; > possible.; > ; > However, we try to not make assumptions about the type of characters that; > your script can have in it. I'm perhaps being a little overly cautious, but; > I'd hate for there to be a case where somebody wants to use a # in their; > command but it gets interpreted as a comment. That could lead to the same; > kind of confusion that we're seeing now.; > ; > I vacillate on this because I also see the pragmatism in implementing your; > suggestion for the common case. In most cases I can think of, a # is a; > comment; > ; > Maybe some approach like Eddie's where I can have the parser give a better; > error message is the best solution.; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863). @eddiebroad But those are all quoted strings, and don't look the same as a WDL comment. From an implementation perspective, doesn't cromwell pipe the command block to /bin/bash anyway? And following bash rules unquoted `#` characters start a comment, so maybe WDL just has to follow the same comment parsing rules as bash?. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadins",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:6866,Availability,error,error,6866,"Timothy DeFreitas <notifications@github.com. > wrote:; > ; > @eddiebroad https://github.com/eddiebroad But those are all quoted; > strings, and don't look the same as a WDL comment. From an implementation; > perspective, doesn't cromwell pipe the command bock to /bin/bash anyway?; > And following bash rules unquoted # characters start a comment, so maybe; > WDL just has to follow the same comment parsing rules as bash?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:6899,Availability,down,down,6899,"Timothy DeFreitas <notifications@github.com. > wrote:; > ; > @eddiebroad https://github.com/eddiebroad But those are all quoted; > strings, and don't look the same as a WDL comment. From an implementation; > perspective, doesn't cromwell pipe the command bock to /bin/bash anyway?; > And following bash rules unquoted # characters start a comment, so maybe; > WDL just has to follow the same comment parsing rules as bash?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7679,Availability,error,error,7679,"ridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7895,Availability,error,error,7895,"hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7928,Availability,down,down,7928,"hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:547,Integrability,message,message,547,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:904,Integrability,message,message,904,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:926,Integrability,message,message,926,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:3012,Integrability,message,message,3012,"613). Admittedly, I have never written a parser before, so I don't know how feasible this is, but can you write the grammar/parser such that everything on a line after a `#` character is ignored?. The only edge cases I imagine are when the `#` character is in a quoted string. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343). @tmdefreitas Yes, that is definitely possible. However, we try to not make assumptions about the type of characters that your script can have in it. I'm perhaps being a little overly cautious, but I'd hate for there to be a case where somebody wants to use a `#` in their command but it gets interpreted as a comment. That could lead to the same kind of confusion that we're seeing now. I vacillate on this because I also see the pragmatism in implementing your suggestion for the common case. In most cases I can think of, a `#` is a comment. Maybe some approach like Eddie's where I can have the parser give a better error message is the best solution. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200508578). Scott,. Not only can I imagine a command where # is used (and in a WDL no less),; but I have actually written such a command. In the merge step for mutect, I use ""#"" to select for header lines in; merging call_stats files and VCF files!. command <<<; #increase verbosity; set -x. #mutect1 call_stats merging; MUTECT1_CS=""MuTect1.call_stats.txt""; head --lines=2 ${mutect1_cs[0]} > $MUTECT1_CS; cat ${sep =' ' mutect1_cs} | grep -Pv '#'|grep -Pv '^contig' >> $MUTECT1_CS. #mutect2 call_stats merging; MUTECT2_CS=""MuTect2.call_stats.txt""; cat ${mutect2_cs[0]} |grep -P '^#' > $MUTECT2_CS ;; cat ${sep=' ' mutect2_cs} |grep -Pv '^#' >> $MUTECT2_CS ;; -eddie. On Wed, Mar 23, 2016 at 3:25 PM, Scott Frazer notifications@github.com; wrote:. > @tmdefreitas https://github.com/tmdefreitas Yes, that is definitely; > possible.; >",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:4599,Integrability,message,message,4599,"} > $MUTECT1_CS; cat ${sep =' ' mutect1_cs} | grep -Pv '#'|grep -Pv '^contig' >> $MUTECT1_CS. #mutect2 call_stats merging; MUTECT2_CS=""MuTect2.call_stats.txt""; cat ${mutect2_cs[0]} |grep -P '^#' > $MUTECT2_CS ;; cat ${sep=' ' mutect2_cs} |grep -Pv '^#' >> $MUTECT2_CS ;; -eddie. On Wed, Mar 23, 2016 at 3:25 PM, Scott Frazer notifications@github.com; wrote:. > @tmdefreitas https://github.com/tmdefreitas Yes, that is definitely; > possible.; > ; > However, we try to not make assumptions about the type of characters that; > your script can have in it. I'm perhaps being a little overly cautious, but; > I'd hate for there to be a case where somebody wants to use a # in their; > command but it gets interpreted as a comment. That could lead to the same; > kind of confusion that we're seeing now.; > ; > I vacillate on this because I also see the pragmatism in implementing your; > suggestion for the common case. In most cases I can think of, a # is a; > comment; > ; > Maybe some approach like Eddie's where I can have the parser give a better; > error message is the best solution.; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863). @eddiebroad But those are all quoted strings, and don't look the same as a WDL comment. From an implementation perspective, doesn't cromwell pipe the command block to /bin/bash anyway? And following bash rules unquoted `#` characters start a comment, so maybe WDL just has to follow the same comment parsing rules as bash?. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadins",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7686,Integrability,message,messages,7686,"ridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:962,Modifiability,variab,variable,962,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:184,Security,validat,validated,184,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:604,Security,validat,validate,604,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:850,Security,validat,validator,850,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:501,Testability,test,test,501,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7142,Usability,simpl,simple,7142,"d # characters start a comment, so maybe; > WDL just has to follow the same comment parsing rules as bash?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:7475,Usability,clear,clear,7475,"ridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2870:8187,Usability,simpl,simple,8187,"hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870
https://github.com/broadinstitute/cromwell/issues/2871:38,Availability,error,error,38,"- [ ] `missing_optional_output`:; The error message is now `""No input x.out_except_undeclared found evaluating inputs for expression x.out_except_undeclared""` which is significantly less friendly than the previous:; ```; out_except_undeclared is not declared as an output of the task x.; Make sure to declare it as an output to be able to use it in the workflow.; ```. - [x] `missing_input_failure`:; We used to get information saying which call, and which input, were given an invalid file. Now we just get `""Workflow Failed""` caused by: `""nonexistingbucket/path/doesnt/exist""`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2871
https://github.com/broadinstitute/cromwell/issues/2871:44,Integrability,message,message,44,"- [ ] `missing_optional_output`:; The error message is now `""No input x.out_except_undeclared found evaluating inputs for expression x.out_except_undeclared""` which is significantly less friendly than the previous:; ```; out_except_undeclared is not declared as an output of the task x.; Make sure to declare it as an output to be able to use it in the workflow.; ```. - [x] `missing_input_failure`:; We used to get information saying which call, and which input, were given an invalid file. Now we just get `""Workflow Failed""` caused by: `""nonexistingbucket/path/doesnt/exist""`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2871
https://github.com/broadinstitute/cromwell/issues/2872:303,Availability,avail,available,303,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:1315,Availability,avail,available,1315,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:1329,Availability,down,download,1329,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:284,Deployability,release,release,284,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:523,Deployability,release,release,523,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:716,Deployability,release,release,716,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:750,Deployability,release,release,750,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:953,Deployability,release,release,953,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:978,Deployability,release,release,978,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:1172,Deployability,release,release,1172,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2872:1298,Deployability,release,releases,1298,"@vdauwera commented on [Sun Jan 08 2017](https://github.com/broadinstitute/wdltool/issues/20). I had a few issues that were fixed by building the latest from source. There's a good chance that will also be the case for the other issues that have been reported. Would be good to cut a release to make it available without requiring people to build from source. . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281030248). Are we responsible for building a new release now that we own this repo? Or am I misremembering?. ---. @ruchim commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281054777). The wdltool release is a part of the Cromwell release process . ---. @knoblett commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281096658). Ah, thank you, that makes sense. @vdauwera do we still need a release? The most recent release was done 3 days prior to the creation of this ticket. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/wdltool/issues/20#issuecomment-281097178). Does the release process include making a packaged jar? I think my problem was that there wasn't a jar that corresponded to the latest releases version available for download, come to think of it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872
https://github.com/broadinstitute/cromwell/issues/2873:268,Availability,error,error,268,"@ruchim commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29). Given a task:. task myTask {; File f; command {; touch ${f.bam.bai}; }; }. A workflow with such a task validates in wdltool-0.10 but when run on cromwell-26, it fails with an error: java.lang.UnsupportedOperationException: Could not evaluate expression:.... Given a slightly altered version of that previous task:. task myTask {; File f; command {; touch ${f%%.bam.bai}; }; }. This task also validates but fails before the Workflow is about to run with the error: scala.MatchError: null. ---. @geoffjentry commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29#issuecomment-303819742). Is this an artifact of wdltool being out of synch? it happens way too often :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873
https://github.com/broadinstitute/cromwell/issues/2873:550,Availability,error,error,550,"@ruchim commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29). Given a task:. task myTask {; File f; command {; touch ${f.bam.bai}; }; }. A workflow with such a task validates in wdltool-0.10 but when run on cromwell-26, it fails with an error: java.lang.UnsupportedOperationException: Could not evaluate expression:.... Given a slightly altered version of that previous task:. task myTask {; File f; command {; touch ${f%%.bam.bai}; }; }. This task also validates but fails before the Workflow is about to run with the error: scala.MatchError: null. ---. @geoffjentry commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29#issuecomment-303819742). Is this an artifact of wdltool being out of synch? it happens way too often :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873
https://github.com/broadinstitute/cromwell/issues/2873:196,Security,validat,validates,196,"@ruchim commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29). Given a task:. task myTask {; File f; command {; touch ${f.bam.bai}; }; }. A workflow with such a task validates in wdltool-0.10 but when run on cromwell-26, it fails with an error: java.lang.UnsupportedOperationException: Could not evaluate expression:.... Given a slightly altered version of that previous task:. task myTask {; File f; command {; touch ${f%%.bam.bai}; }; }. This task also validates but fails before the Workflow is about to run with the error: scala.MatchError: null. ---. @geoffjentry commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29#issuecomment-303819742). Is this an artifact of wdltool being out of synch? it happens way too often :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873
https://github.com/broadinstitute/cromwell/issues/2873:485,Security,validat,validates,485,"@ruchim commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29). Given a task:. task myTask {; File f; command {; touch ${f.bam.bai}; }; }. A workflow with such a task validates in wdltool-0.10 but when run on cromwell-26, it fails with an error: java.lang.UnsupportedOperationException: Could not evaluate expression:.... Given a slightly altered version of that previous task:. task myTask {; File f; command {; touch ${f%%.bam.bai}; }; }. This task also validates but fails before the Workflow is about to run with the error: scala.MatchError: null. ---. @geoffjentry commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29#issuecomment-303819742). Is this an artifact of wdltool being out of synch? it happens way too often :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873
https://github.com/broadinstitute/cromwell/issues/2874:219,Availability,error,error,219,"@tmdefreitas commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8). In the following WDL, **GSEA_v_1_0_fwer_p_val_threshold** was not declared as an input, but the validator didn't raise an error. Cromwell choked when trying to run the task. Is there a reason wdltool shouldn't throw an error here?. ```; task tool_gsea_mrnaseq_subtypes {; String outputprefix; String pheno_from_aggregate_molecular_subtype_clusters; String pheno_name; File tcga_pheno_FileName; File tcga_exp_FileName; File gs_db; String GSEA_v_1_0_reshuffling_type; String GSEA_v_1_0_nperm; String GSEA_v_1_0_weighted_score_type; String GSEA_v_1_0_nom_p_val_threshold; String GSEA_v_1_0_topgs; String GSEA_v_1_0_adjust_FDR_q_val; String GSEA_v_1_0_gs_size_threshold_min; String GSEA_v_1_0_gs_size_threshold_max; String GSEA_v_1_0_reverse_sign; String GSEA_v_1_0_perm_type. command {; /R/RunR.sh -f main /src/Pathway_GSEA.R --libdir/src --disease_type${outputprefix} --pheno.from.Aggregate_Molecular_Subtype_Clusters${pheno_from_aggregate_molecular_subtype_clusters} --pheno.name${pheno_name} --tcga.pheno.FileName${tcga_pheno_FileName} --tcga.exp.FileName${tcga_exp_FileName} --gs.db${gs_db} --GSEA.v.1.0.reshuffling.type${GSEA_v_1_0_reshuffling_type} --GSEA.v.1.0.nperm${GSEA_v_1_0_nperm} --GSEA.v.1.0.weighted.score.type${GSEA_v_1_0_weighted_score_type} --GSEA.v.1.0.nom.p.val.threshold${GSEA_v_1_0_nom_p_val_threshold} --GSEA.v.1.0.fwer.p.val.threshold${GSEA_v_1_0_fwer_p_val_threshold} --GSEA.v.1.0.fdr.q.val.threshold${GSEA_v_1_0_fdr_q_val_threshold} --GSEA.v.1.0.topgs${GSEA_v_1_0_topgs} --GSEA.v.1.0.adjust.FDR.q.val${GSEA_v_1_0_adjust_FDR_q_val} --GSEA.v.1.0.gs.size.threshold.min${GSEA_v_1_0_gs_size_threshold_min} --GSEA.v.1.0.gs.size.threshold.max${GSEA_v_1_0_gs_size_threshold_max} --GSEA.v.1.0.reverse.sign${GSEA_v_1_0_reverse_sign} --GSEA.v.1.0.perm.type${GSEA_v_1_0_perm_type}. zip -r ${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip . ; }. output {; File zip_results=""${outputprefix}.pat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:316,Availability,error,error,316,"@tmdefreitas commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8). In the following WDL, **GSEA_v_1_0_fwer_p_val_threshold** was not declared as an input, but the validator didn't raise an error. Cromwell choked when trying to run the task. Is there a reason wdltool shouldn't throw an error here?. ```; task tool_gsea_mrnaseq_subtypes {; String outputprefix; String pheno_from_aggregate_molecular_subtype_clusters; String pheno_name; File tcga_pheno_FileName; File tcga_exp_FileName; File gs_db; String GSEA_v_1_0_reshuffling_type; String GSEA_v_1_0_nperm; String GSEA_v_1_0_weighted_score_type; String GSEA_v_1_0_nom_p_val_threshold; String GSEA_v_1_0_topgs; String GSEA_v_1_0_adjust_FDR_q_val; String GSEA_v_1_0_gs_size_threshold_min; String GSEA_v_1_0_gs_size_threshold_max; String GSEA_v_1_0_reverse_sign; String GSEA_v_1_0_perm_type. command {; /R/RunR.sh -f main /src/Pathway_GSEA.R --libdir/src --disease_type${outputprefix} --pheno.from.Aggregate_Molecular_Subtype_Clusters${pheno_from_aggregate_molecular_subtype_clusters} --pheno.name${pheno_name} --tcga.pheno.FileName${tcga_pheno_FileName} --tcga.exp.FileName${tcga_exp_FileName} --gs.db${gs_db} --GSEA.v.1.0.reshuffling.type${GSEA_v_1_0_reshuffling_type} --GSEA.v.1.0.nperm${GSEA_v_1_0_nperm} --GSEA.v.1.0.weighted.score.type${GSEA_v_1_0_weighted_score_type} --GSEA.v.1.0.nom.p.val.threshold${GSEA_v_1_0_nom_p_val_threshold} --GSEA.v.1.0.fwer.p.val.threshold${GSEA_v_1_0_fwer_p_val_threshold} --GSEA.v.1.0.fdr.q.val.threshold${GSEA_v_1_0_fdr_q_val_threshold} --GSEA.v.1.0.topgs${GSEA_v_1_0_topgs} --GSEA.v.1.0.adjust.FDR.q.val${GSEA_v_1_0_adjust_FDR_q_val} --GSEA.v.1.0.gs.size.threshold.min${GSEA_v_1_0_gs_size_threshold_min} --GSEA.v.1.0.gs.size.threshold.max${GSEA_v_1_0_gs_size_threshold_max} --GSEA.v.1.0.reverse.sign${GSEA_v_1_0_reverse_sign} --GSEA.v.1.0.perm.type${GSEA_v_1_0_perm_type}. zip -r ${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip . ; }. output {; File zip_results=""${outputprefix}.pat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:2929,Availability,error,error,2929,"sults=""${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip"" ; }. runtime {; docker : ""broadgdac/tool_gsea_mrnaseq_subtypes:22""; }. meta {; author : ""Juok Cho""; email : ""jcho@broadinstitute.org""; }. }. workflow tool_gsea_mrnaseq_subtypes_workflow {; call tool_gsea_mrnaseq_subtypes; }; ```. Thanks,; Tim. ---. @geoffjentry commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203042213). When talking to @knoblett she said that this appears to be something which previously was resolved - perhaps there's been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:3157,Availability,fault,fault,3157,"cho@broadinstitute.org""; }. }. workflow tool_gsea_mrnaseq_subtypes_workflow {; call tool_gsea_mrnaseq_subtypes; }; ```. Thanks,; Tim. ---. @geoffjentry commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203042213). When talking to @knoblett she said that this appears to be something which previously was resolved - perhaps there's been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:5385,Availability,error,error,5385,"ot for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_map} \; -md ${analysis_directory} \; -I ${header_bam} \; -bedFile ${gender_mask_bed} \; -O sample_gender.report.txt; }; runtime {; docker: ""kbergin/kbergin_test""; memory: ""4 GB""; }; output{; File sample_gender_report = ""sample_gender.report.txt""; }; }; ```. ---. @knoblett commented on [Mon Apr 25 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-214441149). In running a highlight command today, I noticed that the wdltool caught an undeclared input error. Has this bug been fixed, or is wdltool still not picking up undeclared inputs within tasks only? (my example is missing a declared input in the workflow's call to the task, due to a typo.). ![screen shot 2016-04-25 at 12 55 02 pm](https://cloud.githubusercontent.com/assets/13629186/14791714/0ca069f8-0ae5-11e6-8b80-37e2a7fecae9.png). I am using the Cromwell 0.18 release and wdltool 0.1 release.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:5756,Deployability,release,release,5756,"ot for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_map} \; -md ${analysis_directory} \; -I ${header_bam} \; -bedFile ${gender_mask_bed} \; -O sample_gender.report.txt; }; runtime {; docker: ""kbergin/kbergin_test""; memory: ""4 GB""; }; output{; File sample_gender_report = ""sample_gender.report.txt""; }; }; ```. ---. @knoblett commented on [Mon Apr 25 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-214441149). In running a highlight command today, I noticed that the wdltool caught an undeclared input error. Has this bug been fixed, or is wdltool still not picking up undeclared inputs within tasks only? (my example is missing a declared input in the workflow's call to the task, due to a typo.). ![screen shot 2016-04-25 at 12 55 02 pm](https://cloud.githubusercontent.com/assets/13629186/14791714/0ca069f8-0ae5-11e6-8b80-37e2a7fecae9.png). I am using the Cromwell 0.18 release and wdltool 0.1 release.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:5780,Deployability,release,release,5780,"ot for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_map} \; -md ${analysis_directory} \; -I ${header_bam} \; -bedFile ${gender_mask_bed} \; -O sample_gender.report.txt; }; runtime {; docker: ""kbergin/kbergin_test""; memory: ""4 GB""; }; output{; File sample_gender_report = ""sample_gender.report.txt""; }; }; ```. ---. @knoblett commented on [Mon Apr 25 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-214441149). In running a highlight command today, I noticed that the wdltool caught an undeclared input error. Has this bug been fixed, or is wdltool still not picking up undeclared inputs within tasks only? (my example is missing a declared input in the workflow's call to the task, due to a typo.). ![screen shot 2016-04-25 at 12 55 02 pm](https://cloud.githubusercontent.com/assets/13629186/14791714/0ca069f8-0ae5-11e6-8b80-37e2a7fecae9.png). I am using the Cromwell 0.18 release and wdltool 0.1 release.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:3767,Integrability,depend,depends,3767,"alidate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:3686,Modifiability,config,configs,3686,"'s been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:4332,Modifiability,variab,variable,4332,"er_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_map} \; -md ${analysis_directory} \; -I ${header_bam} \; -bedFile ${gender_mask_bed} \; -O sample_gender.report.txt; }; runtime {; docker: ""kbergin/kbergin_test""; memory: ""4 GB""; }; output{; File sample_gender_report = ""sample_gender.report.txt""; }; }; ```. ---. @knoblett commented on [Mon Apr 25 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-214441149). In running a highlight command ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:193,Security,validat,validator,193,"@tmdefreitas commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8). In the following WDL, **GSEA_v_1_0_fwer_p_val_threshold** was not declared as an input, but the validator didn't raise an error. Cromwell choked when trying to run the task. Is there a reason wdltool shouldn't throw an error here?. ```; task tool_gsea_mrnaseq_subtypes {; String outputprefix; String pheno_from_aggregate_molecular_subtype_clusters; String pheno_name; File tcga_pheno_FileName; File tcga_exp_FileName; File gs_db; String GSEA_v_1_0_reshuffling_type; String GSEA_v_1_0_nperm; String GSEA_v_1_0_weighted_score_type; String GSEA_v_1_0_nom_p_val_threshold; String GSEA_v_1_0_topgs; String GSEA_v_1_0_adjust_FDR_q_val; String GSEA_v_1_0_gs_size_threshold_min; String GSEA_v_1_0_gs_size_threshold_max; String GSEA_v_1_0_reverse_sign; String GSEA_v_1_0_perm_type. command {; /R/RunR.sh -f main /src/Pathway_GSEA.R --libdir/src --disease_type${outputprefix} --pheno.from.Aggregate_Molecular_Subtype_Clusters${pheno_from_aggregate_molecular_subtype_clusters} --pheno.name${pheno_name} --tcga.pheno.FileName${tcga_pheno_FileName} --tcga.exp.FileName${tcga_exp_FileName} --gs.db${gs_db} --GSEA.v.1.0.reshuffling.type${GSEA_v_1_0_reshuffling_type} --GSEA.v.1.0.nperm${GSEA_v_1_0_nperm} --GSEA.v.1.0.weighted.score.type${GSEA_v_1_0_weighted_score_type} --GSEA.v.1.0.nom.p.val.threshold${GSEA_v_1_0_nom_p_val_threshold} --GSEA.v.1.0.fwer.p.val.threshold${GSEA_v_1_0_fwer_p_val_threshold} --GSEA.v.1.0.fdr.q.val.threshold${GSEA_v_1_0_fdr_q_val_threshold} --GSEA.v.1.0.topgs${GSEA_v_1_0_topgs} --GSEA.v.1.0.adjust.FDR.q.val${GSEA_v_1_0_adjust_FDR_q_val} --GSEA.v.1.0.gs.size.threshold.min${GSEA_v_1_0_gs_size_threshold_min} --GSEA.v.1.0.gs.size.threshold.max${GSEA_v_1_0_gs_size_threshold_max} --GSEA.v.1.0.reverse.sign${GSEA_v_1_0_reverse_sign} --GSEA.v.1.0.perm.type${GSEA_v_1_0_perm_type}. zip -r ${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip . ; }. output {; File zip_results=""${outputprefix}.pat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:2912,Security,validat,validate,2912,"sults=""${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip"" ; }. runtime {; docker : ""broadgdac/tool_gsea_mrnaseq_subtypes:22""; }. meta {; author : ""Juok Cho""; email : ""jcho@broadinstitute.org""; }. }. workflow tool_gsea_mrnaseq_subtypes_workflow {; call tool_gsea_mrnaseq_subtypes; }; ```. Thanks,; Tim. ---. @geoffjentry commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203042213). When talking to @knoblett she said that this appears to be something which previously was resolved - perhaps there's been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2874:3105,Security,validat,validate,3105,"cho@broadinstitute.org""; }. }. workflow tool_gsea_mrnaseq_subtypes_workflow {; call tool_gsea_mrnaseq_subtypes; }; ```. Thanks,; Tim. ---. @geoffjentry commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203042213). When talking to @knoblett she said that this appears to be something which previously was resolved - perhaps there's been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874
https://github.com/broadinstitute/cromwell/issues/2875:143,Availability,error,error,143,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:595,Availability,error,error,595,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:948,Availability,error,error,948,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:1027,Availability,error,error,1027,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:1121,Availability,error,error,1121,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:149,Integrability,message,message,149,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:601,Integrability,message,message,601,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:954,Integrability,message,message,954,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:1033,Integrability,message,message,1033,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:1127,Integrability,message,message,1127,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:633,Performance,load,load,633,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:169,Security,validat,validate,169,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:722,Testability,log,logger,722,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2875:1144,Usability,clear,clearer,1144,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875
https://github.com/broadinstitute/cromwell/issues/2876:168,Availability,error,error,168,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:414,Availability,error,error,414,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:459,Availability,error,error,459,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:526,Availability,down,downloaded,526,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:625,Availability,down,download,625,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:565,Deployability,release,release,565,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:616,Deployability,release,releases,616,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:118,Security,validat,validate,118,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2876:845,Security,validat,validate,845,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876
https://github.com/broadinstitute/cromwell/issues/2878:580,Availability,error,error,580,"@anton-khodak commented on [Wed Jan 25 2017](https://github.com/broadinstitute/wdltool/issues/22). I use `wdltool` to parse descriptions from the main repository, for instance, [this one](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ValidateBamsWf_170107.wdl) and [this](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ConvertPairedFastQToUnmappedBamWf_170107.wdl) . Both descriptions have valid syntax (`validate` and `parse` run smoothly). However, when I run `highlight` on either of them, I get the following error:; ``` ; $ java -jar ~/Downloads/wdltool-0.8.jar highlight ""/media/anton/ECFA959BFA95631E/Programming/wdl2cwl/ValidateBamsWf_170107.wdl"" console. Exception in thread ""main"" scala.MatchError: [Declaration type=Array[File] name=validation_reports expr=Some(ValidateBAM.validation_report)] (of class wdl4s.WorkflowOutput); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatScope(SyntaxFormatter.scala:188); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatWorkflow(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:608,Availability,Down,Downloads,608,"@anton-khodak commented on [Wed Jan 25 2017](https://github.com/broadinstitute/wdltool/issues/22). I use `wdltool` to parse descriptions from the main repository, for instance, [this one](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ValidateBamsWf_170107.wdl) and [this](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ConvertPairedFastQToUnmappedBamWf_170107.wdl) . Both descriptions have valid syntax (`validate` and `parse` run smoothly). However, when I run `highlight` on either of them, I get the following error:; ``` ; $ java -jar ~/Downloads/wdltool-0.8.jar highlight ""/media/anton/ECFA959BFA95631E/Programming/wdl2cwl/ValidateBamsWf_170107.wdl"" console. Exception in thread ""main"" scala.MatchError: [Declaration type=Array[File] name=validation_reports expr=Some(ValidateBAM.validation_report)] (of class wdl4s.WorkflowOutput); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatScope(SyntaxFormatter.scala:188); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatWorkflow(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:2864,Performance,load,loadWdl,2864,153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.format(SyntaxFormatter.scala:73); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:52); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:50); at wdltool.Main$.wdltool$Main$$loadWdl(Main.scala:98); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$.continueIf(Main.scala:94); at wdltool.Main$.highlight(Main.scala:49); at wdltool.Main$.dispatchCommand(Main.scala:34); at wdltool.Main$.delayedEndpoint$wdltool$Main$1(Main.scala:151); at wdltool.Main$delayedInit$body.apply(Main.scala:12); at scala.Function0$class.apply$mcV$sp(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:381); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35); at scala.App$class.main(App.scala:76); at wdltool.Main$.main(Main.scala:12); at wdltool.Main.main(Main.scala). ```. ---. @geoffjentry commented on [Thu Jan 26 2017](https://github.com/broadinstitute/wdltool/issu,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:472,Security,validat,validate,472,"@anton-khodak commented on [Wed Jan 25 2017](https://github.com/broadinstitute/wdltool/issues/22). I use `wdltool` to parse descriptions from the main repository, for instance, [this one](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ValidateBamsWf_170107.wdl) and [this](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ConvertPairedFastQToUnmappedBamWf_170107.wdl) . Both descriptions have valid syntax (`validate` and `parse` run smoothly). However, when I run `highlight` on either of them, I get the following error:; ``` ; $ java -jar ~/Downloads/wdltool-0.8.jar highlight ""/media/anton/ECFA959BFA95631E/Programming/wdl2cwl/ValidateBamsWf_170107.wdl"" console. Exception in thread ""main"" scala.MatchError: [Declaration type=Array[File] name=validation_reports expr=Some(ValidateBAM.validation_report)] (of class wdl4s.WorkflowOutput); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatScope(SyntaxFormatter.scala:188); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatWorkflow(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:840,Security,Validat,ValidateBAM,840,"@anton-khodak commented on [Wed Jan 25 2017](https://github.com/broadinstitute/wdltool/issues/22). I use `wdltool` to parse descriptions from the main repository, for instance, [this one](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ValidateBamsWf_170107.wdl) and [this](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ConvertPairedFastQToUnmappedBamWf_170107.wdl) . Both descriptions have valid syntax (`validate` and `parse` run smoothly). However, when I run `highlight` on either of them, I get the following error:; ``` ; $ java -jar ~/Downloads/wdltool-0.8.jar highlight ""/media/anton/ECFA959BFA95631E/Programming/wdl2cwl/ValidateBamsWf_170107.wdl"" console. Exception in thread ""main"" scala.MatchError: [Declaration type=Array[File] name=validation_reports expr=Some(ValidateBAM.validation_report)] (of class wdl4s.WorkflowOutput); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatScope(SyntaxFormatter.scala:188); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatWorkflow(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:4070,Testability,test,test,4070,"raversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.format(SyntaxFormatter.scala:73); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:52); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:50); at wdltool.Main$.wdltool$Main$$loadWdl(Main.scala:98); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$.continueIf(Main.scala:94); at wdltool.Main$.highlight(Main.scala:49); at wdltool.Main$.dispatchCommand(Main.scala:34); at wdltool.Main$.delayedEndpoint$wdltool$Main$1(Main.scala:151); at wdltool.Main$delayedInit$body.apply(Main.scala:12); at scala.Function0$class.apply$mcV$sp(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:381); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35); at scala.App$class.main(App.scala:76); at wdltool.Main$.main(Main.scala:12); at wdltool.Main.main(Main.scala). ```. ---. @geoffjentry commented on [Thu Jan 26 2017](https://github.com/broadinstitute/wdltool/issues/22#issuecomment-275469010). @anton-khodak Thanks for noticing this! I didn't realize people actually used the highlighting, that's useful info in and of itself :). This looks to be a case where our unit test was overly simplistic. I have a fix but it'll likely be a day or two before it's in place. ---. @anton-khodak commented on [Thu Jan 26 2017](https://github.com/broadinstitute/wdltool/issues/22#issuecomment-275472773). @geoffjentry I wanted to use highlighting in secondary purposes, as a way of exporting WDL description in a parsable format other than AST, so maybe it is not that indicative. It is not blocking me, please take your time",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2878:4086,Usability,simpl,simplistic,4086,"raversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.format(SyntaxFormatter.scala:73); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:52); at wdltool.Main$$anonfun$highlight$2$$anonfun$apply$2.apply(Main.scala:50); at wdltool.Main$.wdltool$Main$$loadWdl(Main.scala:98); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$$anonfun$highlight$2.apply(Main.scala:50); at wdltool.Main$.continueIf(Main.scala:94); at wdltool.Main$.highlight(Main.scala:49); at wdltool.Main$.dispatchCommand(Main.scala:34); at wdltool.Main$.delayedEndpoint$wdltool$Main$1(Main.scala:151); at wdltool.Main$delayedInit$body.apply(Main.scala:12); at scala.Function0$class.apply$mcV$sp(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:381); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35); at scala.App$class.main(App.scala:76); at wdltool.Main$.main(Main.scala:12); at wdltool.Main.main(Main.scala). ```. ---. @geoffjentry commented on [Thu Jan 26 2017](https://github.com/broadinstitute/wdltool/issues/22#issuecomment-275469010). @anton-khodak Thanks for noticing this! I didn't realize people actually used the highlighting, that's useful info in and of itself :). This looks to be a case where our unit test was overly simplistic. I have a fix but it'll likely be a day or two before it's in place. ---. @anton-khodak commented on [Thu Jan 26 2017](https://github.com/broadinstitute/wdltool/issues/22#issuecomment-275472773). @geoffjentry I wanted to use highlighting in secondary purposes, as a way of exporting WDL description in a parsable format other than AST, so maybe it is not that indicative. It is not blocking me, please take your time",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878
https://github.com/broadinstitute/cromwell/issues/2879:117,Security,validat,validate,117,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879
https://github.com/broadinstitute/cromwell/issues/2879:228,Security,validat,validation,228,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879
https://github.com/broadinstitute/cromwell/issues/2879:390,Security,validat,validate,390,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879
https://github.com/broadinstitute/cromwell/issues/2879:500,Security,validat,validate,500,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879
https://github.com/broadinstitute/cromwell/issues/2879:586,Security,validat,validate,586,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879
https://github.com/broadinstitute/cromwell/issues/2880:602,Availability,error,error,602,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:730,Availability,error,error,730,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:800,Availability,Error,Error,800,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:286,Modifiability,variab,variable,286,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:818,Modifiability,variab,variable,818,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:868,Usability,simpl,simpleVariantSelection,868,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2880:952,Usability,simpl,simpleVariantSelection,952,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880
https://github.com/broadinstitute/cromwell/issues/2881:412,Availability,echo,echo,412,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881
https://github.com/broadinstitute/cromwell/issues/2881:126,Security,validat,validation,126,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881
https://github.com/broadinstitute/cromwell/issues/2881:173,Security,validat,validation,173,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881
https://github.com/broadinstitute/cromwell/issues/2881:325,Usability,simpl,simple,325,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881
https://github.com/broadinstitute/cromwell/issues/2881:375,Usability,simpl,simple,375,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881
https://github.com/broadinstitute/cromwell/issues/2882:836,Energy Efficiency,efficient,efficient,836,"@pshapiro4broad commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36). We would like to automate the process of validating a JSON input file against our WDL. Using the `inputs` command is helpful but it would be even easier to use for validation if `wdltool` had a command that generates the JSON schema for the inputs. The format for a JSON schema is here: http://json-schema.org/. ---. @geoffjentry commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36#issuecomment-319471781). Not a comment on the actual topic but just a heads up that the `wdltool` repo is one of the dustiest corners in terms of developer attention :). Also since `wdltool` is really just a command line wrapper around `wdl4s`, really any functionality request would involve a ticket there, might be more efficient to cut out the middle man and go there w/ these requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2882
https://github.com/broadinstitute/cromwell/issues/2882:735,Integrability,wrap,wrapper,735,"@pshapiro4broad commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36). We would like to automate the process of validating a JSON input file against our WDL. Using the `inputs` command is helpful but it would be even easier to use for validation if `wdltool` had a command that generates the JSON schema for the inputs. The format for a JSON schema is here: http://json-schema.org/. ---. @geoffjentry commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36#issuecomment-319471781). Not a comment on the actual topic but just a heads up that the `wdltool` repo is one of the dustiest corners in terms of developer attention :). Also since `wdltool` is really just a command line wrapper around `wdl4s`, really any functionality request would involve a ticket there, might be more efficient to cut out the middle man and go there w/ these requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2882
https://github.com/broadinstitute/cromwell/issues/2882:142,Security,validat,validating,142,"@pshapiro4broad commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36). We would like to automate the process of validating a JSON input file against our WDL. Using the `inputs` command is helpful but it would be even easier to use for validation if `wdltool` had a command that generates the JSON schema for the inputs. The format for a JSON schema is here: http://json-schema.org/. ---. @geoffjentry commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36#issuecomment-319471781). Not a comment on the actual topic but just a heads up that the `wdltool` repo is one of the dustiest corners in terms of developer attention :). Also since `wdltool` is really just a command line wrapper around `wdl4s`, really any functionality request would involve a ticket there, might be more efficient to cut out the middle man and go there w/ these requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2882
https://github.com/broadinstitute/cromwell/issues/2882:265,Security,validat,validation,265,"@pshapiro4broad commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36). We would like to automate the process of validating a JSON input file against our WDL. Using the `inputs` command is helpful but it would be even easier to use for validation if `wdltool` had a command that generates the JSON schema for the inputs. The format for a JSON schema is here: http://json-schema.org/. ---. @geoffjentry commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36#issuecomment-319471781). Not a comment on the actual topic but just a heads up that the `wdltool` repo is one of the dustiest corners in terms of developer attention :). Also since `wdltool` is really just a command line wrapper around `wdl4s`, really any functionality request would involve a ticket there, might be more efficient to cut out the middle man and go there w/ these requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2882
https://github.com/broadinstitute/cromwell/issues/2883:297,Availability,error,error,297,"@ruchim commented on [Thu Aug 24 2017](https://github.com/broadinstitute/wdltool/issues/46). When validating the workflow below with wdltool-0.14.jar, the response is simply ""null"". . ```; workflow w {; String s = ""test"". output {; String o =; }; }; ```; It would be great if a more comprehensive error is returned in the case of invalid workflow outputs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883
https://github.com/broadinstitute/cromwell/issues/2883:98,Security,validat,validating,98,"@ruchim commented on [Thu Aug 24 2017](https://github.com/broadinstitute/wdltool/issues/46). When validating the workflow below with wdltool-0.14.jar, the response is simply ""null"". . ```; workflow w {; String s = ""test"". output {; String o =; }; }; ```; It would be great if a more comprehensive error is returned in the case of invalid workflow outputs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883
https://github.com/broadinstitute/cromwell/issues/2883:215,Testability,test,test,215,"@ruchim commented on [Thu Aug 24 2017](https://github.com/broadinstitute/wdltool/issues/46). When validating the workflow below with wdltool-0.14.jar, the response is simply ""null"". . ```; workflow w {; String s = ""test"". output {; String o =; }; }; ```; It would be great if a more comprehensive error is returned in the case of invalid workflow outputs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883
https://github.com/broadinstitute/cromwell/issues/2883:167,Usability,simpl,simply,167,"@ruchim commented on [Thu Aug 24 2017](https://github.com/broadinstitute/wdltool/issues/46). When validating the workflow below with wdltool-0.14.jar, the response is simply ""null"". . ```; workflow w {; String s = ""test"". output {; String o =; }; }; ```; It would be great if a more comprehensive error is returned in the case of invalid workflow outputs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883
https://github.com/broadinstitute/cromwell/issues/2884:138,Testability,test,test,138,@ruchim commented on [Wed Mar 16 2016](https://github.com/broadinstitute/centaur/issues/16). Enable the following functionality and write test(s) to exercise it in the new framework:; When workflow options specifies final output copying that the outputs are in the correct place; When workflow options specifies log copying that the logs are in the correct place; When both are specified both are correctly working,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2884
https://github.com/broadinstitute/cromwell/issues/2884:312,Testability,log,log,312,@ruchim commented on [Wed Mar 16 2016](https://github.com/broadinstitute/centaur/issues/16). Enable the following functionality and write test(s) to exercise it in the new framework:; When workflow options specifies final output copying that the outputs are in the correct place; When workflow options specifies log copying that the logs are in the correct place; When both are specified both are correctly working,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2884
https://github.com/broadinstitute/cromwell/issues/2884:333,Testability,log,logs,333,@ruchim commented on [Wed Mar 16 2016](https://github.com/broadinstitute/centaur/issues/16). Enable the following functionality and write test(s) to exercise it in the new framework:; When workflow options specifies final output copying that the outputs are in the correct place; When workflow options specifies log copying that the logs are in the correct place; When both are specified both are correctly working,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2884
https://github.com/broadinstitute/cromwell/issues/2885:303,Availability,robust,robust,303,"@geoffjentry commented on [Tue Apr 26 2016](https://github.com/broadinstitute/centaur/issues/36). Initially Centaur loaded in its files for each test (wdl, inputs, etc) using a function which would throw an exception if it wasn't there. As the framework has evolved it has moved to a model that is more robust and would more accurately report what was going on there. Modify these file slurps to play nicer with the rest of the system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2885
https://github.com/broadinstitute/cromwell/issues/2885:258,Modifiability,evolve,evolved,258,"@geoffjentry commented on [Tue Apr 26 2016](https://github.com/broadinstitute/centaur/issues/36). Initially Centaur loaded in its files for each test (wdl, inputs, etc) using a function which would throw an exception if it wasn't there. As the framework has evolved it has moved to a model that is more robust and would more accurately report what was going on there. Modify these file slurps to play nicer with the rest of the system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2885
https://github.com/broadinstitute/cromwell/issues/2885:116,Performance,load,loaded,116,"@geoffjentry commented on [Tue Apr 26 2016](https://github.com/broadinstitute/centaur/issues/36). Initially Centaur loaded in its files for each test (wdl, inputs, etc) using a function which would throw an exception if it wasn't there. As the framework has evolved it has moved to a model that is more robust and would more accurately report what was going on there. Modify these file slurps to play nicer with the rest of the system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2885
https://github.com/broadinstitute/cromwell/issues/2885:145,Testability,test,test,145,"@geoffjentry commented on [Tue Apr 26 2016](https://github.com/broadinstitute/centaur/issues/36). Initially Centaur loaded in its files for each test (wdl, inputs, etc) using a function which would throw an exception if it wasn't there. As the framework has evolved it has moved to a model that is more robust and would more accurately report what was going on there. Modify these file slurps to play nicer with the rest of the system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2885
https://github.com/broadinstitute/cromwell/issues/2886:317,Deployability,integrat,integration,317,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:317,Integrability,integrat,integration,317,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:176,Testability,test,tests,176,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:226,Testability,test,tests,226,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:284,Testability,test,test,284,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:329,Testability,test,tests,329,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2886:265,Usability,simpl,simply,265,"@geoffjentry commented on [Wed May 04 2016](https://github.com/broadinstitute/centaur/issues/38). Now that the centaur code base is starting to accumulate code that's not just tests, we should start having actual centaur unit tests as well. That'll be a little odd simply because sbt test will run both those and the integration tests but i'm sure we'll manage",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2886
https://github.com/broadinstitute/cromwell/issues/2887:966,Availability,down,down,966,"@mcovarr commented on [Thu Aug 04 2016](https://github.com/broadinstitute/centaur/issues/95). It looks like most of the shards are successful, but one fails and might not be retried:. ```; 2016-08-03 15:20:01,502 cromwell-system-akka.dispatchers.backend-dispatcher-107 INFO - $a [UUID(eaeaa32d)DeliciousFileSpam.StringSpam:215:1]: JesAsyncBackendJobExecutionActor [UUID(eaeaa32d):DeliciousFileSpam.StringSpam:215:1] Status change from Running to Success; 2016-08-03 15:20:01,923 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: Job DeliciousFileSpam.StringSpam:215:1 succeeded!; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] transitioning from WorkflowExecutionInProgressState to WorkflowExecutionFailedState. Shutting down.; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] done. Shutting down.; 2016-08-03 15:20:03,593 cromwell-system-akka.dispatchers.engine-dispatcher-85 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from ExecutingWorkflowState to FinalizingWorkflowState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationPendingState to FinalizationInProgressState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationInProgressState to FinalizationSucceededState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatche",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2887
https://github.com/broadinstitute/cromwell/issues/2887:1191,Availability,down,down,1191," 2016-08-03 15:20:01,502 cromwell-system-akka.dispatchers.backend-dispatcher-107 INFO - $a [UUID(eaeaa32d)DeliciousFileSpam.StringSpam:215:1]: JesAsyncBackendJobExecutionActor [UUID(eaeaa32d):DeliciousFileSpam.StringSpam:215:1] Status change from Running to Success; 2016-08-03 15:20:01,923 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: Job DeliciousFileSpam.StringSpam:215:1 succeeded!; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] transitioning from WorkflowExecutionInProgressState to WorkflowExecutionFailedState. Shutting down.; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] done. Shutting down.; 2016-08-03 15:20:03,593 cromwell-system-akka.dispatchers.engine-dispatcher-85 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from ExecutingWorkflowState to FinalizingWorkflowState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationPendingState to FinalizationInProgressState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationInProgressState to FinalizationSucceededState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from FinalizingWorkflowState to WorkflowFailedState; 2016-08-03 15:20:03,594 cromwell-system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2887
https://github.com/broadinstitute/cromwell/issues/2887:2378,Availability,down,down,2378,"tting down.; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] done. Shutting down.; 2016-08-03 15:20:03,593 cromwell-system-akka.dispatchers.engine-dispatcher-85 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from ExecutingWorkflowState to FinalizingWorkflowState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationPendingState to FinalizationInProgressState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationInProgressState to FinalizationSucceededState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from FinalizingWorkflowState to WorkflowFailedState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transition from FinalizingWorkflowState to WorkflowFailedState. Shutting down.; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-68 ERROR - WorkflowManagerActor Workflow eaeaa32d-057d-4f2e-b986-6e8b738dd512 failed (during ExecutingWorkflowState): wdl4s.util.AggregatedException: Error reading gs://miguel-cromwell-dev/DeliciousFileSpam/eaeaa32d-057d-4f2e-b986-6e8b738dd512/call-StringSpam/shard-237/file.txt at position 0; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-133 INFO - WorkflowManagerActor WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 is in a terminal state: WorkflowFailedState; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2887
https://github.com/broadinstitute/cromwell/issues/2887:2463,Availability,ERROR,ERROR,2463,"tting down.; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] done. Shutting down.; 2016-08-03 15:20:03,593 cromwell-system-akka.dispatchers.engine-dispatcher-85 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from ExecutingWorkflowState to FinalizingWorkflowState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationPendingState to FinalizationInProgressState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationInProgressState to FinalizationSucceededState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from FinalizingWorkflowState to WorkflowFailedState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transition from FinalizingWorkflowState to WorkflowFailedState. Shutting down.; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-68 ERROR - WorkflowManagerActor Workflow eaeaa32d-057d-4f2e-b986-6e8b738dd512 failed (during ExecutingWorkflowState): wdl4s.util.AggregatedException: Error reading gs://miguel-cromwell-dev/DeliciousFileSpam/eaeaa32d-057d-4f2e-b986-6e8b738dd512/call-StringSpam/shard-237/file.txt at position 0; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-133 INFO - WorkflowManagerActor WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 is in a terminal state: WorkflowFailedState; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2887
https://github.com/broadinstitute/cromwell/issues/2887:2610,Availability,Error,Error,2610,"tting down.; 2016-08-03 15:20:03,592 cromwell-system-akka.dispatchers.engine-dispatcher-86 INFO - WorkflowExecutionActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: WorkflowExecutionActor [UUID(eaeaa32d)] done. Shutting down.; 2016-08-03 15:20:03,593 cromwell-system-akka.dispatchers.engine-dispatcher-85 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from ExecutingWorkflowState to FinalizingWorkflowState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationPendingState to FinalizationInProgressState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-84 INFO - WorkflowFinalizationActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: State is transitioning from FinalizationInProgressState to FinalizationSucceededState.; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transitioning from FinalizingWorkflowState to WorkflowFailedState; 2016-08-03 15:20:03,594 cromwell-system-akka.dispatchers.engine-dispatcher-138 INFO - WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 [UUID(eaeaa32d)]: transition from FinalizingWorkflowState to WorkflowFailedState. Shutting down.; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-68 ERROR - WorkflowManagerActor Workflow eaeaa32d-057d-4f2e-b986-6e8b738dd512 failed (during ExecutingWorkflowState): wdl4s.util.AggregatedException: Error reading gs://miguel-cromwell-dev/DeliciousFileSpam/eaeaa32d-057d-4f2e-b986-6e8b738dd512/call-StringSpam/shard-237/file.txt at position 0; 2016-08-03 15:20:03,595 cromwell-system-akka.dispatchers.engine-dispatcher-133 INFO - WorkflowManagerActor WorkflowActor-eaeaa32d-057d-4f2e-b986-6e8b738dd512 is in a terminal state: WorkflowFailedState; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2887
https://github.com/broadinstitute/cromwell/issues/2888:189,Usability,guid,guide,189,"Clean up and a little more polish for the docs, as time allows. Review:; - [x] [Execution twists](http://cromwell.readthedocs.io/en/develop/execution/ExecutionTwists/); - [ ] Address [user guide feedback](https://docs.google.com/document/d/1WOuxoZoRpkhZM6AAjszQTYhHx0qQyN3t4Q8-csh25zE/edit?ts=59f3aa92); - [x] Readme on Cromwell has a broken link, ""First time to Cromwell? Get started with **_Tutorials_**!""; - [x] Changelog that docs have moved and links. Related:; - [x] #2812 ; - [ ] #2733 . If time:; - [ ] #2863",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2888
https://github.com/broadinstitute/cromwell/issues/2888:195,Usability,feedback,feedback,195,"Clean up and a little more polish for the docs, as time allows. Review:; - [x] [Execution twists](http://cromwell.readthedocs.io/en/develop/execution/ExecutionTwists/); - [ ] Address [user guide feedback](https://docs.google.com/document/d/1WOuxoZoRpkhZM6AAjszQTYhHx0qQyN3t4Q8-csh25zE/edit?ts=59f3aa92); - [x] Readme on Cromwell has a broken link, ""First time to Cromwell? Get started with **_Tutorials_**!""; - [x] Changelog that docs have moved and links. Related:; - [x] #2812 ; - [ ] #2733 . If time:; - [ ] #2863",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2888
https://github.com/broadinstitute/cromwell/issues/2889:508,Availability,failure,failure,508,"@mcovarr commented on [Fri Aug 05 2016](https://github.com/broadinstitute/centaur/issues/96). ---. @cjllanwarne commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268376059). @mcovarr what's the context of this ticket?. ---. @ruchim commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268390892). I believe he's referring to the test in Centaur? I notice today the test was set to ignored, even though we offer this wf failure mode. Perhaps its just outdated, I'll try un-ignoring the test. ---. @mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/96#issuecomment-276110656). Only seeing this now! Yes I was referring to the test in Centaur, and I just confirmed it still fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889
https://github.com/broadinstitute/cromwell/issues/2889:418,Testability,test,test,418,"@mcovarr commented on [Fri Aug 05 2016](https://github.com/broadinstitute/centaur/issues/96). ---. @cjllanwarne commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268376059). @mcovarr what's the context of this ticket?. ---. @ruchim commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268390892). I believe he's referring to the test in Centaur? I notice today the test was set to ignored, even though we offer this wf failure mode. Perhaps its just outdated, I'll try un-ignoring the test. ---. @mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/96#issuecomment-276110656). Only seeing this now! Yes I was referring to the test in Centaur, and I just confirmed it still fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889
https://github.com/broadinstitute/cromwell/issues/2889:454,Testability,test,test,454,"@mcovarr commented on [Fri Aug 05 2016](https://github.com/broadinstitute/centaur/issues/96). ---. @cjllanwarne commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268376059). @mcovarr what's the context of this ticket?. ---. @ruchim commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268390892). I believe he's referring to the test in Centaur? I notice today the test was set to ignored, even though we offer this wf failure mode. Perhaps its just outdated, I'll try un-ignoring the test. ---. @mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/96#issuecomment-276110656). Only seeing this now! Yes I was referring to the test in Centaur, and I just confirmed it still fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889
https://github.com/broadinstitute/cromwell/issues/2889:574,Testability,test,test,574,"@mcovarr commented on [Fri Aug 05 2016](https://github.com/broadinstitute/centaur/issues/96). ---. @cjllanwarne commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268376059). @mcovarr what's the context of this ticket?. ---. @ruchim commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268390892). I believe he's referring to the test in Centaur? I notice today the test was set to ignored, even though we offer this wf failure mode. Perhaps its just outdated, I'll try un-ignoring the test. ---. @mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/96#issuecomment-276110656). Only seeing this now! Yes I was referring to the test in Centaur, and I just confirmed it still fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889
https://github.com/broadinstitute/cromwell/issues/2889:751,Testability,test,test,751,"@mcovarr commented on [Fri Aug 05 2016](https://github.com/broadinstitute/centaur/issues/96). ---. @cjllanwarne commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268376059). @mcovarr what's the context of this ticket?. ---. @ruchim commented on [Tue Dec 20 2016](https://github.com/broadinstitute/centaur/issues/96#issuecomment-268390892). I believe he's referring to the test in Centaur? I notice today the test was set to ignored, even though we offer this wf failure mode. Perhaps its just outdated, I'll try un-ignoring the test. ---. @mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/96#issuecomment-276110656). Only seeing this now! Yes I was referring to the test in Centaur, and I just confirmed it still fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889
https://github.com/broadinstitute/cromwell/issues/2890:179,Modifiability,Enhance,Enhance,179,"@mcovarr commented on [Wed Aug 10 2016](https://github.com/broadinstitute/centaur/issues/97). Per broadinstitute/cromwell#1275, we have no real test for the workflow outputs API. Enhance Centaur to be able to call the outputs API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2890
https://github.com/broadinstitute/cromwell/issues/2890:144,Testability,test,test,144,"@mcovarr commented on [Wed Aug 10 2016](https://github.com/broadinstitute/centaur/issues/97). Per broadinstitute/cromwell#1275, we have no real test for the workflow outputs API. Enhance Centaur to be able to call the outputs API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2890
https://github.com/broadinstitute/cromwell/issues/2891:255,Integrability,message,message,255,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:284,Safety,detect,detected,284,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:104,Testability,test,test,104,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:138,Testability,log,log,138,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:227,Testability,test,test,227,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:275,Testability,test,test,275,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2891:399,Testability,log,logged,399,"@kshakir commented on [Mon Jan 23 2017](https://github.com/broadinstitute/centaur/issues/134). For each test name, it would be helpful to log the workflowId, as the name of the WDL workflow doesn't always match the name of the test. Additionally, a brief message of when the test was detected as starting & stopped would help debug stuck workflows. If this is deemed too verbose, the above could be logged at level debug.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2891
https://github.com/broadinstitute/cromwell/issues/2892:1796,Availability,Ping,Pinging,1796,"the time being in favor of higher-priority work. Building on #140, confirm other JES parameters are making it to the VM as expected. . I have some WIP [here](https://github.com/broadinstitute/centaur/commit/d7f6a3aa26ea6abc37ce26c8399a39b30c9e9322). In developing this it became apparent that both GCE VM and JES metadata can be introspected, and in most cases this is boilerplate that would be common to all the `check_a_thing` tasks. This should be refactored out into a common script so it's not copy/pasted into each task. Probably the best way to do this is to have the inputs to each task include a common `String script` which would dump GCE VM and JES metadata to files. The `check_a_thing` tasks would then do something like:. ```; task check_a_thing {; String script; String specified_value_of_attr. command <<<; $(script) # writes jes_metadata.yaml and gce_metadata.yaml; grep -Po attr_pattern jes_metadata.yaml; >>>. output {; File jes_metadata = ""jes_metadata.yaml""; File gce_metadata = ""gce_metadata.yaml""; String attr_value = read_string(stdout()); }; ; runtime {; docker: ""google/cloud-sdk""; attr: ""${specified_value_of_attr}""; }; ```. This should confirm that Cromwell's intended attribute values are communicated into JES metadata correctly. It can also be useful to make sure that intent makes it to the GCE metadata correctly (this was particularly key for preemptible). And for attributes like memory or cpu it may also be useful to check that the machine is actually provisioned as expected (e.g. checking /proc/cpu or /proc/memory). ---. @ruchim commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144#issuecomment-276111326). Pinging @kcibul for prioritization -- Miguel brought this up at standup today that it's a very long list of JES attribute values that can be asserted against their expected values. If you believe any specific attribute (other than preemptible) would be an important addition to the tests, those tickets can be prioritized.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2892
https://github.com/broadinstitute/cromwell/issues/2892:569,Modifiability,refactor,refactored,569,"@mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144). Brain-dumping this for the time being in favor of higher-priority work. Building on #140, confirm other JES parameters are making it to the VM as expected. . I have some WIP [here](https://github.com/broadinstitute/centaur/commit/d7f6a3aa26ea6abc37ce26c8399a39b30c9e9322). In developing this it became apparent that both GCE VM and JES metadata can be introspected, and in most cases this is boilerplate that would be common to all the `check_a_thing` tasks. This should be refactored out into a common script so it's not copy/pasted into each task. Probably the best way to do this is to have the inputs to each task include a common `String script` which would dump GCE VM and JES metadata to files. The `check_a_thing` tasks would then do something like:. ```; task check_a_thing {; String script; String specified_value_of_attr. command <<<; $(script) # writes jes_metadata.yaml and gce_metadata.yaml; grep -Po attr_pattern jes_metadata.yaml; >>>. output {; File jes_metadata = ""jes_metadata.yaml""; File gce_metadata = ""gce_metadata.yaml""; String attr_value = read_string(stdout()); }; ; runtime {; docker: ""google/cloud-sdk""; attr: ""${specified_value_of_attr}""; }; ```. This should confirm that Cromwell's intended attribute values are communicated into JES metadata correctly. It can also be useful to make sure that intent makes it to the GCE metadata correctly (this was particularly key for preemptible). And for attributes like memory or cpu it may also be useful to check that the machine is actually provisioned as expected (e.g. checking /proc/cpu or /proc/memory). ---. @ruchim commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144#issuecomment-276111326). Pinging @kcibul for prioritization -- Miguel brought this up at standup today that it's a very long list of JES attribute values that can be asserted against their expected values. If you believe any speci",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2892
https://github.com/broadinstitute/cromwell/issues/2892:1937,Testability,assert,asserted,1937,"the time being in favor of higher-priority work. Building on #140, confirm other JES parameters are making it to the VM as expected. . I have some WIP [here](https://github.com/broadinstitute/centaur/commit/d7f6a3aa26ea6abc37ce26c8399a39b30c9e9322). In developing this it became apparent that both GCE VM and JES metadata can be introspected, and in most cases this is boilerplate that would be common to all the `check_a_thing` tasks. This should be refactored out into a common script so it's not copy/pasted into each task. Probably the best way to do this is to have the inputs to each task include a common `String script` which would dump GCE VM and JES metadata to files. The `check_a_thing` tasks would then do something like:. ```; task check_a_thing {; String script; String specified_value_of_attr. command <<<; $(script) # writes jes_metadata.yaml and gce_metadata.yaml; grep -Po attr_pattern jes_metadata.yaml; >>>. output {; File jes_metadata = ""jes_metadata.yaml""; File gce_metadata = ""gce_metadata.yaml""; String attr_value = read_string(stdout()); }; ; runtime {; docker: ""google/cloud-sdk""; attr: ""${specified_value_of_attr}""; }; ```. This should confirm that Cromwell's intended attribute values are communicated into JES metadata correctly. It can also be useful to make sure that intent makes it to the GCE metadata correctly (this was particularly key for preemptible). And for attributes like memory or cpu it may also be useful to check that the machine is actually provisioned as expected (e.g. checking /proc/cpu or /proc/memory). ---. @ruchim commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144#issuecomment-276111326). Pinging @kcibul for prioritization -- Miguel brought this up at standup today that it's a very long list of JES attribute values that can be asserted against their expected values. If you believe any specific attribute (other than preemptible) would be an important addition to the tests, those tickets can be prioritized.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2892
https://github.com/broadinstitute/cromwell/issues/2892:2078,Testability,test,tests,2078,"the time being in favor of higher-priority work. Building on #140, confirm other JES parameters are making it to the VM as expected. . I have some WIP [here](https://github.com/broadinstitute/centaur/commit/d7f6a3aa26ea6abc37ce26c8399a39b30c9e9322). In developing this it became apparent that both GCE VM and JES metadata can be introspected, and in most cases this is boilerplate that would be common to all the `check_a_thing` tasks. This should be refactored out into a common script so it's not copy/pasted into each task. Probably the best way to do this is to have the inputs to each task include a common `String script` which would dump GCE VM and JES metadata to files. The `check_a_thing` tasks would then do something like:. ```; task check_a_thing {; String script; String specified_value_of_attr. command <<<; $(script) # writes jes_metadata.yaml and gce_metadata.yaml; grep -Po attr_pattern jes_metadata.yaml; >>>. output {; File jes_metadata = ""jes_metadata.yaml""; File gce_metadata = ""gce_metadata.yaml""; String attr_value = read_string(stdout()); }; ; runtime {; docker: ""google/cloud-sdk""; attr: ""${specified_value_of_attr}""; }; ```. This should confirm that Cromwell's intended attribute values are communicated into JES metadata correctly. It can also be useful to make sure that intent makes it to the GCE metadata correctly (this was particularly key for preemptible). And for attributes like memory or cpu it may also be useful to check that the machine is actually provisioned as expected (e.g. checking /proc/cpu or /proc/memory). ---. @ruchim commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144#issuecomment-276111326). Pinging @kcibul for prioritization -- Miguel brought this up at standup today that it's a very long list of JES attribute values that can be asserted against their expected values. If you believe any specific attribute (other than preemptible) would be an important addition to the tests, those tickets can be prioritized.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2892
https://github.com/broadinstitute/cromwell/issues/2895:103,Testability,test,test,103,@ruchim commented on [Fri May 12 2017](https://github.com/broadinstitute/centaur/issues/190). Create a test that passes all WDL Types through the workflow inputs json.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2895
https://github.com/broadinstitute/cromwell/issues/2896:229,Modifiability,config,config,229,"@Horneth commented on [Fri May 12 2017](https://github.com/broadinstitute/centaur/issues/191). This is not necessarily a centaur ticket, more of a ""testing"" ticket. There is no easy way to test different **non-backend specific** config values of Cromwell in travis.; It would be nice to have some way to do that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2896
https://github.com/broadinstitute/cromwell/issues/2896:148,Testability,test,testing,148,"@Horneth commented on [Fri May 12 2017](https://github.com/broadinstitute/centaur/issues/191). This is not necessarily a centaur ticket, more of a ""testing"" ticket. There is no easy way to test different **non-backend specific** config values of Cromwell in travis.; It would be nice to have some way to do that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2896
https://github.com/broadinstitute/cromwell/issues/2896:189,Testability,test,test,189,"@Horneth commented on [Fri May 12 2017](https://github.com/broadinstitute/centaur/issues/191). This is not necessarily a centaur ticket, more of a ""testing"" ticket. There is no easy way to test different **non-backend specific** config values of Cromwell in travis.; It would be nice to have some way to do that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2896
https://github.com/broadinstitute/cromwell/issues/2897:126,Testability,test,tests,126,@geoffjentry commented on [Wed Oct 04 2017](https://github.com/broadinstitute/centaur/issues/234). Analogous to refresh token tests. Add a PAPI backend using user service account. Launch workflows using an account from a different project than cromwell's SA.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2897
https://github.com/broadinstitute/cromwell/issues/2898:150,Testability,test,test,150,"This could be painful in WOM, and I don't know whether anyone uses it, or whether we really want to support it... but if we do, reinstate the centaur test:; - [ ] `inter_scatter_dependencies`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2898
https://github.com/broadinstitute/cromwell/issues/2899:554,Availability,error,error,554,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:740,Availability,error,error,740,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:945,Deployability,update,updated,945,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:648,Security,checksum,checksum,648,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:139,Testability,test,tests,139,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:583,Testability,test,tests,583,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:1010,Testability,test,tests,1010,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/issues/2899:1148,Testability,test,test,1148,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899
https://github.com/broadinstitute/cromwell/pull/2900:68,Testability,test,tests,68,Good news: this PR reinstates globs and almost all relevant centaur tests.; Bad news: I gave the PR such an awful name that nobody wants to talk about it out loud.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2900
https://github.com/broadinstitute/cromwell/issues/2901:161,Integrability,depend,depend,161,"This seems to be the reason that this centaur test is failing even after #2900:; - [x] `globbingindex`; - [ ] `sub_workflow_var_refs` (in this case, the outputs depend on inputs)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2901
https://github.com/broadinstitute/cromwell/issues/2901:46,Testability,test,test,46,"This seems to be the reason that this centaur test is failing even after #2900:; - [x] `globbingindex`; - [ ] `sub_workflow_var_refs` (in this case, the outputs depend on inputs)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2901
https://github.com/broadinstitute/cromwell/issues/2902:907,Availability,down,downs,907,"This is against 29 but could also be an issue with the planned structure for 30. For comparison, a somewhat similar issue with subworkflow declaration evaluation [in 29](https://github.com/broadinstitute/wdl4s/pull/257) will inform the way subworkflow declaration evaluation should work in 30. An uninitialized optional declaration in a subworkflow kills the SubworkflowExecutionActor whether it is referenced or not. The workflow [here](https://github.com/broadinstitute/centaur/pull/242/files) is able to run against 29 hotfix with the patches in the [wdl4s](https://github.com/broadinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2288,Availability,ERROR,ERROR,2288,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:522,Deployability,hotfix,hotfix,522,"This is against 29 but could also be an issue with the planned structure for 30. For comparison, a somewhat similar issue with subworkflow declaration evaluation [in 29](https://github.com/broadinstitute/wdl4s/pull/257) will inform the way subworkflow declaration evaluation should work in 30. An uninitialized optional declaration in a subworkflow kills the SubworkflowExecutionActor whether it is referenced or not. The workflow [here](https://github.com/broadinstitute/centaur/pull/242/files) is able to run against 29 hotfix with the patches in the [wdl4s](https://github.com/broadinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:538,Deployability,patch,patches,538,"This is against 29 but could also be an issue with the planned structure for 30. For comparison, a somewhat similar issue with subworkflow declaration evaluation [in 29](https://github.com/broadinstitute/wdl4s/pull/257) will inform the way subworkflow declaration evaluation should work in 30. An uninitialized optional declaration in a subworkflow kills the SubworkflowExecutionActor whether it is referenced or not. The workflow [here](https://github.com/broadinstitute/centaur/pull/242/files) is able to run against 29 hotfix with the patches in the [wdl4s](https://github.com/broadinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2117,Deployability,configurat,configuration,2117,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:880,Integrability,wrap,wrap,880,"This is against 29 but could also be an issue with the planned structure for 30. For comparison, a somewhat similar issue with subworkflow declaration evaluation [in 29](https://github.com/broadinstitute/wdl4s/pull/257) will inform the way subworkflow declaration evaluation should work in 30. An uninitialized optional declaration in a subworkflow kills the SubworkflowExecutionActor whether it is referenced or not. The workflow [here](https://github.com/broadinstitute/centaur/pull/242/files) is able to run against 29 hotfix with the patches in the [wdl4s](https://github.com/broadinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:1590,Integrability,Message,Message,1590,"dinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2117,Modifiability,config,configuration,2117,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2074,Testability,log,logging,2074,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2146,Testability,log,log-dead-letters,2146,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2902:2174,Testability,log,log-dead-letters-during-shutdown,2174,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902
https://github.com/broadinstitute/cromwell/issues/2903:267,Deployability,release,release,267,"We're soon to have a staging environment for CaaS, which is great for multiple reasons - including we said that we wanted a staging environment to help test upgrading versions of Cromwell. It'd be great to be able to point Centaur at this Cromwell (at least prior to release) but I don't believe Centaur will be able to do that due to auth reasons. . NB: It's possible that we might be able to point centaur directly at the underlying Cromwell server which would be a Good Enough For Now thing (depending on when this is picked up), worth exploring",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2903
https://github.com/broadinstitute/cromwell/issues/2903:495,Integrability,depend,depending,495,"We're soon to have a staging environment for CaaS, which is great for multiple reasons - including we said that we wanted a staging environment to help test upgrading versions of Cromwell. It'd be great to be able to point Centaur at this Cromwell (at least prior to release) but I don't believe Centaur will be able to do that due to auth reasons. . NB: It's possible that we might be able to point centaur directly at the underlying Cromwell server which would be a Good Enough For Now thing (depending on when this is picked up), worth exploring",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2903
https://github.com/broadinstitute/cromwell/issues/2903:152,Testability,test,test,152,"We're soon to have a staging environment for CaaS, which is great for multiple reasons - including we said that we wanted a staging environment to help test upgrading versions of Cromwell. It'd be great to be able to point Centaur at this Cromwell (at least prior to release) but I don't believe Centaur will be able to do that due to auth reasons. . NB: It's possible that we might be able to point centaur directly at the underlying Cromwell server which would be a Good Enough For Now thing (depending on when this is picked up), worth exploring",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2903
https://github.com/broadinstitute/cromwell/issues/2904:39,Availability,failure,failure,39,For whatever reason I get a different `failure`/`causedBy` stack when I run these locally vs in travis. I'm probably being stupid 🤷‍♂️. . Reinstate these centaur tests:; - [x] `invalid_runtime_attributes`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2904
https://github.com/broadinstitute/cromwell/issues/2904:162,Testability,test,tests,162,For whatever reason I get a different `failure`/`causedBy` stack when I run these locally vs in travis. I'm probably being stupid 🤷‍♂️. . Reinstate these centaur tests:; - [x] `invalid_runtime_attributes`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2904
https://github.com/broadinstitute/cromwell/issues/2905:33,Deployability,configurat,configuration,33,"This might be related to centaur configuration, which IIRC requires specific, non-default, options for this test. NB fails on both `centaurLocal` and `centaurTest`. Once fixed, reinstate centaur test:; - [x] `invalidate_bad_caches_local`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905
https://github.com/broadinstitute/cromwell/issues/2905:33,Modifiability,config,configuration,33,"This might be related to centaur configuration, which IIRC requires specific, non-default, options for this test. NB fails on both `centaurLocal` and `centaurTest`. Once fixed, reinstate centaur test:; - [x] `invalidate_bad_caches_local`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905
https://github.com/broadinstitute/cromwell/issues/2905:108,Testability,test,test,108,"This might be related to centaur configuration, which IIRC requires specific, non-default, options for this test. NB fails on both `centaurLocal` and `centaurTest`. Once fixed, reinstate centaur test:; - [x] `invalidate_bad_caches_local`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905
https://github.com/broadinstitute/cromwell/issues/2905:195,Testability,test,test,195,"This might be related to centaur configuration, which IIRC requires specific, non-default, options for this test. NB fails on both `centaurLocal` and `centaurTest`. Once fixed, reinstate centaur test:; - [x] `invalidate_bad_caches_local`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905
https://github.com/broadinstitute/cromwell/issues/2912:377,Availability,failure,failure,377,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:516,Availability,failure,failures,516,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:550,Availability,failure,failures,550,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:3077,Availability,error,error,3077,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:3807,Availability,error,error,3807,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:385,Integrability,message,message,385,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:598,Integrability,message,message,598,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:709,Integrability,message,message,709,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:834,Integrability,message,message,834,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:945,Integrability,message,message,945,"I am trying to run a workflow with a subworkflow that has some workflow level inputs. Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1075,Integrability,message,message,1075," Somethign along the lines of ; ```; Workflow subWorkflow {. File f; String s; ...; ...; }; ```. ```; import ""file/path/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1194,Integrability,message,message,1194,"/subworkflow.wdl"" as sub. workflow root {; call sub.subWorkflow as aliasSub; }; ```. When I try to pass the values for `File f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlig",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1317,Integrability,message,message,1317,"e f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1443,Integrability,message,message,1443,"son I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1554,Integrability,message,message,1554,"; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1675,Integrability,message,message,1675," },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlign",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1785,Integrability,message,message,1785,"ot specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:1912,Integrability,message,message,1912,"},; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2038,Integrability,message,message,2038,".""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2149,Integrability,message,message,2149,"pecified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2260,Integrability,message,message,2260,"uffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2390,Integrability,message,message,2390,"d' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2502,Integrability,message,message,2502,"' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerpri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2629,Integrability,message,message,2629,"specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2742,Integrability,message,message,2742,"cified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2861,Integrability,message,message,2861,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:2958,Integrability,message,message,2958,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:3127,Integrability,message,message,3127,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2912:3646,Integrability,message,message,3646,"TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I'm passing in everything correctly but it could be an error on my part as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912
https://github.com/broadinstitute/cromwell/issues/2914:480,Deployability,pipeline,pipeline,480,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:97,Modifiability,variab,variable,97,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:570,Modifiability,variab,variable,570,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:149,Testability,test,test,149,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:292,Testability,test,test,292,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:369,Testability,test,test,369,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:397,Testability,test,test,397,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2914:426,Testability,test,test,426,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914
https://github.com/broadinstitute/cromwell/issues/2915:4,Deployability,configurat,configuration,4,"The configuration option ""final_workflow_outputs_dir"" is misleading. ; What many users commonly want to do is just to copy final results to the folder in case if the workflow succeded. Right now this option copies standard nested-trash like ""MyWorkflow/bc5f9f3e-0daf-4ee3-b0c2-35971af26772/call-hello/execution"" Although this nested structure is useful for the debugging, it is not what we expect as a final result. ; I suggest giving an option for a folder where _only_ final files will be copied without any nested folders and debugging files/logs/whatsoever.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2915
https://github.com/broadinstitute/cromwell/issues/2915:4,Modifiability,config,configuration,4,"The configuration option ""final_workflow_outputs_dir"" is misleading. ; What many users commonly want to do is just to copy final results to the folder in case if the workflow succeded. Right now this option copies standard nested-trash like ""MyWorkflow/bc5f9f3e-0daf-4ee3-b0c2-35971af26772/call-hello/execution"" Although this nested structure is useful for the debugging, it is not what we expect as a final result. ; I suggest giving an option for a folder where _only_ final files will be copied without any nested folders and debugging files/logs/whatsoever.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2915
https://github.com/broadinstitute/cromwell/issues/2915:545,Testability,log,logs,545,"The configuration option ""final_workflow_outputs_dir"" is misleading. ; What many users commonly want to do is just to copy final results to the folder in case if the workflow succeded. Right now this option copies standard nested-trash like ""MyWorkflow/bc5f9f3e-0daf-4ee3-b0c2-35971af26772/call-hello/execution"" Although this nested structure is useful for the debugging, it is not what we expect as a final result. ; I suggest giving an option for a folder where _only_ final files will be copied without any nested folders and debugging files/logs/whatsoever.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2915
https://github.com/broadinstitute/cromwell/issues/2916:212,Availability,down,download,212,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:373,Availability,error,error,373,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:3606,Availability,error,error,3606,"g calls: atac.filter:1:1; [2017-11-18 19:30:05,51] [warn] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Unrecognized runtime attribute keys: time; [2017-11-18 19:30:05,52] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:3754,Availability,error,error,3754,"untime attribute keys: time; [2017-11-18 19:30:05,52] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4503,Availability,error,error,4503,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:18,Deployability,pipeline,pipeline,18,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:237,Deployability,pipeline,pipeline,237,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:851,Deployability,pipeline,pipeline-genome-data,851,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:960,Deployability,pipeline,pipeline-workflows,960,"ipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01:30,30] [info] Jes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:1325,Deployability,pipeline,pipeline-genome-data,1325,"s"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from - to Initializing; [2017-11-18 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from - to Initializing; [2017-11-18 17:44:21,09] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:1434,Deployability,pipeline,pipeline-workflows,1434,"at [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from - to Initializing; [2017-11-18 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from - to Initializing; [2017-11-18 17:44:21,09] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from Initializing to Running; [2017-11-18 19:30:04,06] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change fro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:2939,Deployability,pipeline,pipeline-workflows,2939," 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from - to Initializing; [2017-11-18 16:01:30,30] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from - to Initializing; [2017-11-18 17:44:21,09] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from Initializing to Running; [2017-11-18 19:30:04,06] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: Status change from Running to Success; [2017-11-18 19:30:05,51] [info] WorkflowExecutionActor-d57a5f97-8542-4fcc-89c4-b7c487957dea [d57a5f97]: Starting calls: atac.filter:1:1; [2017-11-18 19:30:05,51] [warn] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Unrecognized runtime attribute keys: time; [2017-11-18 19:30:05,52] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:3857,Deployability,pipeline,pipeline-genome-data,3857,"tor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:3967,Deployability,pipeline,pipeline-genome-data,3967,"2-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4091,Deployability,pipeline,pipeline-genome-data,4091," \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket b",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4198,Deployability,pipeline,pipeline-genome-data,4198,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4606,Deployability,pipeline,pipeline-genome-data,4606,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4716,Deployability,pipeline,pipeline-genome-data,4716,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4840,Deployability,pipeline,pipeline-genome-data,4840,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4947,Deployability,pipeline,pipeline-genome-data,4947,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:3768,Integrability,Message,Message,3768,"tor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:4517,Integrability,Message,Message,4517,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2916:148,Security,authenticat,authenticated,148,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916
https://github.com/broadinstitute/cromwell/issues/2917:11,Testability,log,logs,11,"When I run logs API on workflow that failed before execution (for instance, when wdl file was damaged) and query for its logs I do not see ""calls"" field. I think it will be good just to give empty ; ```; ""calls"": {}; ```; field instead of omitting it at all.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2917
https://github.com/broadinstitute/cromwell/issues/2917:121,Testability,log,logs,121,"When I run logs API on workflow that failed before execution (for instance, when wdl file was damaged) and query for its logs I do not see ""calls"" field. I think it will be good just to give empty ; ```; ""calls"": {}; ```; field instead of omitting it at all.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2917
https://github.com/broadinstitute/cromwell/issues/2918:132,Security,validat,validating,132,It is sometimes inconvenient to use both WDLTool and Cromwell. Is it possible just to make a REST call in Cromwell specifically for validating WLDs and generating inputs? For people who also write UI-s that interact with Cromwell it will make life easier.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2918
https://github.com/broadinstitute/cromwell/issues/2919:111,Availability,failure,failure,111,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2919:518,Availability,echo,echo,518,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2919:719,Availability,error,error,719,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2919:524,Testability,test,testing,524,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2919:169,Usability,simpl,simply,169,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2919:783,Usability,simpl,simply,783,"In Cromwell 29, having a ':' character present in the filename of a non-glob task output results in a workflow failure. It does not matter whether this is hard-coded or simply in the filename. . `WorkflowManagerActor Workflow 1356670a-cea2-45b7-a9c4-e379dc601f9f failed (during ExecutingWorkflowState): Could not evaluate A.out = ""A:out""; java.lang.RuntimeException: Could not evaluate A.out = ""A:out""`. This is reproducible with the following wdl:; ```; workflow colon_filename{; 	call A {}; }. task A{; 	command{; 		echo ""testing"" > A:out; 	}; 	output{; 		File out = ""A:out""; 	}; }. ```; Task A completes normally with return code 0 and creates the file A:out. . I expected this workflow to complete normally without error. . Workaround; -; I have an acceptable workaround where I simply replace all ':' characters with '-'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919
https://github.com/broadinstitute/cromwell/issues/2924:212,Integrability,depend,depending,212,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924
https://github.com/broadinstitute/cromwell/issues/2924:203,Modifiability,variab,variable,203,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924
https://github.com/broadinstitute/cromwell/issues/2924:61,Security,validat,validates,61,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924
https://github.com/broadinstitute/cromwell/issues/2924:35,Testability,test,test,35,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924
https://github.com/broadinstitute/cromwell/issues/2924:514,Testability,test,test,514,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924
https://github.com/broadinstitute/cromwell/issues/2926:488,Availability,failure,failure,488,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2926:517,Availability,failure,failure,517,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2926:73,Integrability,message,message,73,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2926:554,Safety,safe,safely,554,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2926:32,Testability,test,test,32,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2926:68,Testability,log,log,68,"In PR #2925, the `no_new_calls` test sometimes generates a cromwell log [message](https://github.com/broadinstitute/cromwell/blob/c6ed64617c51c572863b87d324fa8e68fa085b1a/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L118-L121):. > Cromwell server was restarted while this workflow was running. As part of the restart process, Cromwell attempted to reconnect to this job, however it was never started in the first place. This is a benign failure and not the cause of failure for this workflow, it can be safely ignored. This occurs when cromwell is restarted while `shouldSucceed` is still running. `shouldSucceed` finishes, and then a `Restarting calls: no_new_calls.delayedTask:NA:1` is generated, even though `boundToFail` has already failed and NoNewCalls should be started. The easiest way to reproduce this locally and see the delay is to increase the sleep in the wdl from 100 to something like 300 (five minutes). FYI if cromwell is not restarted, `delayedTask` does not start, does not fail, and does not have a metadata stanza for the call.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2926
https://github.com/broadinstitute/cromwell/issues/2927:222,Modifiability,variab,variables,222,Many tools have thread/cores as parameter. It does not influence the end results but its change in inputs may be considered as cache invalidation by cromwell. It would be nice to have a way to tell cromwell to ignore some variables (like threads) in the caching process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927
https://github.com/broadinstitute/cromwell/issues/2927:127,Performance,cache,cache,127,Many tools have thread/cores as parameter. It does not influence the end results but its change in inputs may be considered as cache invalidation by cromwell. It would be nice to have a way to tell cromwell to ignore some variables (like threads) in the caching process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927
https://github.com/broadinstitute/cromwell/issues/2928:141,Deployability,pipeline,pipelines,141,"Currently when I ask for metadata or for logs, I get something like:; ```; {; ""calls"": {; ""annotate_de_novo.transdecoder"": [; {; ""stderr"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stderr"",; ""stdout"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stdout"",; ""attempt"": 1,; ""shardIndex"": -1; }; ]; },; ""id"": ""e64a866e-d5c1-4779-8f9d-75457f22f43e""; }; ```; All the details about what really happened (stderr and stdout of the tools that failed) are not accessible via REST API and I have to ssh to the server to read those files. What can be useful is to have a way to get stdout/stderr content for each call with Cromwell REST API, that can save a lot of time on ssh-ing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928
https://github.com/broadinstitute/cromwell/issues/2928:286,Deployability,pipeline,pipelines,286,"Currently when I ask for metadata or for logs, I get something like:; ```; {; ""calls"": {; ""annotate_de_novo.transdecoder"": [; {; ""stderr"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stderr"",; ""stdout"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stdout"",; ""attempt"": 1,; ""shardIndex"": -1; }; ]; },; ""id"": ""e64a866e-d5c1-4779-8f9d-75457f22f43e""; }; ```; All the details about what really happened (stderr and stdout of the tools that failed) are not accessible via REST API and I have to ssh to the server to read those files. What can be useful is to have a way to get stdout/stderr content for each call with Cromwell REST API, that can save a lot of time on ssh-ing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928
https://github.com/broadinstitute/cromwell/issues/2928:612,Security,access,accessible,612,"Currently when I ask for metadata or for logs, I get something like:; ```; {; ""calls"": {; ""annotate_de_novo.transdecoder"": [; {; ""stderr"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stderr"",; ""stdout"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stdout"",; ""attempt"": 1,; ""shardIndex"": -1; }; ]; },; ""id"": ""e64a866e-d5c1-4779-8f9d-75457f22f43e""; }; ```; All the details about what really happened (stderr and stdout of the tools that failed) are not accessible via REST API and I have to ssh to the server to read those files. What can be useful is to have a way to get stdout/stderr content for each call with Cromwell REST API, that can save a lot of time on ssh-ing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928
https://github.com/broadinstitute/cromwell/issues/2928:41,Testability,log,logs,41,"Currently when I ask for metadata or for logs, I get something like:; ```; {; ""calls"": {; ""annotate_de_novo.transdecoder"": [; {; ""stderr"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stderr"",; ""stdout"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stdout"",; ""attempt"": 1,; ""shardIndex"": -1; }; ]; },; ""id"": ""e64a866e-d5c1-4779-8f9d-75457f22f43e""; }; ```; All the details about what really happened (stderr and stdout of the tools that failed) are not accessible via REST API and I have to ssh to the server to read those files. What can be useful is to have a way to get stdout/stderr content for each call with Cromwell REST API, that can save a lot of time on ssh-ing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928
https://github.com/broadinstitute/cromwell/issues/2930:227,Deployability,release,release,227,"During the doc-a-thon, the version was manually added to [cromwell.yaml](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/engine/src/main/resources/swagger/cromwell.yaml#L8). However the release WDL was not updated to account for this change. Either this version should be [taken back out](https://github.com/broadinstitute/cromwell/blob/2c83f323f202b767a67b0f3058578a797d97082d/engine/src/main/resources/swagger/cromwell.yaml#L11) so it does not go out of sync with the code, or the version should be updated to the latest version by the [release WDL](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/release/release_workflow.wdl#L135-L140).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930
https://github.com/broadinstitute/cromwell/issues/2930:247,Deployability,update,updated,247,"During the doc-a-thon, the version was manually added to [cromwell.yaml](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/engine/src/main/resources/swagger/cromwell.yaml#L8). However the release WDL was not updated to account for this change. Either this version should be [taken back out](https://github.com/broadinstitute/cromwell/blob/2c83f323f202b767a67b0f3058578a797d97082d/engine/src/main/resources/swagger/cromwell.yaml#L11) so it does not go out of sync with the code, or the version should be updated to the latest version by the [release WDL](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/release/release_workflow.wdl#L135-L140).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930
https://github.com/broadinstitute/cromwell/issues/2930:542,Deployability,update,updated,542,"During the doc-a-thon, the version was manually added to [cromwell.yaml](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/engine/src/main/resources/swagger/cromwell.yaml#L8). However the release WDL was not updated to account for this change. Either this version should be [taken back out](https://github.com/broadinstitute/cromwell/blob/2c83f323f202b767a67b0f3058578a797d97082d/engine/src/main/resources/swagger/cromwell.yaml#L11) so it does not go out of sync with the code, or the version should be updated to the latest version by the [release WDL](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/release/release_workflow.wdl#L135-L140).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930
https://github.com/broadinstitute/cromwell/issues/2930:580,Deployability,release,release,580,"During the doc-a-thon, the version was manually added to [cromwell.yaml](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/engine/src/main/resources/swagger/cromwell.yaml#L8). However the release WDL was not updated to account for this change. Either this version should be [taken back out](https://github.com/broadinstitute/cromwell/blob/2c83f323f202b767a67b0f3058578a797d97082d/engine/src/main/resources/swagger/cromwell.yaml#L11) so it does not go out of sync with the code, or the version should be updated to the latest version by the [release WDL](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/release/release_workflow.wdl#L135-L140).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930
https://github.com/broadinstitute/cromwell/issues/2930:682,Deployability,release,release,682,"During the doc-a-thon, the version was manually added to [cromwell.yaml](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/engine/src/main/resources/swagger/cromwell.yaml#L8). However the release WDL was not updated to account for this change. Either this version should be [taken back out](https://github.com/broadinstitute/cromwell/blob/2c83f323f202b767a67b0f3058578a797d97082d/engine/src/main/resources/swagger/cromwell.yaml#L11) so it does not go out of sync with the code, or the version should be updated to the latest version by the [release WDL](https://github.com/broadinstitute/cromwell/blob/c3f7e2de32fa9129a15999fe04dde287388302d2/release/release_workflow.wdl#L135-L140).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930
https://github.com/broadinstitute/cromwell/pull/2931:11,Modifiability,variab,variable,11,Also a few variable renames. Sorry!. Fixes the first half of #2901,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2931
https://github.com/broadinstitute/cromwell/issues/2932:19,Availability,error,error,19,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:253,Availability,error,error,253,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:49,Integrability,message,message,49,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:97,Integrability,message,message,97,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:335,Safety,risk,risk,335,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:66,Security,validat,validation,66,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/issues/2932:309,Security,validat,validating,309,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932
https://github.com/broadinstitute/cromwell/pull/2935:70,Deployability,update,update,70,"Workflow submission has a form field `customLabels` whereas the label update endpoint has the form field `labels`. When one is trying to abstract logic involving labels to the akka http DSL this makes it yucky. There's no reason why these need to be different. Unify them to `labels` terminology. There are still internal references to customLabels, but not in a user visible way. edit: Looks like the command line API also has `labels` as the terminology",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2935
https://github.com/broadinstitute/cromwell/pull/2935:146,Testability,log,logic,146,"Workflow submission has a form field `customLabels` whereas the label update endpoint has the form field `labels`. When one is trying to abstract logic involving labels to the akka http DSL this makes it yucky. There's no reason why these need to be different. Unify them to `labels` terminology. There are still internal references to customLabels, but not in a user visible way. edit: Looks like the command line API also has `labels` as the terminology",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2935
https://github.com/broadinstitute/cromwell/issues/2937:17,Availability,error,errors,17,Otherwise we get errors when a subworkflow presents no outputs: ; - [x] `sub_workflow_var_refs`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2937
https://github.com/broadinstitute/cromwell/pull/2938:728,Availability,failure,failures,728,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:122,Deployability,integrat,integration,122,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:638,Energy Efficiency,reduce,reduce,638,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:36,Integrability,depend,dependency,36,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:122,Integrability,integrat,integration,122,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:354,Integrability,depend,dependencies,354,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:469,Integrability,depend,dependency,469,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:616,Integrability,depend,dependency,616,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:677,Integrability,depend,dependencies,677,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:569,Modifiability,config,configDependencies,569,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:819,Safety,timeout,timeout,819,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:134,Testability,test,tests,134,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:346,Testability,log,logback,346,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:395,Testability,test,testing,395,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:411,Testability,mock,mockito,411,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:435,Testability,test,tests,435,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:461,Testability,test,testkit,461,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:516,Testability,test,test,516,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:692,Testability,Log,Log,692,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2938:791,Testability,test,test,791,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938
https://github.com/broadinstitute/cromwell/pull/2940:158,Integrability,message,messages,158,"A val instead of lazy-val was throwing an exception ""too early"".; The additional ActorInitializationException then affected the depth of the expected causeBy messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2940
https://github.com/broadinstitute/cromwell/pull/2942:217,Modifiability,config,config,217,"Gull away. There are things here that need discussion, in particular `WdlTask#instantiateCommand` that is called only by tests and ""example"" code. Also I'm not sure how to properly honor initialized optionals for the config backend; I'm currently forcing in `none` defaults since if I don't expression evaluation with uninitialized optionals blows up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2942
https://github.com/broadinstitute/cromwell/pull/2942:121,Testability,test,tests,121,"Gull away. There are things here that need discussion, in particular `WdlTask#instantiateCommand` that is called only by tests and ""example"" code. Also I'm not sure how to properly honor initialized optionals for the config backend; I'm currently forcing in `none` defaults since if I don't expression evaluation with uninitialized optionals blows up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2942
https://github.com/broadinstitute/cromwell/issues/2943:242,Deployability,integrat,integration,242,"Codecov can merge multiple reports from our various travis runs. For this to work, three steps are required:. - [x] Remove cromwell-core dependency from cloud-support #2938 ; - [x] Run jes centaur on travis #2948; - [x] Generate coverage for integration tests #2955",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2943
https://github.com/broadinstitute/cromwell/issues/2943:137,Integrability,depend,dependency,137,"Codecov can merge multiple reports from our various travis runs. For this to work, three steps are required:. - [x] Remove cromwell-core dependency from cloud-support #2938 ; - [x] Run jes centaur on travis #2948; - [x] Generate coverage for integration tests #2955",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2943
https://github.com/broadinstitute/cromwell/issues/2943:242,Integrability,integrat,integration,242,"Codecov can merge multiple reports from our various travis runs. For this to work, three steps are required:. - [x] Remove cromwell-core dependency from cloud-support #2938 ; - [x] Run jes centaur on travis #2948; - [x] Generate coverage for integration tests #2955",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2943
https://github.com/broadinstitute/cromwell/issues/2943:254,Testability,test,tests,254,"Codecov can merge multiple reports from our various travis runs. For this to work, three steps are required:. - [x] Remove cromwell-core dependency from cloud-support #2938 ; - [x] Run jes centaur on travis #2948; - [x] Generate coverage for integration tests #2955",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2943
https://github.com/broadinstitute/cromwell/issues/2944:234,Testability,test,test,234,"There's example code in the various `ex[1-7].scala` files that calls directly into the former wdl4s API. In one spot in `ex7.scala` there's a call to the `WdlTask#instantiateCommand` method that is now called only by this example and test code. There are other methods like `WdlTask#inputsFromMap` that are called only by tests. Basically there's tech debt here to clean up after the conversion to WOM, and also to show the correct usage of the WOM API in examples.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2944
https://github.com/broadinstitute/cromwell/issues/2944:322,Testability,test,tests,322,"There's example code in the various `ex[1-7].scala` files that calls directly into the former wdl4s API. In one spot in `ex7.scala` there's a call to the `WdlTask#instantiateCommand` method that is now called only by this example and test code. There are other methods like `WdlTask#inputsFromMap` that are called only by tests. Basically there's tech debt here to clean up after the conversion to WOM, and also to show the correct usage of the WOM API in examples.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2944
https://github.com/broadinstitute/cromwell/issues/2946:1343,Availability,down,down,1343,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946
https://github.com/broadinstitute/cromwell/issues/2946:47,Modifiability,config,config,47,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946
https://github.com/broadinstitute/cromwell/issues/2946:86,Modifiability,config,config,86,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946
https://github.com/broadinstitute/cromwell/issues/2946:843,Modifiability,config,config,843,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946
https://github.com/broadinstitute/cromwell/issues/2946:1155,Usability,clear,clear,1155,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946
https://github.com/broadinstitute/cromwell/pull/2947:207,Integrability,depend,depending,207,"1-minute description of this: VariableReference had to become aware of where it was, because `p.left` might need a `Pair` called `p`'s `""left""` field, or it might need a `task` called `p`'s `""left""` output, depending on its scope, and the variable reference is different in each case (`p` and `p.left` respectively). Determining whether a reference is a member access or a task output reference is a bit inefficient right now, but I think it should be ok since it's only called during WDL instantiation (thereafter it's all just following the links in WOM objects)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947
https://github.com/broadinstitute/cromwell/pull/2947:30,Modifiability,Variab,VariableReference,30,"1-minute description of this: VariableReference had to become aware of where it was, because `p.left` might need a `Pair` called `p`'s `""left""` field, or it might need a `task` called `p`'s `""left""` output, depending on its scope, and the variable reference is different in each case (`p` and `p.left` respectively). Determining whether a reference is a member access or a task output reference is a bit inefficient right now, but I think it should be ok since it's only called during WDL instantiation (thereafter it's all just following the links in WOM objects)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947
https://github.com/broadinstitute/cromwell/pull/2947:239,Modifiability,variab,variable,239,"1-minute description of this: VariableReference had to become aware of where it was, because `p.left` might need a `Pair` called `p`'s `""left""` field, or it might need a `task` called `p`'s `""left""` output, depending on its scope, and the variable reference is different in each case (`p` and `p.left` respectively). Determining whether a reference is a member access or a task output reference is a bit inefficient right now, but I think it should be ok since it's only called during WDL instantiation (thereafter it's all just following the links in WOM objects)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947
https://github.com/broadinstitute/cromwell/pull/2947:361,Security,access,access,361,"1-minute description of this: VariableReference had to become aware of where it was, because `p.left` might need a `Pair` called `p`'s `""left""` field, or it might need a `task` called `p`'s `""left""` output, depending on its scope, and the variable reference is different in each case (`p` and `p.left` respectively). Determining whether a reference is a member access or a task output reference is a bit inefficient right now, but I think it should be ok since it's only called during WDL instantiation (thereafter it's all just following the links in WOM objects)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947
https://github.com/broadinstitute/cromwell/pull/2948:122,Deployability,integrat,integration,122,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948
https://github.com/broadinstitute/cromwell/pull/2948:36,Integrability,depend,dependency,36,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948
https://github.com/broadinstitute/cromwell/pull/2948:122,Integrability,integrat,integration,122,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948
https://github.com/broadinstitute/cromwell/pull/2948:163,Modifiability,config,configurable,163,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948
https://github.com/broadinstitute/cromwell/pull/2948:134,Testability,test,tests,134,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948
https://github.com/broadinstitute/cromwell/issues/2949:561,Availability,avail,available,561,"This would greatly reduce my need to modify WDL scripts to start where I have data already processed. For example, if a script goes BAM-->coverage-->CNVs, if I have already collected coverage on my BAMs, I would like to be able to provide `coverage` to the same script and have Cromwell skip the tasks involving the BAM and run the remaining steps in the workflow, e.g. coverage-->CNVs. . I run WDLs using gcloud, within a VM and locally. I don't use FireCloud so my runs do not use call-caching. I want to take the boilerplate WDL scripts the GATK4 repo makes available to run processes. I am specifically looking at the latest somatic CNV workflow. If I have alreaded padded my intervals and/or collected counts on the BAMs, I'd like to still use the rest of the steps in the workflow by specifying in the INPUTS JSON an intermediate file. If the script is thus:; ```; call CNVTasks.PreprocessIntervals {; input:; intervals = intervals,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }. if (select_first([do_explicit_gc_correction, false])) {; call CNVTasks.AnnotateIntervals {; input:; intervals = PreprocessIntervals.preprocessed_intervals,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }; ```. In the inputs, instead of defining:; ```; ""CNVSomaticPanelWorkflow.intervals"": ""File"",; ```; I would like to be able to instead provide:; ```; ""CNVSomaticPanelWorkflow.PreprocessIntervals.preprocessed_intervals"": ""File"",; ```. And not have the run error due to the lack of the `CNVSomaticPanelWorkflow.intervals` file. . I would really appreciate such a feature as it saves me the time of having to rewrite WDL scripts for each tweaked subset workflow. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2949
https://github.com/broadinstitute/cromwell/issues/2949:1618,Availability,error,error,1618,"This would greatly reduce my need to modify WDL scripts to start where I have data already processed. For example, if a script goes BAM-->coverage-->CNVs, if I have already collected coverage on my BAMs, I would like to be able to provide `coverage` to the same script and have Cromwell skip the tasks involving the BAM and run the remaining steps in the workflow, e.g. coverage-->CNVs. . I run WDLs using gcloud, within a VM and locally. I don't use FireCloud so my runs do not use call-caching. I want to take the boilerplate WDL scripts the GATK4 repo makes available to run processes. I am specifically looking at the latest somatic CNV workflow. If I have alreaded padded my intervals and/or collected counts on the BAMs, I'd like to still use the rest of the steps in the workflow by specifying in the INPUTS JSON an intermediate file. If the script is thus:; ```; call CNVTasks.PreprocessIntervals {; input:; intervals = intervals,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }. if (select_first([do_explicit_gc_correction, false])) {; call CNVTasks.AnnotateIntervals {; input:; intervals = PreprocessIntervals.preprocessed_intervals,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }; ```. In the inputs, instead of defining:; ```; ""CNVSomaticPanelWorkflow.intervals"": ""File"",; ```; I would like to be able to instead provide:; ```; ""CNVSomaticPanelWorkflow.PreprocessIntervals.preprocessed_intervals"": ""File"",; ```. And not have the run error due to the lack of the `CNVSomaticPanelWorkflow.intervals` file. . I would really appreciate such a feature as it saves me the time of having to rewrite WDL scripts for each tweaked subset workflow. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2949
https://github.com/broadinstitute/cromwell/issues/2949:19,Energy Efficiency,reduce,reduce,19,"This would greatly reduce my need to modify WDL scripts to start where I have data already processed. For example, if a script goes BAM-->coverage-->CNVs, if I have already collected coverage on my BAMs, I would like to be able to provide `coverage` to the same script and have Cromwell skip the tasks involving the BAM and run the remaining steps in the workflow, e.g. coverage-->CNVs. . I run WDLs using gcloud, within a VM and locally. I don't use FireCloud so my runs do not use call-caching. I want to take the boilerplate WDL scripts the GATK4 repo makes available to run processes. I am specifically looking at the latest somatic CNV workflow. If I have alreaded padded my intervals and/or collected counts on the BAMs, I'd like to still use the rest of the steps in the workflow by specifying in the INPUTS JSON an intermediate file. If the script is thus:; ```; call CNVTasks.PreprocessIntervals {; input:; intervals = intervals,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }. if (select_first([do_explicit_gc_correction, false])) {; call CNVTasks.AnnotateIntervals {; input:; intervals = PreprocessIntervals.preprocessed_intervals,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }; ```. In the inputs, instead of defining:; ```; ""CNVSomaticPanelWorkflow.intervals"": ""File"",; ```; I would like to be able to instead provide:; ```; ""CNVSomaticPanelWorkflow.PreprocessIntervals.preprocessed_intervals"": ""File"",; ```. And not have the run error due to the lack of the `CNVSomaticPanelWorkflow.intervals` file. . I would really appreciate such a feature as it saves me the time of having to rewrite WDL scripts for each tweaked subset workflow. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2949
https://github.com/broadinstitute/cromwell/issues/2949:1769,Modifiability,rewrite,rewrite,1769,"This would greatly reduce my need to modify WDL scripts to start where I have data already processed. For example, if a script goes BAM-->coverage-->CNVs, if I have already collected coverage on my BAMs, I would like to be able to provide `coverage` to the same script and have Cromwell skip the tasks involving the BAM and run the remaining steps in the workflow, e.g. coverage-->CNVs. . I run WDLs using gcloud, within a VM and locally. I don't use FireCloud so my runs do not use call-caching. I want to take the boilerplate WDL scripts the GATK4 repo makes available to run processes. I am specifically looking at the latest somatic CNV workflow. If I have alreaded padded my intervals and/or collected counts on the BAMs, I'd like to still use the rest of the steps in the workflow by specifying in the INPUTS JSON an intermediate file. If the script is thus:; ```; call CNVTasks.PreprocessIntervals {; input:; intervals = intervals,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }. if (select_first([do_explicit_gc_correction, false])) {; call CNVTasks.AnnotateIntervals {; input:; intervals = PreprocessIntervals.preprocessed_intervals,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }; ```. In the inputs, instead of defining:; ```; ""CNVSomaticPanelWorkflow.intervals"": ""File"",; ```; I would like to be able to instead provide:; ```; ""CNVSomaticPanelWorkflow.PreprocessIntervals.preprocessed_intervals"": ""File"",; ```. And not have the run error due to the lack of the `CNVSomaticPanelWorkflow.intervals` file. . I would really appreciate such a feature as it saves me the time of having to rewrite WDL scripts for each tweaked subset workflow. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2949
https://github.com/broadinstitute/cromwell/pull/2952:92,Testability,test,tests,92,"As well as allowing workflow outputs to refer to other outputs (commit 1), to make the four tests in this ticket work involved:; - Making the result from not-run conditionals be of type `X?`, not the incorrect `X??` (commit 2); - Making task input evaluation honor optionals and defaults, and be evaluated in the right order (commit 3)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2952
https://github.com/broadinstitute/cromwell/issues/2953:30,Deployability,update,updated,30,currently it just returns the updated ones. this is needed for job manager. https://www.youtube.com/watch?v=1Isjgc0oX0s,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2953
https://github.com/broadinstitute/cromwell/pull/2954:88,Security,validat,validation,88,"As `WomValue` can now be represented in `WomExpression` using `ValueAsExpression`, this validation was reinstated.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2954
https://github.com/broadinstitute/cromwell/pull/2955:122,Deployability,integrat,integration,122,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:221,Deployability,Update,Updated,221,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:36,Integrability,depend,dependency,36,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:122,Integrability,integrat,integration,122,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:162,Security,validat,validates,162,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:134,Testability,test,tests,134,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2955:157,Testability,test,test,157,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955
https://github.com/broadinstitute/cromwell/pull/2956:84,Testability,test,test,84,With apologies to @kshakir for stealing his thunder and then forgetting to turn the test back on...,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2956
https://github.com/broadinstitute/cromwell/issues/2957:16,Modifiability,config,config,16,Add ; > all the config options that have been added over time. From [this PR](https://github.com/broadinstitute/cromwell/pull/2950#discussion_r153978653). @mcovarr feel free to add any config options here to start tracking them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2957
https://github.com/broadinstitute/cromwell/issues/2957:185,Modifiability,config,config,185,Add ; > all the config options that have been added over time. From [this PR](https://github.com/broadinstitute/cromwell/pull/2950#discussion_r153978653). @mcovarr feel free to add any config options here to start tracking them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2957
https://github.com/broadinstitute/cromwell/pull/2958:35,Security,expose,exposed,35,"Eg spot the difference between the exposed `err` declaration and the anonymous `b_prime.in_file` expression in:; ```wdl; workflow stdout_stderr_passing {; call a; call b {input: in_file=a.out}; File err = a.err; call b as b_prime {input: in_file=err}; output {; b_prime.out; }; }; ```. ![test](https://user-images.githubusercontent.com/13006282/33454657-7eba9d28-d5e7-11e7-9774-a17cbf3c63e8.png). NB: the dashes on the output are accidental, and I believe to-be-removed in an upcoming @mcovarr PR",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2958
https://github.com/broadinstitute/cromwell/pull/2958:288,Testability,test,test,288,"Eg spot the difference between the exposed `err` declaration and the anonymous `b_prime.in_file` expression in:; ```wdl; workflow stdout_stderr_passing {; call a; call b {input: in_file=a.out}; File err = a.err; call b as b_prime {input: in_file=err}; output {; b_prime.out; }; }; ```. ![test](https://user-images.githubusercontent.com/13006282/33454657-7eba9d28-d5e7-11e7-9774-a17cbf3c63e8.png). NB: the dashes on the output are accidental, and I believe to-be-removed in an upcoming @mcovarr PR",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2958
https://github.com/broadinstitute/cromwell/pull/2959:124,Security,validat,validate,124,"@orodeh it looks like the `WdlStandardLibraryFunctionsType#flatten` method was missing, which meant Cromwell wasn't able to validate workflows with `flatten`s in them. I also added the coercion so that `flatten(_: Array[Map[_]])` works as expected.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2959
https://github.com/broadinstitute/cromwell/issues/2961:91,Availability,error,error,91,"The labels PATCH endpoint will always return a 500 status code, no matter what exactly the error is. For example, using fake id “abc” returns status code 500, and using an unrecognized workflow id “774eeeac-aaaa-bbbb-8bf7-061b87ad19da” will also return 500. This may not be what we expected. . The only way to get a 400 code is to make a request with invalid json input, such as {“”:”test_label”}. But we couldn't get a 404 code as we expected, could someone get this fixed?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2961
https://github.com/broadinstitute/cromwell/issues/2961:11,Deployability,PATCH,PATCH,11,"The labels PATCH endpoint will always return a 500 status code, no matter what exactly the error is. For example, using fake id “abc” returns status code 500, and using an unrecognized workflow id “774eeeac-aaaa-bbbb-8bf7-061b87ad19da” will also return 500. This may not be what we expected. . The only way to get a 400 code is to make a request with invalid json input, such as {“”:”test_label”}. But we couldn't get a 404 code as we expected, could someone get this fixed?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2961
https://github.com/broadinstitute/cromwell/issues/2963:83,Availability,ERROR,ERROR,83,"```; 2017-12-01 11:49:13,302 cromwell-system-akka.dispatchers.engine-dispatcher-63 ERROR - WorkflowManagerActor Workflow 994bc7a0-2340-4903-9feb-af685f3197d0 failed (during ExecutingWorkflowState): Cannot run program ""ps"": /[...]/cromwell-executions/wf_name/994bc7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); java.io.IOException: Cannot run program ""ps"": /[...]/cromwell-executions/wf_name/994bc7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048); 	at cromwell.backend.sfs.ProcessRunner.run(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.Stan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1495,Availability,recover,recover,1495, file or directory); 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048); 	at cromwell.backend.sfs.ProcessRunner.run(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(Standard,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1618,Availability,recover,recover,1618,n(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecove,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1754,Availability,recover,recover,1754,cJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1870,Availability,recover,recoverAsync,1870,a.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2025,Availability,recover,recoverAsync,2025,at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2136,Availability,recover,recoverAsync,2136,cala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65);,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2266,Availability,recover,recoverAsync,2266,190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2751,Availability,robust,robustExecuteOrRecover,2751,obExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.aroundReceiv,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:3094,Availability,robust,robustExecuteOrRecover,3094,ckend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:190); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234);,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1198,Modifiability,config,config,1198,"not run program ""ps"": /[...]/cromwell-executions/wf_name/994bc7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); java.io.IOException: Cannot run program ""ps"": /[...]/cromwell-executions/wf_name/994bc7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048); 	at cromwell.backend.sfs.ProcessRunner.run(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1252,Modifiability,Config,ConfigAsyncJobExecutionActor,1252,"c7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); java.io.IOException: Cannot run program ""ps"": /[...]/cromwell-executions/wf_name/994bc7a0-2340-4903-9feb-af685f3197d0/call-task1/execution/stdout.check (No such file or directory); 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048); 	at cromwell.backend.sfs.ProcessRunner.run(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionAct",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1708,Modifiability,config,config,1708,syncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1762,Modifiability,Config,ConfigAsyncJobExecutionActor,1762,cJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2220,Modifiability,config,config,2220,yncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2279,Modifiability,Config,ConfigAsyncJobExecutionActor,2279,190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2581,Modifiability,config,config,2581,dFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at ak,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2644,Modifiability,Config,ConfigAsyncJobExecutionActor,2644,bExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Act,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:3716,Modifiability,config,config,3716,cutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:190); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:3776,Modifiability,Config,ConfigAsyncJobExecutionActor,3776,cutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:190); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1495,Safety,recover,recover,1495, file or directory); 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048); 	at cromwell.backend.sfs.ProcessRunner.run(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(Standard,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1618,Safety,recover,recover,1618,n(ProcessRunner.scala:20); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$isAlive$1(SharedFileSystemAsyncJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecove,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1754,Safety,recover,recover,1754,cJobExecutionActor.scala:196); 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:1870,Safety,recover,recoverAsync,1870,a.util.Try$.apply(Try.scala:209); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2025,Safety,recover,recoverAsync,2025,at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.isAlive$(SharedFileSystemAsyncJobExecutionActor.scala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2136,Safety,recover,recoverAsync,2136,cala:191); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.isAlive(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65);,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2963:2266,Safety,recover,recoverAsync,2266,190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963
https://github.com/broadinstitute/cromwell/issues/2965:360,Availability,error,errors,360,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:422,Availability,failure,failures,422,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1145,Availability,failure,failures,1145,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:550,Integrability,message,message,550,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:604,Integrability,message,message,604,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:724,Integrability,message,message,724,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:844,Integrability,message,message,844,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:882,Integrability,message,message,882,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:905,Integrability,message,message,905,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:990,Integrability,message,message,990,"on: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1257,Integrability,message,message,1257,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1351,Integrability,message,message,1351,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1445,Integrability,message,message,1445,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1483,Integrability,message,message,1483,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1506,Integrability,message,message,1506,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1591,Integrability,message,message,1591,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2965:1803,Modifiability,variab,variable,1803,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965
https://github.com/broadinstitute/cromwell/issues/2966:48,Performance,queue,queue,48,"My jobs aren't starting because there's a giant queue of jobs that have been cancelled, but are waiting to start before they can be aborted. This shouldn't happen. If a job is aborted before it can be launched it shouldn't take a long time to process it. . I heard this might be fixed in 30 already, but if it's not, it would be great to have it fixed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2966
https://github.com/broadinstitute/cromwell/issues/2966:132,Safety,abort,aborted,132,"My jobs aren't starting because there's a giant queue of jobs that have been cancelled, but are waiting to start before they can be aborted. This shouldn't happen. If a job is aborted before it can be launched it shouldn't take a long time to process it. . I heard this might be fixed in 30 already, but if it's not, it would be great to have it fixed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2966
https://github.com/broadinstitute/cromwell/issues/2966:176,Safety,abort,aborted,176,"My jobs aren't starting because there's a giant queue of jobs that have been cancelled, but are waiting to start before they can be aborted. This shouldn't happen. If a job is aborted before it can be launched it shouldn't take a long time to process it. . I heard this might be fixed in 30 already, but if it's not, it would be great to have it fixed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2966
https://github.com/broadinstitute/cromwell/issues/2967:92,Security,validat,validation,92,if we do this from a workflow:; ```wdl; call foo { input: x = 5 }; ```. Then we should fail validation if `x` is not an input of `foo`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2967
https://github.com/broadinstitute/cromwell/issues/2970:64,Availability,error,error,64,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:195,Availability,error,error,195,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:659,Availability,failure,failures,659,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:800,Availability,error,error,800,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:78,Integrability,Message,Message,78,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:360,Integrability,message,message,360,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:480,Integrability,message,message,480,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:696,Integrability,message,message,696,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:814,Integrability,Message,Message,814,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/issues/2970:396,Safety,safe,safe,396,"There’s a new response from JES that should be retryable: ; JES error code 2. Message: Instance failed to start due to preemption.” . THE CATCH: Henry chatted with Google, and it sounds like JES error code 2 isn’t *always* about preemption. (But in the past few weeks we’ve had a handful of cloud workflows failing each day from this response, always with the message about preemption). So to be safe, we want to make this one retryable based on the combination of the code + the message. . Example: ; UUID: 7da0394b-371f-4fdb-ae70-737833c4fbfa; OPERATION_ID: operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. Relevant workflow metadata: ; ""failures""; : [; {; ""causedBy"": [],; ""message"": ""Task PairedEndSingleSampleWorkflow.CollectUnsortedReadgroupBamQualityMetrics:2:1 failed. JES error code 2. Message: Instance failed to start due to preemption.""; }; ],",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970
https://github.com/broadinstitute/cromwell/pull/2971:0,Deployability,Update,Update,0,"Update the `query` endpoint to take in an `additionalKeys` parameter, which will include the specified keys in the returned workflow metadata. This currently just supports ""labels"" and ""parentWorkflowId"" but can be expanded later if necessary. E.g. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=parentWorkflowId` would return: . ```; {; ""results"": [; {; ""name"": ""test"",; ""id"": ""4e1bf4b5-caea-4e8a-9cd3-f48ac8d11393"",; ""status"": ""Failed"",; ""parentWorkflowId"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""end"": ""2017-12-01T19:00:23.778-05:00"",; ""start"": ""2017-12-01T19:00:16.738-05:00""; }; ]; }; ```. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=labels` would return: . ```; {; ""results"": [; {; ""name"": ""use_sub_wfs"",; ""id"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""labels"": {; ""project"": ""test"",; ""version"": ""2"",; ""cromwell-workflow-id"": ""cromwell-21b58d24-7f14-4e45-a45a-5e8678fd83cb""; },; ""status"": ""Failed"",; ""end"": ""2017-12-01T19:00:24.627-05:00"",; ""start"": ""2017-12-01T19:00:14.210-05:00""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971
https://github.com/broadinstitute/cromwell/pull/2971:395,Testability,test,test,395,"Update the `query` endpoint to take in an `additionalKeys` parameter, which will include the specified keys in the returned workflow metadata. This currently just supports ""labels"" and ""parentWorkflowId"" but can be expanded later if necessary. E.g. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=parentWorkflowId` would return: . ```; {; ""results"": [; {; ""name"": ""test"",; ""id"": ""4e1bf4b5-caea-4e8a-9cd3-f48ac8d11393"",; ""status"": ""Failed"",; ""parentWorkflowId"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""end"": ""2017-12-01T19:00:23.778-05:00"",; ""start"": ""2017-12-01T19:00:16.738-05:00""; }; ]; }; ```. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=labels` would return: . ```; {; ""results"": [; {; ""name"": ""use_sub_wfs"",; ""id"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""labels"": {; ""project"": ""test"",; ""version"": ""2"",; ""cromwell-workflow-id"": ""cromwell-21b58d24-7f14-4e45-a45a-5e8678fd83cb""; },; ""status"": ""Failed"",; ""end"": ""2017-12-01T19:00:24.627-05:00"",; ""start"": ""2017-12-01T19:00:14.210-05:00""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971
https://github.com/broadinstitute/cromwell/pull/2971:852,Testability,test,test,852,"Update the `query` endpoint to take in an `additionalKeys` parameter, which will include the specified keys in the returned workflow metadata. This currently just supports ""labels"" and ""parentWorkflowId"" but can be expanded later if necessary. E.g. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=parentWorkflowId` would return: . ```; {; ""results"": [; {; ""name"": ""test"",; ""id"": ""4e1bf4b5-caea-4e8a-9cd3-f48ac8d11393"",; ""status"": ""Failed"",; ""parentWorkflowId"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""end"": ""2017-12-01T19:00:23.778-05:00"",; ""start"": ""2017-12-01T19:00:16.738-05:00""; }; ]; }; ```. A GET request to `http://localhost:8000/api/workflows/v1/query?additionalKeys=labels` would return: . ```; {; ""results"": [; {; ""name"": ""use_sub_wfs"",; ""id"": ""21b58d24-7f14-4e45-a45a-5e8678fd83cb"",; ""labels"": {; ""project"": ""test"",; ""version"": ""2"",; ""cromwell-workflow-id"": ""cromwell-21b58d24-7f14-4e45-a45a-5e8678fd83cb""; },; ""status"": ""Failed"",; ""end"": ""2017-12-01T19:00:24.627-05:00"",; ""start"": ""2017-12-01T19:00:14.210-05:00""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971
https://github.com/broadinstitute/cromwell/issues/2972:104,Availability,echo,echo,104,"```; workflow test {; 	call t1 { input : flag1 = false, }; }. task t1 {; 	Boolean? flag1; 	command {; 		echo test1 > test1.txt; 		echo test2 > test2.txt; 	}; 	output {; 		File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out; 		File out = if select_first([flag1,false]) then glob('test1.txt')[0] else glob('test2.txt')[0]; 	}; }; ```; This code works fine. But If you comment out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Su",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:130,Availability,echo,echo,130,"```; workflow test {; 	call t1 { input : flag1 = false, }; }. task t1 {; 	Boolean? flag1; 	command {; 		echo test1 > test1.txt; 		echo test2 > test2.txt; 	}; 	output {; 		File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out; 		File out = if select_first([flag1,false]) then glob('test1.txt')[0] else glob('test2.txt')[0]; 	}; }; ```; This code works fine. But If you comment out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Su",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:571,Availability,error,error,571,"```; workflow test {; 	call t1 { input : flag1 = false, }; }. task t1 {; 	Boolean? flag1; 	command {; 		echo test1 > test1.txt; 		echo test2 > test2.txt; 	}; 	output {; 		File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out; 		File out = if select_first([flag1,false]) then glob('test1.txt')[0] else glob('test2.txt')[0]; 	}; }; ```; This code works fine. But If you comment out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Su",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2510,Availability,echo,echo,2510,",89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2534,Availability,echo,echo,2534,"unnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,fal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:3233,Availability,error,error,3233,"ments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:3823,Availability,Failure,Failure,3823,"1] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEval",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:3831,Availability,recover,recoverWith,3831,"ckgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2703,Deployability,pipeline,pipeline,2703,"d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:6890,Deployability,pipeline,pipeline,6890,patch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.nio.file.NoSuchFileException: /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/glob-c91e47329777637e2370464651ba47aa.list; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); at sun.nio.fs.UnixPath.toRealPath(UnixPath.java:837); at cromwell.core.path.NioPathMethods.toRealPath(NioPathMethods.scala:70); at cromwell.core.path.NioPathMethods.toRealPath$(NioPathMethods.scala:70); at cromwell.core.path.DefaultPath.toRealPath(DefaultPathBuilder.scala:53); at cromwell.backend.io.GlobFunctions.glob(GlobFunctions.scala:45); at cromwell.backend.io.GlobFunctions.glob$(GlobFunctions.scala:43); at cromwell.backend.standard.StandardExpressionFunctions.glob(StandardExpressionFunctions.scala:23); at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$glob$1(ReadLikeFunctions.scala:168); at scala.util.Success.$anonfun$map$1(Try.scala:251); at scala.util.Success.map,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:4067,Energy Efficiency,adapt,adapted,4067,"1 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:1276,Modifiability,config,configured,1276,"f select_first([flag1,false]) then glob('test1.txt')[0] else glob('test2.txt')[0]; 	}; }; ```; This code works fine. But If you comment out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:1411,Modifiability,config,configured,1411,"t out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:4067,Modifiability,adapt,adapted,4067,"1 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5100,Modifiability,config,config,5100,at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5162,Modifiability,Config,ConfigAsyncJobExecutionActor,5162,a.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.jav,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5473,Modifiability,config,config,5473,a:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5542,Modifiability,Config,ConfigAsyncJobExecutionActor,5542,cala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5722,Performance,concurren,concurrent,5722,luateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:197,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5787,Performance,concurren,concurrent,5787,aluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:5864,Performance,concurren,concurrent,5864,ard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.evaluateOutputs(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.nio.file.NoSuchFileException: /users/le,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:6185,Performance,concurren,concurrent,6185,.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess(StandardAsyncExecutionActor.scala:458); at cromwell.backend.standard.StandardAsyncExecutionActor.handleExecutionSuccess$(StandardAsyncExecutionActor.scala:455); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionSuccess(ConfigAsyncJobExecutionActor.scala:121); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:651); at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:302); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.nio.file.NoSuchFileException: /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/glob-c91e47329777637e2370464651ba47aa.list; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); at sun.nio.fs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:3831,Safety,recover,recoverWith,3831,"ckgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:14,Testability,test,test,14,"```; workflow test {; 	call t1 { input : flag1 = false, }; }. task t1 {; 	Boolean? flag1; 	command {; 		echo test1 > test1.txt; 		echo test2 > test2.txt; 	}; 	output {; 		File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out; 		File out = if select_first([flag1,false]) then glob('test1.txt')[0] else glob('test2.txt')[0]; 	}; }; ```; This code works fine. But If you comment out a line `File out_false = if false then glob('test1.txt')[0] else glob('test2.txt')[0] # try commenting this out` in output {}, then I get an error. ```; $ java -jar ../cromwell-29.jar run test_select_first_in_if_in_output.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-01 20:00:53,03] [info] Running with database db.url = jdbc:hsqldb:mem:6ae82874-e5ea-4c15-9f1d-09f8d0406019;shutdown=false;hsqldb.tx=mvcc; [2017-12-01 20:01:00,60] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Su",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2263,Testability,test,test,2263,"d batch size of 100000 and a write batch size of 100000; [2017-12-01 20:01:00,61] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-01 20:01:01,07] [info] Slf4jLogger started; [2017-12-01 20:01:01,35] [info] Metadata summary refreshing every 2 seconds.; [2017-12-01 20:01:01,37] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsy",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2401,Testability,test,test,2401,"lush rate 5 seconds.; [2017-12-01 20:01:01,51] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-01 20:01:02,89] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-01 20:01:02,94] [info] Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 submitted.; [2017-12-01 20:01:02,94] [info] SingleWorkflowRunnerActor: Workflow submitted 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkfl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2712,Testability,test,test,2712,"d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:2737,Testability,test,test,2737,"d935e7cd5632; [2017-12-01 20:01:02,95] [info] 1 new workflows fetched; [2017-12-01 20:01:02,95] [info] WorkflowManagerActor Starting workflow 132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] WorkflowManagerActor Successfully started WorkflowActor-132d7527-a0af-4f08-8291-d935e7cd5632; [2017-12-01 20:01:02,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-01 20:01:03,27] [info] MaterializeWorkflowDescriptorActor [132d7527]: Call-to-Backend assignments: test.t1 -> Local; [2017-12-01 20:01:04,64] [info] WorkflowExecutionActor-132d7527-a0af-4f08-8291-d935e7cd5632 [132d7527]: Starting calls: test.t1:NA:1; [2017-12-01 20:01:04,82] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: echo test1 > test1.txt; echo test2 > test2.txt; [2017-12-01 20:01:04,86] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: executing: /bin/bash /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/script; [2017-12-01 20:01:04,91] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: job id: 9836; [2017-12-01 20:01:04,92] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from - to WaitingForReturnCodeFile; [2017-12-01 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:6899,Testability,test,test,6899,patch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.nio.file.NoSuchFileException: /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/glob-c91e47329777637e2370464651ba47aa.list; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); at sun.nio.fs.UnixPath.toRealPath(UnixPath.java:837); at cromwell.core.path.NioPathMethods.toRealPath(NioPathMethods.scala:70); at cromwell.core.path.NioPathMethods.toRealPath$(NioPathMethods.scala:70); at cromwell.core.path.DefaultPath.toRealPath(DefaultPathBuilder.scala:53); at cromwell.backend.io.GlobFunctions.glob(GlobFunctions.scala:45); at cromwell.backend.io.GlobFunctions.glob$(GlobFunctions.scala:43); at cromwell.backend.standard.StandardExpressionFunctions.glob(StandardExpressionFunctions.scala:23); at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$glob$1(ReadLikeFunctions.scala:168); at scala.util.Success.$anonfun$map$1(Try.scala:251); at scala.util.Success.map,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2972:6924,Testability,test,test,6924,patch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:38); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.nio.file.NoSuchFileException: /users/leepc12/code/atac-seq-pipeline/test/cromwell-executions/test/132d7527-a0af-4f08-8291-d935e7cd5632/call-t1/execution/glob-c91e47329777637e2370464651ba47aa.list; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); at sun.nio.fs.UnixPath.toRealPath(UnixPath.java:837); at cromwell.core.path.NioPathMethods.toRealPath(NioPathMethods.scala:70); at cromwell.core.path.NioPathMethods.toRealPath$(NioPathMethods.scala:70); at cromwell.core.path.DefaultPath.toRealPath(DefaultPathBuilder.scala:53); at cromwell.backend.io.GlobFunctions.glob(GlobFunctions.scala:45); at cromwell.backend.io.GlobFunctions.glob$(GlobFunctions.scala:43); at cromwell.backend.standard.StandardExpressionFunctions.glob(StandardExpressionFunctions.scala:23); at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$glob$1(ReadLikeFunctions.scala:168); at scala.util.Success.$anonfun$map$1(Try.scala:251); at scala.util.Success.map,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972
https://github.com/broadinstitute/cromwell/issues/2973:65,Availability,echo,echo,65,"```wdl; task two_input_task {; String inA; String inB; command { echo ${inA} and ${inB} }; runtime { docker: ""ubuntu"" }; }. workflow duplicate_conditional_input {; String my_input = ""input""; if (false) {; call two_input_task { input: inA = my_input, inB = my_input }; }; }; ```. Runs in 29 (d45f001). In develop (0fd1635) this crashes with:. ```java; [2017-12-02 16:30:57,99] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-02 16:30:59,03] [error] WorkflowManagerActor Workflow e7ef9b84-2a08-4295-a2ab-fea19ddcba76 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:7",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973
https://github.com/broadinstitute/cromwell/issues/2973:460,Availability,error,error,460,"```wdl; task two_input_task {; String inA; String inB; command { echo ${inA} and ${inB} }; runtime { docker: ""ubuntu"" }; }. workflow duplicate_conditional_input {; String my_input = ""input""; if (false) {; call two_input_task { input: inA = my_input, inB = my_input }; }; }; ```. Runs in 29 (d45f001). In develop (0fd1635) this crashes with:. ```java; [2017-12-02 16:30:57,99] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-02 16:30:59,03] [error] WorkflowManagerActor Workflow e7ef9b84-2a08-4295-a2ab-fea19ddcba76 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:7",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973
https://github.com/broadinstitute/cromwell/issues/2973:1817,Testability,Log,LoggingFSM,1817,sing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973
https://github.com/broadinstitute/cromwell/issues/2973:1910,Testability,Log,LoggingFSM,1910,s have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973
https://github.com/broadinstitute/cromwell/issues/2973:1965,Testability,Log,LoggingFSM,1965,mwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973
https://github.com/broadinstitute/cromwell/pull/2975:44,Safety,timeout,timeout,44,JES/SFS/Spark initialization specs use same timeout as TES.; Sleep more on no_new_calls to help JES from restarting delayedTask2.; Sleep a bit on local before sync'ing to help avoid (reworded) NoSuchFileException's.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2975
https://github.com/broadinstitute/cromwell/pull/2975:176,Safety,avoid,avoid,176,JES/SFS/Spark initialization specs use same timeout as TES.; Sleep more on no_new_calls to help JES from restarting delayedTask2.; Sleep a bit on local before sync'ing to help avoid (reworded) NoSuchFileException's.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2975
https://github.com/broadinstitute/cromwell/pull/2976:113,Safety,avoid,avoid,113,"The `WdlCall` expression handler contained a `traverse` which generated OGINs for outer lookups in parallel.; To avoid that, the PR pre-generates the OGINs for the expressions to use and doesn't let the `traverse` create its own.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2976
https://github.com/broadinstitute/cromwell/pull/2978:26,Availability,error,error,26,See #2970 for the current error case which we now think should be treated as preemptible.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2978
https://github.com/broadinstitute/cromwell/issues/2980:14,Deployability,release,release,14,"During the 30 release, the previous code repositories should be archived. For each repository:; - Create a new commit on the default branch linking future visitors to cromwell; - Ensure all PRs and Issues are closed/migrated as they will be read-only for all users after archiving; - [Archive](https://help.github.com/articles/archiving-a-github-repository/) the repository making it read-only. Old repositories:; - https://github.com/broadinstitute/lenthall; - https://github.com/broadinstitute/wdl4s; - https://github.com/broadinstitute/wdltool; - https://github.com/broadinstitute/centaur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2980
https://github.com/broadinstitute/cromwell/pull/2987:141,Availability,failure,failure,141,This does assert at least that the value is valid Json. We may consider going to a coproduct in the future but this will get us past parsing failure in the conformance tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2987
https://github.com/broadinstitute/cromwell/pull/2987:10,Testability,assert,assert,10,This does assert at least that the value is valid Json. We may consider going to a coproduct in the future but this will get us past parsing failure in the conformance tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2987
https://github.com/broadinstitute/cromwell/pull/2987:168,Testability,test,tests,168,This does assert at least that the value is valid Json. We may consider going to a coproduct in the future but this will get us past parsing failure in the conformance tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2987
https://github.com/broadinstitute/cromwell/pull/2988:15,Testability,test,tests,15,"A bunch of CWL tests fail at materialization time because CWL expects the keys in the input file to be the ""local name"" of the input whereas WDL expects the ""fully qualified name"" ; e.g. cwl:; ```; {; ""my_input"": ""hello""; }; ``` . wdl:; ```; {; ""my_workflow.my_input"": ""hello""; }; ```. This allows each language to define how an `ExternalGraphInputNode` should be mapped to a `String` to look for in the input file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988
https://github.com/broadinstitute/cromwell/pull/2989:106,Availability,error,errors,106,Custom scaladoc settings must be appended (++=) instead of overwriting (:=).; Fixed unmoored doc warnings/errors.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2989
https://github.com/broadinstitute/cromwell/issues/2990:120,Performance,optimiz,optimize,120,"One of the biggest pain-points in FireCloud is the inability to see how much memory a tool used, thus making it hard to optimize memory requests. It would be awesome if `monitoring_script` could be a runtime attribute as well as a workflow option to enable memory profiling.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990
https://github.com/broadinstitute/cromwell/issues/2991:111,Testability,test,test,111,Link to spec:; - http://www.commonwl.org/v1.0/Workflow.html#SubworkflowFeatureRequirement. Example conformance test(s):. - <span>#</span>40 [v1.0/count-lines8-wf.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/count-lines8-wf.cwl); - <span>#</span>91 [v1.0/count-lines10-wf.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/count-lines10-wf.cwl). A/C: This or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2991
https://github.com/broadinstitute/cromwell/issues/2991:536,Testability,test,test,536,Link to spec:; - http://www.commonwl.org/v1.0/Workflow.html#SubworkflowFeatureRequirement. Example conformance test(s):. - <span>#</span>40 [v1.0/count-lines8-wf.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/count-lines8-wf.cwl); - <span>#</span>91 [v1.0/count-lines10-wf.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/count-lines10-wf.cwl). A/C: This or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2991
https://github.com/broadinstitute/cromwell/issues/2992:411,Availability,echo,echo,411,"* `cromwell-30.jar`; * local; * single workflow mode. ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true	; 	if ( b0 ) {; 		if ( b2 ) {; 			call t0 as t2 { input: i=2 }; 		}; 		if ( b1 ) {; 			call t0 as t1 { input: i=1 }			; 		}; 		#Boolean tmp = b1 && b2; 		#if ( tmp ) {	; 		if ( b1 && b2 ) {; 			call t0 as t12 { input: i=12 }				; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo test > ${i}.txt; 	}; 	output {; 		File out = glob('*.txt')[0]; 	}; }; ```; This code does not work.; ```; $ java -jar ../cromwell-30.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:2377,Availability,error,error,2377,":40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] [info] 1 new workflows fetched; [2017-12-05 09:40:30,69] [info] WorkflowManagerActor Starting workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] WorkflowManagerActor Successfully started WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 09:40:31,66] [error] WorkflowManagerActor Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.b1; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.b2; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.b1; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.b2; at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workf",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5859,Deployability,configurat,configuration,5859,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:6202,Deployability,configurat,configuration,6202,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:1358,Energy Efficiency,monitor,monitor,1358,"t; 	}; 	output {; 		File out = glob('*.txt')[0]; 	}; }; ```; This code does not work.; ```; $ java -jar ../cromwell-30.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] [info] 1 new workflows fetched; [2017-12-05 09:40:30,69] [info] WorkflowManagerActor Starting workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] WorkflowManagerActor Successfully started WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 09:40:31,66] [error] WorkflowManagerActor Workflow 6a6ee0eb-5576-43a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5641,Integrability,Message,Message,5641,"akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5984,Integrability,Message,Message,5984,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:1472,Modifiability,config,configured,1472,"t; 	}; 	output {; 		File out = glob('*.txt')[0]; 	}; }; ```; This code does not work.; ```; $ java -jar ../cromwell-30.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] [info] 1 new workflows fetched; [2017-12-05 09:40:30,69] [info] WorkflowManagerActor Starting workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] WorkflowManagerActor Successfully started WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 09:40:31,66] [error] WorkflowManagerActor Workflow 6a6ee0eb-5576-43a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:1607,Modifiability,config,configured,1607,"-Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] [info] 1 new workflows fetched; [2017-12-05 09:40:30,69] [info] WorkflowManagerActor Starting workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] WorkflowManagerActor Successfully started WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 09:40:31,66] [error] WorkflowManagerActor Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQua",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5859,Modifiability,config,configuration,5859,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:6202,Modifiability,config,configuration,6202,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:68,Testability,test,test,68,"* `cromwell-30.jar`; * local; * single workflow mode. ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true	; 	if ( b0 ) {; 		if ( b2 ) {; 			call t0 as t2 { input: i=2 }; 		}; 		if ( b1 ) {; 			call t0 as t1 { input: i=1 }			; 		}; 		#Boolean tmp = b1 && b2; 		#if ( tmp ) {	; 		if ( b1 && b2 ) {; 			call t0 as t12 { input: i=12 }				; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo test > ${i}.txt; 	}; 	output {; 		File out = glob('*.txt')[0]; 	}; }; ```; This code does not work.; ```; $ java -jar ../cromwell-30.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:416,Testability,test,test,416,"* `cromwell-30.jar`; * local; * single workflow mode. ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true	; 	if ( b0 ) {; 		if ( b2 ) {; 			call t0 as t2 { input: i=2 }; 		}; 		if ( b1 ) {; 			call t0 as t1 { input: i=1 }			; 		}; 		#Boolean tmp = b1 && b2; 		#if ( tmp ) {	; 		if ( b1 && b2 ) {; 			call t0 as t12 { input: i=12 }				; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo test > ${i}.txt; 	}; 	output {; 		File out = glob('*.txt')[0]; 	}; }; ```; This code does not work.; ```; $ java -jar ../cromwell-30.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:3913,Testability,Log,LoggingFSM,3913, FullyQualifiedName: ^.b1; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQualifiedName: ^.b2; at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:4005,Testability,Log,LoggingFSM,4005,o or more nodes have the same FullyQualifiedName: ^.b2; at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:4059,Testability,Log,LoggingFSM,4059,; at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.di,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5816,Testability,log,logging,5816,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5888,Testability,log,log-dead-letters,5888,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:5916,Testability,log,log-dead-letters-during-shutdown,5916,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:6159,Testability,log,logging,6159,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:6231,Testability,log,log-dead-letters,6231,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/issues/2992:6259,Testability,log,log-dead-letters-during-shutdown,6259,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992
https://github.com/broadinstitute/cromwell/pull/2994:106,Testability,test,tests,106,"With https://github.com/broadinstitute/cromwell/pull/2988 it should enable a bunch of new CWL conformance tests to run on travis. They will still need the outputs to look right to fully ""pass""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2994
https://github.com/broadinstitute/cromwell/issues/2995:191,Testability,test,tests,191,Link to specs:; - http://www.commonwl.org/v1.0/CommandLineTool.html#InlineJavascriptRequirement; - http://www.commonwl.org/v1.0/Workflow.html#InlineJavascriptRequirement. Example conformance tests:; - <span>#</span>16 [v1.0/null-expression1-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/null-expression1-tool.cwl); - <span>#</span>17 [v1.0/null-expression2-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/null-expression2-tool.cwl); - <span>#</span>52 [v1.0/wc4-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/wc4-tool.cwl) (Parses file contents in JS). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2995
https://github.com/broadinstitute/cromwell/issues/2995:811,Testability,test,test,811,Link to specs:; - http://www.commonwl.org/v1.0/CommandLineTool.html#InlineJavascriptRequirement; - http://www.commonwl.org/v1.0/Workflow.html#InlineJavascriptRequirement. Example conformance tests:; - <span>#</span>16 [v1.0/null-expression1-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/null-expression1-tool.cwl); - <span>#</span>17 [v1.0/null-expression2-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/null-expression2-tool.cwl); - <span>#</span>52 [v1.0/wc4-tool.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/wc4-tool.cwl) (Parses file contents in JS). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2995
https://github.com/broadinstitute/cromwell/issues/2996:106,Testability,test,test,106,Link to spec:; - http://www.commonwl.org/v1.0/CommandLineTool.html#DockerRequirement. Example conformance test(s):. - <span>#</span>5 [v1.0/cat1-testcli.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/cat1-testcli.cwl); - <span>#</span>95 [v1.0/docker-output-dir.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/docker-output-dir.cwl). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2996
https://github.com/broadinstitute/cromwell/issues/2996:145,Testability,test,testcli,145,Link to spec:; - http://www.commonwl.org/v1.0/CommandLineTool.html#DockerRequirement. Example conformance test(s):. - <span>#</span>5 [v1.0/cat1-testcli.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/cat1-testcli.cwl); - <span>#</span>95 [v1.0/docker-output-dir.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/docker-output-dir.cwl). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2996
https://github.com/broadinstitute/cromwell/issues/2996:254,Testability,test,testcli,254,Link to spec:; - http://www.commonwl.org/v1.0/CommandLineTool.html#DockerRequirement. Example conformance test(s):. - <span>#</span>5 [v1.0/cat1-testcli.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/cat1-testcli.cwl); - <span>#</span>95 [v1.0/docker-output-dir.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/docker-output-dir.cwl). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2996
https://github.com/broadinstitute/cromwell/issues/2996:527,Testability,test,test,527,Link to spec:; - http://www.commonwl.org/v1.0/CommandLineTool.html#DockerRequirement. Example conformance test(s):. - <span>#</span>5 [v1.0/cat1-testcli.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/cat1-testcli.cwl); - <span>#</span>95 [v1.0/docker-output-dir.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/docker-output-dir.cwl). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2996
https://github.com/broadinstitute/cromwell/issues/2997:106,Testability,test,test,106,Link to spec:; - http://www.commonwl.org/v1.0/CommandLineTool.html#EnvVarRequirement. Example conformance test(s):. - <span>#</span>41 [v1.0/env-wf1.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/env-wf1.cwl); - <span>#</span>42 [v1.0/env-wf2.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/env-wf2.cwl); - <span>#</span>43 [v1.0/env-wf3.cwl](https://github.com/common-workflow-language/common-workflow-language/blob/master/v1.0/v1.0/env-wf3.cwl). A/C: These or similar CWL should run to `WorkflowSucceeded` via centaur; Bonus: CWL conformance test passes (may also be a future ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2997
